{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maskGAN_imdb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Midroni/yesweGAN/blob/preprocessing/maskGAN_imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZyejo0JiKGZ",
        "colab_type": "code",
        "outputId": "650e8139-dfa9-48ad-ad9c-7ebc8b5d8090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!git clone -b preprocessing https://github.com/Midroni/yesweGAN"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yesweGAN'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 587 (delta 7), reused 8 (delta 3), pack-reused 570\u001b[K\n",
            "Receiving objects: 100% (587/587), 388.68 MiB | 31.62 MiB/s, done.\n",
            "Resolving deltas: 100% (289/289), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWFMD82PYQQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "while(1):\n",
        "    a.append('a;sdfj;lzkxjcv;oijdfmerivn;ozixcvo0jj;wjf;laksdjcf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOguCX-SiNFt",
        "colab_type": "code",
        "outputId": "3e0916f4-eb88-42d6-93bb-30b04be56c87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.6.0 --ignore-installed\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/a2/38929ec9677cb0009837b77674388ab4a35ad81573f3289b21963eda0f9a/tensorflow_gpu-1.6.0-cp27-cp27mu-manylinux1_x86_64.whl (209.2MB)\n",
            "\u001b[K     |████████████████████████████████| 209.2MB 63kB/s \n",
            "\u001b[?25hCollecting grpcio>=1.8.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/3a/0df95360cde178f6c7cccb5f889aa485b5ab2c8079bb97df97b0f6a96c93/grpcio-1.27.2-cp27-cp27mu-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 26.6MB/s \n",
            "\u001b[?25hCollecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Collecting tensorboard<1.7.0,>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/b8/7f64efd6aea9e21b836dc9acac60634ce9c41fe153ffd4df2acedc9a86e6/tensorboard-1.6.0-py2-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 44.2MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/cc/9180fa1f97ad122d92cfbff413bcd0be4bd3efee284a5fb6344670220709/protobuf-3.11.3-cp27-cp27mu-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 35.6MB/s \n",
            "\u001b[?25hCollecting gast>=0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Collecting wheel\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/23/848298cccf8e40f5bbb59009b32848a4c38f4e7f3364297ab3c3e2e2cd14/wheel-0.34.2-py2.py3-none-any.whl\n",
            "Collecting absl-py>=0.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 58.9MB/s \n",
            "\u001b[?25hCollecting backports.weakref>=1.0rc1\n",
            "  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
            "Collecting enum34>=1.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/2c/a9386903ece2ea85e9807e0e062174dc26fdce8b05f216d00491be29fad5/enum34-1.1.10-py2-none-any.whl\n",
            "Collecting six>=1.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Collecting numpy>=1.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/5f/47e578b3ae79e2624e205445ab77a1848acdaa2929a00eeef6b16eaaeb20/numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n",
            "\u001b[K     |████████████████████████████████| 17.0MB 197kB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
            "Collecting astor>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
            "Collecting futures>=2.2.0; python_version < \"3.2\"\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/a6/f46ae3f1da0cd4361c344888f59ec2f5785e69c872e175a748ef6071cdb5/futures-3.3.0-py2-none-any.whl\n",
            "Collecting funcsigs>=1; python_version < \"3.3\"\n",
            "  Downloading https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 70.8MB/s \n",
            "\u001b[?25hCollecting werkzeug>=0.11.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/a5/d6f8a6e71f15364d35678a4ec8a0186f980b3bd2545f40ad51dd26a87fb1/Werkzeug-1.0.0-py2.py3-none-any.whl (298kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 54.9MB/s \n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 15.1MB/s \n",
            "\u001b[?25hCollecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/b5/3679d7c98be5b65fa5522671ef437b792d909cf3908ba54fe9eca5d2a766/setuptools-44.1.0-py2.py3-none-any.whl (583kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 47.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: absl-py, termcolor, html5lib\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.9.0-cp27-none-any.whl size=121930 sha256=66e5eadb045d938ae212c1a0ffb43e16ffe3e74fc45c49a0815adb0e72284ab5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-cp27-none-any.whl size=4832 sha256=46dab9cd6b267678fb2b8a99d584abb6deec417738506be311d25cce8e92328d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp27-none-any.whl size=107221 sha256=8e2b045602717cdf64fcf2ae446eac3b40a7b83897eb13d90334c255b820fb59\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built absl-py termcolor html5lib\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 0.7.0 has requirement torch<0.4, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.15.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: enum34, six, futures, grpcio, funcsigs, mock, html5lib, bleach, setuptools, protobuf, wheel, numpy, werkzeug, markdown, tensorboard, gast, absl-py, backports.weakref, termcolor, astor, tensorflow-gpu\n",
            "Successfully installed absl-py-0.9.0 astor-0.8.1 backports.weakref-1.0.post1 bleach-3.1.0 enum34-1.1.10 funcsigs-1.0.2 futures-3.3.0 gast-0.3.3 grpcio-1.27.2 html5lib-1.0.1 markdown-3.1.1 mock-3.0.5 numpy-1.16.6 protobuf-3.11.3 setuptools-44.1.0 six-1.14.0 tensorboard-2.1.0 tensorflow-gpu-1.6.0 termcolor-1.1.0 werkzeug-1.0.0 wheel-0.34.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "backports",
                  "concurrent",
                  "enum",
                  "google",
                  "grpc",
                  "numpy",
                  "pkg_resources",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7f7G5dghg-r",
        "colab_type": "code",
        "outputId": "cf52fa89-5545-40d7-887d-1554dfb98efa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
        "!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda=9.0.176-1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-25 01:34:48--  https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb\n",
            "Resolving developer.nvidia.com (developer.nvidia.com)... 152.199.0.24\n",
            "Connecting to developer.nvidia.com (developer.nvidia.com)|152.199.0.24|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb?B_dCx1yK2BApwFwBd8xhWJCz5Y0NVJlksZgnqz-tIbCbbcef_oMIwwHf_yOU1ltxUyC2D7iXNsb620HHAChlek6HFhONe4FDVfhyU-gHh4F_b87t9CXWogJ3_-dY_0n6uSTHZb5i6cwrY68HjRCelBIZ7YecGP8o0hqswzu_OgsjO8rzyzsKbhCxaPz1Rg0lMV3XeHjAGvf96RyXNRLh [following]\n",
            "--2020-03-25 01:34:49--  https://developer.download.nvidia.com/compute/cuda/9.0/secure/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64.deb?B_dCx1yK2BApwFwBd8xhWJCz5Y0NVJlksZgnqz-tIbCbbcef_oMIwwHf_yOU1ltxUyC2D7iXNsb620HHAChlek6HFhONe4FDVfhyU-gHh4F_b87t9CXWogJ3_-dY_0n6uSTHZb5i6cwrY68HjRCelBIZ7YecGP8o0hqswzu_OgsjO8rzyzsKbhCxaPz1Rg0lMV3XeHjAGvf96RyXNRLh\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.195.19.142\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.195.19.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1212738714 (1.1G) [application/x-deb]\n",
            "Saving to: ‘cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb’\n",
            "\n",
            "cuda-repo-ubuntu160 100%[===================>]   1.13G  40.9MB/s    in 24s     \n",
            "\n",
            "2020-03-25 01:35:13 (49.0 MB/s) - ‘cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb’ saved [1212738714/1212738714]\n",
            "\n",
            "Selecting previously unselected package cuda-repo-ubuntu1604-9-0-local.\n",
            "(Reading database ... 144542 files and directories currently installed.)\n",
            "Preparing to unpack cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb ...\n",
            "Unpacking cuda-repo-ubuntu1604-9-0-local (9.0.176-1) ...\n",
            "Setting up cuda-repo-ubuntu1604-9-0-local (9.0.176-1) ...\n",
            "OK\n",
            "Get:1 file:/var/cuda-repo-9-0-local  InRelease\n",
            "Ign:1 file:/var/cuda-repo-9-0-local  InRelease\n",
            "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
            "Get:2 file:/var/cuda-repo-9-0-local  Release [574 B]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  Release.gpg [819 B]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,622 B]\n",
            "Get:9 file:/var/cuda-repo-9-0-local  Packages [15.4 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [861 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [832 kB]\n",
            "Get:20 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,784 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [35.2 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,362 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,155 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [48.7 kB]\n",
            "Get:25 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [862 kB]\n",
            "Fetched 7,211 kB in 4s (1,981 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cuda-9-0 cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
            "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
            "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
            "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
            "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
            "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
            "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
            "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
            "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
            "The following NEW packages will be installed:\n",
            "  cuda cuda-9-0 cuda-command-line-tools-9-0 cuda-core-9-0 cuda-cublas-9-0\n",
            "  cuda-cublas-dev-9-0 cuda-cudart-9-0 cuda-cudart-dev-9-0 cuda-cufft-9-0\n",
            "  cuda-cufft-dev-9-0 cuda-curand-9-0 cuda-curand-dev-9-0 cuda-cusolver-9-0\n",
            "  cuda-cusolver-dev-9-0 cuda-cusparse-9-0 cuda-cusparse-dev-9-0\n",
            "  cuda-demo-suite-9-0 cuda-documentation-9-0 cuda-driver-dev-9-0\n",
            "  cuda-libraries-9-0 cuda-libraries-dev-9-0 cuda-license-9-0\n",
            "  cuda-misc-headers-9-0 cuda-npp-9-0 cuda-npp-dev-9-0 cuda-nvgraph-9-0\n",
            "  cuda-nvgraph-dev-9-0 cuda-nvml-dev-9-0 cuda-nvrtc-9-0 cuda-nvrtc-dev-9-0\n",
            "  cuda-runtime-9-0 cuda-samples-9-0 cuda-toolkit-9-0 cuda-visual-tools-9-0\n",
            "0 upgraded, 34 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 0 B/1,097 MB of archives.\n",
            "After this operation, 2,315 MB of additional disk space will be used.\n",
            "Get:1 file:/var/cuda-repo-9-0-local  cuda-license-9-0 9.0.176-1 [22.0 kB]\n",
            "Get:2 file:/var/cuda-repo-9-0-local  cuda-misc-headers-9-0 9.0.176-1 [684 kB]\n",
            "Get:3 file:/var/cuda-repo-9-0-local  cuda-core-9-0 9.0.176-1 [16.9 MB]\n",
            "Get:4 file:/var/cuda-repo-9-0-local  cuda-cudart-9-0 9.0.176-1 [106 kB]\n",
            "Get:5 file:/var/cuda-repo-9-0-local  cuda-driver-dev-9-0 9.0.176-1 [10.9 kB]\n",
            "Get:6 file:/var/cuda-repo-9-0-local  cuda-cudart-dev-9-0 9.0.176-1 [767 kB]\n",
            "Get:7 file:/var/cuda-repo-9-0-local  cuda-command-line-tools-9-0 9.0.176-1 [25.4 MB]\n",
            "Get:8 file:/var/cuda-repo-9-0-local  cuda-nvrtc-9-0 9.0.176-1 [6,348 kB]\n",
            "Get:9 file:/var/cuda-repo-9-0-local  cuda-nvrtc-dev-9-0 9.0.176-1 [9,334 B]\n",
            "Get:10 file:/var/cuda-repo-9-0-local  cuda-cusolver-9-0 9.0.176-1 [26.2 MB]\n",
            "Get:11 file:/var/cuda-repo-9-0-local  cuda-cusolver-dev-9-0 9.0.176-1 [5,317 kB]\n",
            "Get:12 file:/var/cuda-repo-9-0-local  cuda-cublas-9-0 9.0.176-1 [25.0 MB]\n",
            "Get:13 file:/var/cuda-repo-9-0-local  cuda-cublas-dev-9-0 9.0.176-1 [49.4 MB]\n",
            "Get:14 file:/var/cuda-repo-9-0-local  cuda-cufft-9-0 9.0.176-1 [84.1 MB]\n",
            "Get:15 file:/var/cuda-repo-9-0-local  cuda-cufft-dev-9-0 9.0.176-1 [73.7 MB]\n",
            "Get:16 file:/var/cuda-repo-9-0-local  cuda-curand-9-0 9.0.176-1 [38.8 MB]\n",
            "Get:17 file:/var/cuda-repo-9-0-local  cuda-curand-dev-9-0 9.0.176-1 [57.9 MB]\n",
            "Get:18 file:/var/cuda-repo-9-0-local  cuda-cusparse-9-0 9.0.176-1 [25.2 MB]\n",
            "Get:19 file:/var/cuda-repo-9-0-local  cuda-cusparse-dev-9-0 9.0.176-1 [25.3 MB]\n",
            "Get:20 file:/var/cuda-repo-9-0-local  cuda-npp-9-0 9.0.176-1 [46.6 MB]\n",
            "Get:21 file:/var/cuda-repo-9-0-local  cuda-npp-dev-9-0 9.0.176-1 [46.6 MB]\n",
            "Get:22 file:/var/cuda-repo-9-0-local  cuda-nvgraph-9-0 9.0.176-1 [6,081 kB]\n",
            "Get:23 file:/var/cuda-repo-9-0-local  cuda-nvgraph-dev-9-0 9.0.176-1 [5,658 kB]\n",
            "Get:24 file:/var/cuda-repo-9-0-local  cuda-samples-9-0 9.0.176-1 [75.9 MB]\n",
            "Get:25 file:/var/cuda-repo-9-0-local  cuda-documentation-9-0 9.0.176-1 [53.1 MB]\n",
            "Get:26 file:/var/cuda-repo-9-0-local  cuda-libraries-dev-9-0 9.0.176-1 [2,596 B]\n",
            "Get:27 file:/var/cuda-repo-9-0-local  cuda-nvml-dev-9-0 9.0.176-1 [47.6 kB]\n",
            "Get:28 file:/var/cuda-repo-9-0-local  cuda-visual-tools-9-0 9.0.176-1 [398 MB]\n",
            "Get:29 file:/var/cuda-repo-9-0-local  cuda-toolkit-9-0 9.0.176-1 [2,836 B]\n",
            "Get:30 file:/var/cuda-repo-9-0-local  cuda-libraries-9-0 9.0.176-1 [2,566 B]\n",
            "Get:31 file:/var/cuda-repo-9-0-local  cuda-runtime-9-0 9.0.176-1 [2,526 B]\n",
            "Get:32 file:/var/cuda-repo-9-0-local  cuda-demo-suite-9-0 9.0.176-1 [3,880 kB]\n",
            "Get:33 file:/var/cuda-repo-9-0-local  cuda-9-0 9.0.176-1 [2,552 B]\n",
            "Get:34 file:/var/cuda-repo-9-0-local  cuda 9.0.176-1 [2,504 B]\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package cuda-license-9-0.\n",
            "(Reading database ... 144601 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-license-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-license-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-misc-headers-9-0.\n",
            "Preparing to unpack .../01-cuda-misc-headers-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-misc-headers-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-core-9-0.\n",
            "Preparing to unpack .../02-cuda-core-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-core-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cudart-9-0.\n",
            "Preparing to unpack .../03-cuda-cudart-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-9-0.\n",
            "Preparing to unpack .../04-cuda-driver-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-9-0.\n",
            "Preparing to unpack .../05-cuda-cudart-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-9-0.\n",
            "Preparing to unpack .../06-cuda-command-line-tools-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-9-0.\n",
            "Preparing to unpack .../07-cuda-nvrtc-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-9-0.\n",
            "Preparing to unpack .../08-cuda-nvrtc-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-9-0.\n",
            "Preparing to unpack .../09-cuda-cusolver-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusolver-dev-9-0.\n",
            "Preparing to unpack .../10-cuda-cusolver-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusolver-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cublas-9-0.\n",
            "Preparing to unpack .../11-cuda-cublas-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cublas-dev-9-0.\n",
            "Preparing to unpack .../12-cuda-cublas-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cublas-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cufft-9-0.\n",
            "Preparing to unpack .../13-cuda-cufft-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cufft-dev-9-0.\n",
            "Preparing to unpack .../14-cuda-cufft-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cufft-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-curand-9-0.\n",
            "Preparing to unpack .../15-cuda-curand-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-curand-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-curand-dev-9-0.\n",
            "Preparing to unpack .../16-cuda-curand-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-curand-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-9-0.\n",
            "Preparing to unpack .../17-cuda-cusparse-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-cusparse-dev-9-0.\n",
            "Preparing to unpack .../18-cuda-cusparse-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-cusparse-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-npp-9-0.\n",
            "Preparing to unpack .../19-cuda-npp-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-npp-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-npp-dev-9-0.\n",
            "Preparing to unpack .../20-cuda-npp-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-npp-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-9-0.\n",
            "Preparing to unpack .../21-cuda-nvgraph-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvgraph-dev-9-0.\n",
            "Preparing to unpack .../22-cuda-nvgraph-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvgraph-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-samples-9-0.\n",
            "Preparing to unpack .../23-cuda-samples-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-samples-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-documentation-9-0.\n",
            "Preparing to unpack .../24-cuda-documentation-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-9-0.\n",
            "Preparing to unpack .../25-cuda-libraries-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-9-0.\n",
            "Preparing to unpack .../26-cuda-nvml-dev-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-visual-tools-9-0.\n",
            "Preparing to unpack .../27-cuda-visual-tools-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-visual-tools-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-toolkit-9-0.\n",
            "Preparing to unpack .../28-cuda-toolkit-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-toolkit-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-libraries-9-0.\n",
            "Preparing to unpack .../29-cuda-libraries-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-runtime-9-0.\n",
            "Preparing to unpack .../30-cuda-runtime-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-runtime-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-demo-suite-9-0.\n",
            "Preparing to unpack .../31-cuda-demo-suite-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-demo-suite-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda-9-0.\n",
            "Preparing to unpack .../32-cuda-9-0_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda-9-0 (9.0.176-1) ...\n",
            "Selecting previously unselected package cuda.\n",
            "Preparing to unpack .../33-cuda_9.0.176-1_amd64.deb ...\n",
            "Unpacking cuda (9.0.176-1) ...\n",
            "Setting up cuda-license-9-0 (9.0.176-1) ...\n",
            "*** LICENSE AGREEMENT ***\n",
            "By using this software you agree to fully comply with the terms and \n",
            "conditions of the EULA (End User License Agreement). The EULA is located\n",
            "at /usr/local/cuda-9.0/doc/EULA.txt. The EULA can also be found at\n",
            "http://docs.nvidia.com/cuda/eula/index.html. If you do not agree to the\n",
            "terms and conditions of the EULA, do not use the software.\n",
            "\n",
            "Setting up cuda-cusparse-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cudart-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvrtc-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cusparse-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cufft-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cusolver-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvml-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-npp-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cusolver-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-misc-headers-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cublas-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvrtc-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-driver-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-curand-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvgraph-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-core-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-libraries-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-runtime-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cudart-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cufft-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-npp-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-curand-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-cublas-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-nvgraph-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-command-line-tools-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-demo-suite-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-visual-tools-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-samples-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-libraries-dev-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-documentation-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-toolkit-9-0 (9.0.176-1) ...\n",
            "Setting up cuda-9-0 (9.0.176-1) ...\n",
            "Setting up cuda (9.0.176-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejWdzNrl5IPe",
        "colab_type": "code",
        "outputId": "8dea3b50-00ce-45b1-b777-0d9e69d16f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myXuKPN25x_t",
        "colab_type": "code",
        "outputId": "f4a7bfe8-0b95-4c9d-f3ea-3fbf7c65d524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# copy dataset into working directory\n",
        "%cd /content\n",
        "!cp -r '/content/drive/My Drive/imdb' '/content/yesweGAN/maskgan_colab/dataset'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFfWXj1wuYdY",
        "colab_type": "code",
        "outputId": "f4ca4c23-0fc6-430e-cd87-7bb6bb2e528e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# copy most recent checkpoint into working directory to continue training\n",
        "%cd /content\n",
        "!cp -r '/content/drive/My Drive/imdb gan checkpoint - stochastic contiguous/train' '/content/yesweGAN/maskgan_colab/maskGAN'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6_G3THLoUoi",
        "colab_type": "text"
      },
      "source": [
        "# Must be using python 2 runtime w GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMz5ZNbql-EW",
        "colab_type": "text"
      },
      "source": [
        "## Run MaskGAN in MLE pretraining mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5a426b81-2a5c-435a-c3bd-9dc8d1d63871",
        "id": "3mV31eblvixR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/yesweGAN/maskgan_colab\n",
        "! python train_mask_gan.py \\\n",
        " --data_dir='dataset/imdb' \\\n",
        " --data_set='imdb' \\\n",
        " --batch_size=128 \\\n",
        " --sequence_length=20 \\\n",
        " --base_directory='maskGAN' \\\n",
        " --hparams=\"gen_rnn_size=650,dis_rnn_size=650,gen_num_layers=2,dis_num_layers=2,gen_learning_rate=0.0005,dis_learning_rate=0.0005,baseline_decay=0.99,dis_train_iterations=1,gen_learning_rate_decay=0.95\" \\\n",
        " --mode='TRAIN' \\\n",
        " --max_steps=10000 \\\n",
        " --perplexity_threshold=1000000 \\\n",
        " --generator_model='seq2seq_vd' \\\n",
        " --discriminator_model='seq2seq_vd' \\\n",
        " --generator_optimizer=adam \\\n",
        " --is_present_rate=0.5 \\\n",
        " --summaries_every=50 \\\n",
        " --print_every=250 \\\n",
        " --max_num_to_print=3 \\\n",
        " --gen_training_strategy=cross_entropy \\\n",
        " --seq2seq_share_embedding=true \\\n",
        " --baseline_method=critic \\\n",
        " --attention_option=luong"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "   [1]  t                     0.530   0.000  \n",
            "   [1]  know                  0.529   0.000  \n",
            "   [1]  a                     0.530   0.000  \n",
            "   [0]  thing                 0.532   6.359  \n",
            "   [1]  from                  0.532   0.000  \n",
            "   [1]  the                   0.533   0.000  \n",
            "   [0]  great                 0.532   5.975  \n",
            "   [0]  pino                  0.531   13.640 \n",
            "   [0]  solanas               0.529   13.714 \n",
            "   [1]  this                  0.530   0.000  \n",
            "   [1]  man                   0.530   0.000  \n",
            "   [1]  has                   0.530   0.000  \n",
            "   [1]  been                  0.533   0.000  \n",
            " Sample 2.\n",
            "   [0]  grown                 0.490   9.516  \n",
            "   [0]  up                    0.494   5.430  \n",
            "   [1]  in                    0.498   0.000  \n",
            "   [1]  brighton              0.500   0.000  \n",
            "   [0]  and                   0.504   3.737  \n",
            "   [1]  then                  0.506   0.000  \n",
            "   [1]  watched               0.507   0.000  \n",
            "   [1]  its                   0.506   0.000  \n",
            "   [1]  development           0.505   0.000  \n",
            "   [0]  into                  0.506   6.218  \n",
            "   [0]  a                     0.508   2.989  \n",
            "   [0]  home                  0.507   7.737  \n",
            "   [0]  of                    0.505   3.128  \n",
            "   [0]  the                   0.507   2.772  \n",
            "   [1]  stars                 0.507   0.000  \n",
            "   [0]  i                     0.507   4.775  \n",
            "   [1]  was                   0.505   0.000  \n",
            "   [0]  intrigued             0.503   9.393  \n",
            "   [1]  to                    0.501   0.000  \n",
            "   [1]  see                   0.500   0.000  \n",
            "Samples\n",
            "Sample 0 .  jokes are obvious the gags are corny and the characters are walking characatures but i couldn t stop from laughing\n",
            "Sample 1 .  switzerland you are sick bastard who doesn t know a thing from the great pino solanas this man has been\n",
            "Sample 2 .  grown up in brighton and then watched its development into a home of the stars i was intrigued to see\n",
            "\n",
            "\n",
            "targets[[46 20 148 2 243 34 12 195 13241 1205 20 236 38 10 17 722 127 2824 82 10][4585 3079 45 3521 2 765 6339 43 7 73 38 314 2520 11 12 85 39 25 108 4034][64 2065 10 17 43 3106 1816 602 51 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 46 20 148 2 243 34 12 195 13241]...][[1 1 0 0 0 1 0 1 0 0]...][[591 46 20 69848 69848 69848 34 69848 195 69848]...][[46 20 148 2 243 34 12 195 13241 1205]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 46 20 148 2 243 34 12 195 13241]...][[1 1 0 0 0 1 0 1 0 0]...][[591 46 20 69848 69848 69848 34 69848 195 69848]...][[46 20 148 2 243 34 12 195 13241 1205]...]\n",
            "targets[[499 8 5582 8 4569 111 316 1 8948 2252 7127 1017 3989 11 12 111 32 2384 55 190][13 10403 31 47 35 379 369 10 13 1078 1769 12 6028 2535 376 3611 1 116 5 2][215 10 42 43 414 19 51 7 7980 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[637 499 8 5582 8 4569 111 316 1 8948]...][[0 1 1 1 0 0 0 0 1 0]...][[637 69848 8 5582 8 69848 69848 69848 69848 8948]...][[499 8 5582 8 4569 111 316 1 8948 2252]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[637 499 8 5582 8 4569 111 316 1 8948]...][[0 1 1 1 0 0 0 0 1 0]...][[637 69848 8 5582 8 69848 69848 69848 69848 8948]...][[499 8 5582 8 4569 111 316 1 8948 2252]...]\n",
            "targets[[499 8 5582 8 4569 111 316 1 8948 2252 7127 1017 3989 11 12 111 32 2384 55 190][13 10403 31 47 35 379 369 10 13 1078 1769 12 6028 2535 376 3611 1 116 5 2][215 10 42 43 414 19 51 7 7980 31]...]\n",
            "targets[[499 8 5582 8 4569 111 316 1 8948 2252 7127 1017 3989 11 12 111 32 2384 55 190][13 10403 31 47 35 379 369 10 13 1078 1769 12 6028 2535 376 3611 1 116 5 2][215 10 42 43 414 19 51 7 7980 31]...]\n",
            "targets[[499 8 5582 8 4569 111 316 1 8948 2252 7127 1017 3989 11 12 111 32 2384 55 190][13 10403 31 47 35 379 369 10 13 1078 1769 12 6028 2535 376 3611 1 116 5 2][215 10 42 43 414 19 51 7 7980 31]...]\n",
            "global_step: 1902\n",
            " perplexity: 457.983\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[499 8 5582 8 4569 111 316 1 8948 2252 7127 1017 3989 11 12 111 32 2384 55 190][13 10403 31 47 35 379 369 10 13 1078 1769 12 6028 2535 376 3611 1 116 5 2][215 10 42 43 414 19 51 7 7980 31]...]\n",
            " percent of 3-grams captured: 0.477.\n",
            "targets[[499 8 5582 8 4569 111 316 1 8948 2252 7127 1017 3989 11 12 111 32 2384 55 190][13 10403 31 47 35 379 369 10 13 1078 1769 12 6028 2535 376 3611 1 116 5 2][215 10 42 43 414 19 51 7 7980 31]...]\n",
            " percent of 2-grams captured: 0.692.\n",
            "targets[[499 8 5582 8 4569 111 316 1 8948 2252 7127 1017 3989 11 12 111 32 2384 55 190][13 10403 31 47 35 379 369 10 13 1078 1769 12 6028 2535 376 3611 1 116 5 2][215 10 42 43 414 19 51 7 7980 31]...]\n",
            " percent of 4-grams captured: 0.228.\n",
            " geometric_avg: 0.422.\n",
            " arithmetic_avg: 0.466.\n",
            "global_step: 1902\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69390\n",
            " G train loss: 3.10103\n",
            "targets[[499 8 5582 8 4569 111 316 1 8948 2252 7127 1017 3989 11 12 111 32 2384 55 190][13 10403 31 47 35 379 369 10 13 1078 1769 12 6028 2535 376 3611 1 116 5 2][215 10 42 43 414 19 51 7 7980 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[637 499 8 5582 8 4569 111 316 1 8948]...][[0 1 1 1 0 0 0 0 1 0]...][[637 69848 8 5582 8 69848 69848 69848 69848 8948]...][[499 8 5582 8 4569 111 316 1 8948 2252]...]\n",
            " Sample 0.\n",
            "   [0]  starts                0.509   6.251  \n",
            "   [1]  in                    0.506   0.000  \n",
            "   [1]  1986                  0.504   0.000  \n",
            "   [1]  in                    0.502   0.000  \n",
            "   [0]  nyc                   0.501   9.051  \n",
            "   [0]  where                 0.500   7.004  \n",
            "   [0]  black                 0.501   9.256  \n",
            "   [0]  and                   0.502   3.364  \n",
            "   [1]  hispanic              0.503   0.000  \n",
            "   [0]  drag                  0.504   10.291 \n",
            "   [1]  queens                0.505   0.000  \n",
            "   [0]  hold                  0.505   10.239 \n",
            "   [1]  balls                 0.504   0.000  \n",
            "   [1]  that                  0.503   0.000  \n",
            "   [1]  s                     0.502   0.000  \n",
            "   [1]  where                 0.500   0.000  \n",
            "   [1]  they                  0.501   0.000  \n",
            "   [1]  dress                 0.501   0.000  \n",
            "   [0]  up                    0.502   4.668  \n",
            "   [0]  however               0.504   6.927  \n",
            " Sample 1.\n",
            "   [1]  was                   0.483   0.000  \n",
            "   [0]  astonished            0.486   11.834 \n",
            "   [0]  at                    0.488   4.191  \n",
            "   [1]  what                  0.488   0.000  \n",
            "   [0]  an                    0.488   5.444  \n",
            "   [1]  awful                 0.488   0.000  \n",
            "   [0]  production            0.487   7.611  \n",
            "   [0]  this                  0.485   3.822  \n",
            "   [1]  was                   0.485   0.000  \n",
            "   [0]  considering           0.485   9.457  \n",
            "   [1]  stewart               0.486   0.000  \n",
            "   [1]  s                     0.487   0.000  \n",
            "   [1]  sterling              0.489   0.000  \n",
            "   [1]  reputation            0.489   0.000  \n",
            "   [1]  perhaps               0.487   0.000  \n",
            "   [1]  producing             0.487   0.000  \n",
            "   [0]  and                   0.487   3.315  \n",
            "   [1]  acting                0.488   0.000  \n",
            "   [0]  is                    0.490   4.215  \n",
            "   [1]  a                     0.493   0.000  \n",
            " Sample 2.\n",
            "   [1]  saw                   0.508   0.000  \n",
            "   [0]  this                  0.509   1.124  \n",
            "   [1]  just                  0.510   0.000  \n",
            "   [0]  about                 0.511   5.333  \n",
            "   [1]  perfect               0.511   0.000  \n",
            "   [0]  film                  0.513   4.083  \n",
            "   [1]  when                  0.513   0.000  \n",
            "   [0]  it                    0.513   2.833  \n",
            "   [1]  screened              0.513   0.000  \n",
            "   [0]  at                    0.514   5.059  \n",
            "   [0]  the                   0.516   2.110  \n",
            "   [1]  maryland              0.516   0.000  \n",
            "   [0]  film                  0.518   4.669  \n",
            "   [0]  festival              0.519   6.583  \n",
            "   [1]  in                    0.520   0.000  \n",
            "   [1]  may                   0.520   0.000  \n",
            "   [1]  2005                  0.522   0.000  \n",
            "   [1]  set                   0.523   0.000  \n",
            "   [0]  in                    0.523   3.428  \n",
            "   [0]  a                     0.522   3.019  \n",
            "Samples\n",
            "Sample 0 .  starts in 1986 in nyc where black and hispanic drag queens hold balls that s where they dress up however\n",
            "Sample 1 .  was astonished at what an awful production this was considering stewart s sterling reputation perhaps producing and acting is a\n",
            "Sample 2 .  saw this just about perfect film when it screened at the maryland film festival in may 2005 set in a\n",
            "\n",
            "\n",
            "targets[[9 353 10 298 1 13 2229 4 66 0 17 4 66 47 32 59 6 6 9 67][9 27 110 10 17 1 59 38 4 198 3823 1808 29 39 5 161 43 10 17 4][42251 5 2 81 19 16 0 5438 7 971]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 9 353 10 298 1 13 2229 4 66]...][[1 0 0 1 1 0 0 1 0 0]...][[591 9 69848 69848 298 1 69848 69848 4 69848]...][[9 353 10 298 1 13 2229 4 66 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 9 353 10 298 1 13 2229 4 66]...][[1 0 0 1 1 0 0 1 0 0]...][[591 9 69848 69848 298 1 69848 69848 4 69848]...][[9 353 10 298 1 13 2229 4 66 0]...]\n",
            "targets[[46 20 148 2 243 34 12 195 13241 1205 20 236 38 10 17 722 127 2824 82 10][4585 3079 45 3521 2 765 6339 43 7 73 38 314 2520 11 12 85 39 25 108 4034][64 2065 10 17 43 3106 1816 602 51 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 46 20 148 2 243 34 12 195 13241]...][[0 0 0 1 0 1 0 0 1 1]...][[591 69848 69848 69848 2 69848 34 69848 69848 13241]...][[46 20 148 2 243 34 12 195 13241 1205]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 46 20 148 2 243 34 12 195 13241]...][[0 0 0 1 0 1 0 0 1 1]...][[591 69848 69848 69848 2 69848 34 69848 69848 13241]...][[46 20 148 2 243 34 12 195 13241 1205]...]\n",
            "targets[[46 20 148 2 243 34 12 195 13241 1205 20 236 38 10 17 722 127 2824 82 10][4585 3079 45 3521 2 765 6339 43 7 73 38 314 2520 11 12 85 39 25 108 4034][64 2065 10 17 43 3106 1816 602 51 9]...]\n",
            "targets[[46 20 148 2 243 34 12 195 13241 1205 20 236 38 10 17 722 127 2824 82 10][4585 3079 45 3521 2 765 6339 43 7 73 38 314 2520 11 12 85 39 25 108 4034][64 2065 10 17 43 3106 1816 602 51 9]...]\n",
            "targets[[46 20 148 2 243 34 12 195 13241 1205 20 236 38 10 17 722 127 2824 82 10][4585 3079 45 3521 2 765 6339 43 7 73 38 314 2520 11 12 85 39 25 108 4034][64 2065 10 17 43 3106 1816 602 51 9]...]\n",
            "global_step: 1905\n",
            " perplexity: 458.356\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[46 20 148 2 243 34 12 195 13241 1205 20 236 38 10 17 722 127 2824 82 10][4585 3079 45 3521 2 765 6339 43 7 73 38 314 2520 11 12 85 39 25 108 4034][64 2065 10 17 43 3106 1816 602 51 9]...]\n",
            " percent of 3-grams captured: 0.489.\n",
            "targets[[46 20 148 2 243 34 12 195 13241 1205 20 236 38 10 17 722 127 2824 82 10][4585 3079 45 3521 2 765 6339 43 7 73 38 314 2520 11 12 85 39 25 108 4034][64 2065 10 17 43 3106 1816 602 51 9]...]\n",
            " percent of 2-grams captured: 0.699.\n",
            "targets[[46 20 148 2 243 34 12 195 13241 1205 20 236 38 10 17 722 127 2824 82 10][4585 3079 45 3521 2 765 6339 43 7 73 38 314 2520 11 12 85 39 25 108 4034][64 2065 10 17 43 3106 1816 602 51 9]...]\n",
            " percent of 4-grams captured: 0.241.\n",
            " geometric_avg: 0.435.\n",
            " arithmetic_avg: 0.476.\n",
            "global_step: 1905\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69382\n",
            " G train loss: 3.10213\n",
            "targets[[46 20 148 2 243 34 12 195 13241 1205 20 236 38 10 17 722 127 2824 82 10][4585 3079 45 3521 2 765 6339 43 7 73 38 314 2520 11 12 85 39 25 108 4034][64 2065 10 17 43 3106 1816 602 51 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 46 20 148 2 243 34 12 195 13241]...][[0 0 0 1 0 1 0 0 1 1]...][[591 69848 69848 69848 2 69848 34 69848 69848 13241]...][[46 20 148 2 243 34 12 195 13241 1205]...]\n",
            " Sample 0.\n",
            "   [0]  if                    0.493   6.071  \n",
            "   [0]  you                   0.494   2.264  \n",
            "   [0]  re                    0.491   4.458  \n",
            "   [1]  a                     0.490   0.000  \n",
            "   [0]  woman                 0.490   6.995  \n",
            "   [1]  who                   0.488   0.000  \n",
            "   [0]  s                     0.487   5.079  \n",
            "   [0]  got                   0.488   6.720  \n",
            "   [1]  aggression            0.490   0.000  \n",
            "   [1]  issues                0.491   0.000  \n",
            "   [1]  you                   0.490   0.000  \n",
            "   [1]  might                 0.490   0.000  \n",
            "   [0]  like                  0.489   3.961  \n",
            "   [0]  this                  0.490   2.956  \n",
            "   [0]  movie                 0.490   1.007  \n",
            "   [0]  hate                  0.489   9.774  \n",
            "   [1]  your                  0.488   0.000  \n",
            "   [1]  significant           0.486   0.000  \n",
            "   [0]  other                 0.486   7.103  \n",
            "   [0]  this                  0.487   3.634  \n",
            " Sample 1.\n",
            "   [0]  twilight              0.502   8.509  \n",
            "   [0]  zone                  0.502   8.374  \n",
            "   [1]  has                   0.501   0.000  \n",
            "   [0]  achieved              0.499   10.101 \n",
            "   [1]  a                     0.501   0.000  \n",
            "   [0]  certain               0.502   8.139  \n",
            "   [1]  mythology             0.503   0.000  \n",
            "   [1]  about                 0.504   0.000  \n",
            "   [0]  it                    0.506   4.953  \n",
            "   [0]  much                  0.505   7.593  \n",
            "   [0]  like                  0.505   6.437  \n",
            "   [0]  star                  0.503   7.914  \n",
            "   [0]  trek                  0.500   8.526  \n",
            "   [0]  that                  0.499   4.066  \n",
            "   [0]  s                     0.499   4.027  \n",
            "   [1]  because               0.499   0.000  \n",
            "   [0]  there                 0.500   5.243  \n",
            "   [0]  are                   0.499   3.430  \n",
            "   [1]  many                  0.497   0.000  \n",
            "   [1]  devoted               0.495   0.000  \n",
            " Sample 2.\n",
            "   [1]  only                  0.503   0.000  \n",
            "   [1]  discovered            0.503   0.000  \n",
            "   [1]  this                  0.503   0.000  \n",
            "   [1]  movie                 0.503   0.000  \n",
            "   [0]  about                 0.503   4.470  \n",
            "   [1]  18                    0.502   0.000  \n",
            "   [0]  months                0.501   7.836  \n",
            "   [0]  ago                   0.499   5.849  \n",
            "   [1]  when                  0.500   0.000  \n",
            "   [1]  i                     0.500   0.000  \n",
            "   [0]  saw                   0.501   3.753  \n",
            "   [0]  it                    0.501   2.025  \n",
            "   [1]  on                    0.500   0.000  \n",
            "   [0]  tv                    0.499   5.561  \n",
            "   [1]  i                     0.497   0.000  \n",
            "   [0]  really                0.497   4.385  \n",
            "   [1]  enjoyed               0.497   0.000  \n",
            "   [1]  it                    0.497   0.000  \n",
            "   [1]  and                   0.498   0.000  \n",
            "   [1]  have                  0.499   0.000  \n",
            "Samples\n",
            "Sample 0 .  if you re a woman who s got aggression issues you might like this movie hate your significant other this\n",
            "Sample 1 .  twilight zone has achieved a certain mythology about it much like star trek that s because there are many devoted\n",
            "Sample 2 .  only discovered this movie about 18 months ago when i saw it on tv i really enjoyed it and have\n",
            "\n",
            "\n",
            "targets[[1430 1022 10 17 210 21 497 7 12 165 2 977 49 17 30513 20 139 113 110 555][37 32 350 4 93 10 38 35 851 145 176 122 1 94 7 267 17 22 178 1][7497 12 6441 4 0 276 443 5 4064 26]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1831 1430 1022 10 17 210 21 497 7 12]...][[1 0 1 0 0 1 0 1 0 0]...][[1831 1430 69848 10 69848 69848 21 69848 7 69848]...][[1430 1022 10 17 210 21 497 7 12 165]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1831 1430 1022 10 17 210 21 497 7 12]...][[1 0 1 0 0 1 0 1 0 0]...][[1831 1430 69848 10 69848 69848 21 69848 7 69848]...][[1430 1022 10 17 210 21 497 7 12 165]...]\n",
            "targets[[9 353 10 298 1 13 2229 4 66 0 17 4 66 47 32 59 6 6 9 67][9 27 110 10 17 1 59 38 4 198 3823 1808 29 39 5 161 43 10 17 4][42251 5 2 81 19 16 0 5438 7 971]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 9 353 10 298 1 13 2229 4 66]...][[1 1 1 1 0 1 0 1 1 0]...][[591 9 353 10 298 69848 13 69848 4 66]...][[9 353 10 298 1 13 2229 4 66 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 9 353 10 298 1 13 2229 4 66]...][[1 1 1 1 0 1 0 1 1 0]...][[591 9 353 10 298 69848 13 69848 4 66]...][[9 353 10 298 1 13 2229 4 66 0]...]\n",
            "targets[[9 353 10 298 1 13 2229 4 66 0 17 4 66 47 32 59 6 6 9 67][9 27 110 10 17 1 59 38 4 198 3823 1808 29 39 5 161 43 10 17 4][42251 5 2 81 19 16 0 5438 7 971]...]\n",
            "targets[[9 353 10 298 1 13 2229 4 66 0 17 4 66 47 32 59 6 6 9 67][9 27 110 10 17 1 59 38 4 198 3823 1808 29 39 5 161 43 10 17 4][42251 5 2 81 19 16 0 5438 7 971]...]\n",
            "targets[[9 353 10 298 1 13 2229 4 66 0 17 4 66 47 32 59 6 6 9 67][9 27 110 10 17 1 59 38 4 198 3823 1808 29 39 5 161 43 10 17 4][42251 5 2 81 19 16 0 5438 7 971]...]\n",
            "global_step: 1908\n",
            " perplexity: 458.751\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[9 353 10 298 1 13 2229 4 66 0 17 4 66 47 32 59 6 6 9 67][9 27 110 10 17 1 59 38 4 198 3823 1808 29 39 5 161 43 10 17 4][42251 5 2 81 19 16 0 5438 7 971]...]\n",
            " percent of 3-grams captured: 0.485.\n",
            "targets[[9 353 10 298 1 13 2229 4 66 0 17 4 66 47 32 59 6 6 9 67][9 27 110 10 17 1 59 38 4 198 3823 1808 29 39 5 161 43 10 17 4][42251 5 2 81 19 16 0 5438 7 971]...]\n",
            " percent of 2-grams captured: 0.708.\n",
            "targets[[9 353 10 298 1 13 2229 4 66 0 17 4 66 47 32 59 6 6 9 67][9 27 110 10 17 1 59 38 4 198 3823 1808 29 39 5 161 43 10 17 4][42251 5 2 81 19 16 0 5438 7 971]...]\n",
            " percent of 4-grams captured: 0.225.\n",
            " geometric_avg: 0.426.\n",
            " arithmetic_avg: 0.473.\n",
            "global_step: 1908\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69380\n",
            " G train loss: 3.10481\n",
            "targets[[9 353 10 298 1 13 2229 4 66 0 17 4 66 47 32 59 6 6 9 67][9 27 110 10 17 1 59 38 4 198 3823 1808 29 39 5 161 43 10 17 4][42251 5 2 81 19 16 0 5438 7 971]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 9 353 10 298 1 13 2229 4 66]...][[1 1 1 1 0 1 0 1 1 0]...][[591 9 353 10 298 69848 13 69848 4 66]...][[9 353 10 298 1 13 2229 4 66 0]...]\n",
            " Sample 0.\n",
            "   [1]  i                     0.495   0.000  \n",
            "   [1]  read                  0.494   0.000  \n",
            "   [1]  this                  0.492   0.000  \n",
            "   [1]  book                  0.490   0.000  \n",
            "   [0]  and                   0.488   3.455  \n",
            "   [1]  was                   0.487   0.000  \n",
            "   [0]  curious               0.487   9.589  \n",
            "   [1]  to                    0.488   0.000  \n",
            "   [1]  see                   0.490   0.000  \n",
            "   [0]  the                   0.494   2.090  \n",
            "   [1]  movie                 0.496   0.000  \n",
            "   [0]  to                    0.499   3.420  \n",
            "   [0]  see                   0.499   3.961  \n",
            "   [0]  what                  0.500   5.330  \n",
            "   [1]  they                  0.501   0.000  \n",
            "   [1]  would                 0.502   0.000  \n",
            "   [1]  br                    0.501   0.000  \n",
            "   [1]  br                    0.499   0.000  \n",
            "   [0]  i                     0.497   2.743  \n",
            "   [0]  had                   0.494   3.532  \n",
            " Sample 1.\n",
            "   [1]  i                     0.485   0.000  \n",
            "   [0]  have                  0.483   3.110  \n",
            "   [0]  seen                  0.481   2.188  \n",
            "   [0]  this                  0.478   2.186  \n",
            "   [0]  movie                 0.477   0.817  \n",
            "   [1]  and                   0.477   0.000  \n",
            "   [1]  would                 0.477   0.000  \n",
            "   [1]  like                  0.475   0.000  \n",
            "   [1]  to                    0.474   0.000  \n",
            "   [1]  give                  0.475   0.000  \n",
            "   [1]  marks                 0.476   0.000  \n",
            "   [0]  below                 0.477   8.999  \n",
            "   [0]  one                   0.477   5.900  \n",
            "   [0]  there                 0.478   5.867  \n",
            "   [1]  is                    0.478   0.000  \n",
            "   [1]  nothing               0.478   0.000  \n",
            "   [1]  about                 0.478   0.000  \n",
            "   [0]  this                  0.478   3.563  \n",
            "   [1]  movie                 0.477   0.000  \n",
            "   [0]  to                    0.477   3.004  \n",
            " Sample 2.\n",
            "   [0]  5150                  0.493   14.710 \n",
            "   [1]  is                    0.496   0.000  \n",
            "   [1]  a                     0.496   0.000  \n",
            "   [1]  great                 0.497   0.000  \n",
            "   [0]  film                  0.496   2.769  \n",
            "   [1]  for                   0.496   0.000  \n",
            "   [0]  the                   0.495   1.586  \n",
            "   [0]  authenticity          0.493   11.576 \n",
            "   [1]  it                    0.492   0.000  \n",
            "   [1]  brings                0.491   0.000  \n",
            "   [1]  to                    0.490   0.000  \n",
            "   [1]  screen                0.487   0.000  \n",
            "   [1]  a                     0.486   0.000  \n",
            "   [1]  rare                  0.485   0.000  \n",
            "   [0]  gem                   0.485   8.101  \n",
            "   [1]  in                    0.484   0.000  \n",
            "   [1]  the                   0.486   0.000  \n",
            "   [1]  rough                 0.487   0.000  \n",
            "   [1]  by                    0.489   0.000  \n",
            "   [1]  comparison            0.491   0.000  \n",
            "Samples\n",
            "Sample 0 .  i read this book and was curious to see the movie to see what they would br br i had\n",
            "Sample 1 .  i have seen this movie and would like to give marks below one there is nothing about this movie to\n",
            "Sample 2 .  5150 is a great film for the authenticity it brings to screen a rare gem in the rough by comparison\n",
            "\n",
            "\n",
            "targets[[42 110 22538 10 17 389 4 333 4376 0 105 9 103 10 29 13 52 1097 0 4032][181 2702 201 11 12 1034 53 3186 882 155 10 10362 4798 1109 18998 947 49869 144 2 5803][215 11 17 173 483 602 10 17 5 37]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[256 42 110 22538 10 17 389 4 333 4376]...][[1 0 1 1 0 1 0 0 0 1]...][[256 42 69848 22538 10 69848 389 69848 69848 69848]...][[42 110 22538 10 17 389 4 333 4376 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[256 42 110 22538 10 17 389 4 333 4376]...][[1 0 1 1 0 1 0 0 0 1]...][[256 42 69848 22538 10 69848 389 69848 69848 69848]...][[42 110 22538 10 17 389 4 333 4376 0]...]\n",
            "targets[[1430 1022 10 17 210 21 497 7 12 165 2 977 49 17 30513 20 139 113 110 555][37 32 350 4 93 10 38 35 851 145 176 122 1 94 7 267 17 22 178 1][7497 12 6441 4 0 276 443 5 4064 26]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1831 1430 1022 10 17 210 21 497 7 12]...][[1 0 1 1 0 1 0 0 0 0]...][[1831 1430 69848 10 17 69848 21 69848 69848 69848]...][[1430 1022 10 17 210 21 497 7 12 165]...]\n",
            "2020-03-24 03:43:55.324399: E tensorflow/core/util/events_writer.cc:162] The events file maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0 has disappeared.\n",
            "2020-03-24 03:43:55.324452: E tensorflow/core/util/events_writer.cc:131] Failed to flush 464 events to maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0\n",
            "inputs, targets_present, masked_inputs, sequence[[1831 1430 1022 10 17 210 21 497 7 12]...][[1 0 1 1 0 1 0 0 0 0]...][[1831 1430 69848 10 17 69848 21 69848 69848 69848]...][[1430 1022 10 17 210 21 497 7 12 165]...]\n",
            "targets[[1430 1022 10 17 210 21 497 7 12 165 2 977 49 17 30513 20 139 113 110 555][37 32 350 4 93 10 38 35 851 145 176 122 1 94 7 267 17 22 178 1][7497 12 6441 4 0 276 443 5 4064 26]...]\n",
            "targets[[1430 1022 10 17 210 21 497 7 12 165 2 977 49 17 30513 20 139 113 110 555][37 32 350 4 93 10 38 35 851 145 176 122 1 94 7 267 17 22 178 1][7497 12 6441 4 0 276 443 5 4064 26]...]\n",
            "targets[[1430 1022 10 17 210 21 497 7 12 165 2 977 49 17 30513 20 139 113 110 555][37 32 350 4 93 10 38 35 851 145 176 122 1 94 7 267 17 22 178 1][7497 12 6441 4 0 276 443 5 4064 26]...]\n",
            "global_step: 1911\n",
            " perplexity: 458.321\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[1430 1022 10 17 210 21 497 7 12 165 2 977 49 17 30513 20 139 113 110 555][37 32 350 4 93 10 38 35 851 145 176 122 1 94 7 267 17 22 178 1][7497 12 6441 4 0 276 443 5 4064 26]...]\n",
            " percent of 3-grams captured: 0.491.\n",
            "targets[[1430 1022 10 17 210 21 497 7 12 165 2 977 49 17 30513 20 139 113 110 555][37 32 350 4 93 10 38 35 851 145 176 122 1 94 7 267 17 22 178 1][7497 12 6441 4 0 276 443 5 4064 26]...]\n",
            " percent of 2-grams captured: 0.703.\n",
            "targets[[1430 1022 10 17 210 21 497 7 12 165 2 977 49 17 30513 20 139 113 110 555][37 32 350 4 93 10 38 35 851 145 176 122 1 94 7 267 17 22 178 1][7497 12 6441 4 0 276 443 5 4064 26]...]\n",
            " percent of 4-grams captured: 0.237.\n",
            " geometric_avg: 0.434.\n",
            " arithmetic_avg: 0.477.\n",
            "global_step: 1911\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69384\n",
            " G train loss: 3.10509\n",
            "targets[[1430 1022 10 17 210 21 497 7 12 165 2 977 49 17 30513 20 139 113 110 555][37 32 350 4 93 10 38 35 851 145 176 122 1 94 7 267 17 22 178 1][7497 12 6441 4 0 276 443 5 4064 26]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1831 1430 1022 10 17 210 21 497 7 12]...][[1 0 1 1 0 1 0 0 0 0]...][[1831 1430 69848 10 17 69848 21 69848 69848 69848]...][[1430 1022 10 17 210 21 497 7 12 165]...]\n",
            " Sample 0.\n",
            "   [1]  contains              0.498   0.000  \n",
            "   [0]  spoilers              0.502   6.459  \n",
            "   [1]  this                  0.504   0.000  \n",
            "   [1]  movie                 0.506   0.000  \n",
            "   [0]  isn                   0.505   6.478  \n",
            "   [1]  t                     0.503   0.000  \n",
            "   [0]  horrible              0.502   6.936  \n",
            "   [0]  it                    0.501   3.306  \n",
            "   [0]  s                     0.500   2.557  \n",
            "   [0]  actually              0.497   6.580  \n",
            "   [1]  a                     0.496   0.000  \n",
            "   [1]  fairly                0.495   0.000  \n",
            "   [1]  good                  0.495   0.000  \n",
            "   [0]  movie                 0.497   3.289  \n",
            "   [1]  presuming             0.497   0.000  \n",
            "   [1]  you                   0.498   0.000  \n",
            "   [1]  ve                    0.498   0.000  \n",
            "   [0]  never                 0.498   3.985  \n",
            "   [0]  seen                  0.499   2.287  \n",
            "   [1]  heard                 0.499   0.000  \n",
            " Sample 1.\n",
            "   [1]  so                    0.498   0.000  \n",
            "   [0]  they                  0.500   7.041  \n",
            "   [0]  try                   0.501   6.330  \n",
            "   [1]  to                    0.502   0.000  \n",
            "   [1]  make                  0.502   0.000  \n",
            "   [1]  this                  0.503   0.000  \n",
            "   [1]  like                  0.502   0.000  \n",
            "   [1]  an                    0.502   0.000  \n",
            "   [1]  actual                0.500   0.000  \n",
            "   [1]  real                  0.501   0.000  \n",
            "   [0]  world                 0.500   6.913  \n",
            "   [0]  show                  0.500   6.941  \n",
            "   [1]  and                   0.499   0.000  \n",
            "   [1]  then                  0.499   0.000  \n",
            "   [1]  it                    0.499   0.000  \n",
            "   [0]  goes                  0.499   7.057  \n",
            "   [0]  movie                 0.501   8.583  \n",
            "   [0]  on                    0.503   4.110  \n",
            "   [1]  us                    0.503   0.000  \n",
            "   [1]  and                   0.503   0.000  \n",
            " Sample 2.\n",
            "   [1]  lubitsch              0.470   0.000  \n",
            "   [0]  s                     0.471   3.244  \n",
            "   [0]  contribution          0.471   12.069 \n",
            "   [0]  to                    0.470   3.507  \n",
            "   [1]  the                   0.470   0.000  \n",
            "   [0]  american              0.470   6.799  \n",
            "   [1]  cinema                0.469   0.000  \n",
            "   [0]  is                    0.468   4.177  \n",
            "   [1]  enormous              0.470   0.000  \n",
            "   [1]  his                   0.470   0.000  \n",
            "   [0]  legacy                0.470   13.746 \n",
            "   [0]  is                    0.470   3.868  \n",
            "   [0]  an                    0.470   3.615  \n",
            "   [0]  outstanding           0.469   7.572  \n",
            "   [1]  group                 0.469   0.000  \n",
            "   [1]  of                    0.468   0.000  \n",
            "   [0]  movies                0.466   6.410  \n",
            "   [0]  that                  0.466   3.794  \n",
            "   [1]  will                  0.466   0.000  \n",
            "   [0]  live                  0.466   6.422  \n",
            "Samples\n",
            "Sample 0 .  contains spoilers this movie isn t horrible it s actually a fairly good movie presuming you ve never seen heard\n",
            "Sample 1 .  so they try to make this like an actual real world show and then it goes movie on us and\n",
            "Sample 2 .  lubitsch s contribution to the american cinema is enormous his legacy is an outstanding group of movies that will live\n",
            "\n",
            "\n",
            "targets[[9 970 970 629 5 0 8714 19 123 92 9 50 21 262 60 324 1291 10 609 10][183 10132 342 2384 14 921 1 350 4 76 78 2 176 4165 28200 1162 199 7156 1 27559][0 20230 3 0 1278 12505 1 3 0 11674]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1236 9 970 970 629 5 0 8714 19 123]...][[1 0 1 0 0 0 0 1 0 1]...][[1236 9 69848 970 69848 69848 69848 69848 19 69848]...][[9 970 970 629 5 0 8714 19 123 92]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1236 9 970 970 629 5 0 8714 19 123]...][[1 0 1 0 0 0 0 1 0 1]...][[1236 9 69848 970 69848 69848 69848 69848 19 69848]...][[9 970 970 629 5 0 8714 19 123 92]...]\n",
            "targets[[42 110 22538 10 17 389 4 333 4376 0 105 9 103 10 29 13 52 1097 0 4032][181 2702 201 11 12 1034 53 3186 882 155 10 10362 4798 1109 18998 947 49869 144 2 5803][215 11 17 173 483 602 10 17 5 37]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[256 42 110 22538 10 17 389 4 333 4376]...][[1 1 1 1 1 0 0 0 0 0]...][[256 42 110 22538 10 17 69848 69848 69848 69848]...][[42 110 22538 10 17 389 4 333 4376 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[256 42 110 22538 10 17 389 4 333 4376]...][[1 1 1 1 1 0 0 0 0 0]...][[256 42 110 22538 10 17 69848 69848 69848 69848]...][[42 110 22538 10 17 389 4 333 4376 0]...]\n",
            "targets[[42 110 22538 10 17 389 4 333 4376 0 105 9 103 10 29 13 52 1097 0 4032][181 2702 201 11 12 1034 53 3186 882 155 10 10362 4798 1109 18998 947 49869 144 2 5803][215 11 17 173 483 602 10 17 5 37]...]\n",
            "targets[[42 110 22538 10 17 389 4 333 4376 0 105 9 103 10 29 13 52 1097 0 4032][181 2702 201 11 12 1034 53 3186 882 155 10 10362 4798 1109 18998 947 49869 144 2 5803][215 11 17 173 483 602 10 17 5 37]...]\n",
            "targets[[42 110 22538 10 17 389 4 333 4376 0 105 9 103 10 29 13 52 1097 0 4032][181 2702 201 11 12 1034 53 3186 882 155 10 10362 4798 1109 18998 947 49869 144 2 5803][215 11 17 173 483 602 10 17 5 37]...]\n",
            "global_step: 1914\n",
            " perplexity: 458.288\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[42 110 22538 10 17 389 4 333 4376 0 105 9 103 10 29 13 52 1097 0 4032][181 2702 201 11 12 1034 53 3186 882 155 10 10362 4798 1109 18998 947 49869 144 2 5803][215 11 17 173 483 602 10 17 5 37]...]\n",
            " percent of 3-grams captured: 0.511.\n",
            "targets[[42 110 22538 10 17 389 4 333 4376 0 105 9 103 10 29 13 52 1097 0 4032][181 2702 201 11 12 1034 53 3186 882 155 10 10362 4798 1109 18998 947 49869 144 2 5803][215 11 17 173 483 602 10 17 5 37]...]\n",
            " percent of 2-grams captured: 0.711.\n",
            "targets[[42 110 22538 10 17 389 4 333 4376 0 105 9 103 10 29 13 52 1097 0 4032][181 2702 201 11 12 1034 53 3186 882 155 10 10362 4798 1109 18998 947 49869 144 2 5803][215 11 17 173 483 602 10 17 5 37]...]\n",
            " percent of 4-grams captured: 0.244.\n",
            " geometric_avg: 0.446.\n",
            " arithmetic_avg: 0.489.\n",
            "global_step: 1914\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69381\n",
            " G train loss: 3.10516\n",
            "targets[[42 110 22538 10 17 389 4 333 4376 0 105 9 103 10 29 13 52 1097 0 4032][181 2702 201 11 12 1034 53 3186 882 155 10 10362 4798 1109 18998 947 49869 144 2 5803][215 11 17 173 483 602 10 17 5 37]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[256 42 110 22538 10 17 389 4 333 4376]...][[1 1 1 1 1 0 0 0 0 0]...][[256 42 110 22538 10 17 69848 69848 69848 69848]...][[42 110 22538 10 17 389 4 333 4376 0]...]\n",
            " Sample 0.\n",
            "   [1]  just                  0.480   0.000  \n",
            "   [1]  seen                  0.482   0.000  \n",
            "   [1]  bamboozled            0.483   0.000  \n",
            "   [1]  this                  0.484   0.000  \n",
            "   [1]  movie                 0.483   0.000  \n",
            "   [0]  came                  0.482   7.177  \n",
            "   [0]  to                    0.482   3.458  \n",
            "   [0]  mind                  0.482   7.436  \n",
            "   [0]  comparing             0.481   10.249 \n",
            "   [0]  the                   0.480   2.983  \n",
            "   [1]  two                   0.480   0.000  \n",
            "   [1]  i                     0.480   0.000  \n",
            "   [1]  think                 0.480   0.000  \n",
            "   [0]  this                  0.479   2.485  \n",
            "   [1]  one                   0.478   0.000  \n",
            "   [1]  was                   0.477   0.000  \n",
            "   [1]  more                  0.476   0.000  \n",
            "   [1]  effective             0.477   0.000  \n",
            "   [0]  the                   0.478   3.517  \n",
            "   [0]  similarities          0.479   9.353  \n",
            " Sample 1.\n",
            "   [1]  action                0.503   0.000  \n",
            "   [1]  packed                0.503   0.000  \n",
            "   [0]  comedy                0.502   5.664  \n",
            "   [1]  that                  0.501   0.000  \n",
            "   [0]  s                     0.499   3.554  \n",
            "   [0]  neither               0.499   9.955  \n",
            "   [0]  very                  0.499   6.441  \n",
            "   [0]  thrilling             0.499   9.570  \n",
            "   [0]  nor                   0.499   8.162  \n",
            "   [0]  funny                 0.498   7.519  \n",
            "   [1]  this                  0.498   0.000  \n",
            "   [1]  sophomoric            0.499   0.000  \n",
            "   [0]  romp                  0.499   9.562  \n",
            "   [0]  follows               0.498   8.664  \n",
            "   [0]  hitman                0.499   13.059 \n",
            "   [0]  mark                  0.499   9.227  \n",
            "   [1]  whalberg              0.499   0.000  \n",
            "   [1]  through               0.499   0.000  \n",
            "   [1]  a                     0.499   0.000  \n",
            "   [0]  kidnapping            0.500   10.051 \n",
            " Sample 2.\n",
            "   [0]  saw                   0.508   2.060  \n",
            "   [0]  that                  0.508   3.815  \n",
            "   [1]  movie                 0.510   0.000  \n",
            "   [0]  few                   0.512   10.464 \n",
            "   [0]  days                  0.512   7.395  \n",
            "   [1]  ago                   0.513   0.000  \n",
            "   [0]  this                  0.513   3.887  \n",
            "   [0]  movie                 0.514   1.657  \n",
            "   [1]  is                    0.514   0.000  \n",
            "   [1]  so                    0.514   0.000  \n",
            "   [1]  great                 0.514   0.000  \n",
            "   [0]  that                  0.511   4.130  \n",
            "   [0]  it                    0.510   3.128  \n",
            "   [0]  makes                 0.510   6.329  \n",
            "   [1]  me                    0.510   0.000  \n",
            "   [0]  feel                  0.511   7.893  \n",
            "   [1]  that                  0.510   0.000  \n",
            "   [1]  if                    0.511   0.000  \n",
            "   [1]  you                   0.510   0.000  \n",
            "   [1]  want                  0.510   0.000  \n",
            "Samples\n",
            "Sample 0 .  just seen bamboozled this movie came to mind comparing the two i think this one was more effective the similarities\n",
            "Sample 1 .  action packed comedy that s neither very thrilling nor funny this sophomoric romp follows hitman mark whalberg through a kidnapping\n",
            "Sample 2 .  saw that movie few days ago this movie is so great that it makes me feel that if you want\n",
            "\n",
            "\n",
            "targets[[5 0 447 19 9 139 581 31 8 2 194 57 0 116 5149 36 379 4 2975 18][49 6 6 2 1043 641 7681 7407 261 125 1455 22 0 1350 3 0 4794 3 0 89][78 2 3061 10600 624 31 311 1 136 1785]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 447 19 9 139 581 31 8]...][[1 1 1 0 0 0 1 0 0 1]...][[10 5 0 447 69848 69848 69848 581 69848 69848]...][[5 0 447 19 9 139 581 31 8 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 447 19 9 139 581 31 8]...][[1 1 1 0 0 0 1 0 0 1]...][[10 5 0 447 69848 69848 69848 581 69848 69848]...][[5 0 447 19 9 139 581 31 8 2]...]\n",
            "targets[[9 970 970 629 5 0 8714 19 123 92 9 50 21 262 60 324 1291 10 609 10][183 10132 342 2384 14 921 1 350 4 76 78 2 176 4165 28200 1162 199 7156 1 27559][0 20230 3 0 1278 12505 1 3 0 11674]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1236 9 970 970 629 5 0 8714 19 123]...][[1 0 0 1 1 0 1 1 1 0]...][[1236 9 69848 69848 629 5 69848 8714 19 123]...][[9 970 970 629 5 0 8714 19 123 92]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1236 9 970 970 629 5 0 8714 19 123]...][[1 0 0 1 1 0 1 1 1 0]...][[1236 9 69848 69848 629 5 69848 8714 19 123]...][[9 970 970 629 5 0 8714 19 123 92]...]\n",
            "targets[[9 970 970 629 5 0 8714 19 123 92 9 50 21 262 60 324 1291 10 609 10][183 10132 342 2384 14 921 1 350 4 76 78 2 176 4165 28200 1162 199 7156 1 27559][0 20230 3 0 1278 12505 1 3 0 11674]...]\n",
            "targets[[9 970 970 629 5 0 8714 19 123 92 9 50 21 262 60 324 1291 10 609 10][183 10132 342 2384 14 921 1 350 4 76 78 2 176 4165 28200 1162 199 7156 1 27559][0 20230 3 0 1278 12505 1 3 0 11674]...]\n",
            "targets[[9 970 970 629 5 0 8714 19 123 92 9 50 21 262 60 324 1291 10 609 10][183 10132 342 2384 14 921 1 350 4 76 78 2 176 4165 28200 1162 199 7156 1 27559][0 20230 3 0 1278 12505 1 3 0 11674]...]\n",
            "global_step: 1917\n",
            " perplexity: 458.076\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[9 970 970 629 5 0 8714 19 123 92 9 50 21 262 60 324 1291 10 609 10][183 10132 342 2384 14 921 1 350 4 76 78 2 176 4165 28200 1162 199 7156 1 27559][0 20230 3 0 1278 12505 1 3 0 11674]...]\n",
            " percent of 3-grams captured: 0.499.\n",
            "targets[[9 970 970 629 5 0 8714 19 123 92 9 50 21 262 60 324 1291 10 609 10][183 10132 342 2384 14 921 1 350 4 76 78 2 176 4165 28200 1162 199 7156 1 27559][0 20230 3 0 1278 12505 1 3 0 11674]...]\n",
            " percent of 2-grams captured: 0.694.\n",
            "targets[[9 970 970 629 5 0 8714 19 123 92 9 50 21 262 60 324 1291 10 609 10][183 10132 342 2384 14 921 1 350 4 76 78 2 176 4165 28200 1162 199 7156 1 27559][0 20230 3 0 1278 12505 1 3 0 11674]...]\n",
            " percent of 4-grams captured: 0.248.\n",
            " geometric_avg: 0.441.\n",
            " arithmetic_avg: 0.480.\n",
            "global_step: 1917\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69378\n",
            " G train loss: 3.10508\n",
            "targets[[9 970 970 629 5 0 8714 19 123 92 9 50 21 262 60 324 1291 10 609 10][183 10132 342 2384 14 921 1 350 4 76 78 2 176 4165 28200 1162 199 7156 1 27559][0 20230 3 0 1278 12505 1 3 0 11674]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1236 9 970 970 629 5 0 8714 19 123]...][[1 0 0 1 1 0 1 1 1 0]...][[1236 9 69848 69848 629 5 69848 8714 19 123]...][[9 970 970 629 5 0 8714 19 123 92]...]\n",
            " Sample 0.\n",
            "   [1]  i                     0.507   0.000  \n",
            "   [0]  c                     0.507   10.463 \n",
            "   [0]  c                     0.506   8.610  \n",
            "   [1]  o                     0.505   0.000  \n",
            "   [1]  is                    0.505   0.000  \n",
            "   [0]  the                   0.506   2.387  \n",
            "   [1]  stupidest             0.507   0.000  \n",
            "   [1]  film                  0.507   0.000  \n",
            "   [1]  ever                  0.508   0.000  \n",
            "   [0]  made                  0.508   5.086  \n",
            "   [1]  i                     0.507   0.000  \n",
            "   [0]  can                   0.506   4.467  \n",
            "   [1]  t                     0.505   0.000  \n",
            "   [0]  believe               0.503   3.909  \n",
            "   [1]  my                    0.502   0.000  \n",
            "   [1]  father                0.501   0.000  \n",
            "   [1]  bought                0.502   0.000  \n",
            "   [1]  this                  0.503   0.000  \n",
            "   [0]  crap                  0.504   7.886  \n",
            "   [1]  this                  0.505   0.000  \n",
            " Sample 1.\n",
            "   [1]  young                 0.494   0.000  \n",
            "   [0]  iranian               0.497   11.112 \n",
            "   [1]  women                 0.499   0.000  \n",
            "   [0]  dress                 0.499   11.861 \n",
            "   [1]  as                    0.499   0.000  \n",
            "   [0]  boys                  0.501   9.544  \n",
            "   [0]  and                   0.502   3.294  \n",
            "   [1]  try                   0.503   0.000  \n",
            "   [0]  to                    0.504   2.098  \n",
            "   [0]  get                   0.505   4.554  \n",
            "   [0]  into                  0.506   5.988  \n",
            "   [0]  a                     0.507   1.858  \n",
            "   [0]  world                 0.507   6.234  \n",
            "   [0]  cup                   0.506   10.352 \n",
            "   [0]  qualifying            0.506   13.897 \n",
            "   [0]  match                 0.503   9.913  \n",
            "   [0]  between               0.500   6.594  \n",
            "   [1]  iran                  0.499   0.000  \n",
            "   [1]  and                   0.499   0.000  \n",
            "   [0]  bahrain               0.498   12.107 \n",
            " Sample 2.\n",
            "   [1]  the                   0.495   0.000  \n",
            "   [0]  cancellation          0.495   12.467 \n",
            "   [1]  of                    0.495   0.000  \n",
            "   [1]  the                   0.496   0.000  \n",
            "   [1]  teen                  0.497   0.000  \n",
            "   [0]  titans                0.497   12.536 \n",
            "   [1]  and                   0.497   0.000  \n",
            "   [1]  of                    0.496   0.000  \n",
            "   [0]  the                   0.496   2.276  \n",
            "   [0]  hideously             0.496   12.009 \n",
            "   [0]  awful                 0.496   7.766  \n",
            "   [1]  superman              0.497   0.000  \n",
            "   [0]  brainiac              0.497   13.865 \n",
            "   [1]  attacks               0.497   0.000  \n",
            "   [0]  simultaneously        0.496   11.883 \n",
            "   [0]  in                    0.496   3.831  \n",
            "   [0]  2006                  0.496   8.587  \n",
            "   [1]  i                     0.495   0.000  \n",
            "   [1]  was                   0.494   0.000  \n",
            "   [1]  sure                  0.492   0.000  \n",
            "Samples\n",
            "Sample 0 .  i c c o is the stupidest film ever made i can t believe my father bought this crap this\n",
            "Sample 1 .  young iranian women dress as boys and try to get into a world cup qualifying match between iran and bahrain\n",
            "Sample 2 .  the cancellation of the teen titans and of the hideously awful superman brainiac attacks simultaneously in 2006 i was sure\n",
            "\n",
            "\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 1996 1 3566 319 44 5 0 117 172]...][[0 0 0 0 0 1 1 0 0 1]...][[47 69848 69848 69848 69848 69848 5 0 69848 69848]...][[1996 1 3566 319 44 5 0 117 172 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 1996 1 3566 319 44 5 0 117 172]...][[0 0 0 0 0 1 1 0 0 1]...][[47 69848 69848 69848 69848 69848 5 0 69848 69848]...][[1996 1 3566 319 44 5 0 117 172 1]...]\n",
            "targets[[5 0 447 19 9 139 581 31 8 2 194 57 0 116 5149 36 379 4 2975 18][49 6 6 2 1043 641 7681 7407 261 125 1455 22 0 1350 3 0 4794 3 0 89][78 2 3061 10600 624 31 311 1 136 1785]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 447 19 9 139 581 31 8]...][[1 1 1 1 0 1 0 1 1 0]...][[10 5 0 447 19 69848 139 69848 31 8]...][[5 0 447 19 9 139 581 31 8 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 447 19 9 139 581 31 8]...][[1 1 1 1 0 1 0 1 1 0]...][[10 5 0 447 19 69848 139 69848 31 8]...][[5 0 447 19 9 139 581 31 8 2]...]\n",
            "targets[[5 0 447 19 9 139 581 31 8 2 194 57 0 116 5149 36 379 4 2975 18][49 6 6 2 1043 641 7681 7407 261 125 1455 22 0 1350 3 0 4794 3 0 89][78 2 3061 10600 624 31 311 1 136 1785]...]\n",
            "targets[[5 0 447 19 9 139 581 31 8 2 194 57 0 116 5149 36 379 4 2975 18][49 6 6 2 1043 641 7681 7407 261 125 1455 22 0 1350 3 0 4794 3 0 89][78 2 3061 10600 624 31 311 1 136 1785]...]\n",
            "targets[[5 0 447 19 9 139 581 31 8 2 194 57 0 116 5149 36 379 4 2975 18][49 6 6 2 1043 641 7681 7407 261 125 1455 22 0 1350 3 0 4794 3 0 89][78 2 3061 10600 624 31 311 1 136 1785]...]\n",
            "global_step: 1920\n",
            " perplexity: 456.848\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[5 0 447 19 9 139 581 31 8 2 194 57 0 116 5149 36 379 4 2975 18][49 6 6 2 1043 641 7681 7407 261 125 1455 22 0 1350 3 0 4794 3 0 89][78 2 3061 10600 624 31 311 1 136 1785]...]\n",
            " percent of 3-grams captured: 0.526.\n",
            "targets[[5 0 447 19 9 139 581 31 8 2 194 57 0 116 5149 36 379 4 2975 18][49 6 6 2 1043 641 7681 7407 261 125 1455 22 0 1350 3 0 4794 3 0 89][78 2 3061 10600 624 31 311 1 136 1785]...]\n",
            " percent of 2-grams captured: 0.703.\n",
            "targets[[5 0 447 19 9 139 581 31 8 2 194 57 0 116 5149 36 379 4 2975 18][49 6 6 2 1043 641 7681 7407 261 125 1455 22 0 1350 3 0 4794 3 0 89][78 2 3061 10600 624 31 311 1 136 1785]...]\n",
            " percent of 4-grams captured: 0.256.\n",
            " geometric_avg: 0.456.\n",
            " arithmetic_avg: 0.495.\n",
            "global_step: 1920\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69377\n",
            " G train loss: 3.10418\n",
            "targets[[5 0 447 19 9 139 581 31 8 2 194 57 0 116 5149 36 379 4 2975 18][49 6 6 2 1043 641 7681 7407 261 125 1455 22 0 1350 3 0 4794 3 0 89][78 2 3061 10600 624 31 311 1 136 1785]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 447 19 9 139 581 31 8]...][[1 1 1 1 0 1 0 1 1 0]...][[10 5 0 447 19 69848 139 69848 31 8]...][[5 0 447 19 9 139 581 31 8 2]...]\n",
            " Sample 0.\n",
            "   [1]  is                    0.505   0.000  \n",
            "   [1]  the                   0.503   0.000  \n",
            "   [1]  worse                 0.502   0.000  \n",
            "   [1]  film                  0.500   0.000  \n",
            "   [0]  i                     0.499   2.209  \n",
            "   [1]  ve                    0.500   0.000  \n",
            "   [0]  looked                0.499   8.208  \n",
            "   [1]  at                    0.499   0.000  \n",
            "   [1]  in                    0.499   0.000  \n",
            "   [0]  a                     0.498   2.724  \n",
            "   [1]  long                  0.497   0.000  \n",
            "   [0]  time                  0.494   3.348  \n",
            "   [0]  the                   0.492   3.851  \n",
            "   [0]  acting                0.491   4.480  \n",
            "   [1]  rises                 0.491   0.000  \n",
            "   [0]  from                  0.492   4.740  \n",
            "   [1]  awful                 0.493   0.000  \n",
            "   [0]  to                    0.493   4.194  \n",
            "   [1]  alright               0.495   0.000  \n",
            "   [0]  but                   0.496   4.869  \n",
            " Sample 1.\n",
            "   [0]  good                  0.531   8.143  \n",
            "   [0]  br                    0.535   4.729  \n",
            "   [0]  br                    0.537   3.255  \n",
            "   [0]  a                     0.540   3.884  \n",
            "   [0]  plain                 0.542   9.471  \n",
            "   [1]  somewhat              0.543   0.000  \n",
            "   [1]  overweight            0.542   0.000  \n",
            "   [0]  nerdy                 0.541   11.916 \n",
            "   [1]  looking               0.540   0.000  \n",
            "   [0]  man                   0.539   7.198  \n",
            "   [0]  stands                0.540   8.851  \n",
            "   [1]  on                    0.542   0.000  \n",
            "   [0]  the                   0.544   1.734  \n",
            "   [0]  edge                  0.544   8.547  \n",
            "   [0]  of                    0.542   2.406  \n",
            "   [1]  the                   0.543   0.000  \n",
            "   [1]  roof                  0.543   0.000  \n",
            "   [0]  of                    0.542   2.515  \n",
            "   [0]  the                   0.544   1.964  \n",
            "   [0]  don                   0.545   10.077 \n",
            " Sample 2.\n",
            "   [1]  into                  0.482   0.000  \n",
            "   [0]  a                     0.486   2.107  \n",
            "   [0]  mirror                0.488   10.588 \n",
            "   [0]  preferably            0.490   15.368 \n",
            "   [0]  alone                 0.491   8.473  \n",
            "   [0]  at                    0.493   4.321  \n",
            "   [0]  night                 0.495   6.806  \n",
            "   [1]  and                   0.497   0.000  \n",
            "   [1]  say                   0.497   0.000  \n",
            "   [1]  candy                 0.497   0.000  \n",
            "   [0]  man                   0.497   8.514  \n",
            "   [1]  5                     0.496   0.000  \n",
            "   [0]  times                 0.497   7.346  \n",
            "   [1]  and                   0.497   0.000  \n",
            "   [0]  uh                    0.497   10.046 \n",
            "   [1]  see                   0.496   0.000  \n",
            "   [1]  what                  0.495   0.000  \n",
            "   [1]  happens               0.495   0.000  \n",
            "   [1]  little                0.495   0.000  \n",
            "   [0]  known                 0.495   8.025  \n",
            "Samples\n",
            "Sample 0 .  is the worse film i ve looked at in a long time the acting rises from awful to alright but\n",
            "Sample 1 .  good br br a plain somewhat overweight nerdy looking man stands on the edge of the roof of the don\n",
            "Sample 2 .  into a mirror preferably alone at night and say candy man 5 times and uh see what happens little known\n",
            "\n",
            "\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[0 1 1 0 1 1 0 0 1 1]...][[48 69848 0 881 69848 27 446 69848 69848 1099]...][[3 0 881 1996 27 446 24579 774 1099 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[0 1 1 0 1 1 0 0 1 1]...][[48 69848 0 881 69848 27 446 69848 69848 1099]...][[3 0 881 1996 27 446 24579 774 1099 1]...]\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 1996 1 3566 319 44 5 0 117 172]...][[0 0 0 1 1 0 0 1 0 0]...][[47 69848 69848 69848 319 44 69848 69848 117 69848]...][[1996 1 3566 319 44 5 0 117 172 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 1996 1 3566 319 44 5 0 117 172]...][[0 0 0 1 1 0 0 1 0 0]...][[47 69848 69848 69848 319 44 69848 69848 117 69848]...][[1996 1 3566 319 44 5 0 117 172 1]...]\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            "global_step: 1923\n",
            " perplexity: 455.711\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            " percent of 3-grams captured: 0.537.\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            " percent of 2-grams captured: 0.704.\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            " percent of 4-grams captured: 0.263.\n",
            " geometric_avg: 0.463.\n",
            " arithmetic_avg: 0.501.\n",
            "global_step: 1923\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69378\n",
            " G train loss: 3.10264\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 1996 1 3566 319 44 5 0 117 172]...][[0 0 0 1 1 0 0 1 0 0]...][[47 69848 69848 69848 319 44 69848 69848 117 69848]...][[1996 1 3566 319 44 5 0 117 172 1]...]\n",
            " Sample 0.\n",
            "   [0]  reviewers             0.509   10.913 \n",
            "   [0]  and                   0.509   5.197  \n",
            "   [0]  mst3k                 0.507   9.932  \n",
            "   [1]  left                  0.506   0.000  \n",
            "   [1]  out                   0.506   0.000  \n",
            "   [0]  is                    0.506   4.185  \n",
            "   [0]  the                   0.506   1.920  \n",
            "   [1]  best                  0.506   0.000  \n",
            "   [0]  part                  0.507   6.234  \n",
            "   [0]  and                   0.506   2.677  \n",
            "   [1]  only                  0.506   0.000  \n",
            "   [0]  memorable             0.508   9.063  \n",
            "   [1]  scene                 0.510   0.000  \n",
            "   [1]  of                    0.512   0.000  \n",
            "   [0]  this                  0.514   2.708  \n",
            "   [0]  otherwise             0.515   9.665  \n",
            "   [1]  dreadful              0.515   0.000  \n",
            "   [1]  movie                 0.514   0.000  \n",
            "   [0]  there                 0.512   4.603  \n",
            "   [0]  is                    0.510   1.548  \n",
            " Sample 1.\n",
            "   [0]  from                  0.512   4.860  \n",
            "   [1]  waterworld            0.517   0.000  \n",
            "   [0]  and                   0.522   3.648  \n",
            "   [1]  mad                   0.525   0.000  \n",
            "   [0]  max                   0.527   9.132  \n",
            "   [0]  this                  0.529   5.591  \n",
            "   [1]  film                  0.532   0.000  \n",
            "   [1]  is                    0.532   0.000  \n",
            "   [1]  a                     0.532   0.000  \n",
            "   [0]  pleasure              0.532   7.743  \n",
            "   [1]  to                    0.531   0.000  \n",
            "   [0]  the                   0.531   3.210  \n",
            "   [1]  eyes                  0.531   0.000  \n",
            "   [1]  with                  0.529   0.000  \n",
            "   [0]  beautiful             0.526   7.395  \n",
            "   [0]  sand                  0.526   12.027 \n",
            "   [1]  landscapes            0.525   0.000  \n",
            "   [0]  from                  0.526   4.718  \n",
            "   [0]  s                     0.525   6.045  \n",
            "   [1]  desert                0.523   0.000  \n",
            " Sample 2.\n",
            "   [0]  said                  0.493   8.813  \n",
            "   [1]  a                     0.494   0.000  \n",
            "   [0]  comment               0.494   7.626  \n",
            "   [1]  that                  0.493   0.000  \n",
            "   [0]  made                  0.492   5.604  \n",
            "   [0]  me                    0.492   6.143  \n",
            "   [0]  very                  0.493   6.913  \n",
            "   [0]  disappointed          0.496   6.841  \n",
            "   [1]  in                    0.498   0.000  \n",
            "   [0]  her                   0.501   6.251  \n",
            "   [1]  i                     0.501   0.000  \n",
            "   [1]  have                  0.500   0.000  \n",
            "   [0]  watched               0.500   5.542  \n",
            "   [1]  desperate             0.498   0.000  \n",
            "   [0]  housewives            0.497   11.808 \n",
            "   [1]  and                   0.497   0.000  \n",
            "   [1]  sometimes             0.495   0.000  \n",
            "   [0]  they                  0.496   5.425  \n",
            "   [1]  have                  0.497   0.000  \n",
            "   [1]  shows                 0.498   0.000  \n",
            "Samples\n",
            "Sample 0 .  reviewers and mst3k left out is the best part and only memorable scene of this otherwise dreadful movie there is\n",
            "Sample 1 .  from waterworld and mad max this film is a pleasure to the eyes with beautiful sand landscapes from s desert\n",
            "Sample 2 .  said a comment that made me very disappointed in her i have watched desperate housewives and sometimes they have shows\n",
            "\n",
            "\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 0 0 0 1 1 0 1 0 0]...][[6 6 69848 69848 69848 139 555 69848 0 69848]...][[6 815 37 9 139 555 3 0 21756 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 0 0 0 1 1 0 1 0 0]...][[6 6 69848 69848 69848 139 555 69848 0 69848]...][[6 815 37 9 139 555 3 0 21756 3]...]\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[1 0 1 1 1 1 0 1 1 1]...][[48 3 69848 881 1996 27 446 69848 774 1099]...][[3 0 881 1996 27 446 24579 774 1099 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[1 0 1 1 1 1 0 1 1 1]...][[48 3 69848 881 1996 27 446 69848 774 1099]...][[3 0 881 1996 27 446 24579 774 1099 1]...]\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "global_step: 1926\n",
            " perplexity: 454.682\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            " percent of 3-grams captured: 0.499.\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            " percent of 2-grams captured: 0.695.\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            " percent of 4-grams captured: 0.239.\n",
            " geometric_avg: 0.436.\n",
            " arithmetic_avg: 0.478.\n",
            "global_step: 1926\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69379\n",
            " G train loss: 3.10177\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[1 0 1 1 1 1 0 1 1 1]...][[48 3 69848 881 1996 27 446 69848 774 1099]...][[3 0 881 1996 27 446 24579 774 1099 1]...]\n",
            " Sample 0.\n",
            "   [1]  of                    0.507   0.000  \n",
            "   [0]  the                   0.508   2.022  \n",
            "   [1]  earlier               0.507   0.000  \n",
            "   [1]  reviewers             0.504   0.000  \n",
            "   [1]  have                  0.502   0.000  \n",
            "   [1]  called                0.502   0.000  \n",
            "   [0]  clockwatchers         0.502   14.711 \n",
            "   [1]  dull                  0.502   0.000  \n",
            "   [1]  pointless             0.502   0.000  \n",
            "   [1]  and                   0.502   0.000  \n",
            "   [1]  have                  0.501   0.000  \n",
            "   [1]  asked                 0.500   0.000  \n",
            "   [1]  why                   0.500   0.000  \n",
            "   [1]  it                    0.501   0.000  \n",
            "   [0]  was                   0.501   2.082  \n",
            "   [0]  made                  0.500   5.582  \n",
            "   [0]  my                    0.500   5.966  \n",
            "   [0]  question              0.500   7.540  \n",
            "   [1]  for                   0.500   0.000  \n",
            "   [1]  these                 0.500   0.000  \n",
            " Sample 1.\n",
            "   [1]  film                  0.510   0.000  \n",
            "   [1]  tells                 0.511   0.000  \n",
            "   [1]  a                     0.513   0.000  \n",
            "   [0]  compelling            0.513   8.266  \n",
            "   [0]  story                 0.512   4.680  \n",
            "   [0]  the                   0.513   4.348  \n",
            "   [0]  writing               0.513   8.265  \n",
            "   [1]  and                   0.513   0.000  \n",
            "   [1]  the                   0.515   0.000  \n",
            "   [0]  characters            0.515   5.401  \n",
            "   [1]  are                   0.515   0.000  \n",
            "   [0]  so                    0.516   5.154  \n",
            "   [0]  real                  0.517   6.849  \n",
            "   [0]  and                   0.517   5.211  \n",
            "   [0]  portrayed             0.518   9.798  \n",
            "   [1]  so                    0.519   0.000  \n",
            "   [1]  well                  0.518   0.000  \n",
            "   [1]  you                   0.517   0.000  \n",
            "   [1]  can                   0.515   0.000  \n",
            "   [1]  t                     0.514   0.000  \n",
            " Sample 2.\n",
            "   [0]  m                     0.495   2.446  \n",
            "   [1]  a                     0.492   0.000  \n",
            "   [0]  huge                  0.490   3.967  \n",
            "   [0]  fan                   0.488   2.232  \n",
            "   [0]  of                    0.485   1.164  \n",
            "   [1]  the                   0.485   0.000  \n",
            "   [1]  dukes                 0.485   0.000  \n",
            "   [0]  of                    0.484   2.141  \n",
            "   [0]  hazzard               0.484   10.843 \n",
            "   [0]  tv                    0.483   6.947  \n",
            "   [0]  show                  0.483   6.876  \n",
            "   [1]  and                   0.484   0.000  \n",
            "   [0]  i                     0.483   2.912  \n",
            "   [0]  really                0.483   4.223  \n",
            "   [0]  enjoyed               0.483   4.444  \n",
            "   [1]  this                  0.482   0.000  \n",
            "   [1]  flick                 0.482   0.000  \n",
            "   [1]  i                     0.483   0.000  \n",
            "   [1]  enjoyed               0.482   0.000  \n",
            "   [0]  myself                0.482   7.239  \n",
            "Samples\n",
            "Sample 0 .  of the earlier reviewers have called clockwatchers dull pointless and have asked why it was made my question for these\n",
            "Sample 1 .  film tells a compelling story the writing and the characters are so real and portrayed so well you can t\n",
            "Sample 2 .  m a huge fan of the dukes of hazzard tv show and i really enjoyed this flick i enjoyed myself\n",
            "\n",
            "\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[0 1 1 0 0 1 0 0 1 1]...][[2 69848 1 2 69848 69848 8 69848 69848 346]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[0 1 1 0 0 1 0 0 1 1]...][[2 69848 1 2 69848 69848 8 69848 69848 346]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 1 0 0 1 1 1 0 0 1]...][[6 6 815 69848 69848 139 555 3 69848 69848]...][[6 815 37 9 139 555 3 0 21756 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 1 0 0 1 1 1 0 0 1]...][[6 6 815 69848 69848 139 555 3 69848 69848]...][[6 815 37 9 139 555 3 0 21756 3]...]\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "global_step: 1929\n",
            " perplexity: 453.756\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            " percent of 3-grams captured: 0.517.\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            " percent of 2-grams captured: 0.710.\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            " percent of 4-grams captured: 0.239.\n",
            " geometric_avg: 0.444.\n",
            " arithmetic_avg: 0.488.\n",
            "global_step: 1929\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69380\n",
            " G train loss: 3.10133\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 1 0 0 1 1 1 0 0 1]...][[6 6 815 69848 69848 139 555 3 69848 69848]...][[6 815 37 9 139 555 3 0 21756 3]...]\n",
            " Sample 0.\n",
            "   [1]  br                    0.500   0.000  \n",
            "   [1]  okay                  0.500   0.000  \n",
            "   [0]  so                    0.499   5.717  \n",
            "   [0]  i                     0.499   4.167  \n",
            "   [1]  ve                    0.499   0.000  \n",
            "   [1]  heard                 0.500   0.000  \n",
            "   [1]  of                    0.501   0.000  \n",
            "   [0]  the                   0.502   1.558  \n",
            "   [0]  litany                0.503   14.406 \n",
            "   [1]  of                    0.504   0.000  \n",
            "   [0]  accolades             0.504   12.690 \n",
            "   [0]  this                  0.504   5.187  \n",
            "   [1]  movie                 0.503   0.000  \n",
            "   [1]  has                   0.503   0.000  \n",
            "   [1]  received              0.504   0.000  \n",
            "   [1]  i                     0.503   0.000  \n",
            "   [1]  ve                    0.502   0.000  \n",
            "   [0]  heard                 0.502   5.689  \n",
            "   [0]  how                   0.502   5.507  \n",
            "   [0]  this                  0.502   2.454  \n",
            " Sample 1.\n",
            "   [0]  first                 0.463   4.225  \n",
            "   [0]  saw                   0.466   4.692  \n",
            "   [1]  c                     0.468   0.000  \n",
            "   [0]  est                   0.468   13.509 \n",
            "   [1]  arriv                 0.468   0.000  \n",
            "   [1]  pr                    0.469   0.000  \n",
            "   [0]  s                     0.468   2.846  \n",
            "   [1]  de                    0.466   0.000  \n",
            "   [1]  chez                  0.466   0.000  \n",
            "   [0]  vous                  0.466   15.453 \n",
            "   [1]  man                   0.468   0.000  \n",
            "   [1]  bites                 0.468   0.000  \n",
            "   [1]  dog                   0.468   0.000  \n",
            "   [1]  about                 0.468   0.000  \n",
            "   [0]  ten                   0.468   7.976  \n",
            "   [1]  years                 0.469   0.000  \n",
            "   [0]  ago                   0.468   6.275  \n",
            "   [0]  and                   0.467   2.418  \n",
            "   [0]  i                     0.467   4.491  \n",
            "   [0]  was                   0.466   2.737  \n",
            " Sample 2.\n",
            "   [1]  seems                 0.505   0.000  \n",
            "   [1]  to                    0.506   0.000  \n",
            "   [1]  be                    0.506   0.000  \n",
            "   [1]  and                   0.505   0.000  \n",
            "   [0]  real                  0.504   7.650  \n",
            "   [0]  madonna               0.503   9.538  \n",
            "   [0]  is                    0.503   4.250  \n",
            "   [0]  the                   0.503   1.533  \n",
            "   [1]  queen                 0.503   0.000  \n",
            "   [1]  i                     0.503   0.000  \n",
            "   [0]  am                    0.501   3.617  \n",
            "   [1]  not                   0.501   0.000  \n",
            "   [0]  her                   0.500   7.564  \n",
            "   [1]  fan                   0.500   0.000  \n",
            "   [1]  but                   0.501   0.000  \n",
            "   [0]  i                     0.503   2.033  \n",
            "   [0]  better                0.504   11.748 \n",
            "   [0]  will                  0.503   7.626  \n",
            "   [0]  be                    0.502   2.900  \n",
            "   [0]  cause                 0.501   8.963  \n",
            "Samples\n",
            "Sample 0 .  br okay so i ve heard of the litany of accolades this movie has received i ve heard how this\n",
            "Sample 1 .  first saw c est arriv pr s de chez vous man bites dog about ten years ago and i was\n",
            "Sample 2 .  seems to be and real madonna is the queen i am not her fan but i better will be cause\n",
            "\n",
            "\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[1 1 1 0 1 0 1 0 0 1]...][[9 13 1262 671 69848 10 69848 9 69848 69848]...][[13 1262 671 33 10 17 9 27 1059 1291]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[1 1 1 0 1 0 1 0 0 1]...][[9 13 1262 671 69848 10 69848 9 69848 69848]...][[13 1262 671 33 10 17 9 27 1059 1291]...]\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[1 0 1 1 0 0 1 0 0 1]...][[2 373 69848 2 518 69848 69848 2 69848 69848]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[1 0 1 1 0 0 1 0 0 1]...][[2 373 69848 2 518 69848 69848 2 69848 69848]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "global_step: 1932\n",
            " perplexity: 453.856\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            " percent of 3-grams captured: 0.493.\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            " percent of 2-grams captured: 0.722.\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            " percent of 4-grams captured: 0.217.\n",
            " geometric_avg: 0.426.\n",
            " arithmetic_avg: 0.477.\n",
            "global_step: 1932\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69380\n",
            " G train loss: 3.10197\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[1 0 1 1 0 0 1 0 0 1]...][[2 373 69848 2 518 69848 69848 2 69848 69848]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            " Sample 0.\n",
            "   [1]  mother                0.518   0.000  \n",
            "   [0]  and                   0.523   3.818  \n",
            "   [1]  a                     0.527   0.000  \n",
            "   [1]  daughter              0.527   0.000  \n",
            "   [0]  live                  0.525   9.696  \n",
            "   [0]  in                    0.523   3.552  \n",
            "   [1]  a                     0.524   0.000  \n",
            "   [0]  large                 0.525   7.566  \n",
            "   [0]  home                  0.525   7.570  \n",
            "   [1]  playing               0.527   0.000  \n",
            "   [1]  games                 0.529   0.000  \n",
            "   [1]  of                    0.531   0.000  \n",
            "   [0]  sexual                0.532   8.845  \n",
            "   [0]  domination            0.534   13.462 \n",
            "   [0]  and                   0.535   2.448  \n",
            "   [0]  re                    0.535   7.224  \n",
            "   [1]  enacting              0.534   0.000  \n",
            "   [0]  the                   0.535   2.838  \n",
            "   [1]  murders               0.536   0.000  \n",
            "   [0]  of                    0.534   2.181  \n",
            " Sample 1.\n",
            "   [1]  can                   0.509   0.000  \n",
            "   [1]  watch                 0.508   0.000  \n",
            "   [0]  a                     0.507   2.565  \n",
            "   [0]  good                  0.507   4.577  \n",
            "   [1]  gory                  0.506   0.000  \n",
            "   [0]  film                  0.507   3.478  \n",
            "   [0]  now                   0.508   7.461  \n",
            "   [1]  and                   0.508   0.000  \n",
            "   [0]  then                  0.508   5.723  \n",
            "   [0]  i                     0.508   2.802  \n",
            "   [1]  ve                    0.508   0.000  \n",
            "   [0]  seen                  0.508   2.491  \n",
            "   [0]  some                  0.510   4.414  \n",
            "   [0]  pretty                0.510   7.101  \n",
            "   [1]  sick                  0.510   0.000  \n",
            "   [0]  stuff                 0.511   8.643  \n",
            "   [0]  however               0.512   6.966  \n",
            "   [0]  this                  0.512   3.457  \n",
            "   [1]  is                    0.512   0.000  \n",
            "   [0]  one                   0.511   3.068  \n",
            " Sample 2.\n",
            "   [0]  first                 0.514   4.520  \n",
            "   [1]  caught                0.518   0.000  \n",
            "   [0]  the                   0.520   2.744  \n",
            "   [0]  movie                 0.521   1.856  \n",
            "   [1]  on                    0.521   0.000  \n",
            "   [1]  its                   0.521   0.000  \n",
            "   [0]  first                 0.521   4.821  \n",
            "   [1]  run                   0.522   0.000  \n",
            "   [0]  on                    0.522   4.035  \n",
            "   [0]  hbo                   0.522   9.154  \n",
            "   [0]  in                    0.520   3.777  \n",
            "   [0]  probably              0.520   8.554  \n",
            "   [1]  1981                  0.519   0.000  \n",
            "   [1]  and                   0.518   0.000  \n",
            "   [0]  being                 0.518   5.836  \n",
            "   [1]  15                    0.519   0.000  \n",
            "   [0]  years                 0.520   6.053  \n",
            "   [0]  old                   0.521   6.943  \n",
            "   [1]  i                     0.522   0.000  \n",
            "   [0]  thought               0.523   4.472  \n",
            "Samples\n",
            "Sample 0 .  mother and a daughter live in a large home playing games of sexual domination and re enacting the murders of\n",
            "Sample 1 .  can watch a good gory film now and then i ve seen some pretty sick stuff however this is one\n",
            "Sample 2 .  first caught the movie on its first run on hbo in probably 1981 and being 15 years old i thought\n",
            "\n",
            "\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[0 0 0 0 0 1 1 1 0 0]...][[10 69848 69848 69848 69848 69848 123 92 7 69848]...][[5 0 117 2499 19 123 92 7 1886 52]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[0 0 0 0 0 1 1 1 0 0]...][[10 69848 69848 69848 69848 69848 123 92 7 69848]...][[5 0 117 2499 19 123 92 7 1886 52]...]\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[0 0 0 1 1 0 1 0 1 0]...][[9 69848 69848 69848 33 10 69848 9 69848 1059]...][[13 1262 671 33 10 17 9 27 1059 1291]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[0 0 0 1 1 0 1 0 1 0]...][[9 69848 69848 69848 33 10 69848 9 69848 1059]...][[13 1262 671 33 10 17 9 27 1059 1291]...]\n",
            "2020-03-24 03:46:06.177558: E tensorflow/core/util/events_writer.cc:162] The events file maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0 has disappeared.\n",
            "2020-03-24 03:46:06.177610: E tensorflow/core/util/events_writer.cc:131] Failed to flush 524 events to maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "global_step: 1935\n",
            " perplexity: 454.136\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            " percent of 3-grams captured: 0.507.\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            " percent of 2-grams captured: 0.706.\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            " percent of 4-grams captured: 0.234.\n",
            " geometric_avg: 0.438.\n",
            " arithmetic_avg: 0.483.\n",
            "global_step: 1935\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69379\n",
            " G train loss: 3.10161\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[0 0 0 1 1 0 1 0 1 0]...][[9 69848 69848 69848 33 10 69848 9 69848 1059]...][[13 1262 671 33 10 17 9 27 1059 1291]...]\n",
            " Sample 0.\n",
            "   [0]  was                   0.514   3.289  \n",
            "   [0]  utterly               0.514   7.945  \n",
            "   [0]  disappointed          0.515   6.520  \n",
            "   [1]  by                    0.514   0.000  \n",
            "   [1]  this                  0.512   0.000  \n",
            "   [0]  movie                 0.509   0.784  \n",
            "   [1]  i                     0.505   0.000  \n",
            "   [0]  have                  0.501   2.157  \n",
            "   [1]  recently              0.498   0.000  \n",
            "   [0]  bought                0.497   8.459  \n",
            "   [0]  both                  0.497   7.468  \n",
            "   [0]  series                0.500   8.135  \n",
            "   [1]  on                    0.502   0.000  \n",
            "   [1]  dvd                   0.505   0.000  \n",
            "   [1]  as                    0.508   0.000  \n",
            "   [1]  i                     0.509   0.000  \n",
            "   [1]  had                   0.508   0.000  \n",
            "   [1]  seen                  0.507   0.000  \n",
            "   [1]  the                   0.504   0.000  \n",
            "   [0]  first                 0.501   4.406  \n",
            " Sample 1.\n",
            "   [0]  i                     0.497   1.255  \n",
            "   [1]  first                 0.496   0.000  \n",
            "   [0]  saw                   0.495   4.912  \n",
            "   [1]  zhang                 0.495   0.000  \n",
            "   [1]  yimou                 0.497   0.000  \n",
            "   [1]  s                     0.499   0.000  \n",
            "   [1]  wonderful             0.501   0.000  \n",
            "   [0]  raise                 0.498   11.917 \n",
            "   [0]  the                   0.498   4.258  \n",
            "   [0]  red                   0.499   8.729  \n",
            "   [1]  lantern               0.498   0.000  \n",
            "   [0]  i                     0.498   5.988  \n",
            "   [0]  missed                0.498   7.530  \n",
            "   [0]  all                   0.499   5.276  \n",
            "   [0]  but                   0.500   4.443  \n",
            "   [0]  the                   0.501   2.916  \n",
            "   [1]  last                  0.502   0.000  \n",
            "   [0]  30                    0.503   8.567  \n",
            "   [0]  minutes               0.504   6.640  \n",
            "   [0]  this                  0.503   4.207  \n",
            " Sample 2.\n",
            "   [1]  came                  0.534   0.000  \n",
            "   [1]  across                0.533   0.000  \n",
            "   [1]  this                  0.529   0.000  \n",
            "   [0]  film                  0.524   1.633  \n",
            "   [0]  under                 0.520   8.631  \n",
            "   [0]  the                   0.517   2.474  \n",
            "   [1]  title                 0.516   0.000  \n",
            "   [0]  hot                   0.514   9.842  \n",
            "   [1]  sweat                 0.513   0.000  \n",
            "   [1]  at                    0.514   0.000  \n",
            "   [0]  my                    0.514   4.597  \n",
            "   [0]  local                 0.515   5.987  \n",
            "   [0]  video                 0.517   6.691  \n",
            "   [0]  store                 0.520   7.221  \n",
            "   [0]  and                   0.521   2.498  \n",
            "   [0]  rented                0.520   9.871  \n",
            "   [0]  it                    0.519   2.746  \n",
            "   [0]  out                   0.518   7.924  \n",
            "   [1]  of                    0.516   0.000  \n",
            "   [0]  curiosity             0.515   9.441  \n",
            "Samples\n",
            "Sample 0 .  was utterly disappointed by this movie i have recently bought both series on dvd as i had seen the first\n",
            "Sample 1 .  i first saw zhang yimou s wonderful raise the red lantern i missed all but the last 30 minutes this\n",
            "Sample 2 .  came across this film under the title hot sweat at my local video store and rented it out of curiosity\n",
            "\n",
            "\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[0 0 0 0 0 1 0 1 1 0]...][[9 69848 69848 69848 69848 69848 17 69848 7 13]...][[65 470 4 38 10 17 18 7 13 42]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[0 0 0 0 0 1 0 1 1 0]...][[9 69848 69848 69848 69848 69848 17 69848 7 13]...][[65 470 4 38 10 17 18 7 13 42]...]\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[0 1 0 1 0 0 0 1 1 1]...][[10 69848 0 69848 2499 69848 69848 69848 7 1886]...][[5 0 117 2499 19 123 92 7 1886 52]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[0 1 0 1 0 0 0 1 1 1]...][[10 69848 0 69848 2499 69848 69848 69848 7 1886]...][[5 0 117 2499 19 123 92 7 1886 52]...]\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "global_step: 1938\n",
            " perplexity: 453.930\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            " percent of 3-grams captured: 0.493.\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            " percent of 2-grams captured: 0.707.\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            " percent of 4-grams captured: 0.225.\n",
            " geometric_avg: 0.428.\n",
            " arithmetic_avg: 0.475.\n",
            "global_step: 1938\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69381\n",
            " G train loss: 3.10287\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[0 1 0 1 0 0 0 1 1 1]...][[10 69848 0 69848 2499 69848 69848 69848 7 1886]...][[5 0 117 2499 19 123 92 7 1886 52]...]\n",
            " Sample 0.\n",
            "   [0]  is                    0.527   1.716  \n",
            "   [1]  the                   0.528   0.000  \n",
            "   [0]  best                  0.526   3.671  \n",
            "   [1]  mob                   0.524   0.000  \n",
            "   [0]  film                  0.522   3.129  \n",
            "   [0]  ever                  0.519   6.854  \n",
            "   [0]  made                  0.518   5.482  \n",
            "   [1]  it                    0.517   0.000  \n",
            "   [1]  deserved              0.516   0.000  \n",
            "   [1]  more                  0.515   0.000  \n",
            "   [1]  then                  0.515   0.000  \n",
            "   [0]  what                  0.514   4.902  \n",
            "   [1]  it                    0.515   0.000  \n",
            "   [0]  got                   0.516   6.517  \n",
            "   [0]  at                    0.519   5.019  \n",
            "   [0]  the                   0.520   1.686  \n",
            "   [0]  oscars                0.521   9.950  \n",
            "   [0]  nominated             0.521   9.922  \n",
            "   [0]  for                   0.522   5.282  \n",
            "   [0]  things                0.522   7.878  \n",
            " Sample 1.\n",
            "   [1]  austin                0.495   0.000  \n",
            "   [1]  s                     0.496   0.000  \n",
            "   [0]  novel                 0.497   8.094  \n",
            "   [1]  pride                 0.500   0.000  \n",
            "   [0]  and                   0.502   2.860  \n",
            "   [0]  prejudice             0.505   10.689 \n",
            "   [1]  is                    0.507   0.000  \n",
            "   [0]  without               0.507   8.051  \n",
            "   [1]  a                     0.507   0.000  \n",
            "   [1]  doubt                 0.507   0.000  \n",
            "   [0]  one                   0.506   5.541  \n",
            "   [1]  of                    0.504   0.000  \n",
            "   [0]  my                    0.502   4.567  \n",
            "   [1]  favorite              0.502   0.000  \n",
            "   [0]  books                 0.501   7.277  \n",
            "   [1]  and                   0.502   0.000  \n",
            "   [1]  now                   0.503   0.000  \n",
            "   [0]  finally               0.505   8.622  \n",
            "   [0]  it                    0.505   3.793  \n",
            "   [0]  has                   0.505   4.096  \n",
            " Sample 2.\n",
            "   [0]  very                  0.490   4.993  \n",
            "   [0]  entertaining          0.490   6.485  \n",
            "   [0]  suspense              0.489   9.611  \n",
            "   [0]  movie                 0.489   3.513  \n",
            "   [1]  from                  0.489   0.000  \n",
            "   [1]  germany               0.488   0.000  \n",
            "   [1]  if                    0.488   0.000  \n",
            "   [1]  you                   0.488   0.000  \n",
            "   [1]  love                  0.487   0.000  \n",
            "   [1]  the                   0.490   0.000  \n",
            "   [1]  x                     0.493   0.000  \n",
            "   [0]  files                 0.495   10.158 \n",
            "   [1]  you                   0.495   0.000  \n",
            "   [1]  ll                    0.495   0.000  \n",
            "   [1]  like                  0.493   0.000  \n",
            "   [1]  this                  0.491   0.000  \n",
            "   [1]  one                   0.491   0.000  \n",
            "   [1]  too                   0.490   0.000  \n",
            "   [0]  it                    0.488   4.361  \n",
            "   [1]  gives                 0.485   0.000  \n",
            "Samples\n",
            "Sample 0 .  is the best mob film ever made it deserved more then what it got at the oscars nominated for things\n",
            "Sample 1 .  austin s novel pride and prejudice is without a doubt one of my favorite books and now finally it has\n",
            "Sample 2 .  very entertaining suspense movie from germany if you love the x files you ll like this one too it gives\n",
            "\n",
            "\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[0 1 0 0 1 1 1 0 0 1]...][[161 69848 52 69848 69848 0 372 25 69848 69848]...][[5611 52 72 537 0 372 25 42 4160 2400]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[0 1 0 0 1 1 1 0 0 1]...][[161 69848 52 69848 69848 0 372 25 69848 69848]...][[5611 52 72 537 0 372 25 42 4160 2400]...]\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[0 1 1 0 0 1 1 0 1 0]...][[9 69848 470 4 69848 69848 17 18 69848 13]...][[65 470 4 38 10 17 18 7 13 42]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[0 1 1 0 0 1 1 0 1 0]...][[9 69848 470 4 69848 69848 17 18 69848 13]...][[65 470 4 38 10 17 18 7 13 42]...]\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "global_step: 1941\n",
            " perplexity: 453.304\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            " percent of 3-grams captured: 0.517.\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            " percent of 2-grams captured: 0.695.\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            " percent of 4-grams captured: 0.272.\n",
            " geometric_avg: 0.461.\n",
            " arithmetic_avg: 0.495.\n",
            "global_step: 1941\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69381\n",
            " G train loss: 3.10175\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[0 1 1 0 0 1 1 0 1 0]...][[9 69848 470 4 69848 69848 17 18 69848 13]...][[65 470 4 38 10 17 18 7 13 42]...]\n",
            " Sample 0.\n",
            "   [0]  really                0.501   3.669  \n",
            "   [1]  wanted                0.504   0.000  \n",
            "   [1]  to                    0.506   0.000  \n",
            "   [0]  like                  0.507   3.890  \n",
            "   [0]  this                  0.508   1.772  \n",
            "   [1]  movie                 0.509   0.000  \n",
            "   [1]  but                   0.510   0.000  \n",
            "   [0]  it                    0.510   2.100  \n",
            "   [1]  was                   0.508   0.000  \n",
            "   [0]  just                  0.507   4.813  \n",
            "   [0]  imposable             0.505   16.660 \n",
            "   [1]  the                   0.505   0.000  \n",
            "   [1]  acting                0.506   0.000  \n",
            "   [0]  was                   0.506   3.400  \n",
            "   [0]  ultra                 0.506   10.045 \n",
            "   [1]  hammy                 0.507   0.000  \n",
            "   [1]  the                   0.508   0.000  \n",
            "   [0]  plot                  0.509   4.718  \n",
            "   [1]  was                   0.509   0.000  \n",
            "   [1]  annoying              0.509   0.000  \n",
            " Sample 1.\n",
            "   [1]  thought               0.485   0.000  \n",
            "   [0]  it                    0.489   3.608  \n",
            "   [1]  was                   0.492   0.000  \n",
            "   [0]  a                     0.494   1.685  \n",
            "   [0]  pretty                0.497   5.825  \n",
            "   [1]  good                  0.499   0.000  \n",
            "   [1]  movie                 0.500   0.000  \n",
            "   [1]  the                   0.502   0.000  \n",
            "   [1]  acting                0.502   0.000  \n",
            "   [1]  was                   0.502   0.000  \n",
            "   [0]  good                  0.502   4.585  \n",
            "   [0]  and                   0.502   3.382  \n",
            "   [1]  the                   0.501   0.000  \n",
            "   [0]  story                 0.501   3.355  \n",
            "   [0]  was                   0.501   4.108  \n",
            "   [0]  well                  0.500   5.931  \n",
            "   [1]  told                  0.500   0.000  \n",
            "   [1]  it                    0.500   0.000  \n",
            "   [0]  s                     0.500   2.574  \n",
            "   [1]  one                   0.501   0.000  \n",
            " Sample 2.\n",
            "   [0]  was                   0.508   4.531  \n",
            "   [0]  in                    0.508   5.810  \n",
            "   [1]  a                     0.508   0.000  \n",
            "   [1]  terrible              0.508   0.000  \n",
            "   [1]  way                   0.509   0.000  \n",
            "   [1]  long                  0.510   0.000  \n",
            "   [0]  before                0.511   7.262  \n",
            "   [1]  the                   0.512   0.000  \n",
            "   [0]  american              0.511   6.635  \n",
            "   [1]  came                  0.510   0.000  \n",
            "   [0]  saddam                0.511   15.531 \n",
            "   [0]  was                   0.512   5.346  \n",
            "   [0]  the                   0.513   1.961  \n",
            "   [1]  modern                0.514   0.000  \n",
            "   [0]  day                   0.515   6.305  \n",
            "   [0]  stalin                0.514   11.931 \n",
            "   [1]  and                   0.513   0.000  \n",
            "   [1]  hitler                0.513   0.000  \n",
            "   [1]  people                0.513   0.000  \n",
            "   [1]  with                  0.512   0.000  \n",
            "Samples\n",
            "Sample 0 .  really wanted to like this movie but it was just imposable the acting was ultra hammy the plot was annoying\n",
            "Sample 1 .  thought it was a pretty good movie the acting was good and the story was well told it s one\n",
            "Sample 2 .  was in a terrible way long before the american came saddam was the modern day stalin and hitler people with\n",
            "\n",
            "\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 1 1 1 1 1 1 1 0 1]...][[31 0 457 70 50 66 1102 3 4895 69848]...][[0 457 70 50 66 1102 3 4895 739 1077]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 1 1 1 1 1 1 1 0 1]...][[31 0 457 70 50 66 1102 3 4895 69848]...][[0 457 70 50 66 1102 3 4895 739 1077]...]\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[0 1 1 1 0 0 0 1 0 0]...][[161 69848 52 72 537 69848 69848 69848 42 69848]...][[5611 52 72 537 0 372 25 42 4160 2400]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[0 1 1 1 0 0 0 1 0 0]...][[161 69848 52 72 537 69848 69848 69848 42 69848]...][[5611 52 72 537 0 372 25 42 4160 2400]...]\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "global_step: 1944\n",
            " perplexity: 452.924\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            " percent of 3-grams captured: 0.510.\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            " percent of 2-grams captured: 0.688.\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            " percent of 4-grams captured: 0.262.\n",
            " geometric_avg: 0.451.\n",
            " arithmetic_avg: 0.487.\n",
            "global_step: 1944\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69385\n",
            " G train loss: 3.10235\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[0 1 1 1 0 0 0 1 0 0]...][[161 69848 52 72 537 69848 69848 69848 42 69848]...][[5611 52 72 537 0 372 25 42 4160 2400]...]\n",
            " Sample 0.\n",
            "   [0]  counts                0.497   11.394 \n",
            "   [1]  more                  0.497   0.000  \n",
            "   [1]  than                  0.497   0.000  \n",
            "   [1]  blood                 0.497   0.000  \n",
            "   [0]  the                   0.498   4.732  \n",
            "   [0]  rest                  0.497   6.597  \n",
            "   [0]  are                   0.495   5.831  \n",
            "   [1]  just                  0.495   0.000  \n",
            "   [0]  strangers             0.495   11.695 \n",
            "   [0]  speaks                0.495   11.415 \n",
            "   [1]  wyatt                 0.495   0.000  \n",
            "   [1]  s                     0.495   0.000  \n",
            "   [1]  father                0.496   0.000  \n",
            "   [1]  at                    0.497   0.000  \n",
            "   [1]  the                   0.498   0.000  \n",
            "   [0]  beginning             0.497   6.497  \n",
            "   [1]  of                    0.494   0.000  \n",
            "   [1]  the                   0.492   0.000  \n",
            "   [0]  film                  0.493   4.237  \n",
            "   [1]  the                   0.493   0.000  \n",
            " Sample 1.\n",
            "   [1]  baggy                 0.500   0.000  \n",
            "   [1]  sweaty                0.500   0.000  \n",
            "   [0]  pants                 0.501   10.603 \n",
            "   [1]  not                   0.503   0.000  \n",
            "   [0]  even                  0.504   6.588  \n",
            "   [0]  good                  0.506   5.271  \n",
            "   [0]  for                   0.507   4.517  \n",
            "   [0]  the                   0.509   2.145  \n",
            "   [1]  wwii                  0.510   0.000  \n",
            "   [0]  pump                  0.509   13.543 \n",
            "   [1]  up                    0.509   0.000  \n",
            "   [1]  the                   0.509   0.000  \n",
            "   [0]  home                  0.509   7.483  \n",
            "   [0]  front                 0.509   9.987  \n",
            "   [0]  so                    0.508   6.603  \n",
            "   [0]  they                  0.509   6.231  \n",
            "   [1]  buy                   0.509   0.000  \n",
            "   [1]  bonds                 0.509   0.000  \n",
            "   [1]  circuit               0.509   0.000  \n",
            "   [0]  it                    0.510   4.323  \n",
            " Sample 2.\n",
            "   [0]  it                    0.501   3.622  \n",
            "   [0]  was                   0.503   2.539  \n",
            "   [1]  one                   0.503   0.000  \n",
            "   [1]  of                    0.502   0.000  \n",
            "   [0]  the                   0.501   1.210  \n",
            "   [1]  best                  0.500   0.000  \n",
            "   [0]  movies                0.499   3.968  \n",
            "   [0]  i                     0.499   2.031  \n",
            "   [1]  have                  0.499   0.000  \n",
            "   [1]  seen                  0.499   0.000  \n",
            "   [1]  well                  0.498   0.000  \n",
            "   [1]  pirates               0.498   0.000  \n",
            "   [1]  of                    0.498   0.000  \n",
            "   [0]  the                   0.497   1.559  \n",
            "   [1]  caribbean             0.497   0.000  \n",
            "   [1]  is                    0.497   0.000  \n",
            "   [0]  first                 0.497   7.253  \n",
            "   [0]  then                  0.497   7.223  \n",
            "   [1]  dark                  0.497   0.000  \n",
            "   [0]  prince                0.499   10.310 \n",
            "Samples\n",
            "Sample 0 .  counts more than blood the rest are just strangers speaks wyatt s father at the beginning of the film the\n",
            "Sample 1 .  baggy sweaty pants not even good for the wwii pump up the home front so they buy bonds circuit it\n",
            "Sample 2 .  it was one of the best movies i have seen well pirates of the caribbean is first then dark prince\n",
            "\n",
            "\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[0 0 0 1 0 1 0 0 0 0]...][[1321 69848 69848 69848 550 69848 2 69848 69848 69848]...][[5826 9716 1721 550 6884 2 941 12 531 1621]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[0 0 0 1 0 1 0 0 0 0]...][[1321 69848 69848 69848 550 69848 2 69848 69848 69848]...][[5826 9716 1721 550 6884 2 941 12 531 1621]...]\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 0 0 0 1 1 0 0 0 1]...][[31 0 69848 69848 69848 66 1102 69848 69848 69848]...][[0 457 70 50 66 1102 3 4895 739 1077]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 0 0 0 1 1 0 0 0 1]...][[31 0 69848 69848 69848 66 1102 69848 69848 69848]...][[0 457 70 50 66 1102 3 4895 739 1077]...]\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "global_step: 1947\n",
            " perplexity: 452.186\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            " percent of 3-grams captured: 0.519.\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            " percent of 2-grams captured: 0.703.\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            " percent of 4-grams captured: 0.243.\n",
            " geometric_avg: 0.446.\n",
            " arithmetic_avg: 0.488.\n",
            "global_step: 1947\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69387\n",
            " G train loss: 3.10112\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 0 0 0 1 1 0 0 0 1]...][[31 0 69848 69848 69848 66 1102 69848 69848 69848]...][[0 457 70 50 66 1102 3 4895 739 1077]...]\n",
            " Sample 0.\n",
            "   [1]  the                   0.540   0.000  \n",
            "   [0]  beginning             0.538   5.534  \n",
            "   [0]  we                    0.535   6.193  \n",
            "   [0]  can                   0.533   4.189  \n",
            "   [1]  see                   0.533   0.000  \n",
            "   [1]  members               0.533   0.000  \n",
            "   [0]  of                    0.532   3.908  \n",
            "   [0]  troma                 0.532   9.778  \n",
            "   [0]  team                  0.532   9.469  \n",
            "   [1]  company               0.532   0.000  \n",
            "   [0]  and                   0.532   2.487  \n",
            "   [0]  uwe                   0.532   10.743 \n",
            "   [1]  boll                  0.531   0.000  \n",
            "   [0]  says                  0.532   8.869  \n",
            "   [1]  this                  0.532   0.000  \n",
            "   [0]  is                    0.532   2.446  \n",
            "   [1]  bad                   0.532   0.000  \n",
            "   [1]  it                    0.532   0.000  \n",
            "   [0]  s                     0.532   2.426  \n",
            "   [0]  a                     0.532   3.040  \n",
            " Sample 1.\n",
            "   [1]  woods                 0.498   0.000  \n",
            "   [0]  plays                 0.498   5.859  \n",
            "   [0]  a                     0.498   1.632  \n",
            "   [1]  stressed              0.498   0.000  \n",
            "   [1]  out                   0.497   0.000  \n",
            "   [1]  but                   0.494   0.000  \n",
            "   [1]  determined            0.493   0.000  \n",
            "   [0]  detective             0.491   8.981  \n",
            "   [1]  on                    0.489   0.000  \n",
            "   [0]  the                   0.488   1.523  \n",
            "   [1]  hunt                  0.487   0.000  \n",
            "   [0]  for                   0.486   4.156  \n",
            "   [0]  a                     0.487   2.024  \n",
            "   [1]  serial                0.486   0.000  \n",
            "   [1]  killer                0.486   0.000  \n",
            "   [1]  who                   0.486   0.000  \n",
            "   [1]  has                   0.486   0.000  \n",
            "   [1]  a                     0.487   0.000  \n",
            "   [0]  vendetta              0.487   14.253 \n",
            "   [0]  against               0.487   8.279  \n",
            " Sample 2.\n",
            "   [1]  m                     0.512   0.000  \n",
            "   [1]  a                     0.515   0.000  \n",
            "   [0]  big                   0.517   4.610  \n",
            "   [1]  fan                   0.516   0.000  \n",
            "   [1]  of                    0.514   0.000  \n",
            "   [0]  giallo                0.515   10.208 \n",
            "   [1]  movies                0.514   0.000  \n",
            "   [0]  and                   0.513   3.312  \n",
            "   [0]  lately                0.514   9.891  \n",
            "   [0]  i                     0.513   2.757  \n",
            "   [1]  have                  0.514   0.000  \n",
            "   [0]  become                0.515   6.838  \n",
            "   [1]  a                     0.516   0.000  \n",
            "   [1]  fan                   0.514   0.000  \n",
            "   [1]  of                    0.512   0.000  \n",
            "   [0]  director              0.512   7.436  \n",
            "   [0]  bava                  0.514   10.564 \n",
            "   [1]  but                   0.516   0.000  \n",
            "   [1]  this                  0.516   0.000  \n",
            "   [0]  film                  0.517   2.114  \n",
            "Samples\n",
            "Sample 0 .  the beginning we can see members of troma team company and uwe boll says this is bad it s a\n",
            "Sample 1 .  woods plays a stressed out but determined detective on the hunt for a serial killer who has a vendetta against\n",
            "Sample 2 .  m a big fan of giallo movies and lately i have become a fan of director bava but this film\n",
            "\n",
            "\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[0 1 1 0 0 1 0 1 0 0]...][[7 69848 27 77 69848 69848 99 69848 13 69848]...][[203 27 77 440 154 99 7 13 645 37]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[0 1 1 0 0 1 0 1 0 0]...][[7 69848 27 77 69848 69848 99 69848 13 69848]...][[203 27 77 440 154 99 7 13 645 37]...]\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[1 0 1 0 0 1 1 0 1 0]...][[1321 5826 69848 1721 69848 69848 2 941 69848 531]...][[5826 9716 1721 550 6884 2 941 12 531 1621]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[1 0 1 0 0 1 1 0 1 0]...][[1321 5826 69848 1721 69848 69848 2 941 69848 531]...][[5826 9716 1721 550 6884 2 941 12 531 1621]...]\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "global_step: 1950\n",
            " perplexity: 451.653\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            " percent of 3-grams captured: 0.525.\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            " percent of 2-grams captured: 0.713.\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            " percent of 4-grams captured: 0.242.\n",
            " geometric_avg: 0.449.\n",
            " arithmetic_avg: 0.493.\n",
            "global_step: 1950\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69389\n",
            " G train loss: 3.10079\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[1 0 1 0 0 1 1 0 1 0]...][[1321 5826 69848 1721 69848 69848 2 941 69848 531]...][[5826 9716 1721 550 6884 2 941 12 531 1621]...]\n",
            " Sample 0.\n",
            "   [1]  chow                  0.524   0.000  \n",
            "   [0]  yun                   0.521   11.871 \n",
            "   [1]  fat                   0.515   0.000  \n",
            "   [0]  says                  0.512   7.910  \n",
            "   [0]  covering              0.510   15.973 \n",
            "   [1]  a                     0.511   0.000  \n",
            "   [1]  baby                  0.512   0.000  \n",
            "   [0]  s                     0.513   5.097  \n",
            "   [1]  eyes                  0.513   0.000  \n",
            "   [0]  x                     0.513   10.617 \n",
            "   [0]  rated                 0.511   10.006 \n",
            "   [0]  action                0.509   8.509  \n",
            "   [0]  he                    0.508   5.481  \n",
            "   [0]  s                     0.509   2.981  \n",
            "   [0]  not                   0.510   4.099  \n",
            "   [1]  wrong                 0.512   0.000  \n",
            "   [1]  hard                  0.514   0.000  \n",
            "   [0]  boiled                0.514   13.099 \n",
            "   [0]  is                    0.515   4.042  \n",
            "   [0]  a                     0.516   1.804  \n",
            " Sample 1.\n",
            "   [1]  will                  0.497   0.000  \n",
            "   [0]  give                  0.500   4.919  \n",
            "   [1]  you                   0.503   0.000  \n",
            "   [0]  two                   0.505   9.555  \n",
            "   [0]  reasons               0.506   7.439  \n",
            "   [0]  for                   0.507   4.216  \n",
            "   [0]  watching              0.507   5.366  \n",
            "   [0]  this                  0.507   2.753  \n",
            "   [1]  sci                   0.508   0.000  \n",
            "   [0]  fi                    0.508   6.480  \n",
            "   [0]  potboiler             0.509   12.131 \n",
            "   [0]  about                 0.511   4.922  \n",
            "   [1]  a                     0.513   0.000  \n",
            "   [0]  solar                 0.514   9.631  \n",
            "   [1]  burst                 0.513   0.000  \n",
            "   [1]  that                  0.512   0.000  \n",
            "   [1]  threatens             0.511   0.000  \n",
            "   [0]  to                    0.510   4.424  \n",
            "   [1]  wipe                  0.509   0.000  \n",
            "   [0]  out                   0.507   5.068  \n",
            " Sample 2.\n",
            "   [0]  episode               0.502   6.689  \n",
            "   [1]  should                0.505   0.000  \n",
            "   [1]  have                  0.508   0.000  \n",
            "   [0]  been                  0.511   2.392  \n",
            "   [1]  carefully             0.512   0.000  \n",
            "   [0]  thought               0.513   9.670  \n",
            "   [1]  out                   0.511   0.000  \n",
            "   [0]  several               0.510   7.910  \n",
            "   [0]  times                 0.508   6.064  \n",
            "   [1]  and                   0.507   0.000  \n",
            "   [0]  with                  0.506   6.551  \n",
            "   [0]  careful               0.507   11.115 \n",
            "   [1]  consideration         0.508   0.000  \n",
            "   [1]  to                    0.509   0.000  \n",
            "   [0]  the                   0.512   3.309  \n",
            "   [0]  fans                  0.512   9.639  \n",
            "   [1]  and                   0.512   0.000  \n",
            "   [1]  the                   0.513   0.000  \n",
            "   [0]  heart                 0.513   7.449  \n",
            "   [0]  of                    0.512   2.164  \n",
            "Samples\n",
            "Sample 0 .  chow yun fat says covering a baby s eyes x rated action he s not wrong hard boiled is a\n",
            "Sample 1 .  will give you two reasons for watching this sci fi potboiler about a solar burst that threatens to wipe out\n",
            "Sample 2 .  episode should have been carefully thought out several times and with careful consideration to the fans and the heart of\n",
            "\n",
            "\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[1 1 1 1 0 1 1 1 1 1]...][[4831 4881 3905 12 88 69848 237 1 1675 698]...][[4881 3905 12 88 1571 237 1 1675 698 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[1 1 1 1 0 1 1 1 1 1]...][[4831 4881 3905 12 88 69848 237 1 1675 698]...][[4881 3905 12 88 1571 237 1 1675 698 0]...]\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[1 0 0 1 1 1 1 0 0 1]...][[7 203 69848 69848 440 154 99 7 69848 69848]...][[203 27 77 440 154 99 7 13 645 37]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[1 0 0 1 1 1 1 0 0 1]...][[7 203 69848 69848 440 154 99 7 69848 69848]...][[203 27 77 440 154 99 7 13 645 37]...]\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "global_step: 1953\n",
            " perplexity: 451.639\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            " percent of 3-grams captured: 0.477.\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            " percent of 2-grams captured: 0.689.\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            " percent of 4-grams captured: 0.215.\n",
            " geometric_avg: 0.413.\n",
            " arithmetic_avg: 0.460.\n",
            "global_step: 1953\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69390\n",
            " G train loss: 3.09969\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[1 0 0 1 1 1 1 0 0 1]...][[7 203 69848 69848 440 154 99 7 69848 69848]...][[203 27 77 440 154 99 7 13 645 37]...]\n",
            " Sample 0.\n",
            "   [1]  must                  0.493   0.000  \n",
            "   [0]  have                  0.492   2.809  \n",
            "   [0]  been                  0.494   3.443  \n",
            "   [1]  several               0.495   0.000  \n",
            "   [1]  years                 0.498   0.000  \n",
            "   [1]  after                 0.501   0.000  \n",
            "   [1]  it                    0.504   0.000  \n",
            "   [0]  was                   0.504   1.677  \n",
            "   [0]  released              0.504   6.352  \n",
            "   [1]  so                    0.505   0.000  \n",
            "   [1]  don                   0.506   0.000  \n",
            "   [1]  t                     0.506   0.000  \n",
            "   [1]  know                  0.505   0.000  \n",
            "   [0]  why                   0.505   5.546  \n",
            "   [1]  it                    0.505   0.000  \n",
            "   [0]  was                   0.504   1.563  \n",
            "   [1]  at                    0.504   0.000  \n",
            "   [0]  the                   0.506   2.717  \n",
            "   [0]  movies                0.507   7.496  \n",
            "   [0]  but                   0.508   4.006  \n",
            " Sample 1.\n",
            "   [1]  movie                 0.524   0.000  \n",
            "   [1]  is                    0.524   0.000  \n",
            "   [1]  so                    0.522   0.000  \n",
            "   [1]  weird                 0.521   0.000  \n",
            "   [1]  it                    0.520   0.000  \n",
            "   [1]  is                    0.519   0.000  \n",
            "   [1]  almost                0.519   0.000  \n",
            "   [0]  comical               0.521   10.701 \n",
            "   [1]  better                0.523   0.000  \n",
            "   [0]  known                 0.523   7.913  \n",
            "   [0]  as                    0.524   4.816  \n",
            "   [0]  godzilla              0.525   9.463  \n",
            "   [1]  vs                    0.526   0.000  \n",
            "   [1]  the                   0.528   0.000  \n",
            "   [0]  smog                  0.527   13.540 \n",
            "   [1]  monster               0.525   0.000  \n",
            "   [0]  this                  0.524   5.223  \n",
            "   [1]  flick                 0.524   0.000  \n",
            "   [1]  tries                 0.524   0.000  \n",
            "   [0]  to                    0.524   2.091  \n",
            " Sample 2.\n",
            "   [0]  finally               0.498   6.785  \n",
            "   [1]  got                   0.497   0.000  \n",
            "   [0]  myself                0.496   5.148  \n",
            "   [1]  set                   0.496   0.000  \n",
            "   [1]  up                    0.495   0.000  \n",
            "   [1]  on                    0.495   0.000  \n",
            "   [0]  mail                  0.493   11.883 \n",
            "   [0]  order                 0.492   8.868  \n",
            "   [0]  dvd                   0.491   8.564  \n",
            "   [0]  rental                0.491   9.403  \n",
            "   [1]  so                    0.490   0.000  \n",
            "   [1]  i                     0.489   0.000  \n",
            "   [0]  could                 0.488   5.431  \n",
            "   [1]  find                  0.488   0.000  \n",
            "   [1]  movies                0.489   0.000  \n",
            "   [1]  not                   0.489   0.000  \n",
            "   [1]  available             0.488   0.000  \n",
            "   [0]  to                    0.489   2.885  \n",
            "   [0]  me                    0.488   5.522  \n",
            "   [0]  in                    0.488   4.394  \n",
            "Samples\n",
            "Sample 0 .  must have been several years after it was released so don t know why it was at the movies but\n",
            "Sample 1 .  movie is so weird it is almost comical better known as godzilla vs the smog monster this flick tries to\n",
            "Sample 2 .  finally got myself set up on mail order dvd rental so i could find movies not available to me in\n",
            "\n",
            "\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 0 1 1 0 1 1 1 0 0]...][[165 221 69848 9 1818 69848 21 940 22 69848]...][[221 283 9 1818 89 21 940 22 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 0 1 1 0 1 1 1 0 0]...][[165 221 69848 9 1818 69848 21 940 22 69848]...][[221 283 9 1818 89 21 940 22 104 9]...]\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[0 0 1 1 0 0 0 1 0 1]...][[4831 69848 69848 12 88 69848 69848 69848 1675 69848]...][[4881 3905 12 88 1571 237 1 1675 698 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[0 0 1 1 0 0 0 1 0 1]...][[4831 69848 69848 12 88 69848 69848 69848 1675 69848]...][[4881 3905 12 88 1571 237 1 1675 698 0]...]\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "global_step: 1956\n",
            " perplexity: 451.450\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            " percent of 3-grams captured: 0.508.\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            " percent of 2-grams captured: 0.725.\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            " percent of 4-grams captured: 0.236.\n",
            " geometric_avg: 0.443.\n",
            " arithmetic_avg: 0.490.\n",
            "global_step: 1956\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69392\n",
            " G train loss: 3.10014\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[0 0 1 1 0 0 0 1 0 1]...][[4831 69848 69848 12 88 69848 69848 69848 1675 69848]...][[4881 3905 12 88 1571 237 1 1675 698 0]...]\n",
            " Sample 0.\n",
            "   [0]  meryl                 0.471   9.566  \n",
            "   [0]  streep                0.471   7.839  \n",
            "   [1]  s                     0.467   0.000  \n",
            "   [1]  most                  0.464   0.000  \n",
            "   [0]  compelling            0.461   8.313  \n",
            "   [0]  performance           0.460   6.394  \n",
            "   [0]  and                   0.459   2.087  \n",
            "   [1]  lord                  0.458   0.000  \n",
            "   [0]  knows                 0.460   9.281  \n",
            "   [1]  the                   0.461   0.000  \n",
            "   [0]  woman                 0.463   6.569  \n",
            "   [0]  has                   0.464   6.269  \n",
            "   [0]  turned                0.464   7.956  \n",
            "   [0]  in                    0.463   3.051  \n",
            "   [1]  a                     0.461   0.000  \n",
            "   [0]  few                   0.461   4.598  \n",
            "   [1]  during                0.460   0.000  \n",
            "   [1]  her                   0.459   0.000  \n",
            "   [1]  career                0.459   0.000  \n",
            "   [0]  i                     0.458   5.572  \n",
            " Sample 1.\n",
            "   [1]  the                   0.478   0.000  \n",
            "   [0]  hard                  0.479   7.856  \n",
            "   [1]  boiled                0.480   0.000  \n",
            "   [0]  detective             0.480   8.527  \n",
            "   [0]  stories               0.481   7.980  \n",
            "   [0]  of                    0.481   3.932  \n",
            "   [0]  dashiell              0.483   10.640 \n",
            "   [0]  hammett               0.484   10.901 \n",
            "   [0]  and                   0.486   3.290  \n",
            "   [1]  raymond               0.488   0.000  \n",
            "   [0]  chandler              0.489   11.008 \n",
            "   [1]  have                  0.490   0.000  \n",
            "   [1]  fitted                0.489   0.000  \n",
            "   [1]  to                    0.489   0.000  \n",
            "   [1]  cinema                0.487   0.000  \n",
            "   [0]  like                  0.487   6.478  \n",
            "   [1]  a                     0.486   0.000  \n",
            "   [0]  fox                   0.485   9.957  \n",
            "   [1]  in                    0.485   0.000  \n",
            "   [0]  a                     0.484   2.819  \n",
            " Sample 2.\n",
            "   [1]  seven                 0.504   0.000  \n",
            "   [1]  year                  0.501   0.000  \n",
            "   [0]  old                   0.499   6.682  \n",
            "   [1]  boy                   0.498   0.000  \n",
            "   [1]  omi                   0.498   0.000  \n",
            "   [0]  is                    0.497   2.433  \n",
            "   [0]  sent                  0.497   8.167  \n",
            "   [1]  from                  0.496   0.000  \n",
            "   [1]  india                 0.496   0.000  \n",
            "   [0]  to                    0.496   3.113  \n",
            "   [1]  live                  0.495   0.000  \n",
            "   [0]  with                  0.495   3.799  \n",
            "   [0]  an                    0.495   4.158  \n",
            "   [1]  uncle                 0.494   0.000  \n",
            "   [0]  in                    0.493   5.050  \n",
            "   [0]  ottawa                0.493   14.274 \n",
            "   [1]  nobody                0.493   0.000  \n",
            "   [0]  is                    0.493   3.888  \n",
            "   [1]  told                  0.492   0.000  \n",
            "   [0]  that                  0.490   3.159  \n",
            "Samples\n",
            "Sample 0 .  meryl streep s most compelling performance and lord knows the woman has turned in a few during her career i\n",
            "Sample 1 .  the hard boiled detective stories of dashiell hammett and raymond chandler have fitted to cinema like a fox in a\n",
            "Sample 2 .  seven year old boy omi is sent from india to live with an uncle in ottawa nobody is told that\n",
            "\n",
            "\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[0 1 0 1 1 0 0 0 1 0]...][[147 69848 5 69848 3 200 69848 69848 69848 12]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[0 1 0 1 1 0 0 0 1 0]...][[147 69848 5 69848 3 200 69848 69848 69848 12]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 1 0 1 1 0 1 1 0 1]...][[165 221 283 69848 1818 89 69848 940 22 69848]...][[221 283 9 1818 89 21 940 22 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 1 0 1 1 0 1 1 0 1]...][[165 221 283 69848 1818 89 69848 940 22 69848]...][[221 283 9 1818 89 21 940 22 104 9]...]\n",
            "2020-03-24 03:48:06.208881: E tensorflow/core/util/events_writer.cc:162] The events file maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0 has disappeared.\n",
            "2020-03-24 03:48:06.208934: E tensorflow/core/util/events_writer.cc:131] Failed to flush 584 events to maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "global_step: 1959\n",
            " perplexity: 451.725\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            " percent of 3-grams captured: 0.482.\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            " percent of 2-grams captured: 0.713.\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            " percent of 4-grams captured: 0.221.\n",
            " geometric_avg: 0.423.\n",
            " arithmetic_avg: 0.472.\n",
            "global_step: 1959\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69391\n",
            " G train loss: 3.10102\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 1 0 1 1 0 1 1 0 1]...][[165 221 283 69848 1818 89 69848 940 22 69848]...][[221 283 9 1818 89 21 940 22 104 9]...]\n",
            " Sample 0.\n",
            "   [1]  almost                0.521   0.000  \n",
            "   [1]  everything            0.525   0.000  \n",
            "   [0]  i                     0.525   4.122  \n",
            "   [1]  normally              0.525   0.000  \n",
            "   [1]  don                   0.525   0.000  \n",
            "   [0]  t                     0.523   0.118  \n",
            "   [1]  comment               0.522   0.000  \n",
            "   [1]  on                    0.522   0.000  \n",
            "   [0]  films                 0.521   6.560  \n",
            "   [1]  i                     0.519   0.000  \n",
            "   [0]  haven                 0.518   4.934  \n",
            "   [1]  t                     0.516   0.000  \n",
            "   [1]  seen                  0.515   0.000  \n",
            "   [1]  all                   0.516   0.000  \n",
            "   [1]  the                   0.517   0.000  \n",
            "   [0]  way                   0.519   5.658  \n",
            "   [0]  through               0.520   6.766  \n",
            "   [0]  but                   0.522   5.460  \n",
            "   [1]  since                 0.523   0.000  \n",
            "   [0]  i                     0.522   2.380  \n",
            " Sample 1.\n",
            "   [1]  is                    0.500   0.000  \n",
            "   [1]  just                  0.499   0.000  \n",
            "   [0]  one                   0.496   2.830  \n",
            "   [1]  of                    0.494   0.000  \n",
            "   [0]  those                 0.492   5.062  \n",
            "   [0]  pro                   0.492   10.624 \n",
            "   [0]  tend                  0.493   9.040  \n",
            "   [0]  be                    0.494   6.627  \n",
            "   [1]  art                   0.494   0.000  \n",
            "   [0]  house                 0.493   9.275  \n",
            "   [1]  junk                  0.492   0.000  \n",
            "   [1]  euro                  0.490   0.000  \n",
            "   [0]  made                  0.489   6.281  \n",
            "   [0]  in                    0.489   3.618  \n",
            "   [1]  70s                   0.488   0.000  \n",
            "   [1]  i                     0.487   0.000  \n",
            "   [1]  do                    0.488   0.000  \n",
            "   [0]  not                   0.488   3.478  \n",
            "   [1]  know                  0.489   0.000  \n",
            "   [1]  why                   0.489   0.000  \n",
            " Sample 2.\n",
            "   [0]  and                   0.512   5.079  \n",
            "   [1]  hollywood             0.512   0.000  \n",
            "   [1]  had                   0.511   0.000  \n",
            "   [1]  been                  0.512   0.000  \n",
            "   [0]  on                    0.511   5.952  \n",
            "   [0]  the                   0.512   1.710  \n",
            "   [1]  map                   0.511   0.000  \n",
            "   [1]  as                    0.512   0.000  \n",
            "   [0]  the                   0.514   1.930  \n",
            "   [1]  centre                0.515   0.000  \n",
            "   [1]  of                    0.515   0.000  \n",
            "   [1]  the                   0.514   0.000  \n",
            "   [0]  cinematic             0.514   7.980  \n",
            "   [1]  world                 0.513   0.000  \n",
            "   [0]  for                   0.512   5.685  \n",
            "   [1]  a                     0.511   0.000  \n",
            "   [1]  little                0.510   0.000  \n",
            "   [0]  over                  0.510   9.545  \n",
            "   [1]  a                     0.509   0.000  \n",
            "   [0]  decade                0.508   7.619  \n",
            "Samples\n",
            "Sample 0 .  almost everything i normally don t comment on films i haven t seen all the way through but since i\n",
            "Sample 1 .  is just one of those pro tend be art house junk euro made in 70s i do not know why\n",
            "Sample 2 .  and hollywood had been on the map as the centre of the cinematic world for a little over a decade\n",
            "\n",
            "\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[0 0 0 1 0 0 1 1 0 1]...][[35 69848 69848 69848 4 69848 69848 1437 22 69848]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[0 0 0 1 0 0 1 1 0 1]...][[35 69848 69848 69848 4 69848 69848 1437 22 69848]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[1 1 0 0 1 0 0 1 0 0]...][[147 10 5 69848 69848 200 69848 69848 685 69848]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[1 1 0 0 1 0 0 1 0 0]...][[147 10 5 69848 69848 200 69848 69848 685 69848]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "global_step: 1962\n",
            " perplexity: 451.590\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            " percent of 3-grams captured: 0.513.\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            " percent of 2-grams captured: 0.709.\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            " percent of 4-grams captured: 0.248.\n",
            " geometric_avg: 0.448.\n",
            " arithmetic_avg: 0.490.\n",
            "global_step: 1962\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69391\n",
            " G train loss: 3.10157\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[1 1 0 0 1 0 0 1 0 0]...][[147 10 5 69848 69848 200 69848 69848 685 69848]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            " Sample 0.\n",
            "   [1]  this                  0.497   0.000  \n",
            "   [1]  is                    0.500   0.000  \n",
            "   [0]  one                   0.499   2.140  \n",
            "   [0]  of                    0.496   0.674  \n",
            "   [1]  big                   0.494   0.000  \n",
            "   [0]  s                     0.492   8.841  \n",
            "   [0]  best                  0.490   4.775  \n",
            "   [1]  jack                  0.490   0.000  \n",
            "   [0]  s                     0.490   5.714  \n",
            "   [0]  single                0.489   7.262  \n",
            "   [0]  role                  0.489   6.928  \n",
            "   [1]  in                    0.490   0.000  \n",
            "   [0]  1931                  0.491   10.809 \n",
            "   [1]  split                 0.493   0.000  \n",
            "   [0]  into                  0.494   6.029  \n",
            "   [0]  two                   0.495   5.790  \n",
            "   [0]  for                   0.496   7.044  \n",
            "   [0]  the                   0.496   1.978  \n",
            "   [0]  band                  0.495   8.986  \n",
            "   [1]  waggon                0.494   0.000  \n",
            " Sample 1.\n",
            "   [1]  may                   0.505   0.000  \n",
            "   [0]  not                   0.508   5.255  \n",
            "   [0]  be                    0.509   4.319  \n",
            "   [0]  the                   0.508   6.188  \n",
            "   [0]  one                   0.507   6.896  \n",
            "   [1]  to                    0.505   0.000  \n",
            "   [0]  review                0.503   6.730  \n",
            "   [0]  this                  0.502   2.438  \n",
            "   [1]  movie                 0.502   0.000  \n",
            "   [0]  because               0.501   5.327  \n",
            "   [1]  after                 0.501   0.000  \n",
            "   [1]  45                    0.501   0.000  \n",
            "   [0]  minutes               0.502   7.163  \n",
            "   [1]  of                    0.502   0.000  \n",
            "   [0]  pure                  0.503   8.539  \n",
            "   [0]  boredom               0.502   10.405 \n",
            "   [1]  and                   0.501   0.000  \n",
            "   [1]  stupidity             0.501   0.000  \n",
            "   [0]  i                     0.500   3.525  \n",
            "   [1]  turned                0.499   0.000  \n",
            " Sample 2.\n",
            "   [0]  regular               0.499   9.402  \n",
            "   [1]  teens                 0.497   0.000  \n",
            "   [0]  what                  0.495   6.081  \n",
            "   [0]  normal                0.497   11.485 \n",
            "   [1]  teenager              0.499   0.000  \n",
            "   [1]  wants                 0.501   0.000  \n",
            "   [0]  to                    0.502   1.879  \n",
            "   [1]  watch                 0.501   0.000  \n",
            "   [0]  or                    0.501   5.695  \n",
            "   [1]  even                  0.499   0.000  \n",
            "   [0]  cares                 0.497   9.804  \n",
            "   [0]  about                 0.497   4.469  \n",
            "   [0]  some                  0.500   5.493  \n",
            "   [0]  spoilt                0.500   11.445 \n",
            "   [0]  brat                  0.502   10.728 \n",
            "   [0]  who                   0.502   4.106  \n",
            "   [0]  they                  0.504   6.630  \n",
            "   [0]  have                  0.507   2.530  \n",
            "   [1]  nothing               0.506   0.000  \n",
            "   [0]  common                0.505   10.320 \n",
            "Samples\n",
            "Sample 0 .  this is one of big s best jack s single role in 1931 split into two for the band waggon\n",
            "Sample 1 .  may not be the one to review this movie because after 45 minutes of pure boredom and stupidity i turned\n",
            "Sample 2 .  regular teens what normal teenager wants to watch or even cares about some spoilt brat who they have nothing common\n",
            "\n",
            "\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 1 0 1 1 0 0 1 0 1]...][[1321 46 20 69848 2 115 69848 69848 541 69848]...][[46 20 27 2 115 119 35 541 4 496]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 1 0 1 1 0 0 1 0 1]...][[1321 46 20 69848 2 115 69848 69848 541 69848]...][[46 20 27 2 115 119 35 541 4 496]...]\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[1 0 0 0 1 0 1 1 0 0]...][[35 276 69848 69848 69848 1738 69848 1437 22 69848]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[1 0 0 0 1 0 1 1 0 0]...][[35 276 69848 69848 69848 1738 69848 1437 22 69848]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "global_step: 1965\n",
            " perplexity: 451.411\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            " percent of 3-grams captured: 0.508.\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            " percent of 2-grams captured: 0.697.\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            " percent of 4-grams captured: 0.248.\n",
            " geometric_avg: 0.445.\n",
            " arithmetic_avg: 0.484.\n",
            "global_step: 1965\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69393\n",
            " G train loss: 3.10241\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[1 0 0 0 1 0 1 1 0 0]...][[35 276 69848 69848 69848 1738 69848 1437 22 69848]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            " Sample 0.\n",
            "   [1]  american              0.526   0.000  \n",
            "   [0]  businessman           0.525   9.986  \n",
            "   [0]  wants                 0.523   8.052  \n",
            "   [0]  to                    0.520   2.385  \n",
            "   [1]  build                 0.518   0.000  \n",
            "   [0]  a                     0.517   2.878  \n",
            "   [1]  hotel                 0.517   0.000  \n",
            "   [1]  on                    0.517   0.000  \n",
            "   [0]  a                     0.516   2.246  \n",
            "   [0]  remote                0.515   7.373  \n",
            "   [1]  island                0.512   0.000  \n",
            "   [0]  so                    0.510   6.311  \n",
            "   [1]  he                    0.509   0.000  \n",
            "   [1]  has                   0.509   0.000  \n",
            "   [1]  someone               0.511   0.000  \n",
            "   [1]  sail                  0.513   0.000  \n",
            "   [1]  him                   0.514   0.000  \n",
            "   [1]  and                   0.515   0.000  \n",
            "   [1]  his                   0.515   0.000  \n",
            "   [0]  girlfriend            0.515   7.568  \n",
            " Sample 1.\n",
            "   [0]  days                  0.495   7.030  \n",
            "   [1]  after                 0.497   0.000  \n",
            "   [1]  seeing                0.497   0.000  \n",
            "   [1]  conceiving            0.495   0.000  \n",
            "   [1]  ada                   0.494   0.000  \n",
            "   [0]  i                     0.492   4.124  \n",
            "   [0]  am                    0.490   2.908  \n",
            "   [1]  still                 0.488   0.000  \n",
            "   [1]  in                    0.488   0.000  \n",
            "   [1]  awe                   0.488   0.000  \n",
            "   [1]  that                  0.487   0.000  \n",
            "   [0]  any                   0.489   7.049  \n",
            "   [1]  group                 0.490   0.000  \n",
            "   [1]  of                    0.490   0.000  \n",
            "   [0]  people                0.491   5.574  \n",
            "   [0]  would                 0.492   5.842  \n",
            "   [1]  spend                 0.493   0.000  \n",
            "   [0]  so                    0.493   4.669  \n",
            "   [1]  much                  0.492   0.000  \n",
            "   [1]  time                  0.492   0.000  \n",
            " Sample 2.\n",
            "   [0]  love                  0.514   3.901  \n",
            "   [1]  a                     0.512   0.000  \n",
            "   [0]  film                  0.511   3.272  \n",
            "   [0]  that                  0.509   2.668  \n",
            "   [0]  doesn                 0.509   7.223  \n",
            "   [0]  t                     0.509   0.393  \n",
            "   [1]  the                   0.509   0.000  \n",
            "   [0]  plot                  0.509   5.276  \n",
            "   [0]  and                   0.509   2.725  \n",
            "   [0]  the                   0.509   2.073  \n",
            "   [1]  story                 0.509   0.000  \n",
            "   [0]  and                   0.508   2.312  \n",
            "   [1]  the                   0.509   0.000  \n",
            "   [1]  interest              0.510   0.000  \n",
            "   [1]  in                    0.512   0.000  \n",
            "   [1]  it                    0.513   0.000  \n",
            "   [1]  to                    0.513   0.000  \n",
            "   [0]  the                   0.512   4.800  \n",
            "   [1]  audience              0.513   0.000  \n",
            "   [0]  this                  0.511   4.366  \n",
            "Samples\n",
            "Sample 0 .  american businessman wants to build a hotel on a remote island so he has someone sail him and his girlfriend\n",
            "Sample 1 .  days after seeing conceiving ada i am still in awe that any group of people would spend so much time\n",
            "Sample 2 .  love a film that doesn t the plot and the story and the interest in it to the audience this\n",
            "\n",
            "\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[0 1 1 1 1 1 1 0 0 1]...][[2 69848 337 63 15 2 1534 43 69848 69848]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[0 1 1 1 1 1 1 0 0 1]...][[2 69848 337 63 15 2 1534 43 69848 69848]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 0 0 0 1 1 1 0 1 1]...][[1321 46 69848 69848 69848 115 119 35 69848 4]...][[46 20 27 2 115 119 35 541 4 496]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 0 0 0 1 1 1 0 1 1]...][[1321 46 69848 69848 69848 115 119 35 69848 4]...][[46 20 27 2 115 119 35 541 4 496]...]\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "global_step: 1968\n",
            " perplexity: 450.589\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            " percent of 3-grams captured: 0.520.\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            " percent of 2-grams captured: 0.711.\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            " percent of 4-grams captured: 0.244.\n",
            " geometric_avg: 0.449.\n",
            " arithmetic_avg: 0.492.\n",
            "global_step: 1968\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69394\n",
            " G train loss: 3.10197\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 0 0 0 1 1 1 0 1 1]...][[1321 46 69848 69848 69848 115 119 35 69848 4]...][[46 20 27 2 115 119 35 541 4 496]...]\n",
            " Sample 0.\n",
            "   [1]  if                    0.502   0.000  \n",
            "   [0]  you                   0.501   1.683  \n",
            "   [0]  have                  0.500   2.752  \n",
            "   [0]  a                     0.499   2.751  \n",
            "   [1]  little                0.497   0.000  \n",
            "   [1]  over                  0.496   0.000  \n",
            "   [1]  an                    0.495   0.000  \n",
            "   [0]  hour                  0.496   6.722  \n",
            "   [1]  to                    0.497   0.000  \n",
            "   [1]  kill                  0.497   0.000  \n",
            "   [1]  and                   0.497   0.000  \n",
            "   [1]  find                  0.497   0.000  \n",
            "   [1]  paint                 0.497   0.000  \n",
            "   [0]  to                    0.497   3.409  \n",
            "   [0]  be                    0.498   3.504  \n",
            "   [1]  too                   0.498   0.000  \n",
            "   [0]  exciting              0.498   7.981  \n",
            "   [1]  i                     0.498   0.000  \n",
            "   [0]  d                     0.497   5.176  \n",
            "   [1]  suggest               0.496   0.000  \n",
            " Sample 1.\n",
            "   [0]  loved                 0.555   3.671  \n",
            "   [1]  this                  0.557   0.000  \n",
            "   [1]  movie                 0.556   0.000  \n",
            "   [1]  it                    0.554   0.000  \n",
            "   [1]  s                     0.552   0.000  \n",
            "   [1]  truly                 0.549   0.000  \n",
            "   [0]  bizarre               0.547   8.837  \n",
            "   [1]  extremely             0.545   0.000  \n",
            "   [0]  funny                 0.545   6.478  \n",
            "   [1]  morbid                0.548   0.000  \n",
            "   [0]  witty                 0.550   9.500  \n",
            "   [0]  it                    0.551   4.726  \n",
            "   [1]  makes                 0.552   0.000  \n",
            "   [0]  no                    0.552   4.971  \n",
            "   [1]  sense                 0.552   0.000  \n",
            "   [0]  to                    0.551   3.370  \n",
            "   [0]  tell                  0.549   6.770  \n",
            "   [0]  about                 0.548   4.700  \n",
            "   [1]  the                   0.548   0.000  \n",
            "   [0]  contents              0.549   12.447 \n",
            " Sample 2.\n",
            "   [1]  movie                 0.513   0.000  \n",
            "   [1]  can                   0.515   0.000  \n",
            "   [0]  claim                 0.516   10.537 \n",
            "   [0]  to                    0.517   2.743  \n",
            "   [0]  be                    0.517   3.374  \n",
            "   [0]  a                     0.518   1.907  \n",
            "   [1]  low                   0.519   0.000  \n",
            "   [1]  low                   0.520   0.000  \n",
            "   [1]  budget                0.520   0.000  \n",
            "   [0]  gore                  0.520   8.647  \n",
            "   [1]  movie                 0.521   0.000  \n",
            "   [0]  without               0.521   7.886  \n",
            "   [1]  any                   0.521   0.000  \n",
            "   [1]  attempt               0.521   0.000  \n",
            "   [0]  to                    0.520   2.860  \n",
            "   [0]  actually              0.520   6.116  \n",
            "   [0]  any                   0.519   5.915  \n",
            "   [0]  talent                0.519   8.206  \n",
            "   [0]  even                  0.518   6.121  \n",
            "   [1]  though                0.518   0.000  \n",
            "Samples\n",
            "Sample 0 .  if you have a little over an hour to kill and find paint to be too exciting i d suggest\n",
            "Sample 1 .  loved this movie it s truly bizarre extremely funny morbid witty it makes no sense to tell about the contents\n",
            "Sample 2 .  movie can claim to be a low low budget gore movie without any attempt to actually any talent even though\n",
            "\n",
            "\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 0 1 0 1 0 1 1 1 0]...][[10 5 69848 64 69848 11 69848 312 1 9]...][[5 0 64 17 11 60 312 1 9 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 0 1 0 1 0 1 1 1 0]...][[10 5 69848 64 69848 11 69848 312 1 9]...][[5 0 64 17 11 60 312 1 9 27]...]\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[1 0 0 1 0 1 1 1 1 1]...][[2 371 69848 69848 15 69848 1534 43 20239 112]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[1 0 0 1 0 1 1 1 1 1]...][[2 371 69848 69848 15 69848 1534 43 20239 112]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "global_step: 1971\n",
            " perplexity: 450.256\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            " percent of 3-grams captured: 0.494.\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            " percent of 2-grams captured: 0.716.\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            " percent of 4-grams captured: 0.226.\n",
            " geometric_avg: 0.431.\n",
            " arithmetic_avg: 0.479.\n",
            "global_step: 1971\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69392\n",
            " G train loss: 3.10187\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[1 0 0 1 0 1 1 1 1 1]...][[2 371 69848 69848 15 69848 1534 43 20239 112]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            " Sample 0.\n",
            "   [1]  truly                 0.483   0.000  \n",
            "   [0]  nice                  0.483   6.258  \n",
            "   [0]  story                 0.481   5.562  \n",
            "   [1]  with                  0.478   0.000  \n",
            "   [0]  a                     0.476   2.452  \n",
            "   [1]  moral                 0.475   0.000  \n",
            "   [1]  about                 0.474   0.000  \n",
            "   [1]  brotherly             0.473   0.000  \n",
            "   [1]  love                  0.473   0.000  \n",
            "   [1]  describes             0.474   0.000  \n",
            "   [1]  this                  0.475   0.000  \n",
            "   [0]  odd                   0.477   9.133  \n",
            "   [0]  david                 0.477   7.562  \n",
            "   [1]  lynch                 0.477   0.000  \n",
            "   [1]  film                  0.477   0.000  \n",
            "   [0]  this                  0.476   4.141  \n",
            "   [0]  was                   0.474   2.644  \n",
            "   [1]  especially            0.472   0.000  \n",
            "   [1]  odd                   0.472   0.000  \n",
            "   [1]  because               0.473   0.000  \n",
            " Sample 1.\n",
            "   [0]  never                 0.495   7.610  \n",
            "   [1]  seems                 0.496   0.000  \n",
            "   [1]  to                    0.498   0.000  \n",
            "   [1]  amaze                 0.497   0.000  \n",
            "   [0]  me                    0.496   4.677  \n",
            "   [1]  how                   0.496   0.000  \n",
            "   [0]  bad                   0.497   5.233  \n",
            "   [0]  films                 0.495   5.015  \n",
            "   [0]  can                   0.494   6.921  \n",
            "   [1]  actually              0.495   0.000  \n",
            "   [0]  be                    0.496   3.068  \n",
            "   [0]  but                   0.497   5.163  \n",
            "   [0]  this                  0.497   3.852  \n",
            "   [1]  is                    0.496   0.000  \n",
            "   [1]  an                    0.495   0.000  \n",
            "   [0]  insult                0.494   9.073  \n",
            "   [1]  to                    0.494   0.000  \n",
            "   [1]  intelligence          0.495   0.000  \n",
            "   [1]  how                   0.494   0.000  \n",
            "   [0]  does                  0.494   7.589  \n",
            " Sample 2.\n",
            "   [1]  long                  0.496   0.000  \n",
            "   [0]  ago                   0.494   6.905  \n",
            "   [1]  i                     0.491   0.000  \n",
            "   [1]  wrote                 0.489   0.000  \n",
            "   [0]  my                    0.486   4.724  \n",
            "   [0]  ideas                 0.486   9.432  \n",
            "   [0]  as                    0.484   4.495  \n",
            "   [1]  to                    0.484   0.000  \n",
            "   [0]  what                  0.483   5.301  \n",
            "   [1]  supermans             0.483   0.000  \n",
            "   [1]  iii                   0.485   0.000  \n",
            "   [1]  and                   0.487   0.000  \n",
            "   [0]  iv                    0.490   10.645 \n",
            "   [0]  should                0.493   6.902  \n",
            "   [0]  have                  0.494   3.218  \n",
            "   [1]  been                  0.494   0.000  \n",
            "   [0]  for                   0.493   5.113  \n",
            "   [1]  superman              0.490   0.000  \n",
            "   [0]  cinema                0.487   7.771  \n",
            "   [0]  s                     0.484   4.518  \n",
            "Samples\n",
            "Sample 0 .  truly nice story with a moral about brotherly love describes this odd david lynch film this was especially odd because\n",
            "Sample 1 .  never seems to amaze me how bad films can actually be but this is an insult to intelligence how does\n",
            "Sample 2 .  long ago i wrote my ideas as to what supermans iii and iv should have been for superman cinema s\n",
            "\n",
            "\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[1 1 0 1 0 1 1 1 0 0]...][[9 389 85 69848 555 69848 13 2 1484 69848]...][[389 85 9 555 7 13 2 1484 199 6963]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[1 1 0 1 0 1 1 1 0 0]...][[9 389 85 69848 555 69848 13 2 1484 69848]...][[389 85 9 555 7 13 2 1484 199 6963]...]\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 1 1 1 1 0 1 0 0 0]...][[10 5 0 64 17 11 69848 312 69848 69848]...][[5 0 64 17 11 60 312 1 9 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 1 1 1 1 0 1 0 0 0]...][[10 5 0 64 17 11 69848 312 69848 69848]...][[5 0 64 17 11 60 312 1 9 27]...]\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "global_step: 1974\n",
            " perplexity: 449.978\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            " percent of 3-grams captured: 0.495.\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            " percent of 2-grams captured: 0.697.\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            " percent of 4-grams captured: 0.259.\n",
            " geometric_avg: 0.447.\n",
            " arithmetic_avg: 0.484.\n",
            "global_step: 1974\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69392\n",
            " G train loss: 3.10171\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 1 1 1 1 0 1 0 0 0]...][[10 5 0 64 17 11 69848 312 69848 69848]...][[5 0 64 17 11 60 312 1 9 27]...]\n",
            " Sample 0.\n",
            "   [1]  is                    0.498   0.000  \n",
            "   [1]  the                   0.499   0.000  \n",
            "   [1]  only                  0.498   0.000  \n",
            "   [1]  movie                 0.497   0.000  \n",
            "   [1]  that                  0.495   0.000  \n",
            "   [0]  my                    0.493   4.907  \n",
            "   [1]  wife                  0.491   0.000  \n",
            "   [0]  and                   0.490   3.346  \n",
            "   [0]  i                     0.487   3.753  \n",
            "   [0]  have                  0.488   2.941  \n",
            "   [1]  ever                  0.489   0.000  \n",
            "   [1]  walked                0.490   0.000  \n",
            "   [1]  out                   0.490   0.000  \n",
            "   [1]  on                    0.491   0.000  \n",
            "   [1]  totally               0.492   0.000  \n",
            "   [0]  sucked                0.492   9.653  \n",
            "   [1]  we                    0.492   0.000  \n",
            "   [1]  saw                   0.494   0.000  \n",
            "   [1]  it                    0.496   0.000  \n",
            "   [0]  in                    0.497   4.806  \n",
            " Sample 1.\n",
            "   [1]  saw                   0.498   0.000  \n",
            "   [0]  it                    0.497   4.122  \n",
            "   [0]  at                    0.496   4.994  \n",
            "   [1]  the                   0.496   0.000  \n",
            "   [0]  kodak                 0.495   15.804 \n",
            "   [1]  with                  0.494   0.000  \n",
            "   [0]  a                     0.494   2.615  \n",
            "   [1]  friend                0.493   0.000  \n",
            "   [1]  in                    0.492   0.000  \n",
            "   [1]  the                   0.492   0.000  \n",
            "   [1]  show                  0.492   0.000  \n",
            "   [1]  horrible              0.492   0.000  \n",
            "   [0]  val                   0.492   12.245 \n",
            "   [0]  was                   0.492   4.308  \n",
            "   [1]  reading               0.493   0.000  \n",
            "   [1]  at                    0.494   0.000  \n",
            "   [1]  the                   0.496   0.000  \n",
            "   [0]  back                  0.496   9.086  \n",
            "   [1]  of                    0.496   0.000  \n",
            "   [0]  the                   0.496   1.427  \n",
            " Sample 2.\n",
            "   [1]  this                  0.505   0.000  \n",
            "   [0]  is                    0.506   1.610  \n",
            "   [1]  a                     0.506   0.000  \n",
            "   [0]  fantasy               0.506   8.354  \n",
            "   [0]  it                    0.505   6.018  \n",
            "   [1]  is                    0.505   0.000  \n",
            "   [0]  a                     0.506   1.600  \n",
            "   [1]  valuable              0.503   0.000  \n",
            "   [1]  film                  0.504   0.000  \n",
            "   [0]  br                    0.504   4.149  \n",
            "   [1]  br                    0.504   0.000  \n",
            "   [0]  slater                0.505   11.816 \n",
            "   [0]  gives                 0.505   7.214  \n",
            "   [0]  an                    0.505   4.279  \n",
            "   [1]  excellent             0.505   0.000  \n",
            "   [1]  performance           0.506   0.000  \n",
            "   [1]  of                    0.506   0.000  \n",
            "   [1]  the                   0.508   0.000  \n",
            "   [0]  schizoid              0.507   15.663 \n",
            "   [0]  loner                 0.508   12.526 \n",
            "Samples\n",
            "Sample 0 .  is the only movie that my wife and i have ever walked out on totally sucked we saw it in\n",
            "Sample 1 .  saw it at the kodak with a friend in the show horrible val was reading at the back of the\n",
            "Sample 2 .  this is a fantasy it is a valuable film br br slater gives an excellent performance of the schizoid loner\n",
            "\n",
            "\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[0 1 0 0 0 1 0 0 0 1]...][[0 69848 202 69848 69848 69848 120 69848 69848 69848]...][[84 202 3 400 4211 120 15 2 3729 1207]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[0 1 0 0 0 1 0 0 0 1]...][[0 69848 202 69848 69848 69848 120 69848 69848 69848]...][[84 202 3 400 4211 120 15 2 3729 1207]...]\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[0 1 0 1 0 1 0 1 0 0]...][[9 69848 85 69848 555 69848 13 69848 1484 69848]...][[389 85 9 555 7 13 2 1484 199 6963]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[0 1 0 1 0 1 0 1 0 0]...][[9 69848 85 69848 555 69848 13 69848 1484 69848]...][[389 85 9 555 7 13 2 1484 199 6963]...]\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "global_step: 1977\n",
            " perplexity: 450.465\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            " percent of 3-grams captured: 0.476.\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            " percent of 2-grams captured: 0.717.\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            " percent of 4-grams captured: 0.209.\n",
            " geometric_avg: 0.414.\n",
            " arithmetic_avg: 0.467.\n",
            "global_step: 1977\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69392\n",
            " G train loss: 3.10126\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[0 1 0 1 0 1 0 1 0 0]...][[9 69848 85 69848 555 69848 13 69848 1484 69848]...][[389 85 9 555 7 13 2 1484 199 6963]...]\n",
            " Sample 0.\n",
            "   [0]  came                  0.492   5.764  \n",
            "   [1]  because               0.492   0.000  \n",
            "   [0]  i                     0.491   3.235  \n",
            "   [1]  heard                 0.490   0.000  \n",
            "   [0]  it                    0.489   3.303  \n",
            "   [1]  was                   0.489   0.000  \n",
            "   [0]  a                     0.489   2.604  \n",
            "   [1]  cross                 0.488   0.000  \n",
            "   [0]  between               0.488   7.636  \n",
            "   [0]  buffy                 0.488   10.997 \n",
            "   [0]  the                   0.490   5.048  \n",
            "   [1]  vampire               0.491   0.000  \n",
            "   [0]  slayer                0.493   13.818 \n",
            "   [1]  the                   0.495   0.000  \n",
            "   [0]  and                   0.496   9.340  \n",
            "   [1]  charmed               0.495   0.000  \n",
            "   [1]  i                     0.495   0.000  \n",
            "   [0]  stayed                0.493   7.170  \n",
            "   [0]  because               0.492   7.018  \n",
            "   [1]  it                    0.492   0.000  \n",
            " Sample 1.\n",
            "   [1]  is                    0.502   0.000  \n",
            "   [1]  an                    0.504   0.000  \n",
            "   [0]  interesting           0.506   5.479  \n",
            "   [1]  true                  0.507   0.000  \n",
            "   [0]  story                 0.507   4.953  \n",
            "   [1]  of                    0.508   0.000  \n",
            "   [1]  archie                0.510   0.000  \n",
            "   [1]  grey                  0.511   0.000  \n",
            "   [0]  owl                   0.512   10.307 \n",
            "   [1]  who                   0.512   0.000  \n",
            "   [0]  dreamed               0.513   9.096  \n",
            "   [1]  of                    0.514   0.000  \n",
            "   [1]  being                 0.515   0.000  \n",
            "   [0]  an                    0.517   4.111  \n",
            "   [1]  when                  0.517   0.000  \n",
            "   [0]  he                    0.517   4.510  \n",
            "   [1]  was                   0.517   0.000  \n",
            "   [1]  a                     0.519   0.000  \n",
            "   [0]  child                 0.520   7.403  \n",
            "   [1]  until                 0.522   0.000  \n",
            " Sample 2.\n",
            "   [0]  think                 0.487   4.528  \n",
            "   [0]  this                  0.483   0.924  \n",
            "   [0]  movie                 0.479   1.064  \n",
            "   [0]  is                    0.476   3.336  \n",
            "   [1]  best                  0.473   0.000  \n",
            "   [1]  summed                0.471   0.000  \n",
            "   [0]  up                    0.469   5.753  \n",
            "   [1]  as                    0.469   0.000  \n",
            "   [1]  follows               0.470   0.000  \n",
            "   [0]  eventually            0.470   10.758 \n",
            "   [0]  all                   0.471   5.989  \n",
            "   [0]  things                0.471   6.740  \n",
            "   [0]  merge                 0.471   15.416 \n",
            "   [1]  into                  0.472   0.000  \n",
            "   [0]  one                   0.471   5.278  \n",
            "   [0]  and                   0.469   2.891  \n",
            "   [1]  a                     0.468   0.000  \n",
            "   [1]  river                 0.469   0.000  \n",
            "   [1]  runs                  0.470   0.000  \n",
            "   [0]  through               0.472   6.903  \n",
            "Samples\n",
            "Sample 0 .  came because i heard it was a cross between buffy the vampire slayer the and charmed i stayed because it\n",
            "Sample 1 .  is an interesting true story of archie grey owl who dreamed of being an when he was a child until\n",
            "Sample 2 .  think this movie is best summed up as follows eventually all things merge into one and a river runs through\n",
            "\n",
            "\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 0 1 1 1 1 1 1 0]...][[10 5 0 69848 1211 19 9 27 110 8]...][[5 0 88 1211 19 9 27 110 8 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 0 1 1 1 1 1 1 0]...][[10 5 0 69848 1211 19 9 27 110 8]...][[5 0 88 1211 19 9 27 110 8 2]...]\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[0 1 1 1 0 0 0 1 1 1]...][[0 69848 202 3 400 69848 69848 69848 2 3729]...][[84 202 3 400 4211 120 15 2 3729 1207]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[0 1 1 1 0 0 0 1 1 1]...][[0 69848 202 3 400 69848 69848 69848 2 3729]...][[84 202 3 400 4211 120 15 2 3729 1207]...]\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "global_step: 1980\n",
            " perplexity: 450.252\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            " percent of 3-grams captured: 0.475.\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            " percent of 2-grams captured: 0.703.\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            " percent of 4-grams captured: 0.214.\n",
            " geometric_avg: 0.415.\n",
            " arithmetic_avg: 0.464.\n",
            "global_step: 1980\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69392\n",
            " G train loss: 3.10072\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[0 1 1 1 0 0 0 1 1 1]...][[0 69848 202 3 400 69848 69848 69848 2 3729]...][[84 202 3 400 4211 120 15 2 3729 1207]...]\n",
            " Sample 0.\n",
            "   [0]  first                 0.522   3.538  \n",
            "   [1]  series                0.518   0.000  \n",
            "   [1]  of                    0.516   0.000  \n",
            "   [1]  lost                  0.514   0.000  \n",
            "   [0]  kicked                0.514   10.332 \n",
            "   [0]  off                   0.514   6.399  \n",
            "   [0]  with                  0.515   4.285  \n",
            "   [1]  a                     0.517   0.000  \n",
            "   [1]  bang                  0.517   0.000  \n",
            "   [1]  literally             0.518   0.000  \n",
            "   [0]  and                   0.518   2.747  \n",
            "   [1]  slowly                0.518   0.000  \n",
            "   [0]  decreased             0.516   15.355 \n",
            "   [0]  in                    0.515   3.170  \n",
            "   [0]  pace                  0.514   9.792  \n",
            "   [1]  this                  0.513   0.000  \n",
            "   [1]  may                   0.512   0.000  \n",
            "   [0]  have                  0.514   4.165  \n",
            "   [0]  put                   0.513   6.522  \n",
            "   [0]  some                  0.514   5.072  \n",
            " Sample 1.\n",
            "   [0]  movie                 0.501   2.237  \n",
            "   [0]  is                    0.499   0.883  \n",
            "   [1]  similar               0.497   0.000  \n",
            "   [0]  to                    0.496   2.773  \n",
            "   [0]  the                   0.496   3.717  \n",
            "   [1]  play                  0.496   0.000  \n",
            "   [1]  entitled              0.498   0.000  \n",
            "   [1]  blithe                0.499   0.000  \n",
            "   [0]  spirit                0.501   8.722  \n",
            "   [0]  written               0.501   7.930  \n",
            "   [1]  by                    0.501   0.000  \n",
            "   [1]  noel                  0.501   0.000  \n",
            "   [1]  coward                0.500   0.000  \n",
            "   [1]  the                   0.500   0.000  \n",
            "   [0]  plot                  0.501   5.369  \n",
            "   [0]  of                    0.499   2.843  \n",
            "   [1]  a                     0.496   0.000  \n",
            "   [1]  ghost                 0.496   0.000  \n",
            "   [1]  wife                  0.496   0.000  \n",
            "   [1]  and                   0.496   0.000  \n",
            " Sample 2.\n",
            "   [0]  well                  0.516   6.456  \n",
            "   [0]  well                  0.519   6.451  \n",
            "   [0]  satish                0.520   15.135 \n",
            "   [1]  kaushik               0.522   0.000  \n",
            "   [1]  is                    0.523   0.000  \n",
            "   [0]  one                   0.525   4.023  \n",
            "   [1]  of                    0.525   0.000  \n",
            "   [0]  the                   0.526   1.817  \n",
            "   [0]  funniest              0.526   7.034  \n",
            "   [0]  actors                0.525   6.007  \n",
            "   [0]  on                    0.524   4.169  \n",
            "   [1]  hindi                 0.523   0.000  \n",
            "   [1]  screen                0.521   0.000  \n",
            "   [0]  at                    0.520   5.065  \n",
            "   [1]  least                 0.519   0.000  \n",
            "   [0]  in                    0.518   4.285  \n",
            "   [1]  some                  0.519   0.000  \n",
            "   [0]  films                 0.519   4.797  \n",
            "   [0]  he                    0.520   5.162  \n",
            "   [1]  was                   0.520   0.000  \n",
            "Samples\n",
            "Sample 0 .  first series of lost kicked off with a bang literally and slowly decreased in pace this may have put some\n",
            "Sample 1 .  movie is similar to the play entitled blithe spirit written by noel coward the plot of a ghost wife and\n",
            "Sample 2 .  well well satish kaushik is one of the funniest actors on hindi screen at least in some films he was\n",
            "\n",
            "\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[1 1 1 0 1 1 1 0 0 1]...][[3857 471 5 23 69848 1101 4 3862 69848 69848]...][[471 5 23 74 1101 4 3862 2124 184 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[1 1 1 0 1 1 1 0 0 1]...][[3857 471 5 23 69848 1101 4 3862 69848 69848]...][[471 5 23 74 1101 4 3862 2124 184 7]...]\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 1 0 0 0 1 0 1 1]...][[10 5 0 88 69848 69848 69848 27 69848 8]...][[5 0 88 1211 19 9 27 110 8 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 1 0 0 0 1 0 1 1]...][[10 5 0 88 69848 69848 69848 27 69848 8]...][[5 0 88 1211 19 9 27 110 8 2]...]\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "global_step: 1983\n",
            " perplexity: 450.221\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            " percent of 3-grams captured: 0.502.\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            " percent of 2-grams captured: 0.713.\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            " percent of 4-grams captured: 0.230.\n",
            " geometric_avg: 0.435.\n",
            " arithmetic_avg: 0.482.\n",
            "global_step: 1983\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69390\n",
            " G train loss: 3.10040\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 1 0 0 0 1 0 1 1]...][[10 5 0 88 69848 69848 69848 27 69848 8]...][[5 0 88 1211 19 9 27 110 8 2]...]\n",
            " Sample 0.\n",
            "   [1]  is                    0.504   0.000  \n",
            "   [1]  the                   0.505   0.000  \n",
            "   [1]  most                  0.505   0.000  \n",
            "   [0]  disturbing            0.504   9.305  \n",
            "   [0]  film                  0.504   2.599  \n",
            "   [0]  i                     0.503   2.771  \n",
            "   [1]  have                  0.502   0.000  \n",
            "   [0]  seen                  0.502   2.596  \n",
            "   [1]  in                    0.502   0.000  \n",
            "   [1]  a                     0.503   0.000  \n",
            "   [0]  long                  0.503   5.183  \n",
            "   [1]  time                  0.503   0.000  \n",
            "   [1]  if                    0.503   0.000  \n",
            "   [0]  you                   0.503   1.844  \n",
            "   [0]  like                  0.503   4.327  \n",
            "   [1]  this                  0.504   0.000  \n",
            "   [1]  movie                 0.504   0.000  \n",
            "   [1]  go                    0.504   0.000  \n",
            "   [0]  rent                  0.503   8.773  \n",
            "   [0]  bastard               0.501   14.326 \n",
            " Sample 1.\n",
            "   [0]  of                    0.527   3.279  \n",
            "   [0]  a                     0.528   2.090  \n",
            "   [1]  spoiled               0.529   0.000  \n",
            "   [0]  rich                  0.531   9.638  \n",
            "   [0]  kid                   0.532   8.501  \n",
            "   [0]  who                   0.532   4.224  \n",
            "   [0]  begins                0.533   7.188  \n",
            "   [0]  to                    0.533   2.193  \n",
            "   [1]  sell                  0.533   0.000  \n",
            "   [0]  ritalin               0.532   15.266 \n",
            "   [0]  and                   0.532   2.860  \n",
            "   [0]  advice                0.532   10.585 \n",
            "   [1]  to                    0.533   0.000  \n",
            "   [0]  the                   0.532   3.816  \n",
            "   [1]  student               0.532   0.000  \n",
            "   [1]  body                  0.532   0.000  \n",
            "   [0]  of                    0.531   2.203  \n",
            "   [0]  his                   0.531   3.962  \n",
            "   [1]  new                   0.532   0.000  \n",
            "   [0]  high                  0.532   6.210  \n",
            " Sample 2.\n",
            "   [1]  tessari               0.489   0.000  \n",
            "   [1]  really                0.490   0.000  \n",
            "   [1]  ought                 0.491   0.000  \n",
            "   [1]  to                    0.494   0.000  \n",
            "   [1]  be                    0.496   0.000  \n",
            "   [1]  applauded             0.497   0.000  \n",
            "   [1]  for                   0.500   0.000  \n",
            "   [1]  this                  0.503   0.000  \n",
            "   [1]  truly                 0.505   0.000  \n",
            "   [0]  proficient            0.507   13.080 \n",
            "   [1]  but                   0.508   0.000  \n",
            "   [0]  sadly                 0.508   9.058  \n",
            "   [1]  still                 0.507   0.000  \n",
            "   [0]  neglected             0.507   12.039 \n",
            "   [1]  giallo                0.509   0.000  \n",
            "   [0]  achievement           0.512   10.929 \n",
            "   [1]  i                     0.513   0.000  \n",
            "   [0]  sincerely             0.511   9.667  \n",
            "   [0]  hope                  0.509   10.910 \n",
            "   [1]  this                  0.507   0.000  \n",
            "Samples\n",
            "Sample 0 .  is the most disturbing film i have seen in a long time if you like this movie go rent bastard\n",
            "Sample 1 .  of a spoiled rich kid who begins to sell ritalin and advice to the student body of his new high\n",
            "Sample 2 .  tessari really ought to be applauded for this truly proficient but sadly still neglected giallo achievement i sincerely hope this\n",
            "\n",
            "\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[0 1 0 1 0 0 0 0 0 0]...][[9 69848 715 69848 202 69848 69848 69848 69848 69848]...][[242 715 10 202 2 163 23 85 3 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[0 1 0 1 0 0 0 0 0 0]...][[9 69848 715 69848 202 69848 69848 69848 69848 69848]...][[242 715 10 202 2 163 23 85 3 0]...]\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[0 1 1 0 0 0 0 0 1 0]...][[3857 69848 5 23 69848 69848 69848 69848 69848 184]...][[471 5 23 74 1101 4 3862 2124 184 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[0 1 1 0 0 0 0 0 1 0]...][[3857 69848 5 23 69848 69848 69848 69848 69848 184]...][[471 5 23 74 1101 4 3862 2124 184 7]...]\n",
            "2020-03-24 03:50:09.673437: E tensorflow/core/util/events_writer.cc:162] The events file maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0 has disappeared.\n",
            "2020-03-24 03:50:09.673504: E tensorflow/core/util/events_writer.cc:131] Failed to flush 649 events to maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "global_step: 1986\n",
            " perplexity: 449.856\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            " percent of 3-grams captured: 0.534.\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            " percent of 2-grams captured: 0.709.\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            " percent of 4-grams captured: 0.275.\n",
            " geometric_avg: 0.470.\n",
            " arithmetic_avg: 0.506.\n",
            "global_step: 1986\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69390\n",
            " G train loss: 3.10046\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[0 1 1 0 0 0 0 0 1 0]...][[3857 69848 5 23 69848 69848 69848 69848 69848 184]...][[471 5 23 74 1101 4 3862 2124 184 7]...]\n",
            " Sample 0.\n",
            "   [0]  b                     0.494   8.053  \n",
            "   [1]  is                    0.497   0.000  \n",
            "   [1]  not                   0.499   0.000  \n",
            "   [0]  bad                   0.499   5.044  \n",
            "   [0]  compared              0.500   9.527  \n",
            "   [0]  to                    0.500   2.737  \n",
            "   [0]  conventional          0.499   11.058 \n",
            "   [0]  crappy                0.499   9.666  \n",
            "   [1]  horror                0.498   0.000  \n",
            "   [0]  it                    0.498   4.702  \n",
            "   [1]  shows                 0.499   0.000  \n",
            "   [0]  the                   0.500   2.631  \n",
            "   [1]  beginning             0.501   0.000  \n",
            "   [1]  and                   0.502   0.000  \n",
            "   [0]  birth                 0.502   9.761  \n",
            "   [0]  of                    0.501   3.436  \n",
            "   [1]  our                   0.500   0.000  \n",
            "   [0]  favorite              0.499   7.342  \n",
            "   [1]  horror                0.498   0.000  \n",
            "   [1]  star                  0.498   0.000  \n",
            " Sample 1.\n",
            "   [0]  don                   0.483   4.227  \n",
            "   [0]  t                     0.484   0.158  \n",
            "   [1]  think                 0.483   0.000  \n",
            "   [0]  any                   0.481   6.193  \n",
            "   [1]  player                0.480   0.000  \n",
            "   [0]  in                    0.476   4.208  \n",
            "   [0]  hollywood             0.473   6.937  \n",
            "   [0]  history               0.471   7.761  \n",
            "   [1]  lasted                0.471   0.000  \n",
            "   [0]  as                    0.472   4.731  \n",
            "   [1]  long                  0.473   0.000  \n",
            "   [1]  as                    0.474   0.000  \n",
            "   [0]  david                 0.475   8.643  \n",
            "   [1]  niven                 0.477   0.000  \n",
            "   [1]  did                   0.478   0.000  \n",
            "   [1]  given                 0.478   0.000  \n",
            "   [1]  most                  0.478   0.000  \n",
            "   [0]  of                    0.475   3.742  \n",
            "   [0]  the                   0.473   2.041  \n",
            "   [0]  weak                  0.473   8.826  \n",
            " Sample 2.\n",
            "   [0]  movie                 0.493   4.015  \n",
            "   [0]  was                   0.492   3.502  \n",
            "   [0]  very                  0.492   4.246  \n",
            "   [1]  moving                0.492   0.000  \n",
            "   [1]  it                    0.492   0.000  \n",
            "   [0]  was                   0.491   2.728  \n",
            "   [0]  tender                0.490   11.863 \n",
            "   [1]  and                   0.491   0.000  \n",
            "   [0]  funny                 0.491   6.855  \n",
            "   [1]  at                    0.493   0.000  \n",
            "   [1]  the                   0.493   0.000  \n",
            "   [1]  same                  0.494   0.000  \n",
            "   [0]  time                  0.492   4.428  \n",
            "   [0]  the                   0.492   3.699  \n",
            "   [1]  scenery               0.491   0.000  \n",
            "   [1]  was                   0.488   0.000  \n",
            "   [1]  absolutely            0.488   0.000  \n",
            "   [1]  beautiful             0.488   0.000  \n",
            "   [1]  peter                 0.490   0.000  \n",
            "   [0]  faulk                 0.491   14.368 \n",
            "Samples\n",
            "Sample 0 .  b is not bad compared to conventional crappy horror it shows the beginning and birth of our favorite horror star\n",
            "Sample 1 .  don t think any player in hollywood history lasted as long as david niven did given most of the weak\n",
            "Sample 2 .  movie was very moving it was tender and funny at the same time the scenery was absolutely beautiful peter faulk\n",
            "\n",
            "\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[0 1 0 0 1 1 1 0 1 1]...][[14553 69848 21 69848 69848 19 165 1225 69848 107]...][[210 21 2 414 19 165 1225 740 107 414]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[0 1 0 0 1 1 1 0 1 1]...][[14553 69848 21 69848 69848 19 165 1225 69848 107]...][[210 21 2 414 19 165 1225 740 107 414]...]\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[0 0 1 1 1 1 1 1 0 0]...][[9 69848 69848 10 202 2 163 23 85 69848]...][[242 715 10 202 2 163 23 85 3 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[0 0 1 1 1 1 1 1 0 0]...][[9 69848 69848 10 202 2 163 23 85 69848]...][[242 715 10 202 2 163 23 85 3 0]...]\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "global_step: 1989\n",
            " perplexity: 449.390\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            " percent of 3-grams captured: 0.522.\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            " percent of 2-grams captured: 0.718.\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            " percent of 4-grams captured: 0.235.\n",
            " geometric_avg: 0.445.\n",
            " arithmetic_avg: 0.492.\n",
            "global_step: 1989\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69393\n",
            " G train loss: 3.10019\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[0 0 1 1 1 1 1 1 0 0]...][[9 69848 69848 10 202 2 163 23 85 69848]...][[242 715 10 202 2 163 23 85 3 0]...]\n",
            " Sample 0.\n",
            "   [0]  am                    0.495   2.667  \n",
            "   [0]  giving                0.493   8.101  \n",
            "   [1]  this                  0.492   0.000  \n",
            "   [1]  series                0.492   0.000  \n",
            "   [1]  a                     0.493   0.000  \n",
            "   [1]  10                    0.496   0.000  \n",
            "   [1]  not                   0.498   0.000  \n",
            "   [1]  because               0.499   0.000  \n",
            "   [0]  of                    0.498   4.294  \n",
            "   [0]  the                   0.497   1.651  \n",
            "   [1]  plot                  0.497   0.000  \n",
            "   [0]  who                   0.497   4.908  \n",
            "   [1]  s                     0.497   0.000  \n",
            "   [1]  noticing              0.497   0.000  \n",
            "   [1]  but                   0.499   0.000  \n",
            "   [0]  for                   0.502   4.820  \n",
            "   [1]  the                   0.502   0.000  \n",
            "   [0]  incredible            0.504   8.555  \n",
            "   [0]  allure                0.504   13.873 \n",
            "   [0]  and                   0.504   2.765  \n",
            " Sample 1.\n",
            "   [1]  don                   0.508   0.000  \n",
            "   [0]  t                     0.512   0.088  \n",
            "   [0]  want                  0.514   4.597  \n",
            "   [0]  to                    0.516   0.807  \n",
            "   [0]  give                  0.517   5.412  \n",
            "   [0]  this                  0.515   2.562  \n",
            "   [1]  1                     0.512   0.000  \n",
            "   [1]  star                  0.510   0.000  \n",
            "   [1]  i                     0.509   0.000  \n",
            "   [0]  wanted                0.509   5.176  \n",
            "   [1]  to                    0.510   0.000  \n",
            "   [1]  like                  0.511   0.000  \n",
            "   [1]  it                    0.512   0.000  \n",
            "   [0]  but                   0.515   5.943  \n",
            "   [0]  it                    0.517   2.792  \n",
            "   [1]  failed                0.517   0.000  \n",
            "   [0]  on                    0.516   4.491  \n",
            "   [0]  so                    0.513   5.295  \n",
            "   [0]  many                  0.510   5.186  \n",
            "   [0]  counts                0.509   11.675 \n",
            " Sample 2.\n",
            "   [0]  is                    0.497   0.617  \n",
            "   [1]  probably              0.495   0.000  \n",
            "   [0]  one                   0.493   3.492  \n",
            "   [1]  of                    0.490   0.000  \n",
            "   [0]  the                   0.488   0.877  \n",
            "   [0]  worst                 0.488   3.182  \n",
            "   [0]  movies                0.488   4.577  \n",
            "   [1]  i                     0.487   0.000  \n",
            "   [0]  have                  0.487   2.361  \n",
            "   [0]  ever                  0.487   2.584  \n",
            "   [0]  seen                  0.487   1.232  \n",
            "   [0]  jessica               0.487   10.626 \n",
            "   [1]  simpson               0.488   0.000  \n",
            "   [1]  not                   0.489   0.000  \n",
            "   [0]  only                  0.490   5.462  \n",
            "   [1]  lacks                 0.491   0.000  \n",
            "   [0]  any                   0.492   6.115  \n",
            "   [0]  acting                0.492   5.634  \n",
            "   [0]  skill                 0.490   11.085 \n",
            "   [0]  but                   0.490   4.113  \n",
            "Samples\n",
            "Sample 0 .  am giving this series a 10 not because of the plot who s noticing but for the incredible allure and\n",
            "Sample 1 .  don t want to give this 1 star i wanted to like it but it failed on so many counts\n",
            "Sample 2 .  is probably one of the worst movies i have ever seen jessica simpson not only lacks any acting skill but\n",
            "\n",
            "\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[1 1 1 0 0 0 1 1 1 0]...][[473 0 3988 1 69848 69848 69848 5421 13 5363]...][[0 3988 1 407 3821 8286 5421 13 5363 1267]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[1 1 1 0 0 0 1 1 1 0]...][[473 0 3988 1 69848 69848 69848 5421 13 5363]...][[0 3988 1 407 3821 8286 5421 13 5363 1267]...]\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[0 0 0 1 0 1 1 0 1 0]...][[14553 69848 69848 69848 414 69848 165 1225 69848 107]...][[210 21 2 414 19 165 1225 740 107 414]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[0 0 0 1 0 1 1 0 1 0]...][[14553 69848 69848 69848 414 69848 165 1225 69848 107]...][[210 21 2 414 19 165 1225 740 107 414]...]\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "global_step: 1992\n",
            " perplexity: 448.918\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            " percent of 3-grams captured: 0.534.\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            " percent of 2-grams captured: 0.727.\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            " percent of 4-grams captured: 0.260.\n",
            " geometric_avg: 0.466.\n",
            " arithmetic_avg: 0.507.\n",
            "global_step: 1992\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69390\n",
            " G train loss: 3.09977\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[0 0 0 1 0 1 1 0 1 0]...][[14553 69848 69848 69848 414 69848 165 1225 69848 107]...][[210 21 2 414 19 165 1225 740 107 414]...]\n",
            " Sample 0.\n",
            "   [0]  isn                   0.482   6.279  \n",
            "   [0]  t                     0.487   0.265  \n",
            "   [0]  a                     0.490   3.860  \n",
            "   [1]  perfect               0.491   0.000  \n",
            "   [0]  film                  0.492   3.084  \n",
            "   [1]  actually              0.493   0.000  \n",
            "   [1]  nowhere               0.495   0.000  \n",
            "   [0]  near                  0.496   8.557  \n",
            "   [1]  being                 0.498   0.000  \n",
            "   [0]  perfect               0.498   8.204  \n",
            "   [0]  but                   0.498   4.015  \n",
            "   [1]  hey                   0.497   0.000  \n",
            "   [0]  this                  0.497   3.358  \n",
            "   [0]  movie                 0.495   2.430  \n",
            "   [0]  isn                   0.494   5.859  \n",
            "   [0]  t                     0.494   0.230  \n",
            "   [0]  a                     0.494   4.115  \n",
            "   [1]  trash                 0.494   0.000  \n",
            "   [0]  either                0.494   8.510  \n",
            "   [1]  i                     0.495   0.000  \n",
            " Sample 1.\n",
            "   [0]  captivating           0.495   11.186 \n",
            "   [0]  tale                  0.494   6.980  \n",
            "   [1]  of                    0.493   0.000  \n",
            "   [0]  a                     0.494   2.026  \n",
            "   [1]  couple                0.497   0.000  \n",
            "   [1]  returning             0.499   0.000  \n",
            "   [1]  to                    0.501   0.000  \n",
            "   [1]  the                   0.502   0.000  \n",
            "   [0]  soviet                0.501   8.728  \n",
            "   [1]  union                 0.501   0.000  \n",
            "   [1]  and                   0.501   0.000  \n",
            "   [0]  finding               0.501   8.225  \n",
            "   [0]  out                   0.501   5.324  \n",
            "   [0]  the                   0.501   2.338  \n",
            "   [0]  trip                  0.503   9.018  \n",
            "   [1]  was                   0.502   0.000  \n",
            "   [1]  not                   0.503   0.000  \n",
            "   [0]  exactly               0.503   7.288  \n",
            "   [1]  as                    0.503   0.000  \n",
            "   [1]  advertised            0.505   0.000  \n",
            " Sample 2.\n",
            "   [0]  t                     0.492   0.238  \n",
            "   [1]  be                    0.492   0.000  \n",
            "   [1]  fooled                0.492   0.000  \n",
            "   [0]  by                    0.493   4.103  \n",
            "   [0]  anything              0.494   7.151  \n",
            "   [1]  that                  0.495   0.000  \n",
            "   [0]  you                   0.495   3.510  \n",
            "   [0]  have                  0.497   2.623  \n",
            "   [1]  ever                  0.497   0.000  \n",
            "   [1]  read                  0.497   0.000  \n",
            "   [0]  about                 0.497   4.562  \n",
            "   [1]  this                  0.497   0.000  \n",
            "   [0]  movie                 0.497   1.257  \n",
            "   [1]  no                    0.497   0.000  \n",
            "   [1]  matter                0.497   0.000  \n",
            "   [0]  how                   0.497   5.807  \n",
            "   [0]  good                  0.497   6.369  \n",
            "   [1]  someone               0.497   0.000  \n",
            "   [0]  has                   0.499   5.954  \n",
            "   [0]  said                  0.498   6.430  \n",
            "Samples\n",
            "Sample 0 .  isn t a perfect film actually nowhere near being perfect but hey this movie isn t a trash either i\n",
            "Sample 1 .  captivating tale of a couple returning to the soviet union and finding out the trip was not exactly as advertised\n",
            "Sample 2 .  t be fooled by anything that you have ever read about this movie no matter how good someone has said\n",
            "\n",
            "\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 1 0 1 1 0 0 0 0 0]...][[46 20 38 69848 827 1890 69848 69848 69848 69848]...][[20 38 832 827 1890 1 2291 4749 94 20]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 1 0 1 1 0 0 0 0 0]...][[46 20 38 69848 827 1890 69848 69848 69848 69848]...][[20 38 832 827 1890 1 2291 4749 94 20]...]\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[0 0 0 0 1 1 0 0 1 0]...][[473 69848 69848 69848 69848 3821 8286 69848 69848 5363]...][[0 3988 1 407 3821 8286 5421 13 5363 1267]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[0 0 0 0 1 1 0 0 1 0]...][[473 69848 69848 69848 69848 3821 8286 69848 69848 5363]...][[0 3988 1 407 3821 8286 5421 13 5363 1267]...]\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "global_step: 1995\n",
            " perplexity: 448.387\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            " percent of 3-grams captured: 0.523.\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            " percent of 2-grams captured: 0.726.\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            " percent of 4-grams captured: 0.251.\n",
            " geometric_avg: 0.457.\n",
            " arithmetic_avg: 0.500.\n",
            "global_step: 1995\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69387\n",
            " G train loss: 3.09891\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[0 0 0 0 1 1 0 0 1 0]...][[473 69848 69848 69848 69848 3821 8286 69848 69848 5363]...][[0 3988 1 407 3821 8286 5421 13 5363 1267]...]\n",
            " Sample 0.\n",
            "   [0]  the                   0.505   2.377  \n",
            "   [0]  seventies             0.504   8.926  \n",
            "   [0]  and                   0.505   3.423  \n",
            "   [0]  early                 0.506   9.160  \n",
            "   [1]  eighties              0.507   0.000  \n",
            "   [1]  tobe                  0.509   0.000  \n",
            "   [0]  hooper                0.511   9.715  \n",
            "   [0]  was                   0.513   4.794  \n",
            "   [1]  widely                0.515   0.000  \n",
            "   [0]  considered            0.515   10.000 \n",
            "   [1]  as                    0.515   0.000  \n",
            "   [1]  one                   0.516   0.000  \n",
            "   [0]  of                    0.516   1.575  \n",
            "   [0]  the                   0.516   1.400  \n",
            "   [0]  greatest              0.514   6.461  \n",
            "   [0]  horror                0.513   5.682  \n",
            "   [1]  directors             0.513   0.000  \n",
            "   [0]  ever                  0.512   6.556  \n",
            "   [1]  to                    0.513   0.000  \n",
            "   [1]  grace                 0.513   0.000  \n",
            " Sample 1.\n",
            "   [0]  and                   0.474   4.602  \n",
            "   [0]  christian             0.473   9.280  \n",
            "   [0]  bale                  0.472   11.741 \n",
            "   [1]  give                  0.472   0.000  \n",
            "   [1]  good                  0.470   0.000  \n",
            "   [1]  performances          0.472   0.000  \n",
            "   [1]  as                    0.472   0.000  \n",
            "   [1]  two                   0.473   0.000  \n",
            "   [0]  foes                  0.475   12.779 \n",
            "   [1]  coming                0.476   0.000  \n",
            "   [0]  together              0.476   7.344  \n",
            "   [1]  to                    0.475   0.000  \n",
            "   [1]  wipe                  0.474   0.000  \n",
            "   [1]  out                   0.474   0.000  \n",
            "   [0]  the                   0.475   2.606  \n",
            "   [1]  dragon                0.475   0.000  \n",
            "   [1]  race                  0.476   0.000  \n",
            "   [1]  the                   0.477   0.000  \n",
            "   [0]  start                 0.477   8.704  \n",
            "   [1]  of                    0.476   0.000  \n",
            " Sample 2.\n",
            "   [1]  on                    0.502   0.000  \n",
            "   [0]  s                     0.506   6.226  \n",
            "   [1]  new                   0.509   0.000  \n",
            "   [0]  schedule              0.510   11.405 \n",
            "   [0]  at                    0.512   5.233  \n",
            "   [0]  4                     0.514   8.134  \n",
            "   [1]  pm                    0.517   0.000  \n",
            "   [1]  on                    0.519   0.000  \n",
            "   [1]  weekdays              0.520   0.000  \n",
            "   [1]  right                 0.520   0.000  \n",
            "   [1]  after                 0.523   0.000  \n",
            "   [1]  maverick              0.524   0.000  \n",
            "   [1]  and                   0.525   0.000  \n",
            "   [0]  right                 0.523   7.520  \n",
            "   [1]  before                0.521   0.000  \n",
            "   [0]  wild                  0.519   11.574 \n",
            "   [1]  wild                  0.519   0.000  \n",
            "   [1]  west                  0.520   0.000  \n",
            "   [1]  followed              0.521   0.000  \n",
            "   [1]  by                    0.523   0.000  \n",
            "Samples\n",
            "Sample 0 .  the seventies and early eighties tobe hooper was widely considered as one of the greatest horror directors ever to grace\n",
            "Sample 1 .  and christian bale give good performances as two foes coming together to wipe out the dragon race the start of\n",
            "Sample 2 .  on s new schedule at 4 pm on weekdays right after maverick and right before wild wild west followed by\n",
            "\n",
            "\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[0 0 0 1 1 0 1 1 0 0]...][[49 69848 69848 69848 19754 5745 69848 0 705 69848]...][[548 10 122 19754 5745 36 0 705 298 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[0 0 0 1 1 0 1 1 0 0]...][[49 69848 69848 69848 19754 5745 69848 0 705 69848]...][[548 10 122 19754 5745 36 0 705 298 1]...]\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 0 1 0 0 0 0 0 1 1]...][[46 20 69848 832 69848 69848 69848 69848 69848 94]...][[20 38 832 827 1890 1 2291 4749 94 20]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 0 1 0 0 0 0 0 1 1]...][[46 20 69848 832 69848 69848 69848 69848 69848 94]...][[20 38 832 827 1890 1 2291 4749 94 20]...]\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "global_step: 1998\n",
            " perplexity: 448.978\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            " percent of 3-grams captured: 0.483.\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            " percent of 2-grams captured: 0.703.\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            " percent of 4-grams captured: 0.222.\n",
            " geometric_avg: 0.422.\n",
            " arithmetic_avg: 0.469.\n",
            "global_step: 1998\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69388\n",
            " G train loss: 3.09959\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 0 1 0 0 0 0 0 1 1]...][[46 20 69848 832 69848 69848 69848 69848 69848 94]...][[20 38 832 827 1890 1 2291 4749 94 20]...]\n",
            " Sample 0.\n",
            "   [1]  you                   0.509   0.000  \n",
            "   [0]  like                  0.509   4.728  \n",
            "   [1]  sci                   0.510   0.000  \n",
            "   [0]  fi                    0.513   5.641  \n",
            "   [0]  monsters              0.517   9.436  \n",
            "   [0]  and                   0.520   2.804  \n",
            "   [0]  ancient               0.522   9.459  \n",
            "   [0]  legends               0.523   9.209  \n",
            "   [1]  then                  0.523   0.000  \n",
            "   [1]  you                   0.524   0.000  \n",
            "   [1]  will                  0.523   0.000  \n",
            "   [0]  love                  0.522   4.928  \n",
            "   [1]  this                  0.521   0.000  \n",
            "   [0]  movie                 0.520   1.882  \n",
            "   [1]  br                    0.519   0.000  \n",
            "   [0]  br                    0.519   2.545  \n",
            "   [1]  the                   0.522   0.000  \n",
            "   [0]  special               0.524   7.043  \n",
            "   [0]  effects               0.526   6.974  \n",
            "   [1]  are                   0.526   0.000  \n",
            " Sample 1.\n",
            "   [1]  goes                  0.477   0.000  \n",
            "   [1]  to                    0.477   0.000  \n",
            "   [0]  the                   0.476   2.457  \n",
            "   [0]  well                  0.474   7.435  \n",
            "   [1]  one                   0.473   0.000  \n",
            "   [0]  too                   0.472   8.940  \n",
            "   [0]  many                  0.471   4.906  \n",
            "   [0]  times                 0.471   5.447  \n",
            "   [0]  as                    0.473   4.334  \n",
            "   [1]  anybody               0.475   0.000  \n",
            "   [1]  who                   0.475   0.000  \n",
            "   [1]  has                   0.477   0.000  \n",
            "   [1]  seen                  0.479   0.000  \n",
            "   [1]  the                   0.480   0.000  \n",
            "   [0]  original              0.478   4.869  \n",
            "   [1]  little                0.478   0.000  \n",
            "   [0]  mermaid               0.478   11.374 \n",
            "   [1]  will                  0.479   0.000  \n",
            "   [1]  feel                  0.477   0.000  \n",
            "   [1]  blatantly             0.476   0.000  \n",
            " Sample 2.\n",
            "   [0]  sachs                 0.500   12.067 \n",
            "   [1]  if                    0.499   0.000  \n",
            "   [1]  you                   0.499   0.000  \n",
            "   [1]  didn                  0.499   0.000  \n",
            "   [1]  t                     0.501   0.000  \n",
            "   [0]  even                  0.504   5.066  \n",
            "   [1]  chuckles              0.506   0.000  \n",
            "   [0]  at                    0.507   4.772  \n",
            "   [1]  that                  0.506   0.000  \n",
            "   [1]  name                  0.506   0.000  \n",
            "   [0]  the                   0.508   3.204  \n",
            "   [1]  ill                   0.509   0.000  \n",
            "   [0]  conceived             0.509   10.126 \n",
            "   [1]  humor                 0.508   0.000  \n",
            "   [0]  in                    0.507   3.275  \n",
            "   [0]  this                  0.506   3.889  \n",
            "   [1]  horror                0.507   0.000  \n",
            "   [1]  film                  0.508   0.000  \n",
            "   [1]  will                  0.509   0.000  \n",
            "   [1]  bore                  0.509   0.000  \n",
            "Samples\n",
            "Sample 0 .  you like sci fi monsters and ancient legends then you will love this movie br br the special effects are\n",
            "Sample 1 .  goes to the well one too many times as anybody who has seen the original little mermaid will feel blatantly\n",
            "Sample 2 .  sachs if you didn t even chuckles at that name the ill conceived humor in this horror film will bore\n",
            "\n",
            "\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[1 1 1 0 0 1 0 1 0 0]...][[401 29 3 0 69848 69848 139 69848 110 69848]...][[29 3 0 250 9 139 123 110 51 60]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[1 1 1 0 0 1 0 1 0 0]...][[401 29 3 0 69848 69848 139 69848 110 69848]...][[29 3 0 250 9 139 123 110 51 60]...]\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[0 1 1 1 1 0 1 0 0 1]...][[49 69848 10 122 19754 5745 69848 0 69848 69848]...][[548 10 122 19754 5745 36 0 705 298 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[0 1 1 1 1 0 1 0 0 1]...][[49 69848 10 122 19754 5745 69848 0 69848 69848]...][[548 10 122 19754 5745 36 0 705 298 1]...]\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "global_step: 2001\n",
            " perplexity: 447.973\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            " percent of 3-grams captured: 0.543.\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            " percent of 2-grams captured: 0.718.\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            " percent of 4-grams captured: 0.255.\n",
            " geometric_avg: 0.463.\n",
            " arithmetic_avg: 0.505.\n",
            "global_step: 2001\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69387\n",
            " G train loss: 3.09778\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[0 1 1 1 1 0 1 0 0 1]...][[49 69848 10 122 19754 5745 69848 0 69848 69848]...][[548 10 122 19754 5745 36 0 705 298 1]...]\n",
            " Sample 0.\n",
            "   [0]  god                   0.502   7.756  \n",
            "   [1]  this                  0.496   0.000  \n",
            "   [1]  show                  0.492   0.000  \n",
            "   [1]  deviates              0.492   0.000  \n",
            "   [1]  hugely                0.493   0.000  \n",
            "   [0]  from                  0.497   4.852  \n",
            "   [1]  the                   0.501   0.000  \n",
            "   [0]  comic                 0.505   7.312  \n",
            "   [0]  book                  0.507   7.140  \n",
            "   [1]  and                   0.509   0.000  \n",
            "   [1]  movie                 0.508   0.000  \n",
            "   [0]  in                    0.507   3.731  \n",
            "   [0]  fact                  0.507   7.936  \n",
            "   [1]  i                     0.504   0.000  \n",
            "   [0]  liked                 0.503   5.514  \n",
            "   [0]  this                  0.502   1.191  \n",
            "   [1]  this                  0.501   0.000  \n",
            "   [0]  tv                    0.501   7.086  \n",
            "   [1]  show                  0.502   0.000  \n",
            "   [0]  the                   0.505   4.366  \n",
            " Sample 1.\n",
            "   [1]  is                    0.490   0.000  \n",
            "   [0]  a                     0.493   1.097  \n",
            "   [0]  exellent              0.493   14.401 \n",
            "   [1]  film                  0.494   0.000  \n",
            "   [1]  to                    0.495   0.000  \n",
            "   [1]  watch                 0.495   0.000  \n",
            "   [1]  a                     0.494   0.000  \n",
            "   [0]  rainy                 0.495   10.252 \n",
            "   [1]  night                 0.496   0.000  \n",
            "   [0]  with                  0.496   3.993  \n",
            "   [0]  your                  0.498   6.186  \n",
            "   [0]  friends               0.496   7.424  \n",
            "   [0]  their                 0.495   6.514  \n",
            "   [0]  old                   0.494   6.958  \n",
            "   [1]  stockholm             0.494   0.000  \n",
            "   [0]  ghetto                0.494   11.996 \n",
            "   [1]  talk                  0.494   0.000  \n",
            "   [1]  is                    0.496   0.000  \n",
            "   [1]  really                0.498   0.000  \n",
            "   [0]  something             0.496   5.948  \n",
            " Sample 2.\n",
            "   [1]  all                   0.509   0.000  \n",
            "   [0]  american              0.508   7.457  \n",
            "   [1]  soaps                 0.506   0.000  \n",
            "   [0]  dynasty               0.505   11.708 \n",
            "   [0]  is                    0.506   2.695  \n",
            "   [0]  nothing               0.507   6.695  \n",
            "   [0]  but                   0.508   5.353  \n",
            "   [1]  a                     0.508   0.000  \n",
            "   [0]  mish                  0.507   10.342 \n",
            "   [1]  mash                  0.507   0.000  \n",
            "   [1]  of                    0.506   0.000  \n",
            "   [1]  ropey                 0.506   0.000  \n",
            "   [0]  acting                0.505   7.804  \n",
            "   [0]  inane                 0.507   11.864 \n",
            "   [1]  plots                 0.507   0.000  \n",
            "   [0]  and                   0.508   2.988  \n",
            "   [1]  one                   0.510   0.000  \n",
            "   [0]  dimensional           0.510   9.953  \n",
            "   [1]  characters            0.510   0.000  \n",
            "   [1]  many                  0.510   0.000  \n",
            "Samples\n",
            "Sample 0 .  god this show deviates hugely from the comic book and movie in fact i liked this this tv show the\n",
            "Sample 1 .  is a exellent film to watch a rainy night with your friends their old stockholm ghetto talk is really something\n",
            "Sample 2 .  all american soaps dynasty is nothing but a mish mash of ropey acting inane plots and one dimensional characters many\n",
            "\n",
            "\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[0 1 1 0 1 0 0 1 0 0]...][[10 69848 13 2 69848 432 69848 69848 20 69848]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[0 1 1 0 1 0 0 1 0 0]...][[10 69848 13 2 69848 432 69848 69848 20 69848]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[0 0 1 0 0 1 1 0 1 0]...][[401 69848 69848 0 69848 69848 139 123 69848 51]...][[29 3 0 250 9 139 123 110 51 60]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[0 0 1 0 0 1 1 0 1 0]...][[401 69848 69848 0 69848 69848 139 123 69848 51]...][[29 3 0 250 9 139 123 110 51 60]...]\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "global_step: 2004\n",
            " perplexity: 447.744\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            " percent of 3-grams captured: 0.510.\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            " percent of 2-grams captured: 0.701.\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            " percent of 4-grams captured: 0.236.\n",
            " geometric_avg: 0.439.\n",
            " arithmetic_avg: 0.482.\n",
            "global_step: 2004\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69387\n",
            " G train loss: 3.09693\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[0 0 1 0 0 1 1 0 1 0]...][[401 69848 69848 0 69848 69848 139 123 69848 51]...][[29 3 0 250 9 139 123 110 51 60]...]\n",
            " Sample 0.\n",
            "   [0]  one                   0.500   4.294  \n",
            "   [0]  of                    0.501   1.759  \n",
            "   [1]  the                   0.501   0.000  \n",
            "   [0]  worst                 0.501   4.011  \n",
            "   [0]  i                     0.499   4.341  \n",
            "   [1]  ve                    0.497   0.000  \n",
            "   [1]  ever                  0.496   0.000  \n",
            "   [0]  seen                  0.497   1.935  \n",
            "   [1]  when                  0.497   0.000  \n",
            "   [0]  my                    0.498   5.178  \n",
            "   [1]  cousin                0.499   0.000  \n",
            "   [1]  called                0.502   0.000  \n",
            "   [0]  me                    0.504   6.945  \n",
            "   [0]  up                    0.506   6.421  \n",
            "   [1]  to                    0.504   0.000  \n",
            "   [1]  let                   0.501   0.000  \n",
            "   [0]  me                    0.498   4.926  \n",
            "   [1]  know                  0.496   0.000  \n",
            "   [0]  that                  0.495   3.379  \n",
            "   [0]  megalodon             0.494   11.762 \n",
            " Sample 1.\n",
            "   [1]  was                   0.495   0.000  \n",
            "   [0]  a                     0.498   1.616  \n",
            "   [0]  scene                 0.500   7.373  \n",
            "   [1]  in                    0.502   0.000  \n",
            "   [0]  this                  0.504   3.348  \n",
            "   [0]  movie                 0.505   1.919  \n",
            "   [1]  cold                  0.505   0.000  \n",
            "   [0]  is                    0.506   4.400  \n",
            "   [0]  running               0.505   8.841  \n",
            "   [1]  up                    0.506   0.000  \n",
            "   [1]  the                   0.506   0.000  \n",
            "   [0]  hotel                 0.507   9.644  \n",
            "   [1]  stairs                0.507   0.000  \n",
            "   [0]  and                   0.506   3.037  \n",
            "   [0]  fighting              0.505   8.954  \n",
            "   [0]  bad                   0.504   7.707  \n",
            "   [0]  guys                  0.502   8.892  \n",
            "   [1]  along                 0.502   0.000  \n",
            "   [1]  the                   0.504   0.000  \n",
            "   [1]  way                   0.505   0.000  \n",
            " Sample 2.\n",
            "   [0]  was                   0.487   3.600  \n",
            "   [1]  forced                0.486   0.000  \n",
            "   [1]  to                    0.484   0.000  \n",
            "   [0]  go                    0.480   5.881  \n",
            "   [1]  see                   0.477   0.000  \n",
            "   [0]  this                  0.475   1.812  \n",
            "   [0]  movie                 0.473   1.092  \n",
            "   [1]  with                  0.470   0.000  \n",
            "   [1]  a                     0.468   0.000  \n",
            "   [1]  bunch                 0.469   0.000  \n",
            "   [0]  of                    0.468   1.613  \n",
            "   [0]  ten                   0.466   7.913  \n",
            "   [1]  year                  0.466   0.000  \n",
            "   [1]  old                   0.467   0.000  \n",
            "   [1]  and                   0.466   0.000  \n",
            "   [1]  even                  0.466   0.000  \n",
            "   [1]  they                  0.465   0.000  \n",
            "   [0]  found                 0.465   5.084  \n",
            "   [1]  this                  0.466   0.000  \n",
            "   [0]  boring                0.466   7.715  \n",
            "Samples\n",
            "Sample 0 .  one of the worst i ve ever seen when my cousin called me up to let me know that megalodon\n",
            "Sample 1 .  was a scene in this movie cold is running up the hotel stairs and fighting bad guys along the way\n",
            "Sample 2 .  was forced to go see this movie with a bunch of ten year old and even they found this boring\n",
            "\n",
            "\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[0 0 0 0 0 0 0 0 1 1]...][[1058 69848 69848 69848 69848 69848 69848 69848 69848 19]...][[9 27 4 4938 0 543 3 0 19 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[0 0 0 0 0 0 0 0 1 1]...][[1058 69848 69848 69848 69848 69848 69848 69848 69848 19]...][[9 27 4 4938 0 543 3 0 19 34]...]\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[1 0 0 0 1 1 0 0 0 0]...][[10 17 69848 69848 69848 432 3 69848 69848 69848]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[1 0 0 0 1 1 0 0 0 0]...][[10 17 69848 69848 69848 432 3 69848 69848 69848]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "global_step: 2007\n",
            " perplexity: 447.311\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            " percent of 3-grams captured: 0.507.\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            " percent of 2-grams captured: 0.711.\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            " percent of 4-grams captured: 0.243.\n",
            " geometric_avg: 0.444.\n",
            " arithmetic_avg: 0.487.\n",
            "global_step: 2007\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69387\n",
            " G train loss: 3.09675\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[1 0 0 0 1 1 0 0 0 0]...][[10 17 69848 69848 69848 432 3 69848 69848 69848]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            " Sample 0.\n",
            "   [1]  movie                 0.471   0.000  \n",
            "   [0]  was                   0.471   2.170  \n",
            "   [0]  a                     0.470   1.257  \n",
            "   [0]  confusing             0.470   9.815  \n",
            "   [1]  piece                 0.469   0.000  \n",
            "   [1]  of                    0.469   0.000  \n",
            "   [0]  garbage               0.472   7.974  \n",
            "   [0]  you                   0.474   4.119  \n",
            "   [0]  never                 0.477   5.927  \n",
            "   [0]  knew                  0.478   7.183  \n",
            "   [1]  what                  0.478   0.000  \n",
            "   [0]  was                   0.476   4.807  \n",
            "   [1]  going                 0.474   0.000  \n",
            "   [0]  on                    0.471   4.825  \n",
            "   [1]  the                   0.470   0.000  \n",
            "   [1]  characters            0.470   0.000  \n",
            "   [0]  were                  0.471   5.748  \n",
            "   [0]  poorly                0.471   8.305  \n",
            "   [0]  written               0.472   7.662  \n",
            "   [1]  and                   0.473   0.000  \n",
            " Sample 1.\n",
            "   [1]  into                  0.511   0.000  \n",
            "   [0]  this                  0.516   2.331  \n",
            "   [0]  movie                 0.521   1.181  \n",
            "   [1]  you                   0.525   0.000  \n",
            "   [0]  know                  0.528   5.519  \n",
            "   [1]  that                  0.529   0.000  \n",
            "   [0]  this                  0.529   3.719  \n",
            "   [0]  is                    0.528   2.113  \n",
            "   [0]  movie                 0.527   5.693  \n",
            "   [0]  has                   0.528   5.300  \n",
            "   [0]  six                   0.529   9.449  \n",
            "   [0]  lab                   0.531   11.117 \n",
            "   [1]  technicians           0.532   0.000  \n",
            "   [0]  in                    0.532   3.285  \n",
            "   [0]  a                     0.530   3.203  \n",
            "   [1]  sealed                0.529   0.000  \n",
            "   [0]  lab                   0.528   11.732 \n",
            "   [0]  with                  0.527   4.715  \n",
            "   [0]  an                    0.527   4.880  \n",
            "   [1]  invisible             0.530   0.000  \n",
            " Sample 2.\n",
            "   [0]  saw                   0.495   3.582  \n",
            "   [1]  grease                0.496   0.000  \n",
            "   [1]  for                   0.498   0.000  \n",
            "   [0]  the                   0.501   1.808  \n",
            "   [1]  first                 0.503   0.000  \n",
            "   [0]  time                  0.506   3.926  \n",
            "   [1]  last                  0.507   0.000  \n",
            "   [1]  summer                0.508   0.000  \n",
            "   [1]  because               0.509   0.000  \n",
            "   [1]  i                     0.508   0.000  \n",
            "   [0]  was                   0.507   2.372  \n",
            "   [0]  curious               0.506   8.434  \n",
            "   [1]  about                 0.507   0.000  \n",
            "   [0]  the                   0.508   1.991  \n",
            "   [0]  movie                 0.509   2.537  \n",
            "   [1]  my                    0.510   0.000  \n",
            "   [0]  mother                0.509   7.743  \n",
            "   [0]  loved                 0.506   8.997  \n",
            "   [0]  so                    0.504   5.041  \n",
            "   [1]  much                  0.503   0.000  \n",
            "Samples\n",
            "Sample 0 .  movie was a confusing piece of garbage you never knew what was going on the characters were poorly written and\n",
            "Sample 1 .  into this movie you know that this is movie has six lab technicians in a sealed lab with an invisible\n",
            "Sample 2 .  saw grease for the first time last summer because i was curious about the movie my mother loved so much\n",
            "\n",
            "\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[0 1 1 1 1 1 0 1 1 1]...][[9 69848 555 43 460 3694 51 69848 215 0]...][[84 555 43 460 3694 51 9 215 0 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[0 1 1 1 1 1 0 1 1 1]...][[9 69848 555 43 460 3694 51 69848 215 0]...][[84 555 43 460 3694 51 9 215 0 246]...]\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[1 0 1 1 1 1 1 0 1 1]...][[1058 9 69848 4 4938 0 543 3 69848 19]...][[9 27 4 4938 0 543 3 0 19 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[1 0 1 1 1 1 1 0 1 1]...][[1058 9 69848 4 4938 0 543 3 69848 19]...][[9 27 4 4938 0 543 3 0 19 34]...]\n",
            "2020-03-24 03:52:16.205167: E tensorflow/core/util/events_writer.cc:162] The events file maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0 has disappeared.\n",
            "2020-03-24 03:52:16.205234: E tensorflow/core/util/events_writer.cc:131] Failed to flush 709 events to maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "global_step: 2010\n",
            " perplexity: 446.980\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            " percent of 3-grams captured: 0.498.\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            " percent of 2-grams captured: 0.712.\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            " percent of 4-grams captured: 0.240.\n",
            " geometric_avg: 0.440.\n",
            " arithmetic_avg: 0.483.\n",
            "global_step: 2010\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69387\n",
            " G train loss: 3.09590\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[1 0 1 1 1 1 1 0 1 1]...][[1058 9 69848 4 4938 0 543 3 69848 19]...][[9 27 4 4938 0 543 3 0 19 34]...]\n",
            " Sample 0.\n",
            "   [1]  i                     0.500   0.000  \n",
            "   [0]  have                  0.500   3.094  \n",
            "   [1]  to                    0.500   0.000  \n",
            "   [1]  defend                0.502   0.000  \n",
            "   [1]  the                   0.502   0.000  \n",
            "   [1]  writer                0.503   0.000  \n",
            "   [1]  of                    0.504   0.000  \n",
            "   [0]  the                   0.505   2.118  \n",
            "   [1]  film                  0.506   0.000  \n",
            "   [1]  who                   0.506   0.000  \n",
            "   [0]  did                   0.508   5.173  \n",
            "   [1]  manage                0.508   0.000  \n",
            "   [1]  to                    0.509   0.000  \n",
            "   [1]  get                   0.509   0.000  \n",
            "   [1]  a                     0.508   0.000  \n",
            "   [1]  certain               0.508   0.000  \n",
            "   [1]  amount                0.508   0.000  \n",
            "   [1]  of                    0.508   0.000  \n",
            "   [1]  emotional             0.507   0.000  \n",
            "   [1]  situations            0.508   0.000  \n",
            " Sample 1.\n",
            "   [1]  this                  0.473   0.000  \n",
            "   [1]  show                  0.472   0.000  \n",
            "   [0]  came                  0.473   5.593  \n",
            "   [0]  on                    0.472   4.423  \n",
            "   [1]  back                  0.472   0.000  \n",
            "   [1]  in                    0.471   0.000  \n",
            "   [0]  the                   0.472   1.564  \n",
            "   [0]  mid                   0.472   8.040  \n",
            "   [1]  90s                   0.473   0.000  \n",
            "   [0]  it                    0.474   3.805  \n",
            "   [1]  was                   0.473   0.000  \n",
            "   [0]  a                     0.473   1.522  \n",
            "   [0]  treat                 0.474   8.465  \n",
            "   [1]  for                   0.474   0.000  \n",
            "   [0]  both                  0.474   6.986  \n",
            "   [1]  kids                  0.474   0.000  \n",
            "   [1]  and                   0.474   0.000  \n",
            "   [1]  adults                0.474   0.000  \n",
            "   [0]  alike                 0.475   10.795 \n",
            "   [1]  with                  0.473   0.000  \n",
            " Sample 2.\n",
            "   [0]  appearance            0.500   8.635  \n",
            "   [1]  of                    0.499   0.000  \n",
            "   [1]  michelle              0.501   0.000  \n",
            "   [1]  yeoh                  0.503   0.000  \n",
            "   [1]  in                    0.505   0.000  \n",
            "   [1]  tomorrow              0.508   0.000  \n",
            "   [0]  never                 0.511   7.973  \n",
            "   [0]  dies                  0.513   8.693  \n",
            "   [0]  and                   0.513   3.721  \n",
            "   [0]  then                  0.514   7.081  \n",
            "   [1]  crouching             0.513   0.000  \n",
            "   [1]  tiger                 0.513   0.000  \n",
            "   [1]  hidden                0.512   0.000  \n",
            "   [1]  dragon                0.511   0.000  \n",
            "   [1]  piqued                0.511   0.000  \n",
            "   [1]  my                    0.510   0.000  \n",
            "   [0]  interest              0.509   8.788  \n",
            "   [1]  in                    0.508   0.000  \n",
            "   [0]  the                   0.508   1.981  \n",
            "   [1]  lady                  0.508   0.000  \n",
            "Samples\n",
            "Sample 0 .  i have to defend the writer of the film who did manage to get a certain amount of emotional situations\n",
            "Sample 1 .  this show came on back in the mid 90s it was a treat for both kids and adults alike with\n",
            "Sample 2 .  appearance of michelle yeoh in tomorrow never dies and then crouching tiger hidden dragon piqued my interest in the lady\n",
            "\n",
            "\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[0 1 0 0 1 1 0 0 0 0]...][[7 69848 180 69848 69848 1401 2 69848 69848 69848]...][[188 180 31129 4 1401 2 12137 153 12 84]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[0 1 0 0 1 1 0 0 0 0]...][[7 69848 180 69848 69848 1401 2 69848 69848 69848]...][[188 180 31129 4 1401 2 12137 153 12 84]...]\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[0 0 1 1 0 1 1 1 1 1]...][[9 69848 69848 43 460 69848 51 9 215 0]...][[84 555 43 460 3694 51 9 215 0 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[0 0 1 1 0 1 1 1 1 1]...][[9 69848 69848 43 460 69848 51 9 215 0]...][[84 555 43 460 3694 51 9 215 0 246]...]\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "global_step: 2013\n",
            " perplexity: 447.033\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            " percent of 3-grams captured: 0.512.\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            " percent of 2-grams captured: 0.707.\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            " percent of 4-grams captured: 0.240.\n",
            " geometric_avg: 0.443.\n",
            " arithmetic_avg: 0.486.\n",
            "global_step: 2013\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69387\n",
            " G train loss: 3.09706\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[0 0 1 1 0 1 1 1 1 1]...][[9 69848 69848 43 460 69848 51 9 215 0]...][[84 555 43 460 3694 51 9 215 0 246]...]\n",
            " Sample 0.\n",
            "   [0]  first                 0.508   2.904  \n",
            "   [0]  heard                 0.511   5.381  \n",
            "   [1]  about                 0.515   0.000  \n",
            "   [1]  white                 0.519   0.000  \n",
            "   [0]  noise                 0.522   10.953 \n",
            "   [1]  when                  0.525   0.000  \n",
            "   [1]  i                     0.525   0.000  \n",
            "   [1]  saw                   0.525   0.000  \n",
            "   [1]  the                   0.527   0.000  \n",
            "   [1]  tv                    0.527   0.000  \n",
            "   [0]  advert                0.527   13.270 \n",
            "   [0]  before                0.525   6.387  \n",
            "   [1]  then                  0.524   0.000  \n",
            "   [0]  i                     0.523   2.553  \n",
            "   [0]  didn                  0.524   4.808  \n",
            "   [1]  t                     0.526   0.000  \n",
            "   [1]  even                  0.527   0.000  \n",
            "   [0]  know                  0.526   4.869  \n",
            "   [0]  it                    0.528   2.766  \n",
            "   [1]  existed               0.528   0.000  \n",
            " Sample 1.\n",
            "   [1]  it                    0.532   0.000  \n",
            "   [0]  s                     0.532   1.871  \n",
            "   [1]  only                  0.530   0.000  \n",
            "   [0]  one                   0.530   3.290  \n",
            "   [0]  hour                  0.529   8.016  \n",
            "   [0]  long                  0.528   9.259  \n",
            "   [0]  teen                  0.528   8.530  \n",
            "   [1]  ape                   0.529   0.000  \n",
            "   [1]  is                    0.530   0.000  \n",
            "   [1]  a                     0.529   0.000  \n",
            "   [1]  very                  0.528   0.000  \n",
            "   [1]  likable               0.527   0.000  \n",
            "   [1]  character             0.527   0.000  \n",
            "   [0]  lots                  0.526   8.721  \n",
            "   [0]  of                    0.525   2.564  \n",
            "   [0]  angular               0.525   14.998 \n",
            "   [1]  goofiness             0.526   0.000  \n",
            "   [0]  lead                  0.528   9.258  \n",
            "   [1]  actress               0.529   0.000  \n",
            "   [0]  missy                 0.530   11.982 \n",
            " Sample 2.\n",
            "   [0]  film                  0.488   4.017  \n",
            "   [0]  is                    0.489   2.120  \n",
            "   [1]  based                 0.489   0.000  \n",
            "   [1]  on                    0.488   0.000  \n",
            "   [1]  a                     0.487   0.000  \n",
            "   [1]  genuine               0.487   0.000  \n",
            "   [0]  1950s                 0.488   9.266  \n",
            "   [1]  novel                 0.488   0.000  \n",
            "   [1]  br                    0.489   0.000  \n",
            "   [0]  br                    0.490   2.251  \n",
            "   [1]  journalist            0.492   0.000  \n",
            "   [1]  colin                 0.493   0.000  \n",
            "   [0]  mcinnes               0.494   13.120 \n",
            "   [1]  wrote                 0.494   0.000  \n",
            "   [0]  a                     0.494   2.683  \n",
            "   [0]  set                   0.495   8.911  \n",
            "   [1]  of                    0.495   0.000  \n",
            "   [1]  three                 0.496   0.000  \n",
            "   [1]  london                0.497   0.000  \n",
            "   [0]  novels                0.497   8.960  \n",
            "Samples\n",
            "Sample 0 .  first heard about white noise when i saw the tv advert before then i didn t even know it existed\n",
            "Sample 1 .  it s only one hour long teen ape is a very likable character lots of angular goofiness lead actress missy\n",
            "Sample 2 .  film is based on a genuine 1950s novel br br journalist colin mcinnes wrote a set of three london novels\n",
            "\n",
            "\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[0 1 1 1 1 1 1 1 0 1]...][[9 69848 2215 56 1731 2346 8 10 17 69848]...][[215 2215 56 1731 2346 8 10 17 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[0 1 1 1 1 1 1 1 0 1]...][[9 69848 2215 56 1731 2346 8 10 17 69848]...][[215 2215 56 1731 2346 8 10 17 0 64]...]\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[1 1 0 1 0 0 1 0 0 1]...][[7 188 180 69848 4 69848 69848 12137 69848 69848]...][[188 180 31129 4 1401 2 12137 153 12 84]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[1 1 0 1 0 0 1 0 0 1]...][[7 188 180 69848 4 69848 69848 12137 69848 69848]...][[188 180 31129 4 1401 2 12137 153 12 84]...]\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "global_step: 2016\n",
            " perplexity: 446.624\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            " percent of 3-grams captured: 0.504.\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            " percent of 2-grams captured: 0.720.\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            " percent of 4-grams captured: 0.250.\n",
            " geometric_avg: 0.449.\n",
            " arithmetic_avg: 0.491.\n",
            "global_step: 2016\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69390\n",
            " G train loss: 3.09605\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[1 1 0 1 0 0 1 0 0 1]...][[7 188 180 69848 4 69848 69848 12137 69848 69848]...][[188 180 31129 4 1401 2 12137 153 12 84]...]\n",
            " Sample 0.\n",
            "   [1]  seems                 0.503   0.000  \n",
            "   [1]  quite                 0.502   0.000  \n",
            "   [0]  churlish              0.502   14.745 \n",
            "   [1]  to                    0.503   0.000  \n",
            "   [0]  excuse                0.505   10.112 \n",
            "   [0]  a                     0.507   3.207  \n",
            "   [1]  novice                0.511   0.000  \n",
            "   [0]  director              0.513   6.266  \n",
            "   [0]  s                     0.513   5.284  \n",
            "   [1]  first                 0.512   0.000  \n",
            "   [1]  feature               0.512   0.000  \n",
            "   [1]  length                0.513   0.000  \n",
            "   [1]  outing                0.514   0.000  \n",
            "   [0]  especially            0.515   7.373  \n",
            "   [1]  when                  0.514   0.000  \n",
            "   [0]  you                   0.514   2.836  \n",
            "   [1]  have                  0.515   0.000  \n",
            "   [0]  not                   0.516   3.281  \n",
            "   [0]  yet                   0.516   7.422  \n",
            "   [0]  made                  0.517   5.117  \n",
            " Sample 1.\n",
            "   [1]  alfred                0.503   0.000  \n",
            "   [0]  green                 0.499   9.278  \n",
            "   [0]  s                     0.496   3.017  \n",
            "   [1]  melodrama             0.492   0.000  \n",
            "   [1]  baby                  0.490   0.000  \n",
            "   [0]  face                  0.489   9.883  \n",
            "   [1]  with                  0.490   0.000  \n",
            "   [0]  barbara               0.493   9.500  \n",
            "   [0]  stanwyck              0.497   9.599  \n",
            "   [0]  ranks                 0.499   9.869  \n",
            "   [1]  as                    0.500   0.000  \n",
            "   [1]  one                   0.501   0.000  \n",
            "   [1]  of                    0.500   0.000  \n",
            "   [0]  the                   0.498   0.788  \n",
            "   [1]  more                  0.497   0.000  \n",
            "   [0]  notorious             0.494   10.026 \n",
            "   [1]  of                    0.493   0.000  \n",
            "   [0]  the                   0.492   1.148  \n",
            "   [0]  pre                   0.492   8.017  \n",
            "   [1]  code                  0.493   0.000  \n",
            " Sample 2.\n",
            "   [1]  i                     0.490   0.000  \n",
            "   [1]  heard                 0.489   0.000  \n",
            "   [0]  what                  0.490   5.364  \n",
            "   [0]  s                     0.492   5.998  \n",
            "   [1]  the                   0.494   0.000  \n",
            "   [1]  theme                 0.495   0.000  \n",
            "   [1]  of                    0.495   0.000  \n",
            "   [1]  common                0.495   0.000  \n",
            "   [1]  ground                0.495   0.000  \n",
            "   [1]  i                     0.492   0.000  \n",
            "   [0]  thought               0.490   3.915  \n",
            "   [1]  first                 0.488   0.000  \n",
            "   [1]  about                 0.489   0.000  \n",
            "   [0]  other                 0.491   6.337  \n",
            "   [0]  attempts              0.493   9.507  \n",
            "   [1]  like                  0.494   0.000  \n",
            "   [1]  in                    0.494   0.000  \n",
            "   [1]  out                   0.494   0.000  \n",
            "   [1]  jeffrey               0.493   0.000  \n",
            "   [1]  also                  0.495   0.000  \n",
            "Samples\n",
            "Sample 0 .  seems quite churlish to excuse a novice director s first feature length outing especially when you have not yet made\n",
            "Sample 1 .  alfred green s melodrama baby face with barbara stanwyck ranks as one of the more notorious of the pre code\n",
            "Sample 2 .  i heard what s the theme of common ground i thought first about other attempts like in out jeffrey also\n",
            "\n",
            "\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[0 1 0 1 1 0 1 0 1 1]...][[499 69848 839 69848 3 38 69848 1808 69848 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[0 1 0 1 1 0 1 0 1 1]...][[499 69848 839 69848 3 38 69848 1808 69848 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[1 1 1 0 1 1 1 1 0 0]...][[9 215 2215 56 69848 2346 8 10 17 69848]...][[215 2215 56 1731 2346 8 10 17 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[1 1 1 0 1 1 1 1 0 0]...][[9 215 2215 56 69848 2346 8 10 17 69848]...][[215 2215 56 1731 2346 8 10 17 0 64]...]\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "global_step: 2019\n",
            " perplexity: 446.588\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            " percent of 3-grams captured: 0.497.\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            " percent of 2-grams captured: 0.709.\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            " percent of 4-grams captured: 0.239.\n",
            " geometric_avg: 0.438.\n",
            " arithmetic_avg: 0.482.\n",
            "global_step: 2019\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69389\n",
            " G train loss: 3.09575\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[1 1 1 0 1 1 1 1 0 0]...][[9 215 2215 56 69848 2346 8 10 17 69848]...][[215 2215 56 1731 2346 8 10 17 0 64]...]\n",
            " Sample 0.\n",
            "   [1]  saw                   0.498   0.000  \n",
            "   [1]  virtually             0.498   0.000  \n",
            "   [1]  no                    0.495   0.000  \n",
            "   [0]  redeeming             0.492   8.049  \n",
            "   [1]  qualities             0.490   0.000  \n",
            "   [1]  in                    0.488   0.000  \n",
            "   [1]  this                  0.488   0.000  \n",
            "   [1]  movie                 0.489   0.000  \n",
            "   [0]  the                   0.489   4.131  \n",
            "   [0]  only                  0.489   4.558  \n",
            "   [1]  thing                 0.489   0.000  \n",
            "   [0]  i                     0.486   1.999  \n",
            "   [1]  did                   0.484   0.000  \n",
            "   [1]  see                   0.482   0.000  \n",
            "   [0]  was                   0.480   6.561  \n",
            "   [0]  quentin               0.479   11.936 \n",
            "   [0]  tarantino             0.479   10.999 \n",
            "   [1]  s                     0.482   0.000  \n",
            "   [0]  seeming               0.484   10.673 \n",
            "   [0]  insane                0.485   10.509 \n",
            " Sample 1.\n",
            "   [1]  real                  0.504   0.000  \n",
            "   [0]  was                   0.504   6.207  \n",
            "   [1]  all                   0.504   0.000  \n",
            "   [1]  shot                  0.504   0.000  \n",
            "   [1]  in                    0.505   0.000  \n",
            "   [1]  one                   0.505   0.000  \n",
            "   [1]  take                  0.506   0.000  \n",
            "   [0]  it                    0.506   2.913  \n",
            "   [0]  made                  0.505   5.368  \n",
            "   [0]  the                   0.504   2.136  \n",
            "   [0]  guiness               0.505   15.676 \n",
            "   [1]  book                  0.506   0.000  \n",
            "   [0]  of                    0.507   2.936  \n",
            "   [0]  records               0.508   13.335 \n",
            "   [1]  now                   0.508   0.000  \n",
            "   [1]  in                    0.509   0.000  \n",
            "   [0]  my                    0.508   4.520  \n",
            "   [1]  opinion               0.508   0.000  \n",
            "   [1]  any                   0.508   0.000  \n",
            "   [1]  work                  0.509   0.000  \n",
            " Sample 2.\n",
            "   [1]  many                  0.491   0.000  \n",
            "   [0]  other                 0.494   6.013  \n",
            "   [0]  films                 0.498   4.681  \n",
            "   [1]  which                 0.502   0.000  \n",
            "   [1]  are                   0.504   0.000  \n",
            "   [0]  disturbing            0.506   9.723  \n",
            "   [0]  either                0.507   8.097  \n",
            "   [1]  by                    0.508   0.000  \n",
            "   [1]  dint                  0.507   0.000  \n",
            "   [1]  of                    0.506   0.000  \n",
            "   [1]  their                 0.505   0.000  \n",
            "   [1]  naked                 0.504   0.000  \n",
            "   [1]  unpleasantness        0.504   0.000  \n",
            "   [0]  man                   0.506   6.895  \n",
            "   [0]  bites                 0.508   12.473 \n",
            "   [1]  dog                   0.508   0.000  \n",
            "   [1]  or                    0.508   0.000  \n",
            "   [0]  their                 0.507   4.241  \n",
            "   [0]  sheer                 0.505   8.296  \n",
            "   [1]  violence              0.503   0.000  \n",
            "Samples\n",
            "Sample 0 .  saw virtually no redeeming qualities in this movie the only thing i did see was quentin tarantino s seeming insane\n",
            "Sample 1 .  real was all shot in one take it made the guiness book of records now in my opinion any work\n",
            "Sample 2 .  many other films which are disturbing either by dint of their naked unpleasantness man bites dog or their sheer violence\n",
            "\n",
            "\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[0 0 0 1 0 0 0 1 1 0]...][[25081 69848 69848 69848 9 69848 69848 69848 10 17]...][[5 29 151 9 50 136 43 10 17 1317]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[0 0 0 1 0 0 0 1 1 0]...][[25081 69848 69848 69848 9 69848 69848 69848 10 17]...][[5 29 151 9 50 136 43 10 17 1317]...]\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[1 1 0 0 1 1 0 1 1 0]...][[499 44 839 69848 69848 38 2 69848 823 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[1 1 0 0 1 1 0 1 1 0]...][[499 44 839 69848 69848 38 2 69848 823 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "global_step: 2022\n",
            " perplexity: 446.495\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            " percent of 3-grams captured: 0.496.\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            " percent of 2-grams captured: 0.701.\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            " percent of 4-grams captured: 0.238.\n",
            " geometric_avg: 0.435.\n",
            " arithmetic_avg: 0.478.\n",
            "global_step: 2022\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69386\n",
            " G train loss: 3.09419\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[1 1 0 0 1 1 0 1 1 0]...][[499 44 839 69848 69848 38 2 69848 823 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            " Sample 0.\n",
            "   [1]  out                   0.492   0.000  \n",
            "   [1]  poorly                0.493   0.000  \n",
            "   [0]  sort                  0.492   8.000  \n",
            "   [0]  of                    0.491   1.567  \n",
            "   [1]  like                  0.490   0.000  \n",
            "   [1]  a                     0.490   0.000  \n",
            "   [0]  below                 0.492   10.033 \n",
            "   [1]  average               0.493   0.000  \n",
            "   [1]  tv                    0.493   0.000  \n",
            "   [0]  movie                 0.494   4.023  \n",
            "   [0]  about                 0.493   5.379  \n",
            "   [1]  a                     0.493   0.000  \n",
            "   [0]  plane                 0.492   9.376  \n",
            "   [0]  crash                 0.490   10.056 \n",
            "   [1]  drags                 0.487   0.000  \n",
            "   [1]  on                    0.485   0.000  \n",
            "   [0]  for                   0.484   6.166  \n",
            "   [1]  about                 0.484   0.000  \n",
            "   [1]  twenty                0.484   0.000  \n",
            "   [0]  minutes               0.485   6.799  \n",
            " Sample 1.\n",
            "   [1]  s                     0.487   0.000  \n",
            "   [1]  not                   0.494   0.000  \n",
            "   [1]  the                   0.499   0.000  \n",
            "   [1]  best                  0.501   0.000  \n",
            "   [0]  gun                   0.502   9.377  \n",
            "   [0]  movie                 0.503   2.792  \n",
            "   [0]  it                    0.504   2.662  \n",
            "   [1]  s                     0.506   0.000  \n",
            "   [0]  definitely            0.508   6.755  \n",
            "   [0]  not                   0.510   3.249  \n",
            "   [0]  the                   0.512   3.585  \n",
            "   [1]  best                  0.513   0.000  \n",
            "   [1]  fighting              0.511   0.000  \n",
            "   [0]  movie                 0.510   3.322  \n",
            "   [0]  it                    0.509   2.228  \n",
            "   [0]  doesn                 0.510   4.819  \n",
            "   [1]  t                     0.510   0.000  \n",
            "   [0]  have                  0.510   3.143  \n",
            "   [0]  the                   0.511   4.221  \n",
            "   [0]  best                  0.511   4.369  \n",
            " Sample 2.\n",
            "   [1]  film                  0.505   0.000  \n",
            "   [1]  makes                 0.505   0.000  \n",
            "   [1]  no                    0.506   0.000  \n",
            "   [0]  pretense              0.507   15.240 \n",
            "   [1]  about                 0.508   0.000  \n",
            "   [0]  being                 0.508   6.656  \n",
            "   [1]  anything              0.511   0.000  \n",
            "   [1]  except                0.512   0.000  \n",
            "   [1]  a                     0.510   0.000  \n",
            "   [0]  tale                  0.509   7.462  \n",
            "   [1]  fantasy               0.510   0.000  \n",
            "   [0]  about                 0.508   5.846  \n",
            "   [0]  time                  0.508   6.755  \n",
            "   [0]  travel                0.507   9.402  \n",
            "   [1]  you                   0.507   0.000  \n",
            "   [1]  can                   0.506   0.000  \n",
            "   [1]  see                   0.507   0.000  \n",
            "   [0]  it                    0.509   2.865  \n",
            "   [1]  in                    0.509   0.000  \n",
            "   [1]  the                   0.508   0.000  \n",
            "Samples\n",
            "Sample 0 .  out poorly sort of like a below average tv movie about a plane crash drags on for about twenty minutes\n",
            "Sample 1 .  s not the best gun movie it s definitely not the best fighting movie it doesn t have the best\n",
            "Sample 2 .  film makes no pretense about being anything except a tale fantasy about time travel you can see it in the\n",
            "\n",
            "\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 0 1 0 1 1 0 0 0 1]...][[115 2838 69848 50 69848 136 5 69848 69848 69848]...][[2838 9 50 6208 136 5 241 60 160 1628]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 0 1 0 1 1 0 0 0 1]...][[115 2838 69848 50 69848 136 5 69848 69848 69848]...][[2838 9 50 6208 136 5 241 60 160 1628]...]\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[1 0 1 1 0 0 1 0 1 1]...][[25081 5 69848 151 9 69848 69848 43 69848 17]...][[5 29 151 9 50 136 43 10 17 1317]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[1 0 1 1 0 0 1 0 1 1]...][[25081 5 69848 151 9 69848 69848 43 69848 17]...][[5 29 151 9 50 136 43 10 17 1317]...]\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "global_step: 2025\n",
            " perplexity: 445.819\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            " percent of 3-grams captured: 0.503.\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            " percent of 2-grams captured: 0.700.\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            " percent of 4-grams captured: 0.243.\n",
            " geometric_avg: 0.441.\n",
            " arithmetic_avg: 0.482.\n",
            "global_step: 2025\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69382\n",
            " G train loss: 3.09337\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[1 0 1 1 0 0 1 0 1 1]...][[25081 5 69848 151 9 69848 69848 43 69848 17]...][[5 29 151 9 50 136 43 10 17 1317]...]\n",
            " Sample 0.\n",
            "   [1]  is                    0.503   0.000  \n",
            "   [0]  one                   0.506   3.539  \n",
            "   [1]  thing                 0.508   0.000  \n",
            "   [1]  i                     0.508   0.000  \n",
            "   [0]  can                   0.507   3.578  \n",
            "   [0]  say                   0.507   5.043  \n",
            "   [1]  about                 0.507   0.000  \n",
            "   [0]  this                  0.507   2.416  \n",
            "   [1]  movie                 0.507   0.000  \n",
            "   [1]  personally            0.507   0.000  \n",
            "   [1]  i                     0.506   0.000  \n",
            "   [1]  m                     0.505   0.000  \n",
            "   [1]  one                   0.506   0.000  \n",
            "   [1]  of                    0.507   0.000  \n",
            "   [1]  those                 0.508   0.000  \n",
            "   [0]  people                0.510   4.589  \n",
            "   [0]  who                   0.511   6.160  \n",
            "   [0]  loves                 0.514   8.370  \n",
            "   [1]  cats                  0.517   0.000  \n",
            "   [1]  so                    0.518   0.000  \n",
            " Sample 1.\n",
            "   [0]  there                 0.492   4.234  \n",
            "   [0]  s                     0.490   2.978  \n",
            "   [0]  anything              0.491   7.498  \n",
            "   [1]  on                    0.492   0.000  \n",
            "   [1]  tv                    0.493   0.000  \n",
            "   [0]  that                  0.492   4.450  \n",
            "   [0]  could                 0.492   6.189  \n",
            "   [0]  make                  0.493   4.481  \n",
            "   [1]  cop                   0.494   0.000  \n",
            "   [0]  rock                  0.495   9.496  \n",
            "   [1]  look                  0.496   0.000  \n",
            "   [0]  like                  0.497   6.460  \n",
            "   [0]  masterpiece           0.497   9.805  \n",
            "   [1]  theatre               0.497   0.000  \n",
            "   [1]  san                   0.497   0.000  \n",
            "   [0]  francisco             0.496   9.192  \n",
            "   [0]  international         0.495   8.777  \n",
            "   [1]  is                    0.494   0.000  \n",
            "   [1]  it                    0.493   0.000  \n",
            "   [1]  pernell               0.492   0.000  \n",
            " Sample 2.\n",
            "   [0]  wasn                  0.499   5.980  \n",
            "   [0]  t                     0.500   0.554  \n",
            "   [1]  sure                  0.501   0.000  \n",
            "   [0]  what                  0.500   4.546  \n",
            "   [0]  to                    0.500   3.848  \n",
            "   [0]  expect                0.501   4.831  \n",
            "   [0]  when                  0.501   4.869  \n",
            "   [0]  i                     0.499   1.934  \n",
            "   [1]  went                  0.498   0.000  \n",
            "   [1]  to                    0.497   0.000  \n",
            "   [0]  see                   0.498   2.914  \n",
            "   [1]  this                  0.498   0.000  \n",
            "   [1]  film                  0.498   0.000  \n",
            "   [1]  i                     0.497   0.000  \n",
            "   [1]  liked                 0.497   0.000  \n",
            "   [0]  the                   0.499   3.006  \n",
            "   [0]  graphic               0.501   10.330 \n",
            "   [1]  novel                 0.504   0.000  \n",
            "   [1]  and                   0.506   0.000  \n",
            "   [1]  was                   0.506   0.000  \n",
            "Samples\n",
            "Sample 0 .  is one thing i can say about this movie personally i m one of those people who loves cats so\n",
            "Sample 1 .  there s anything on tv that could make cop rock look like masterpiece theatre san francisco international is it pernell\n",
            "Sample 2 .  wasn t sure what to expect when i went to see this film i liked the graphic novel and was\n",
            "\n",
            "\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[0 0 1 1 1 0 0 0 0 0]...][[1818 69848 69848 23 8014 4 69848 69848 69848 69848]...][[9 140 23 8014 4 949 829 18 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[0 0 1 1 1 0 0 0 0 0]...][[1818 69848 69848 23 8014 4 69848 69848 69848 69848]...][[9 140 23 8014 4 949 829 18 10 17]...]\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 1 0 1 0 0 0 0 1 0]...][[115 2838 9 69848 6208 69848 69848 69848 69848 160]...][[2838 9 50 6208 136 5 241 60 160 1628]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 1 0 1 0 0 0 0 1 0]...][[115 2838 9 69848 6208 69848 69848 69848 69848 160]...][[2838 9 50 6208 136 5 241 60 160 1628]...]\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "global_step: 2028\n",
            " perplexity: 445.950\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            " percent of 3-grams captured: 0.491.\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            " percent of 2-grams captured: 0.704.\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            " percent of 4-grams captured: 0.234.\n",
            " geometric_avg: 0.433.\n",
            " arithmetic_avg: 0.477.\n",
            "global_step: 2028\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69382\n",
            " G train loss: 3.09366\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 1 0 1 0 0 0 0 1 0]...][[115 2838 9 69848 6208 69848 69848 69848 69848 160]...][[2838 9 50 6208 136 5 241 60 160 1628]...]\n",
            " Sample 0.\n",
            "   [1]  britain               0.498   0.000  \n",
            "   [1]  i                     0.497   0.000  \n",
            "   [0]  can                   0.498   4.170  \n",
            "   [1]  safely                0.500   0.000  \n",
            "   [0]  say                   0.502   7.826  \n",
            "   [0]  is                    0.504   6.229  \n",
            "   [0]  probably              0.506   6.116  \n",
            "   [0]  my                    0.507   5.294  \n",
            "   [1]  new                   0.507   0.000  \n",
            "   [0]  favourite             0.507   8.315  \n",
            "   [0]  show                  0.504   6.344  \n",
            "   [1]  it                    0.501   0.000  \n",
            "   [0]  s                     0.498   2.777  \n",
            "   [1]  so                    0.497   0.000  \n",
            "   [0]  creative              0.497   9.744  \n",
            "   [0]  and                   0.498   2.290  \n",
            "   [1]  hilarious             0.501   0.000  \n",
            "   [1]  and                   0.503   0.000  \n",
            "   [0]  even                  0.504   6.048  \n",
            "   [0]  the                   0.504   4.579  \n",
            " Sample 1.\n",
            "   [1]  first                 0.500   0.000  \n",
            "   [1]  i                     0.499   0.000  \n",
            "   [0]  was                   0.499   3.113  \n",
            "   [0]  a                     0.502   3.161  \n",
            "   [0]  little                0.506   5.691  \n",
            "   [0]  hesitant              0.511   9.988  \n",
            "   [1]  about                 0.515   0.000  \n",
            "   [1]  taking                0.520   0.000  \n",
            "   [1]  time                  0.523   0.000  \n",
            "   [1]  out                   0.524   0.000  \n",
            "   [1]  of                    0.524   0.000  \n",
            "   [1]  my                    0.524   0.000  \n",
            "   [1]  life                  0.521   0.000  \n",
            "   [1]  to                    0.517   0.000  \n",
            "   [0]  see                   0.514   4.588  \n",
            "   [0]  seven                 0.512   9.279  \n",
            "   [1]  i                     0.510   0.000  \n",
            "   [1]  mean                  0.510   0.000  \n",
            "   [0]  i                     0.510   3.444  \n",
            "   [1]  am                    0.512   0.000  \n",
            " Sample 2.\n",
            "   [0]  ve                    0.499   2.843  \n",
            "   [0]  been                  0.504   3.949  \n",
            "   [0]  trying                0.511   7.920  \n",
            "   [1]  to                    0.517   0.000  \n",
            "   [1]  track                 0.520   0.000  \n",
            "   [0]  down                  0.521   6.675  \n",
            "   [1]  this                  0.522   0.000  \n",
            "   [0]  film                  0.523   1.802  \n",
            "   [0]  just                  0.526   5.707  \n",
            "   [0]  by                    0.527   8.095  \n",
            "   [0]  googling              0.528   16.261 \n",
            "   [1]  bad                   0.529   0.000  \n",
            "   [0]  phrases               0.529   14.137 \n",
            "   [1]  about                 0.529   0.000  \n",
            "   [1]  teenagers             0.529   0.000  \n",
            "   [1]  seduce                0.528   0.000  \n",
            "   [1]  and                   0.528   0.000  \n",
            "   [1]  kill                  0.528   0.000  \n",
            "   [0]  man                   0.528   7.649  \n",
            "   [0]  in                    0.528   3.546  \n",
            "Samples\n",
            "Sample 0 .  britain i can safely say is probably my new favourite show it s so creative and hilarious and even the\n",
            "Sample 1 .  first i was a little hesitant about taking time out of my life to see seven i mean i am\n",
            "Sample 2 .  ve been trying to track down this film just by googling bad phrases about teenagers seduce and kill man in\n",
            "\n",
            "\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[0 0 1 0 1 1 0 1 0 1]...][[23256 69848 69848 142 69848 1133 1670 69848 11 69848]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[0 0 1 0 1 1 0 1 0 1]...][[23256 69848 69848 142 69848 1133 1670 69848 11 69848]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[0 1 1 0 0 1 0 0 0 0]...][[1818 69848 140 23 69848 69848 949 69848 69848 69848]...][[9 140 23 8014 4 949 829 18 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[0 1 1 0 0 1 0 0 0 0]...][[1818 69848 140 23 69848 69848 949 69848 69848 69848]...][[9 140 23 8014 4 949 829 18 10 17]...]\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "global_step: 2031\n",
            " perplexity: 445.950\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            " percent of 3-grams captured: 0.481.\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            " percent of 2-grams captured: 0.701.\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            " percent of 4-grams captured: 0.232.\n",
            " geometric_avg: 0.428.\n",
            " arithmetic_avg: 0.471.\n",
            "global_step: 2031\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69381\n",
            " G train loss: 3.09386\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[0 1 1 0 0 1 0 0 0 0]...][[1818 69848 140 23 69848 69848 949 69848 69848 69848]...][[9 140 23 8014 4 949 829 18 10 17]...]\n",
            " Sample 0.\n",
            "   [0]  i                     0.504   3.304  \n",
            "   [1]  m                     0.507   0.000  \n",
            "   [1]  not                   0.510   0.000  \n",
            "   [0]  motivated             0.512   13.844 \n",
            "   [0]  to                    0.513   2.435  \n",
            "   [1]  write                 0.514   0.000  \n",
            "   [0]  reviews               0.514   7.970  \n",
            "   [0]  but                   0.514   3.898  \n",
            "   [0]  this                  0.512   3.596  \n",
            "   [0]  movie                 0.509   1.163  \n",
            "   [0]  was                   0.507   2.053  \n",
            "   [1]  so                    0.506   0.000  \n",
            "   [0]  excruciatingly        0.506   11.493 \n",
            "   [0]  painful               0.507   9.680  \n",
            "   [0]  i                     0.506   2.896  \n",
            "   [1]  feel                  0.505   0.000  \n",
            "   [0]  i                     0.505   4.058  \n",
            "   [0]  must                  0.505   4.949  \n",
            "   [0]  i                     0.504   7.889  \n",
            "   [0]  cringed               0.504   13.954 \n",
            " Sample 1.\n",
            "   [1]  on                    0.515   0.000  \n",
            "   [0]  the                   0.517   1.829  \n",
            "   [1]  original              0.520   0.000  \n",
            "   [0]  the                   0.524   4.917  \n",
            "   [0]  awful                 0.528   7.455  \n",
            "   [0]  truth                 0.530   8.972  \n",
            "   [1]  this                  0.532   0.000  \n",
            "   [1]  update                0.531   0.000  \n",
            "   [1]  is                    0.532   0.000  \n",
            "   [0]  so                    0.532   4.519  \n",
            "   [0]  completely            0.533   7.843  \n",
            "   [0]  inferior              0.532   10.171 \n",
            "   [0]  one                   0.533   6.304  \n",
            "   [1]  has                   0.535   0.000  \n",
            "   [0]  to                    0.536   4.162  \n",
            "   [1]  wonder                0.535   0.000  \n",
            "   [0]  what                  0.535   4.912  \n",
            "   [0]  the                   0.537   2.638  \n",
            "   [1]  intent                0.537   0.000  \n",
            "   [1]  was                   0.536   0.000  \n",
            " Sample 2.\n",
            "   [1]  0                     0.517   0.000  \n",
            "   [0]  shooting              0.517   9.891  \n",
            "   [1]  0                     0.519   0.000  \n",
            "   [0]  script                0.521   7.980  \n",
            "   [1]  1                     0.521   0.000  \n",
            "   [1]  direction             0.522   0.000  \n",
            "   [0]  5                     0.523   7.989  \n",
            "   [1]  photography           0.523   0.000  \n",
            "   [1]  nil                   0.523   0.000  \n",
            "   [1]  acting                0.523   0.000  \n",
            "   [0]  pretty                0.523   8.146  \n",
            "   [1]  poor                  0.524   0.000  \n",
            "   [0]  br                    0.523   4.614  \n",
            "   [0]  br                    0.521   2.639  \n",
            "   [1]  this                  0.520   0.000  \n",
            "   [0]  movie                 0.520   1.468  \n",
            "   [0]  could                 0.521   5.291  \n",
            "   [0]  have                  0.522   2.643  \n",
            "   [0]  been                  0.522   2.680  \n",
            "   [1]  entirely              0.523   0.000  \n",
            "Samples\n",
            "Sample 0 .  i m not motivated to write reviews but this movie was so excruciatingly painful i feel i must i cringed\n",
            "Sample 1 .  on the original the awful truth this update is so completely inferior one has to wonder what the intent was\n",
            "Sample 2 .  0 shooting 0 script 1 direction 5 photography nil acting pretty poor br br this movie could have been entirely\n",
            "\n",
            "\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[0 0 1 0 0 1 1 1 0 0]...][[14 69848 69848 9 69848 69848 10 74 235 69848]...][[2 543 9 169 104 10 74 235 7 78]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[0 0 1 0 0 1 1 1 0 0]...][[14 69848 69848 9 69848 69848 10 74 235 69848]...][[2 543 9 169 104 10 74 235 7 78]...]\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[1 1 0 1 1 0 0 1 1 1]...][[23256 958 13 69848 2 1133 69848 69848 11 1426]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[1 1 0 1 1 0 0 1 1 1]...][[23256 958 13 69848 2 1133 69848 69848 11 1426]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "global_step: 2034\n",
            " perplexity: 445.621\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            " percent of 3-grams captured: 0.515.\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            " percent of 2-grams captured: 0.723.\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            " percent of 4-grams captured: 0.260.\n",
            " geometric_avg: 0.459.\n",
            " arithmetic_avg: 0.499.\n",
            "global_step: 2034\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69381\n",
            " G train loss: 3.09348\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[1 1 0 1 1 0 0 1 1 1]...][[23256 958 13 69848 2 1133 69848 69848 11 1426]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            " Sample 0.\n",
            "   [1]  island                0.492   0.000  \n",
            "   [1]  was                   0.492   0.000  \n",
            "   [0]  such                  0.494   6.947  \n",
            "   [1]  a                     0.495   0.000  \n",
            "   [1]  successful            0.495   0.000  \n",
            "   [0]  fox                   0.493   8.472  \n",
            "   [0]  musical               0.491   7.660  \n",
            "   [1]  that                  0.488   0.000  \n",
            "   [1]  seven                 0.485   0.000  \n",
            "   [1]  years                 0.484   0.000  \n",
            "   [1]  later                 0.487   0.000  \n",
            "   [1]  it                    0.490   0.000  \n",
            "   [1]  was                   0.491   0.000  \n",
            "   [1]  turned                0.492   0.000  \n",
            "   [0]  into                  0.493   4.769  \n",
            "   [1]  another               0.493   0.000  \n",
            "   [1]  starring              0.492   0.000  \n",
            "   [0]  vehicle               0.494   8.950  \n",
            "   [0]  for                   0.495   4.127  \n",
            "   [0]  grable                0.495   11.913 \n",
            " Sample 1.\n",
            "   [0]  and                   0.507   4.555  \n",
            "   [1]  time                  0.510   0.000  \n",
            "   [0]  again                 0.515   6.104  \n",
            "   [0]  it                    0.516   2.813  \n",
            "   [1]  seems                 0.518   0.000  \n",
            "   [0]  that                  0.517   3.709  \n",
            "   [0]  the                   0.515   3.421  \n",
            "   [0]  comedic               0.514   8.690  \n",
            "   [0]  actors                0.514   5.796  \n",
            "   [1]  of                    0.512   0.000  \n",
            "   [1]  hollywood             0.513   0.000  \n",
            "   [0]  are                   0.513   6.725  \n",
            "   [1]  surprising            0.513   0.000  \n",
            "   [1]  me                    0.514   0.000  \n",
            "   [0]  with                  0.515   5.157  \n",
            "   [0]  their                 0.515   5.715  \n",
            "   [0]  talents               0.514   8.873  \n",
            "   [1]  as                    0.514   0.000  \n",
            "   [0]  dramatic              0.512   8.774  \n",
            "   [0]  performers            0.511   9.781  \n",
            " Sample 2.\n",
            "   [0]  is                    0.489   2.247  \n",
            "   [1]  survive               0.495   0.000  \n",
            "   [0]  style                 0.498   8.724  \n",
            "   [0]  5                     0.499   8.006  \n",
            "   [1]  one                   0.500   0.000  \n",
            "   [1]  of                    0.500   0.000  \n",
            "   [0]  the                   0.500   1.727  \n",
            "   [0]  best                  0.499   4.398  \n",
            "   [1]  films                 0.501   0.000  \n",
            "   [0]  i                     0.502   1.910  \n",
            "   [1]  have                  0.506   0.000  \n",
            "   [1]  ever                  0.509   0.000  \n",
            "   [0]  seen                  0.513   2.244  \n",
            "   [0]  in                    0.514   4.362  \n",
            "   [1]  my                    0.515   0.000  \n",
            "   [1]  life                  0.513   0.000  \n",
            "   [1]  this                  0.510   0.000  \n",
            "   [0]  film                  0.508   2.347  \n",
            "   [0]  is                    0.508   2.564  \n",
            "   [1]  about                 0.507   0.000  \n",
            "Samples\n",
            "Sample 0 .  island was such a successful fox musical that seven years later it was turned into another starring vehicle for grable\n",
            "Sample 1 .  and time again it seems that the comedic actors of hollywood are surprising me with their talents as dramatic performers\n",
            "Sample 2 .  is survive style 5 one of the best films i have ever seen in my life this film is about\n",
            "\n",
            "\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 1 1 1 1 1 0 0 0 1]...][[397 177 1024 22 3851 225 720 69848 69848 69848]...][[177 1024 22 3851 225 720 41 37 1532 9125]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 1 1 1 1 1 0 0 0 1]...][[397 177 1024 22 3851 225 720 69848 69848 69848]...][[177 1024 22 3851 225 720 41 37 1532 9125]...]\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[0 0 0 0 0 0 1 0 0 0]...][[14 69848 69848 69848 69848 69848 69848 74 69848 69848]...][[2 543 9 169 104 10 74 235 7 78]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[0 0 0 0 0 0 1 0 0 0]...][[14 69848 69848 69848 69848 69848 69848 74 69848 69848]...][[2 543 9 169 104 10 74 235 7 78]...]\n",
            "2020-03-24 03:54:26.887409: E tensorflow/core/util/events_writer.cc:162] The events file maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0 has disappeared.\n",
            "2020-03-24 03:54:26.887475: E tensorflow/core/util/events_writer.cc:131] Failed to flush 775 events to maskGAN/train/events.out.tfevents.1585011473.168dbe34b6b0\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "global_step: 2037\n",
            " perplexity: 445.208\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            " percent of 3-grams captured: 0.492.\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            " percent of 2-grams captured: 0.703.\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            " percent of 4-grams captured: 0.243.\n",
            " geometric_avg: 0.438.\n",
            " arithmetic_avg: 0.479.\n",
            "global_step: 2037\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69382\n",
            " G train loss: 3.09302\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[0 0 0 0 0 0 1 0 0 0]...][[14 69848 69848 69848 69848 69848 69848 74 69848 69848]...][[2 543 9 169 104 10 74 235 7 78]...]\n",
            " Sample 0.\n",
            "   [0]  a                     0.506   2.235  \n",
            "   [0]  writer                0.502   8.052  \n",
            "   [0]  i                     0.499   5.041  \n",
            "   [0]  find                  0.499   4.722  \n",
            "   [0]  films                 0.500   8.494  \n",
            "   [0]  this                  0.502   2.532  \n",
            "   [1]  bad                   0.505   0.000  \n",
            "   [0]  making                0.509   7.850  \n",
            "   [0]  it                    0.513   2.881  \n",
            "   [0]  into                  0.514   8.409  \n",
            "   [0]  production            0.515   8.880  \n",
            "   [1]  a                     0.515   0.000  \n",
            "   [0]  complete              0.515   7.516  \n",
            "   [1]  slap                  0.514   0.000  \n",
            "   [1]  in                    0.512   0.000  \n",
            "   [0]  the                   0.511   1.552  \n",
            "   [1]  face                  0.511   0.000  \n",
            "   [0]  talk                  0.510   9.887  \n",
            "   [0]  about                 0.509   4.746  \n",
            "   [0]  insulting             0.509   10.866 \n",
            " Sample 1.\n",
            "   [1]  of                    0.510   0.000  \n",
            "   [1]  the                   0.511   0.000  \n",
            "   [1]  most                  0.514   0.000  \n",
            "   [0]  excellent             0.517   6.387  \n",
            "   [1]  movies                0.517   0.000  \n",
            "   [1]  ever                  0.517   0.000  \n",
            "   [1]  produced              0.514   0.000  \n",
            "   [1]  in                    0.509   0.000  \n",
            "   [0]  russia                0.505   10.288 \n",
            "   [0]  and                   0.504   2.662  \n",
            "   [1]  certainly             0.505   0.000  \n",
            "   [0]  the                   0.508   3.098  \n",
            "   [0]  best                  0.512   4.470  \n",
            "   [0]  one                   0.516   4.643  \n",
            "   [0]  made                  0.520   7.667  \n",
            "   [1]  during                0.521   0.000  \n",
            "   [0]  the                   0.521   2.382  \n",
            "   [1]  decline               0.518   0.000  \n",
            "   [0]  of                    0.514   2.849  \n",
            "   [0]  the                   0.512   2.693  \n",
            " Sample 2.\n",
            "   [1]  title                 0.512   0.000  \n",
            "   [1]  says                  0.514   0.000  \n",
            "   [0]  it                    0.515   3.790  \n",
            "   [1]  all                   0.516   0.000  \n",
            "   [1]  danny                 0.517   0.000  \n",
            "   [1]  trejo                 0.518   0.000  \n",
            "   [1]  isn                   0.519   0.000  \n",
            "   [0]  t                     0.518   0.253  \n",
            "   [0]  the                   0.517   4.990  \n",
            "   [1]  only                  0.516   0.000  \n",
            "   [0]  similarity            0.516   9.894  \n",
            "   [1]  between               0.516   0.000  \n",
            "   [1]  fdtd                  0.516   0.000  \n",
            "   [0]  and                   0.515   2.841  \n",
            "   [0]  this                  0.513   4.098  \n",
            "   [1]  bad                   0.513   0.000  \n",
            "   [0]  copycat               0.515   14.585 \n",
            "   [0]  the                   0.515   3.891  \n",
            "   [1]  plot                  0.516   0.000  \n",
            "   [1]  is                    0.517   0.000  \n",
            "Samples\n",
            "Sample 0 .  a writer i find films this bad making it into production a complete slap in the face talk about insulting\n",
            "Sample 1 .  of the most excellent movies ever produced in russia and certainly the best one made during the decline of the\n",
            "Sample 2 .  title says it all danny trejo isn t the only similarity between fdtd and this bad copycat the plot is\n",
            "\n",
            "\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[0 1 0 1 0 0 1 1 0 1]...][[307 69848 176 69848 31 69848 69848 19 1322 69848]...][[0 176 8859 31 0 6181 19 1322 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[0 1 0 1 0 0 1 1 0 1]...][[307 69848 176 69848 31 69848 69848 19 1322 69848]...][[0 176 8859 31 0 6181 19 1322 6 6]...]\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 0 1 0 1 0 1 0 0 0]...][[397 177 69848 22 69848 225 69848 41 69848 69848]...][[177 1024 22 3851 225 720 41 37 1532 9125]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 0 1 0 1 0 1 0 0 0]...][[397 177 69848 22 69848 225 69848 41 69848 69848]...][[177 1024 22 3851 225 720 41 37 1532 9125]...]\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "global_step: 2040\n",
            " perplexity: 444.796\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            " percent of 3-grams captured: 0.507.\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            " percent of 2-grams captured: 0.706.\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            " percent of 4-grams captured: 0.246.\n",
            " geometric_avg: 0.445.\n",
            " arithmetic_avg: 0.486.\n",
            "global_step: 2040\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69381\n",
            " G train loss: 3.09233\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 0 1 0 1 0 1 0 0 0]...][[397 177 69848 22 69848 225 69848 41 69848 69848]...][[177 1024 22 3851 225 720 41 37 1532 9125]...]\n",
            " Sample 0.\n",
            "   [1]  cast                  0.512   0.000  \n",
            "   [0]  wasted                0.511   10.147 \n",
            "   [1]  on                    0.513   0.000  \n",
            "   [0]  worthless             0.516   9.702  \n",
            "   [1]  script                0.517   0.000  \n",
            "   [0]  ten                   0.517   8.883  \n",
            "   [1]  or                    0.518   0.000  \n",
            "   [0]  so                    0.519   5.617  \n",
            "   [0]  adults                0.520   9.247  \n",
            "   [0]  reunite               0.520   13.499 \n",
            "   [1]  at                    0.520   0.000  \n",
            "   [0]  the                   0.520   1.924  \n",
            "   [0]  summer                0.521   7.300  \n",
            "   [0]  camp                  0.523   8.671  \n",
            "   [1]  they                  0.524   0.000  \n",
            "   [1]  attended              0.525   0.000  \n",
            "   [0]  as                    0.526   4.633  \n",
            "   [1]  juveniles             0.526   0.000  \n",
            "   [1]  could                 0.525   0.000  \n",
            "   [1]  this                  0.523   0.000  \n",
            " Sample 1.\n",
            "   [1]  this                  0.469   0.000  \n",
            "   [0]  review                0.467   6.318  \n",
            "   [1]  is                    0.468   0.000  \n",
            "   [1]  generally             0.470   0.000  \n",
            "   [0]  negative              0.472   9.677  \n",
            "   [1]  i                     0.472   0.000  \n",
            "   [1]  want                  0.473   0.000  \n",
            "   [0]  to                    0.475   1.163  \n",
            "   [0]  make                  0.476   4.396  \n",
            "   [1]  a                     0.476   0.000  \n",
            "   [1]  positive              0.475   0.000  \n",
            "   [0]  point                 0.476   8.633  \n",
            "   [0]  first                 0.476   9.153  \n",
            "   [0]  another               0.477   7.102  \n",
            "   [1]  poster                0.478   0.000  \n",
            "   [1]  here                  0.478   0.000  \n",
            "   [0]  noted                 0.479   12.734 \n",
            "   [1]  that                  0.477   0.000  \n",
            "   [1]  moonlight             0.477   0.000  \n",
            "   [1]  mile                  0.475   0.000  \n",
            " Sample 2.\n",
            "   [1]  opera                 0.502   0.000  \n",
            "   [0]  about                 0.501   5.798  \n",
            "   [1]  a                     0.499   0.000  \n",
            "   [0]  small                 0.501   5.504  \n",
            "   [1]  town                  0.504   0.000  \n",
            "   [0]  married               0.506   8.509  \n",
            "   [0]  woman                 0.509   6.963  \n",
            "   [0]  kay                   0.509   9.604  \n",
            "   [1]  francis               0.509   0.000  \n",
            "   [1]  who                   0.509   0.000  \n",
            "   [0]  works                 0.510   7.921  \n",
            "   [1]  at                    0.510   0.000  \n",
            "   [1]  the                   0.510   0.000  \n",
            "   [1]  local                 0.511   0.000  \n",
            "   [0]  newsstand             0.512   13.901 \n",
            "   [0]  performs              0.512   11.737 \n",
            "   [0]  as                    0.512   4.110  \n",
            "   [1]  leading               0.512   0.000  \n",
            "   [1]  lady                  0.513   0.000  \n",
            "   [0]  in                    0.512   3.903  \n",
            "Samples\n",
            "Sample 0 .  cast wasted on worthless script ten or so adults reunite at the summer camp they attended as juveniles could this\n",
            "Sample 1 .  this review is generally negative i want to make a positive point first another poster here noted that moonlight mile\n",
            "Sample 2 .  opera about a small town married woman kay francis who works at the local newsstand performs as leading lady in\n",
            "\n",
            "\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20820 144 0 4278 544 31 311 9 389 596]...][[1 0 1 1 1 1 0 0 1 1]...][[20820 144 69848 4278 544 31 311 69848 69848 596]...][[144 0 4278 544 31 311 9 389 596 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20820 144 0 4278 544 31 311 9 389 596]...][[1 0 1 1 1 1 0 0 1 1]...][[20820 144 69848 4278 544 31 311 69848 69848 596]...][[144 0 4278 544 31 311 9 389 596 10]...]\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[1 0 1 1 0 1 1 1 0 1]...][[307 0 69848 8859 31 69848 6181 19 1322 69848]...][[0 176 8859 31 0 6181 19 1322 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[1 0 1 1 0 1 1 1 0 1]...][[307 0 69848 8859 31 69848 6181 19 1322 69848]...][[0 176 8859 31 0 6181 19 1322 6 6]...]\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "global_step: 2043\n",
            " perplexity: 444.816\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            " percent of 3-grams captured: 0.497.\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            " percent of 2-grams captured: 0.706.\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            " percent of 4-grams captured: 0.228.\n",
            " geometric_avg: 0.431.\n",
            " arithmetic_avg: 0.477.\n",
            "global_step: 2043\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69381\n",
            " G train loss: 3.09265\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[1 0 1 1 0 1 1 1 0 1]...][[307 0 69848 8859 31 69848 6181 19 1322 69848]...][[0 176 8859 31 0 6181 19 1322 6 6]...]\n",
            " Sample 0.\n",
            "   [1]  the                   0.510   0.000  \n",
            "   [0]  world                 0.510   5.691  \n",
            "   [1]  premier               0.509   0.000  \n",
            "   [1]  at                    0.509   0.000  \n",
            "   [0]  the                   0.509   1.832  \n",
            "   [1]  toronto               0.509   0.000  \n",
            "   [1]  film                  0.510   0.000  \n",
            "   [1]  festival              0.511   0.000  \n",
            "   [0]  br                    0.512   3.255  \n",
            "   [1]  br                    0.513   0.000  \n",
            "   [0]  you                   0.514   3.948  \n",
            "   [0]  are                   0.516   3.165  \n",
            "   [1]  drawn                 0.517   0.000  \n",
            "   [1]  into                  0.516   0.000  \n",
            "   [1]  this                  0.516   0.000  \n",
            "   [0]  dark                  0.515   8.836  \n",
            "   [1]  movie                 0.514   0.000  \n",
            "   [0]  and                   0.513   3.126  \n",
            "   [1]  cannot                0.512   0.000  \n",
            "   [0]  turn                  0.512   7.682  \n",
            " Sample 1.\n",
            "   [0]  bad                   0.510   5.172  \n",
            "   [1]  if                    0.512   0.000  \n",
            "   [0]  you                   0.511   2.611  \n",
            "   [0]  read                  0.510   6.045  \n",
            "   [0]  the                   0.509   1.953  \n",
            "   [1]  books                 0.507   0.000  \n",
            "   [1]  do                    0.506   0.000  \n",
            "   [0]  yourself              0.505   9.520  \n",
            "   [1]  a                     0.506   0.000  \n",
            "   [1]  favor                 0.508   0.000  \n",
            "   [0]  and                   0.509   2.331  \n",
            "   [0]  don                   0.510   7.228  \n",
            "   [1]  t                     0.510   0.000  \n",
            "   [1]  put                   0.509   0.000  \n",
            "   [0]  yourself              0.509   9.673  \n",
            "   [1]  through               0.509   0.000  \n",
            "   [1]  the                   0.509   0.000  \n",
            "   [1]  agony                 0.509   0.000  \n",
            "   [1]  of                    0.508   0.000  \n",
            "   [0]  sitting               0.506   9.757  \n",
            " Sample 2.\n",
            "   [1]  film                  0.507   0.000  \n",
            "   [0]  deserves              0.509   8.876  \n",
            "   [1]  recognition           0.510   0.000  \n",
            "   [0]  by                    0.512   4.143  \n",
            "   [0]  virtue                0.512   11.413 \n",
            "   [0]  of                    0.511   2.910  \n",
            "   [0]  its                   0.510   5.021  \n",
            "   [0]  cinematography        0.508   7.844  \n",
            "   [1]  and                   0.507   0.000  \n",
            "   [1]  for                   0.507   0.000  \n",
            "   [1]  the                   0.508   0.000  \n",
            "   [1]  first                 0.509   0.000  \n",
            "   [1]  class                 0.510   0.000  \n",
            "   [0]  almost                0.511   8.211  \n",
            "   [1]  brilliant             0.513   0.000  \n",
            "   [0]  job                   0.517   7.781  \n",
            "   [0]  done                  0.518   7.999  \n",
            "   [1]  by                    0.519   0.000  \n",
            "   [1]  the                   0.518   0.000  \n",
            "   [1]  leading               0.517   0.000  \n",
            "Samples\n",
            "Sample 0 .  the world premier at the toronto film festival br br you are drawn into this dark movie and cannot turn\n",
            "Sample 1 .  bad if you read the books do yourself a favor and don t put yourself through the agony of sitting\n",
            "Sample 2 .  film deserves recognition by virtue of its cinematography and for the first class almost brilliant job done by the leading\n",
            "\n",
            "\n",
            "targets[[848 1 48 21413 102 954 383 10 1264 1744 9036 36 12291 31 219 1678 190 7 1386 641][20 123 169 661 149 2 246 122 1 532 9 656 11 67 77 226 5103 80 20 123][89 21 333 11 0 17 45 56 109 41]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[523 848 1 48 21413 102 954 383 10 1264]...][[1 0 0 1 0 0 1 1 0 0]...][[523 848 69848 69848 21413 69848 69848 383 10 69848]...][[848 1 48 21413 102 954 383 10 1264 1744]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[523 848 1 48 21413 102 954 383 10 1264]...][[1 0 0 1 0 0 1 1 0 0]...][[523 848 69848 69848 21413 69848 69848 383 10 69848]...][[848 1 48 21413 102 954 383 10 1264 1744]...]\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20820 144 0 4278 544 31 311 9 389 596]...][[1 1 0 1 0 1 0 0 1 1]...][[20820 144 0 69848 544 69848 311 69848 69848 596]...][[144 0 4278 544 31 311 9 389 596 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20820 144 0 4278 544 31 311 9 389 596]...][[1 1 0 1 0 1 0 0 1 1]...][[20820 144 0 69848 544 69848 311 69848 69848 596]...][[144 0 4278 544 31 311 9 389 596 10]...]\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            "global_step: 2046\n",
            " perplexity: 444.653\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            " percent of 3-grams captured: 0.489.\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            " percent of 2-grams captured: 0.706.\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            " percent of 4-grams captured: 0.229.\n",
            " geometric_avg: 0.429.\n",
            " arithmetic_avg: 0.475.\n",
            "global_step: 2046\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69380\n",
            " G train loss: 3.09257\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20820 144 0 4278 544 31 311 9 389 596]...][[1 1 0 1 0 1 0 0 1 1]...][[20820 144 0 69848 544 69848 311 69848 69848 596]...][[144 0 4278 544 31 311 9 389 596 10]...]\n",
            " Sample 0.\n",
            "   [1]  through               0.541   0.000  \n",
            "   [1]  the                   0.541   0.000  \n",
            "   [0]  channels              0.541   9.495  \n",
            "   [1]  late                  0.540   0.000  \n",
            "   [0]  at                    0.540   6.585  \n",
            "   [1]  night                 0.540   0.000  \n",
            "   [0]  i                     0.538   3.416  \n",
            "   [0]  came                  0.537   5.510  \n",
            "   [1]  across                0.536   0.000  \n",
            "   [1]  this                  0.535   0.000  \n",
            "   [0]  movie                 0.535   1.467  \n",
            "   [0]  and                   0.535   4.357  \n",
            "   [0]  figured               0.535   9.283  \n",
            "   [1]  i                     0.535   0.000  \n",
            "   [1]  d                     0.534   0.000  \n",
            "   [0]  check                 0.533   8.166  \n",
            "   [0]  it                    0.534   2.244  \n",
            "   [0]  out                   0.534   6.519  \n",
            "   [1]  i                     0.534   0.000  \n",
            "   [1]  missed                0.534   0.000  \n",
            " Sample 1.\n",
            "   [0]  and                   0.497   4.407  \n",
            "   [1]  margareth             0.498   0.000  \n",
            "   [0]  has                   0.497   4.731  \n",
            "   [1]  always                0.496   0.000  \n",
            "   [1]  been                  0.498   0.000  \n",
            "   [0]  my                    0.499   5.289  \n",
            "   [1]  favorite              0.500   0.000  \n",
            "   [0]  book                  0.504   7.165  \n",
            "   [1]  i                     0.504   0.000  \n",
            "   [0]  have                  0.505   3.166  \n",
            "   [0]  read                  0.503   6.038  \n",
            "   [0]  a                     0.502   2.429  \n",
            "   [1]  lot                   0.502   0.000  \n",
            "   [0]  of                    0.502   2.333  \n",
            "   [1]  books                 0.502   0.000  \n",
            "   [0]  and                   0.504   3.122  \n",
            "   [1]  none                  0.506   0.000  \n",
            "   [1]  of                    0.506   0.000  \n",
            "   [1]  them                  0.507   0.000  \n",
            "   [1]  had                   0.508   0.000  \n",
            " Sample 2.\n",
            "   [1]  classic               0.509   0.000  \n",
            "   [0]  sadly                 0.512   10.130 \n",
            "   [0]  almost                0.513   6.983  \n",
            "   [1]  ignored               0.514   0.000  \n",
            "   [0]  and                   0.512   3.580  \n",
            "   [1]  forgotten             0.512   0.000  \n",
            "   [0]  probably              0.510   7.974  \n",
            "   [1]  because               0.510   0.000  \n",
            "   [0]  of                    0.510   2.471  \n",
            "   [1]  it                    0.509   0.000  \n",
            "   [0]  s                     0.510   1.617  \n",
            "   [0]  small                 0.511   7.307  \n",
            "   [1]  scale                 0.513   0.000  \n",
            "   [0]  being                 0.515   7.314  \n",
            "   [1]  a                     0.517   0.000  \n",
            "   [1]  quite                 0.518   0.000  \n",
            "   [0]  simple                0.517   7.485  \n",
            "   [0]  screen                0.516   8.656  \n",
            "   [0]  version               0.514   7.644  \n",
            "   [0]  of                    0.514   1.953  \n",
            "Samples\n",
            "Sample 0 .  through the channels late at night i came across this movie and figured i d check it out i missed\n",
            "Sample 1 .  and margareth has always been my favorite book i have read a lot of books and none of them had\n",
            "Sample 2 .  classic sadly almost ignored and forgotten probably because of it s small scale being a quite simple screen version of\n",
            "\n",
            "\n",
            "targets[[312 1591 10 349 15 30596 481 61 29 5 126 9 140 2 6293 16 2 49 5097 17][5 29 3 0 117 98 9 27 123 110 0 684 535 181 5601 15 0 2028 20940 3][20 27 0 598 4 106 0 17 41 353]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 312 1591 10 349 15 30596 481 61 29]...][[1 1 0 0 1 1 0 1 0 1]...][[60 312 1591 69848 69848 15 30596 69848 61 69848]...][[312 1591 10 349 15 30596 481 61 29 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 312 1591 10 349 15 30596 481 61 29]...][[1 1 0 0 1 1 0 1 0 1]...][[60 312 1591 69848 69848 15 30596 69848 61 69848]...][[312 1591 10 349 15 30596 481 61 29 5]...]\n",
            "targets[[848 1 48 21413 102 954 383 10 1264 1744 9036 36 12291 31 219 1678 190 7 1386 641][20 123 169 661 149 2 246 122 1 532 9 656 11 67 77 226 5103 80 20 123][89 21 333 11 0 17 45 56 109 41]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[523 848 1 48 21413 102 954 383 10 1264]...][[1 0 1 0 0 0 1 1 1 0]...][[523 848 69848 48 69848 69848 69848 383 10 1264]...][[848 1 48 21413 102 954 383 10 1264 1744]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[523 848 1 48 21413 102 954 383 10 1264]...][[1 0 1 0 0 0 1 1 1 0]...][[523 848 69848 48 69848 69848 69848 383 10 1264]...][[848 1 48 21413 102 954 383 10 1264 1744]...]\n",
            "targets[[848 1 48 21413 102 954 383 10 1264 1744 9036 36 12291 31 219 1678 190 7 1386 641][20 123 169 661 149 2 246 122 1 532 9 656 11 67 77 226 5103 80 20 123][89 21 333 11 0 17 45 56 109 41]...]\n",
            "targets[[848 1 48 21413 102 954 383 10 1264 1744 9036 36 12291 31 219 1678 190 7 1386 641][20 123 169 661 149 2 246 122 1 532 9 656 11 67 77 226 5103 80 20 123][89 21 333 11 0 17 45 56 109 41]...]\n",
            "targets[[848 1 48 21413 102 954 383 10 1264 1744 9036 36 12291 31 219 1678 190 7 1386 641][20 123 169 661 149 2 246 122 1 532 9 656 11 67 77 226 5103 80 20 123][89 21 333 11 0 17 45 56 109 41]...]\n",
            "global_step: 2049\n",
            " perplexity: 444.278\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[848 1 48 21413 102 954 383 10 1264 1744 9036 36 12291 31 219 1678 190 7 1386 641][20 123 169 661 149 2 246 122 1 532 9 656 11 67 77 226 5103 80 20 123][89 21 333 11 0 17 45 56 109 41]...]\n",
            " percent of 3-grams captured: 0.511.\n",
            "targets[[848 1 48 21413 102 954 383 10 1264 1744 9036 36 12291 31 219 1678 190 7 1386 641][20 123 169 661 149 2 246 122 1 532 9 656 11 67 77 226 5103 80 20 123][89 21 333 11 0 17 45 56 109 41]...]\n",
            " percent of 2-grams captured: 0.721.\n",
            "targets[[848 1 48 21413 102 954 383 10 1264 1744 9036 36 12291 31 219 1678 190 7 1386 641][20 123 169 661 149 2 246 122 1 532 9 656 11 67 77 226 5103 80 20 123][89 21 333 11 0 17 45 56 109 41]...]\n",
            " percent of 4-grams captured: 0.263.\n",
            " geometric_avg: 0.459.\n",
            " arithmetic_avg: 0.498.\n",
            "global_step: 2049\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69380\n",
            " G train loss: 3.09205\n",
            "targets[[848 1 48 21413 102 954 383 10 1264 1744 9036 36 12291 31 219 1678 190 7 1386 641][20 123 169 661 149 2 246 122 1 532 9 656 11 67 77 226 5103 80 20 123][89 21 333 11 0 17 45 56 109 41]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[523 848 1 48 21413 102 954 383 10 1264]...][[1 0 1 0 0 0 1 1 1 0]...][[523 848 69848 48 69848 69848 69848 383 10 1264]...][[848 1 48 21413 102 954 383 10 1264 1744]...]\n",
            " Sample 0.\n",
            "   [1]  animation             0.481   0.000  \n",
            "   [0]  and                   0.480   3.420  \n",
            "   [1]  some                  0.480   0.000  \n",
            "   [0]  workable              0.479   14.259 \n",
            "   [0]  character             0.478   7.997  \n",
            "   [0]  development           0.477   8.893  \n",
            "   [1]  keep                  0.476   0.000  \n",
            "   [1]  this                  0.475   0.000  \n",
            "   [1]  animated              0.475   0.000  \n",
            "   [0]  horse                 0.476   9.946  \n",
            "   [0]  fable                 0.476   10.951 \n",
            "   [0]  from                  0.475   4.728  \n",
            "   [1]  dreamworks            0.476   0.000  \n",
            "   [1]  at                    0.475   0.000  \n",
            "   [0]  least                 0.475   6.953  \n",
            "   [0]  watchable             0.478   9.450  \n",
            "   [0]  however               0.479   6.921  \n",
            "   [0]  it                    0.479   2.687  \n",
            "   [1]  remains               0.479   0.000  \n",
            "   [1]  somewhat              0.478   0.000  \n",
            " Sample 1.\n",
            "   [1]  you                   0.484   0.000  \n",
            "   [0]  ever                  0.486   5.767  \n",
            "   [1]  find                  0.486   0.000  \n",
            "   [1]  yourself              0.486   0.000  \n",
            "   [1]  watching              0.485   0.000  \n",
            "   [0]  a                     0.483   3.021  \n",
            "   [1]  tv                    0.481   0.000  \n",
            "   [0]  show                  0.479   5.805  \n",
            "   [1]  and                   0.477   0.000  \n",
            "   [1]  thinking              0.476   0.000  \n",
            "   [1]  i                     0.474   0.000  \n",
            "   [1]  wish                  0.474   0.000  \n",
            "   [0]  that                  0.474   3.592  \n",
            "   [1]  had                   0.475   0.000  \n",
            "   [0]  been                  0.477   5.162  \n",
            "   [0]  done                  0.479   6.238  \n",
            "   [0]  differently           0.483   11.727 \n",
            "   [0]  do                    0.486   7.378  \n",
            "   [1]  you                   0.487   0.000  \n",
            "   [1]  ever                  0.487   0.000  \n",
            " Sample 2.\n",
            "   [1]  don                   0.503   0.000  \n",
            "   [1]  t                     0.504   0.000  \n",
            "   [1]  mind                  0.504   0.000  \n",
            "   [0]  that                  0.503   3.618  \n",
            "   [0]  the                   0.501   2.891  \n",
            "   [1]  movie                 0.498   0.000  \n",
            "   [0]  has                   0.496   4.748  \n",
            "   [1]  no                    0.495   0.000  \n",
            "   [1]  plot                  0.492   0.000  \n",
            "   [1]  or                    0.491   0.000  \n",
            "   [0]  that                  0.490   5.868  \n",
            "   [0]  it                    0.491   2.522  \n",
            "   [0]  s                     0.491   1.363  \n",
            "   [1]  so                    0.491   0.000  \n",
            "   [0]  noisy                 0.492   12.948 \n",
            "   [1]  my                    0.493   0.000  \n",
            "   [0]  90                    0.494   7.568  \n",
            "   [1]  year                  0.495   0.000  \n",
            "   [1]  old                   0.495   0.000  \n",
            "   [0]  grandmother           0.494   11.510 \n",
            "Samples\n",
            "Sample 0 .  animation and some workable character development keep this animated horse fable from dreamworks at least watchable however it remains somewhat\n",
            "Sample 1 .  you ever find yourself watching a tv show and thinking i wish that had been done differently do you ever\n",
            "Sample 2 .  don t mind that the movie has no plot or that it s so noisy my 90 year old grandmother\n",
            "\n",
            "\n",
            "targets[[19 5 2 13420 21967 8 61 0 276 1790 571 8 0 5353 15390 38892 25 30 21248 1][2 13100 206 202 9 207 136 91 539 873 9 207 136 91 186 1587 49 0 547 25][736 109 264 0 466 173 6448 68 1764 226]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 2 13420 21967 8 61 0 276]...][[1 1 0 0 1 1 1 0 0 1]...][[10 19 5 69848 69848 21967 8 61 69848 69848]...][[19 5 2 13420 21967 8 61 0 276 1790]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 2 13420 21967 8 61 0 276]...][[1 1 0 0 1 1 1 0 0 1]...][[10 19 5 69848 69848 21967 8 61 69848 69848]...][[19 5 2 13420 21967 8 61 0 276 1790]...]\n",
            "targets[[312 1591 10 349 15 30596 481 61 29 5 126 9 140 2 6293 16 2 49 5097 17][5 29 3 0 117 98 9 27 123 110 0 684 535 181 5601 15 0 2028 20940 3][20 27 0 598 4 106 0 17 41 353]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 312 1591 10 349 15 30596 481 61 29]...][[0 1 0 1 1 0 0 0 0 1]...][[60 69848 1591 69848 349 15 69848 69848 69848 69848]...][[312 1591 10 349 15 30596 481 61 29 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 312 1591 10 349 15 30596 481 61 29]...][[0 1 0 1 1 0 0 0 0 1]...][[60 69848 1591 69848 349 15 69848 69848 69848 69848]...][[312 1591 10 349 15 30596 481 61 29 5]...]\n",
            "targets[[312 1591 10 349 15 30596 481 61 29 5 126 9 140 2 6293 16 2 49 5097 17][5 29 3 0 117 98 9 27 123 110 0 684 535 181 5601 15 0 2028 20940 3][20 27 0 598 4 106 0 17 41 353]...]\n",
            "targets[[312 1591 10 349 15 30596 481 61 29 5 126 9 140 2 6293 16 2 49 5097 17][5 29 3 0 117 98 9 27 123 110 0 684 535 181 5601 15 0 2028 20940 3][20 27 0 598 4 106 0 17 41 353]...]\n",
            "targets[[312 1591 10 349 15 30596 481 61 29 5 126 9 140 2 6293 16 2 49 5097 17][5 29 3 0 117 98 9 27 123 110 0 684 535 181 5601 15 0 2028 20940 3][20 27 0 598 4 106 0 17 41 353]...]\n",
            "global_step: 2052\n",
            " perplexity: 443.879\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[312 1591 10 349 15 30596 481 61 29 5 126 9 140 2 6293 16 2 49 5097 17][5 29 3 0 117 98 9 27 123 110 0 684 535 181 5601 15 0 2028 20940 3][20 27 0 598 4 106 0 17 41 353]...]\n",
            " percent of 3-grams captured: 0.514.\n",
            "targets[[312 1591 10 349 15 30596 481 61 29 5 126 9 140 2 6293 16 2 49 5097 17][5 29 3 0 117 98 9 27 123 110 0 684 535 181 5601 15 0 2028 20940 3][20 27 0 598 4 106 0 17 41 353]...]\n",
            " percent of 2-grams captured: 0.711.\n",
            "targets[[312 1591 10 349 15 30596 481 61 29 5 126 9 140 2 6293 16 2 49 5097 17][5 29 3 0 117 98 9 27 123 110 0 684 535 181 5601 15 0 2028 20940 3][20 27 0 598 4 106 0 17 41 353]...]\n",
            " percent of 4-grams captured: 0.238.\n",
            " geometric_avg: 0.443.\n",
            " arithmetic_avg: 0.488.\n",
            "global_step: 2052\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69378\n",
            " G train loss: 3.09157\n",
            "targets[[312 1591 10 349 15 30596 481 61 29 5 126 9 140 2 6293 16 2 49 5097 17][5 29 3 0 117 98 9 27 123 110 0 684 535 181 5601 15 0 2028 20940 3][20 27 0 598 4 106 0 17 41 353]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 312 1591 10 349 15 30596 481 61 29]...][[0 1 0 1 1 0 0 0 0 1]...][[60 69848 1591 69848 349 15 69848 69848 69848 69848]...][[312 1591 10 349 15 30596 481 61 29 5]...]\n",
            " Sample 0.\n",
            "   [0]  wife                  0.499   6.855  \n",
            "   [1]  rented                0.495   0.000  \n",
            "   [0]  this                  0.493   3.976  \n",
            "   [1]  along                 0.492   0.000  \n",
            "   [1]  with                  0.491   0.000  \n",
            "   [0]  syriana               0.491   14.861 \n",
            "   [0]  guess                 0.491   9.690  \n",
            "   [0]  which                 0.492   6.098  \n",
            "   [0]  one                   0.492   6.676  \n",
            "   [1]  is                    0.492   0.000  \n",
            "   [1]  better                0.492   0.000  \n",
            "   [1]  i                     0.490   0.000  \n",
            "   [1]  m                     0.488   0.000  \n",
            "   [0]  a                     0.487   3.771  \n",
            "   [1]  sucker                0.488   0.000  \n",
            "   [1]  for                   0.489   0.000  \n",
            "   [0]  a                     0.490   2.505  \n",
            "   [0]  good                  0.490   4.339  \n",
            "   [0]  pirate                0.491   10.045 \n",
            "   [0]  movie                 0.492   4.336  \n",
            " Sample 1.\n",
            "   [0]  is                    0.492   1.557  \n",
            "   [0]  one                   0.493   2.529  \n",
            "   [1]  of                    0.494   0.000  \n",
            "   [1]  the                   0.494   0.000  \n",
            "   [1]  best                  0.495   0.000  \n",
            "   [0]  movies                0.495   3.453  \n",
            "   [1]  i                     0.493   0.000  \n",
            "   [0]  have                  0.491   2.495  \n",
            "   [0]  ever                  0.488   1.762  \n",
            "   [0]  seen                  0.486   1.997  \n",
            "   [0]  the                   0.486   2.570  \n",
            "   [0]  non                   0.487   9.083  \n",
            "   [0]  stop                  0.488   10.373 \n",
            "   [1]  action                0.490   0.000  \n",
            "   [1]  coupled               0.492   0.000  \n",
            "   [0]  with                  0.491   4.438  \n",
            "   [0]  the                   0.490   1.388  \n",
            "   [1]  insane                0.491   0.000  \n",
            "   [0]  awesomeness           0.492   15.476 \n",
            "   [1]  of                    0.492   0.000  \n",
            " Sample 2.\n",
            "   [0]  you                   0.492   1.994  \n",
            "   [0]  have                  0.490   2.834  \n",
            "   [0]  the                   0.488   4.226  \n",
            "   [1]  chance                0.486   0.000  \n",
            "   [0]  to                    0.484   1.575  \n",
            "   [1]  watch                 0.482   0.000  \n",
            "   [0]  the                   0.481   2.342  \n",
            "   [0]  movie                 0.480   2.649  \n",
            "   [0]  or                    0.479   5.226  \n",
            "   [1]  read                  0.477   0.000  \n",
            "   [1]  the                   0.477   0.000  \n",
            "   [0]  book                  0.479   5.440  \n",
            "   [0]  i                     0.476   3.686  \n",
            "   [0]  highly                0.477   7.549  \n",
            "   [1]  recommend             0.479   0.000  \n",
            "   [0]  that                  0.479   3.178  \n",
            "   [1]  you                   0.479   0.000  \n",
            "   [1]  do                    0.480   0.000  \n",
            "   [1]  so                    0.481   0.000  \n",
            "   [0]  both                  0.483   7.477  \n",
            "Samples\n",
            "Sample 0 .  wife rented this along with syriana guess which one is better i m a sucker for a good pirate movie\n",
            "Sample 1 .  is one of the best movies i have ever seen the non stop action coupled with the insane awesomeness of\n",
            "Sample 2 .  you have the chance to watch the movie or read the book i highly recommend that you do so both\n",
            "\n",
            "\n",
            "targets[[3 0 117 699 2299 202 123 9 139 77 259 4 810 10 202 22 1912 41 277 16][984 3 0 5388 19 33 0 170 390 4069 576 5724 4 114 5 323 18 7 5 2][9 13 2 183 125 3 2873 154 3 567]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 117 699 2299 202 123 9 139]...][[0 0 1 0 1 0 1 1 1 1]...][[29 69848 69848 117 69848 2299 69848 123 9 139]...][[3 0 117 699 2299 202 123 9 139 77]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 117 699 2299 202 123 9 139]...][[0 0 1 0 1 0 1 1 1 1]...][[29 69848 69848 117 69848 2299 69848 123 9 139]...][[3 0 117 699 2299 202 123 9 139 77]...]\n",
            "targets[[19 5 2 13420 21967 8 61 0 276 1790 571 8 0 5353 15390 38892 25 30 21248 1][2 13100 206 202 9 207 136 91 539 873 9 207 136 91 186 1587 49 0 547 25][736 109 264 0 466 173 6448 68 1764 226]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 2 13420 21967 8 61 0 276]...][[1 0 0 0 0 0 0 0 1 0]...][[10 19 69848 69848 69848 69848 69848 69848 69848 276]...][[19 5 2 13420 21967 8 61 0 276 1790]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 2 13420 21967 8 61 0 276]...][[1 0 0 0 0 0 0 0 1 0]...][[10 19 69848 69848 69848 69848 69848 69848 69848 276]...][[19 5 2 13420 21967 8 61 0 276 1790]...]\n",
            "targets[[19 5 2 13420 21967 8 61 0 276 1790 571 8 0 5353 15390 38892 25 30 21248 1][2 13100 206 202 9 207 136 91 539 873 9 207 136 91 186 1587 49 0 547 25][736 109 264 0 466 173 6448 68 1764 226]...]\n",
            "targets[[19 5 2 13420 21967 8 61 0 276 1790 571 8 0 5353 15390 38892 25 30 21248 1][2 13100 206 202 9 207 136 91 539 873 9 207 136 91 186 1587 49 0 547 25][736 109 264 0 466 173 6448 68 1764 226]...]\n",
            "targets[[19 5 2 13420 21967 8 61 0 276 1790 571 8 0 5353 15390 38892 25 30 21248 1][2 13100 206 202 9 207 136 91 539 873 9 207 136 91 186 1587 49 0 547 25][736 109 264 0 466 173 6448 68 1764 226]...]\n",
            "global_step: 2055\n",
            " perplexity: 444.214\n",
            " gen_learning_rate: 0.000500\n",
            "targets[[19 5 2 13420 21967 8 61 0 276 1790 571 8 0 5353 15390 38892 25 30 21248 1][2 13100 206 202 9 207 136 91 539 873 9 207 136 91 186 1587 49 0 547 25][736 109 264 0 466 173 6448 68 1764 226]...]\n",
            " percent of 3-grams captured: 0.458.\n",
            "targets[[19 5 2 13420 21967 8 61 0 276 1790 571 8 0 5353 15390 38892 25 30 21248 1][2 13100 206 202 9 207 136 91 539 873 9 207 136 91 186 1587 49 0 547 25][736 109 264 0 466 173 6448 68 1764 226]...]\n",
            " percent of 2-grams captured: 0.676.\n",
            "targets[[19 5 2 13420 21967 8 61 0 276 1790 571 8 0 5353 15390 38892 25 30 21248 1][2 13100 206 202 9 207 136 91 539 873 9 207 136 91 186 1587 49 0 547 25][736 109 264 0 466 173 6448 68 1764 226]...]\n",
            " percent of 4-grams captured: 0.209.\n",
            " geometric_avg: 0.401.\n",
            " arithmetic_avg: 0.448.\n",
            "global_step: 2055\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.69375\n",
            " G train loss: 3.09165\n",
            "targets[[19 5 2 13420 21967 8 61 0 276 1790 571 8 0 5353 15390 38892 25 30 21248 1][2 13100 206 202 9 207 136 91 539 873 9 207 136 91 186 1587 49 0 547 25][736 109 264 0 466 173 6448 68 1764 226]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 2 13420 21967 8 61 0 276]...][[1 0 0 0 0 0 0 0 1 0]...][[10 19 69848 69848 69848 69848 69848 69848 69848 276]...][[19 5 2 13420 21967 8 61 0 276 1790]...]\n",
            " Sample 0.\n",
            "   [1]  film                  0.473   0.000  \n",
            "   [0]  is                    0.471   1.070  \n",
            "   [0]  a                     0.470   1.306  \n",
            "   [0]  leftist               0.468   14.306 \n",
            "   [0]  polemic               0.466   12.528 \n",
            "   [0]  in                    0.464   3.086  \n",
            "   [0]  which                 0.465   6.307  \n",
            "   [0]  the                   0.467   3.863  \n",
            "   [1]  american              0.468   0.000  \n",
            "   [0]  forces                0.468   8.767  \n",
            "   [0]  involved              0.468   8.812  \n",
            "   [1]  in                    0.467   0.000  \n",
            "   [1]  the                   0.468   0.000  \n",
            "   [1]  1989                  0.467   0.000  \n",
            "   [1]  panama                0.468   0.000  \n",
            "   [1]  incursion             0.470   0.000  \n",
            "   [0]  are                   0.471   5.313  \n",
            "   [0]  all                   0.470   5.389  \n",
            "   [0]  liars                 0.469   13.282 \n",
            "   [1]  and                   0.468   0.000  \n",
            " Sample 1.\n",
            "   [0]  a                     0.475   2.445  \n",
            "   [0]  tbs                   0.473   9.631  \n",
            "   [0]  original              0.473   7.903  \n",
            "   [0]  series                0.474   5.442  \n",
            "   [0]  i                     0.472   2.925  \n",
            "   [1]  d                     0.472   0.000  \n",
            "   [0]  say                   0.470   3.965  \n",
            "   [0]  its                   0.469   7.101  \n",
            "   [1]  brilliant             0.468   0.000  \n",
            "   [1]  otherwise             0.470   0.000  \n",
            "   [1]  i                     0.468   0.000  \n",
            "   [1]  d                     0.469   0.000  \n",
            "   [1]  say                   0.468   0.000  \n",
            "   [1]  its                   0.468   0.000  \n",
            "   [0]  pretty                0.469   7.009  \n",
            "   [1]  damn                  0.472   0.000  \n",
            "   [0]  good                  0.473   5.743  \n",
            "   [0]  the                   0.473   3.562  \n",
            "   [1]  stories               0.473   0.000  \n",
            "   [1]  are                   0.472   0.000  \n",
            " Sample 2.\n",
            "   [1]  predictable           0.504   0.000  \n",
            "   [0]  plot                  0.505   7.474  \n",
            "   [1]  although              0.506   0.000  \n",
            "   [1]  the                   0.508   0.000  \n",
            "   [0]  final                 0.509   7.077  \n",
            "   [0]  few                   0.509   8.123  \n",
            "   [0]  frames                0.508   11.355 \n",
            "   [1]  were                  0.507   0.000  \n",
            "   [1]  nicely                0.506   0.000  \n",
            "   [1]  done                  0.505   0.000  \n",
            "   [1]  unbelievably          0.504   0.000  \n",
            "   [1]  banal                 0.504   0.000  \n",
            "   [0]  dialog                0.505   8.927  \n",
            "   [0]  capped                0.506   12.892 \n",
            "   [1]  by                    0.506   0.000  \n",
            "   [1]  mcdormand             0.506   0.000  \n",
            "   [0]  s                     0.506   4.834  \n",
            "   [1]  soliloquy             0.506   0.000  \n",
            "   [1]  to                    0.505   0.000  \n",
            "   [0]  her                   0.506   6.304  \n",
            "Samples\n",
            "Sample 0 .  film is a leftist polemic in which the american forces involved in the 1989 panama incursion are all liars and\n",
            "Sample 1 .  a tbs original series i d say its brilliant otherwise i d say its pretty damn good the stories are\n",
            "Sample 2 .  predictable plot although the final few frames were nicely done unbelievably banal dialog capped by mcdormand s soliloquy to her\n",
            "\n",
            "\n",
            "targets[[144 0 829 3 10 19 7 12 731 4 71 11 0 746 816 1008 0 1475 34 89][5 35 322 556 3 567 5240 19 14261 9 139 1018 7 22 1901 119 0 154 9 139][8 3207 0 68578 3030 25 355 3 0 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[884 144 0 829 3 10 19 7 12 731]...][[1 1 0 0 1 0 0 0 0 1]...][[884 144 0 69848 69848 10 69848 69848 69848 69848]...][[144 0 829 3 10 19 7 12 731 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[884 144 0 829 3 10 19 7 12 731]...][[1 1 0 0 1 0 0 0 0 1]...][[884 144 0 69848 69848 10 69848 69848 69848 69848]...][[144 0 829 3 10 19 7 12 731 4]...]\n",
            "targets[[3 0 117 699 2299 202 123 9 139 77 259 4 810 10 202 22 1912 41 277 16][984 3 0 5388 19 33 0 170 390 4069 576 5724 4 114 5 323 18 7 5 2][9 13 2 183 125 3 2873 154 3 567]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 117 699 2299 202 123 9 139]...][[0 0 1 0 1 1 0 0 1 1]...][[29 69848 69848 117 69848 2299 202 69848 69848 139]...][[3 0 117 699 2299 202 123 9 139 77]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 117 699 2299 202 123 9 139]...][[0 0 1 0 1 1 0 0 1 1]...][[29 69848 69848 117 69848 2299 202 69848 69848 139]...][[3 0 117 699 2299 202 123 9 139 77]...]\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFD9rWo42ezv",
        "colab_type": "code",
        "outputId": "d854b4d2-91da-43d3-861a-f8221e355471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# make copy of mle training checkpoints\n",
        "%cd /content\n",
        "!cp -r '/content/yesweGAN/maskgan_colab/maskGAN/train' '/content/drive/My Drive/imdb mle checkpoint - stochastic'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3pcQ4Gpl2wp",
        "colab_type": "text"
      },
      "source": [
        "## Run MaskGAN in GAN mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5e93b1b3-e87e-445a-8b60-4484f2733893",
        "id": "dLyPlm0cGEZu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/yesweGAN/maskgan_colab\n",
        "!python train_mask_gan.py \\\n",
        " --data_dir='dataset/imdb' \\\n",
        " --data_set='imdb' \\\n",
        " --batch_size=128 \\\n",
        " --sequence_length=20 \\\n",
        " --base_directory='/content/yesweGAN/maskgan_colab/maskGAN' \\\n",
        " --maskgan_ckpt='/content/yesweGAN/maskgan_colab/maskGAN/train/model.ckpt-6006' \\\n",
        " --hparams=\"gen_rnn_size=650,dis_rnn_size=650,gen_num_layers=2,dis_num_layers=2,gen_learning_rate=0.00001,gen_learning_rate_decay=0.999999,gen_full_learning_rate_steps=1e9,gen_vd_keep_prob=0.33971,rl_discount_rate=0.8835659,dis_learning_rate=0.001,baseline_decay=0.99,dis_train_iterations=8,dis_pretrain_learning_rate=0.00005,critic_learning_rate=0.0009,dis_vd_keep_prob=0.71940\" \\\n",
        " --mode='TRAIN' \\\n",
        " --mask_strategy=contiguous \\\n",
        " --max_steps=10000 \\\n",
        " --generator_optimizer=adam \\\n",
        " --perplexity_threshold=1000000 \\\n",
        " --generator_model='seq2seq_vd' \\\n",
        " --discriminator_model='seq2seq_vd' \\\n",
        " --summaries_every=250 \\\n",
        " --print_every=250 \\\n",
        " --max_num_to_print=3 \\\n",
        " --gen_training_strategy='reinforce' \\\n",
        " --seq2seq_share_embedding=true \\\n",
        " --baseline_method=critic \\\n",
        " --attention_option=luong"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "global_step: 7469\n",
            " perplexity: 422.639\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            " percent of 3-grams captured: 0.352.\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            " percent of 2-grams captured: 0.648.\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            " percent of 4-grams captured: 0.119.\n",
            " geometric_avg: 0.300.\n",
            " arithmetic_avg: 0.373.\n",
            "global_step: 7469\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39521\n",
            " G train loss: -7.63679\n",
            "targets[[1996 1 3566 319 44 5 0 117 172 1 64 913 130 3 10 873 2062 17 39 5][36 22764 1 1192 2095 10 19 5 2 1792 4 0 531 15 323 5501 5883 36 12 2059][300 2 940 11 92 71 53 671 8 40]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 1996 1 3566 319 44 5 0 117 172]...][[1 1 0 0 0 0 0 0 0 0]...][[47 1996 1 69848 69848 69848 69848 69848 69848 69848]...][[1996 1 3566 319 44 5 0 117 172 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 1996 1 3566 319 44 5 0 117 172]...][[1 1 0 0 0 0 0 0 0 0]...][[47 1996 1 69848 69848 69848 69848 69848 69848 69848]...][[1996 1 0 1619 5043 2847 181 3732 1088 104]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  reviewers           0.575        0.000        0.000        0.000        -8.309       -3.873       -0.000       \n",
            "   [1]  and                 0.479        0.000        0.000        0.000        -9.404       -10.257      0.000        \n",
            "   [0]  the                 0.418        9.233        -1.905       -0.873       -10.643      -9.404       -1.239       \n",
            "   [0]  comedic             0.500        8.419        -9.271       -0.692       -11.058      -9.244       -1.813       \n",
            "   [0]  indulgent           0.249        7.713        -10.623      -1.392       -11.731      -8.274       -3.457       \n",
            "   [0]  lane                0.056        2.657        -8.791       -2.889       -11.702      -9.546       -2.155       \n",
            "   [0]  action              0.304        3.424        -6.868       -1.192       -9.974       -13.595      3.621        \n",
            "   [0]  ginger              0.113        7.868        -8.796       -2.178       -9.940       -10.511      0.572        \n",
            "   [0]  fiction             0.026        8.290        -8.346       -3.655       -8.784       -12.069      3.285        \n",
            "   [0]  films               0.036        3.065        -6.412       -3.325       -5.806       -11.766      5.000        \n",
            "   [0]  nonsense            0.060        7.809        -8.510       -2.807       -2.807       -10.604      5.000        \n",
            "   [1]  memorable           0.359        0.000        0.000        0.000        0.000        -10.807      0.000        \n",
            "   [1]  scene               0.452        0.000        0.000        0.000        0.000        -9.542       0.000        \n",
            "   [1]  of                  0.701        0.000        0.000        0.000        0.000        -9.333       0.000        \n",
            "   [1]  this                0.783        0.000        0.000        0.000        0.000        -9.763       0.000        \n",
            "   [1]  otherwise           0.752        0.000        0.000        0.000        0.000        -9.346       0.000        \n",
            "   [1]  dreadful            0.922        0.000        0.000        0.000        0.000        -10.841      0.000        \n",
            "   [1]  movie               0.991        0.000        0.000        0.000        0.000        -7.684       0.000        \n",
            "   [1]  there               0.997        0.000        0.000        0.000        0.000        -7.307       0.000        \n",
            "   [1]  is                  0.997        0.000        0.000        0.000        0.000        -7.917       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  from                0.548        0.000        0.000        0.000        -5.521       -3.769       -0.000       \n",
            "   [1]  waterworld          0.353        0.000        0.000        0.000        -6.248       -7.724       0.000        \n",
            "   [1]  and                 0.609        0.000        0.000        0.000        -7.072       -5.809       -0.000       \n",
            "   [1]  mad                 0.812        0.000        0.000        0.000        -8.004       -7.579       -0.000       \n",
            "   [1]  max                 0.507        0.000        0.000        0.000        -9.058       -5.625       -0.000       \n",
            "   [0]  returns             0.562        5.792        -8.010       -0.577       -10.252      -5.755       -4.497       \n",
            "   [0]  one                 0.332        6.792        -5.893       -1.102       -10.950      -4.774       -5.000       \n",
            "   [0]  the                 0.302        3.305        -3.081       -1.198       -11.146      -7.346       -3.800       \n",
            "   [0]  all                 0.383        5.769        -6.717       -0.959       -11.259      -9.808       -1.451       \n",
            "   [0]  his                 0.317        9.546        -7.050       -1.150       -11.658      -6.374       -5.000       \n",
            "   [0]  big                 0.126        10.112       -5.960       -2.070       -11.892      -7.126       -4.766       \n",
            "   [0]  format              0.040        6.591        -9.844       -3.228       -11.117      -8.042       -3.076       \n",
            "   [0]  movie               0.008        8.971        -4.078       -4.843       -8.929       -11.394      2.465        \n",
            "   [0]  skin                0.010        4.031        -12.397      -4.624       -4.624       -13.792      5.000        \n",
            "   [1]  beautiful           0.013        0.000        0.000        0.000        0.000        -9.570       0.000        \n",
            "   [1]  sand                0.008        0.000        0.000        0.000        0.000        -9.109       0.000        \n",
            "   [1]  landscapes          0.013        0.000        0.000        0.000        0.000        -10.073      0.000        \n",
            "   [1]  from                0.010        0.000        0.000        0.000        0.000        -10.101      0.000        \n",
            "   [1]  s                   0.003        0.000        0.000        0.000        0.000        -12.071      0.000        \n",
            "   [1]  desert              0.002        0.000        0.000        0.000        0.000        -14.557      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  said                0.635        0.000        0.000        0.000        -7.174       -3.864       -0.000       \n",
            "   [0]  this                0.417        2.667        -3.747       -0.875       -8.120       -9.137       1.018        \n",
            "   [0]  is                  0.575        8.498        -0.794       -0.554       -8.199       -7.861       -0.337       \n",
            "   [0]  the                 0.665        6.001        -2.397       -0.407       -8.653       -7.078       -1.575       \n",
            "   [0]  world               0.313        6.731        -5.865       -1.161       -9.332       -9.788       0.456        \n",
            "   [0]  technicolor         0.111        7.240        -11.274      -2.201       -9.248       -9.826       0.579        \n",
            "   [0]  decent              0.091        6.293        -8.749       -2.401       -7.975       -11.798      3.823        \n",
            "   [0]  time                0.079        8.126        -5.024       -2.537       -6.308       -11.013      4.705        \n",
            "   [0]  the                 0.075        3.560        -1.969       -2.587       -4.268       -11.420      5.000        \n",
            "   [0]  love                0.149        10.279       -5.143       -1.903       -1.903       -11.246      5.000        \n",
            "   [1]  i                   0.093        0.000        0.000        0.000        0.000        -8.832       0.000        \n",
            "   [1]  have                0.093        0.000        0.000        0.000        0.000        -10.616      0.000        \n",
            "   [1]  watched             0.089        0.000        0.000        0.000        0.000        -9.921       0.000        \n",
            "   [1]  desperate           0.188        0.000        0.000        0.000        0.000        -9.990       0.000        \n",
            "   [1]  housewives          0.737        0.000        0.000        0.000        0.000        -6.328       0.000        \n",
            "   [1]  and                 0.753        0.000        0.000        0.000        0.000        -6.830       0.000        \n",
            "   [1]  sometimes           0.600        0.000        0.000        0.000        0.000        -9.076       0.000        \n",
            "   [1]  they                0.738        0.000        0.000        0.000        0.000        -8.079       0.000        \n",
            "   [1]  have                0.658        0.000        0.000        0.000        0.000        -6.218       0.000        \n",
            "   [1]  shows               0.829        0.000        0.000        0.000        0.000        -7.605       0.000        \n",
            "Samples\n",
            "Sample 0 .  reviewers and the comedic indulgent lane action ginger fiction films nonsense memorable scene of this otherwise dreadful movie there is\n",
            "Sample 1 .  from waterworld and mad max returns one the all his big format movie skin beautiful sand landscapes from s desert\n",
            "Sample 2 .  said this is the world technicolor decent time the love i have watched desperate housewives and sometimes they have shows\n",
            "\n",
            "\n",
            "targets[[140 23 2 200 340 3 1224 1412 14 2 477 18 58 33 0 1645 3 360 360 341][13 2 49 17 7 288 21 127 737 299 487 18 137 2 222 263 10 17 1197 178][10 569 21 27 77 35 1373 17 46 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 140 23 2 200 340 3 1224 1412 14]...][[1 1 1 1 1 1 1 1 1 1]...][[9 140 23 2 200 340 3 1224 1412 14]...][[140 23 2 200 340 3 1224 1412 14 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 140 23 2 200 340 3 1224 1412 14]...][[1 1 1 1 1 1 1 1 1 1]...][[9 140 23 2 200 340 3 1224 1412 14]...][[140 23 2 200 340 3 1224 1412 14 2]...]\n",
            "targets[[12 727 4 1226 22 19242 1 651 7 2 74 17 7 12 23 206 7 1449 2 222][7 12 4914 12979 1 780 14418 8 2 17 43 2 330 939 2404 0 160 939 7 12][2117 8715 3247 3861 4943 45 2 679 430 22]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 727 4 1226 22 19242 1 651 7]...][[1 1 0 0 0 0 0 0 0 0]...][[7 12 727 69848 69848 69848 69848 69848 69848 69848]...][[12 727 4 1226 22 19242 1 651 7 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 727 4 1226 22 19242 1 651 7]...][[1 1 0 0 0 0 0 0 0 0]...][[7 12 727 69848 69848 69848 69848 69848 69848 69848]...][[12 727 4 367 2 115 17 11 256 28]...]\n",
            "targets[[13 1435 78 483 8 27114 19832 51 15132 13 8979 1722 2227 42 167 24 654 78 0 2630][481 9 50 21 1652 7 8 2 126 41 5785 11942 95 348 1 374 116 47 116 134][2617 5 2 53 49 7816 339 3 0 368]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1435 78 483 8 27114 19832 51 15132]...][[1 1 1 1 1 1 1 1 1 1]...][[9 13 1435 78 483 8 27114 19832 51 15132]...][[13 1435 78 483 8 27114 19832 51 15132 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1435 78 483 8 27114 19832 51 15132]...][[1 1 1 1 1 1 1 1 1 1]...][[9 13 1435 78 483 8 27114 19832 51 15132]...][[13 1435 78 483 8 27114 19832 51 15132 13]...]\n",
            "targets[[75 210 21 43 22368 7 210 21 43 75 7 210 21 65 43 238 7 5 180 853][408 17689 12 84 8 26 2622 10 695 0 1194 16 0 6280 6296 1 405 3 0 105][17 8088 747 1 623 31 7443 1654 8088 12]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9338 75 210 21 43 22368 7 210 21 43]...][[1 1 1 1 1 0 0 0 0 0]...][[9338 75 210 21 43 22368 69848 69848 69848 69848]...][[75 210 21 43 22368 7 210 21 43 75]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9338 75 210 21 43 22368 7 210 21 43]...][[1 1 1 1 1 0 0 0 0 0]...][[9338 75 210 21 43 22368 69848 69848 69848 69848]...][[75 210 21 43 22368 54 6644 22 7 13]...]\n",
            "targets[[6 37 595 37 49 10 19 5 2 7514 8 4982 443 20 83 23 66 0 37 446][121 39 25 108 44 39 34 103 11 8302 23295 59 27 77 126 177 14 2106 72 11603][12 213 2 2319 842 4 2505 35 25909 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 37 595 37 49 10 19 5 2]...][[1 1 1 1 1 1 1 0 0 0]...][[6 6 37 595 37 49 10 19 69848 69848]...][[6 37 595 37 49 10 19 5 2 7514]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 37 595 37 49 10 19 5 2]...][[1 1 1 1 1 1 1 0 0 0]...][[6 6 37 595 37 49 10 19 69848 69848]...][[6 37 595 37 49 10 19 8 101 9]...]\n",
            "targets[[192 10 19 45 955 1425 2 81 109 1 523 156 190 9 604 345 18 4 28 671][471 6512 65 693 87 4 1006 2 368 1 99 700 2688 26 869 269 596 14 0 145][3285 431 3285 6 6 16 44298 439 10 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1270 192 10 19 45 955 1425 2 81 109]...][[1 1 1 1 1 1 1 1 1 0]...][[1270 192 10 19 45 955 1425 2 81 109]...][[192 10 19 45 955 1425 2 81 109 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1270 192 10 19 45 955 1425 2 81 109]...][[1 1 1 1 1 1 1 1 1 0]...][[1270 192 10 19 45 955 1425 2 81 109]...][[192 10 19 45 955 1425 2 81 109 1]...]\n",
            "targets[[84 422 1240 529 2 49 1461 47 4 512 36 0 202 4644 1073 4 28 6971 1 2][455 619 12 2913 435 67 31 48 220 8 0 501 77 2227 1827 1978 22 0 95 346][0 88 172 10 19 5 7046 33 48 397]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 422 1240 529 2 49 1461 47 4]...][[1 0 0 0 0 0 0 0 0 0]...][[0 84 69848 69848 69848 69848 69848 69848 69848 69848]...][[84 422 1240 529 2 49 1461 47 4 512]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 422 1240 529 2 49 1461 47 4]...][[1 0 0 0 0 0 0 0 0 0]...][[0 84 69848 69848 69848 69848 69848 69848 69848 69848]...][[84 157 453 30 17 5 2 81 181 321]...]\n",
            "targets[[196 9 13 164 4 27 4 366 7536 60 531 44 294 10 17 4 93 0 57 1372][371 777 63 397 7744 3 676 1 2 583 757 93 10 5 2 1571 2789 17 23 29][43 10 17 49 177 1 523 116 18 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 196 9 13 164 4 27 4 366 7536]...][[1 1 1 0 0 0 0 0 0 0]...][[9 196 9 13 69848 69848 69848 69848 69848 69848]...][[196 9 13 164 4 27 4 366 7536 60]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 196 9 13 164 4 27 4 366 7536]...][[1 1 1 0 0 0 0 0 0 0]...][[9 196 9 13 69848 69848 69848 69848 69848 69848]...][[196 9 13 2 200 153 57 0 82 754]...]\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[1 1 1 1 1 1 1 1 1 0]...][[48 3 0 881 1996 27 446 24579 774 1099]...][[3 0 881 1996 27 446 24579 774 1099 135]...]\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[1 1 1 1 1 1 1 1 1 0]...][[48 3 0 881 1996 27 446 24579 774 1099]...][[3 0 881 1996 27 446 24579 774 1099 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[1 1 1 1 1 1 1 1 1 0]...][[48 3 0 881 1996 27 446 24579 774 1099]...][[3 0 881 1996 27 446 24579 774 1099 898]...]\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "global_step: 7486\n",
            " perplexity: 421.866\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            " percent of 3-grams captured: 0.338.\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            " percent of 2-grams captured: 0.640.\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            " percent of 4-grams captured: 0.108.\n",
            " geometric_avg: 0.285.\n",
            " arithmetic_avg: 0.362.\n",
            "global_step: 7486\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39473\n",
            " G train loss: -7.63584\n",
            "targets[[3 0 881 1996 27 446 24579 774 1099 1 27 1712 134 7 13 92 60 864 16 131][19 702 2 1571 63 0 503 1 0 101 25 37 145 1 1011 37 69 20 50 21][140 2 669 340 3 0 9196 3 13691 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[1 1 1 1 1 1 1 1 1 0]...][[48 3 0 881 1996 27 446 24579 774 1099]...][[3 0 881 1996 27 446 24579 774 1099 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[48 3 0 881 1996 27 446 24579 774 1099]...][[1 1 1 1 1 1 1 1 1 0]...][[48 3 0 881 1996 27 446 24579 774 1099]...][[3 0 881 1996 27 446 24579 774 1099 1]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  of                  0.301        0.000        0.000        0.000        -3.801       -4.118       0.000        \n",
            "   [1]  the                 0.568        0.000        0.000        0.000        -4.302       -11.686      0.000        \n",
            "   [1]  earlier             0.583        0.000        0.000        0.000        -4.869       -8.266       0.000        \n",
            "   [1]  reviewers           0.574        0.000        0.000        0.000        -5.511       -7.329       0.000        \n",
            "   [1]  have                0.465        0.000        0.000        0.000        -6.237       -10.721      0.000        \n",
            "   [1]  called              0.483        0.000        0.000        0.000        -7.059       -9.784       0.000        \n",
            "   [1]  clockwatchers       0.843        0.000        0.000        0.000        -7.989       -8.637       0.000        \n",
            "   [1]  dull                0.481        0.000        0.000        0.000        -9.041       -9.679       0.000        \n",
            "   [1]  pointless           0.821        0.000        0.000        0.000        -10.233      -9.523       -0.000       \n",
            "   [0]  and                 0.782        2.379        -2.379       -0.246       -11.581      -11.694      0.113        \n",
            "   [0]  his                 0.532        6.025        -5.215       -0.631       -12.830      -9.712       -3.118       \n",
            "   [0]  sunday              0.192        10.845       -8.189       -1.650       -13.806      -8.532       -5.000       \n",
            "   [0]  in                  0.128        8.986        -4.872       -2.054       -13.758      -12.294      -1.464       \n",
            "   [0]  trading             0.188        5.736        -12.990      -1.674       -13.246      -13.487      0.242        \n",
            "   [0]  in                  0.175        5.489        -3.434       -1.745       -13.097      -11.052      -2.046       \n",
            "   [0]  carried             0.016        7.302        -10.996      -4.162       -12.848      -11.553      -1.295       \n",
            "   [0]  the                 0.008        6.744        -3.197       -4.887       -9.831       -17.677      5.000        \n",
            "   [0]  interesting         0.004        8.259        -7.523       -5.595       -5.595       -16.575      5.000        \n",
            "   [1]  for                 0.004        0.000        0.000        0.000        0.000        -13.713      0.000        \n",
            "   [1]  these               0.005        0.000        0.000        0.000        0.000        -12.771      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  film                0.636        0.000        0.000        0.000        -2.907       -3.969       0.000        \n",
            "   [1]  tells               0.669        0.000        0.000        0.000        -3.290       -13.490      0.000        \n",
            "   [1]  a                   0.697        0.000        0.000        0.000        -3.724       -8.224       0.000        \n",
            "   [1]  compelling          0.595        0.000        0.000        0.000        -4.215       -11.900      0.000        \n",
            "   [1]  story               0.603        0.000        0.000        0.000        -4.770       -10.122      0.000        \n",
            "   [1]  the                 0.534        0.000        0.000        0.000        -5.398       -11.638      0.000        \n",
            "   [1]  writing             0.569        0.000        0.000        0.000        -6.110       -11.268      0.000        \n",
            "   [1]  and                 0.582        0.000        0.000        0.000        -6.915       -8.629       0.000        \n",
            "   [1]  the                 0.631        0.000        0.000        0.000        -7.826       -8.716       0.000        \n",
            "   [1]  characters          0.717        0.000        0.000        0.000        -8.858       -9.888       0.000        \n",
            "   [0]  that                0.631        4.055        -3.771       -0.460       -10.025      -8.385       -1.640       \n",
            "   [0]  the                 0.530        6.467        -4.990       -0.635       -10.825      -7.940       -2.885       \n",
            "   [0]  most                0.592        6.113        -5.149       -0.525       -11.532      -8.635       -2.897       \n",
            "   [0]  movie               0.069        5.676        -2.363       -2.674       -12.458      -9.055       -3.403       \n",
            "   [0]  i                   0.050        12.141       -1.855       -2.992       -11.074      -18.053      5.000        \n",
            "   [0]  do                  0.047        9.736        -5.307       -3.057       -9.147       -14.897      5.000        \n",
            "   [0]  ever                0.046        7.663        -2.608       -3.074       -6.892       -12.177      5.000        \n",
            "   [0]  averaged            0.105        8.231        -16.041      -2.253       -4.321       -10.033      5.000        \n",
            "   [0]  married             0.096        8.011        -9.543       -2.341       -2.341       -10.258      5.000        \n",
            "   [1]  t                   0.011        0.000        0.000        0.000        0.000        -9.003       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  m                   0.320        0.000        0.000        0.000        -1.819       -3.620       0.000        \n",
            "   [1]  a                   0.567        0.000        0.000        0.000        -2.059       -4.937       0.000        \n",
            "   [1]  huge                0.693        0.000        0.000        0.000        -2.330       -6.486       0.000        \n",
            "   [1]  fan                 0.653        0.000        0.000        0.000        -2.637       -5.028       0.000        \n",
            "   [1]  of                  0.576        0.000        0.000        0.000        -2.985       -7.185       0.000        \n",
            "   [1]  the                 0.516        0.000        0.000        0.000        -3.378       -7.130       0.000        \n",
            "   [1]  dukes               0.583        0.000        0.000        0.000        -3.823       -7.994       0.000        \n",
            "   [1]  of                  0.734        0.000        0.000        0.000        -4.327       -7.062       0.000        \n",
            "   [1]  hazzard             0.868        0.000        0.000        0.000        -4.897       -6.650       0.000        \n",
            "   [1]  tv                  0.610        0.000        0.000        0.000        -5.543       -9.298       0.000        \n",
            "   [0]  out                 0.819        6.682        -6.920       -0.200       -6.273       -9.934       3.661        \n",
            "   [0]  they                0.627        1.609        -5.902       -0.466       -6.873       -9.942       3.069        \n",
            "   [0]  will                0.682        4.290        -4.730       -0.383       -7.251       -9.783       2.531        \n",
            "   [0]  got                 0.295        4.450        -4.408       -1.221       -7.773       -9.374       1.601        \n",
            "   [0]  a                   0.135        7.751        -2.463       -1.999       -7.416       -11.015      3.599        \n",
            "   [0]  classic             0.260        7.071        -5.806       -1.347       -6.131       -10.413      4.282        \n",
            "   [0]  performance         0.136        7.747        -7.225       -1.993       -5.414       -9.322       3.908        \n",
            "   [0]  for                 0.113        3.732        -3.177       -2.183       -3.872       -11.806      5.000        \n",
            "   [0]  them                0.148        11.816       -6.062       -1.911       -1.911       -9.688       5.000        \n",
            "   [1]  myself              0.053        0.000        0.000        0.000        0.000        -8.876       0.000        \n",
            "Samples\n",
            "Sample 0 .  of the earlier reviewers have called clockwatchers dull pointless and his sunday in trading in carried the interesting for these\n",
            "Sample 1 .  film tells a compelling story the writing and the characters that the most movie i do ever averaged married t\n",
            "Sample 2 .  m a huge fan of the dukes of hazzard tv out they will got a classic performance for them myself\n",
            "\n",
            "\n",
            "targets[[20 38 98 15 56 11343 109 15 3094 20 89 21 456 43 11 560 20 1716 4 12938][2 194 57 0 22066 13 60 519 314 2520 422 152 8 1187 154 7 45 77 19878 33][17 5 4339 8 181 7 45 756 3 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 98 15 56 11343 109 15 3094]...][[1 1 1 1 1 0 0 0 0 0]...][[46 20 38 98 15 56 69848 69848 69848 69848]...][[20 38 98 15 56 11343 109 15 3094 20]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 98 15 56 11343 109 15 3094]...][[1 1 1 1 1 0 0 0 0 0]...][[46 20 38 98 15 56 69848 69848 69848 69848]...][[20 38 98 15 56 210 21 110 36 0]...]\n",
            "targets[[17 4655 10363 30 3 131 37 446 156 8 10 19 365 4 113 123 166 8 0 19][480 17 5417 43 0 5352 3 0 176 299 1331 18285 583 347 25 358 33 468 1644 1][215 10 8 2 5862 105 483 167 0 3955]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 4655 10363 30 3 131 37 446 156]...][[1 1 1 1 1 1 1 1 0 0]...][[10 17 4655 10363 30 3 131 37 446 69848]...][[17 4655 10363 30 3 131 37 446 156 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 4655 10363 30 3 131 37 446 156]...][[1 1 1 1 1 1 1 1 0 0]...][[10 17 4655 10363 30 3 131 37 446 69848]...][[17 4655 10363 30 3 131 37 446 311 99]...]\n",
            "targets[[5 2 81 1641 11 193 751 2322 1 284 3412 25 56 1123 15 178 18 11 1525 21][3 2804 5 29 3 2 202 3 322 2651 92 33 4954 1042 8 0 3239 10 29 45][19 5 35 322 502 3 0 12278 3 303]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 2 81 1641 11 193 751 2322 1]...][[1 1 1 1 1 0 0 0 0 0]...][[7 5 2 81 1641 11 69848 69848 69848 69848]...][[5 2 81 1641 11 193 751 2322 1 284]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 2 81 1641 11 193 751 2322 1]...][[1 1 1 1 1 0 0 0 0 0]...][[7 5 2 81 1641 11 69848 69848 69848 69848]...][[5 2 81 1641 11 5 822 1 106 1448]...]\n",
            "targets[[3 60 30 57 519 98 43 2922 70 843 11 5215 5 5850 22 108 12519 1 23 30][210 21 39 2 378 3 10 607 19 61 5 5145 642 22 729 29 3 108 4453 22752][37 446 201 5 3704 22 30 2056 1 250]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 60 30 57 519 98 43 2922 70]...][[1 1 1 1 1 1 1 1 1 0]...][[29 3 60 30 57 519 98 43 2922 70]...][[3 60 30 57 519 98 43 2922 70 843]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 60 30 57 519 98 43 2922 70]...][[1 1 1 1 1 1 1 1 1 0]...][[29 3 60 30 57 519 98 43 2922 70]...][[3 60 30 57 519 98 43 2922 70 3188]...]\n",
            "targets[[466 19 16 11819 7497 5941 33 6725 7929 99 7497 12 11445 320 294 369 5 2 17331 486][1373 1966 3 153 10018 13583 1 986 279 13464 1642 27 2770 4 1006 35 1373 17 144 7304][81 19 1 180 631 5148 16 27254 12 667]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 466 19 16 11819 7497 5941 33 6725 7929]...][[1 1 1 1 1 1 1 1 1 1]...][[0 466 19 16 11819 7497 5941 33 6725 7929]...][[466 19 16 11819 7497 5941 33 6725 7929 99]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 466 19 16 11819 7497 5941 33 6725 7929]...][[1 1 1 1 1 1 1 1 1 1]...][[0 466 19 16 11819 7497 5941 33 6725 7929]...][[466 19 16 11819 7497 5941 33 6725 7929 99]...]\n",
            "targets[[39 13 520 4035 94 389 1306 1597 33 2675 9569 6 6 1 147 70 892 4494 31044 2][19 13 2 453 3 1774 57 1 281 8 2 266 10 17 5 212 18 649 1614 0][229 0 250 7602 3 2684 8 61 8178 9459]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[84 39 13 520 4035 94 389 1306 1597 33]...][[1 1 1 1 1 1 1 1 1 1]...][[84 39 13 520 4035 94 389 1306 1597 33]...][[39 13 520 4035 94 389 1306 1597 33 2675]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[84 39 13 520 4035 94 389 1306 1597 33]...][[1 1 1 1 1 1 1 1 1 1]...][[84 39 13 520 4035 94 389 1306 1597 33]...][[39 13 520 4035 94 389 1306 1597 33 2675]...]\n",
            "targets[[473 6 6 9 693 9 207 112 3272 14659 1 1059 67 2 598 4 66 7 9 424][9 467 0 6720 9 874 4 350 10 29 132 7 13 2 53 2565 19 15 745 3][0 17 13 186 838 15 30 3974 7 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1022 473 6 6 9 693 9 207 112 3272]...][[1 1 1 1 1 1 1 1 1 1]...][[1022 473 6 6 9 693 9 207 112 3272]...][[473 6 6 9 693 9 207 112 3272 14659]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1022 473 6 6 9 693 9 207 112 3272]...][[1 1 1 1 1 1 1 1 1 1]...][[1022 473 6 6 9 693 9 207 112 3272]...][[473 6 6 9 693 9 207 112 3272 14659]...]\n",
            "targets[[3 127 2073 181 2019 1229 1 885 524 960 452 5 39 238 356 15 10 17 69 416][215 10 2645 154 602 22 6996 7 13 53 871 4 106 37 145 4 106 10 385 231][3345 2576 11083 4451 5960 1 40 425 21707 4978]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1350 3 127 2073 181 2019 1229 1 885 524]...][[1 1 1 1 1 1 1 1 1 1]...][[1350 3 127 2073 181 2019 1229 1 885 524]...][[3 127 2073 181 2019 1229 1 885 524 960]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1350 3 127 2073 181 2019 1229 1 885 524]...][[1 1 1 1 1 1 1 1 1 1]...][[1350 3 127 2073 181 2019 1229 1 885 524]...][[3 127 2073 181 2019 1229 1 885 524 960]...]\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 1 1 1 1 1 1 1 0 0]...][[6 6 815 37 9 139 555 3 0 69848]...][[6 815 37 9 139 555 3 0 938 61]...]\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 1 1 1 1 1 1 1 0 0]...][[6 6 815 37 9 139 555 3 0 69848]...][[6 815 37 9 139 555 3 0 21756 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 1 1 1 1 1 1 1 0 0]...][[6 6 815 37 9 139 555 3 0 69848]...][[6 815 37 9 139 555 3 0 183 268]...]\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "global_step: 7503\n",
            " perplexity: 421.838\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            " percent of 3-grams captured: 0.352.\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            " percent of 2-grams captured: 0.643.\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            " percent of 4-grams captured: 0.128.\n",
            " geometric_avg: 0.307.\n",
            " arithmetic_avg: 0.374.\n",
            "global_step: 7503\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39391\n",
            " G train loss: -7.66922\n",
            "targets[[6 815 37 9 139 555 3 0 21756 3 12410 10 17 45 2034 9 139 555 87 10][84 215 970 11406 42091 10761 12 786 31358 29341 125 6611 821 43 720 154 602 1 9 13][188 4 28 1 145 6115 5 0 1406 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 1 1 1 1 1 1 1 0 0]...][[6 6 815 37 9 139 555 3 0 69848]...][[6 815 37 9 139 555 3 0 21756 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6 6 815 37 9 139 555 3 0 21756]...][[1 1 1 1 1 1 1 1 0 0]...][[6 6 815 37 9 139 555 3 0 69848]...][[6 815 37 9 139 555 3 0 9287 825]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  br                  0.686        0.000        0.000        0.000        -5.719       -3.837       -0.000       \n",
            "   [1]  okay                0.660        0.000        0.000        0.000        -6.472       -18.085      0.000        \n",
            "   [1]  so                  0.692        0.000        0.000        0.000        -7.325       -31.321      0.000        \n",
            "   [1]  i                   0.641        0.000        0.000        0.000        -8.290       -48.282      0.000        \n",
            "   [1]  ve                  0.517        0.000        0.000        0.000        -9.383       -42.596      0.000        \n",
            "   [1]  heard               0.803        0.000        0.000        0.000        -10.619      -31.684      0.000        \n",
            "   [1]  of                  0.938        0.000        0.000        0.000        -12.019      -27.642      0.000        \n",
            "   [1]  the                 0.659        0.000        0.000        0.000        -13.603      -24.165      0.000        \n",
            "   [0]  lodger              0.131        13.206       -10.669      -2.035       -15.395      -17.569      2.174        \n",
            "   [0]  realistic           0.213        2.595        -9.431       -1.546       -15.121      -23.142      5.000        \n",
            "   [0]  has                 0.186        11.212       -6.281       -1.684       -15.364      -20.678      5.000        \n",
            "   [0]  this                0.191        3.114        -3.114       -1.653       -15.482      -17.738      2.256        \n",
            "   [0]  the                 0.047        1.435        -4.094       -3.064       -15.651      -18.536      2.885        \n",
            "   [0]  that                0.034        7.570        -8.084       -3.382       -14.245      -21.629      5.000        \n",
            "   [0]  with                0.018        9.492        -5.415       -3.998       -12.295      -19.686      5.000        \n",
            "   [0]  wonderful           0.010        3.828        -7.471       -4.584       -9.390       -19.776      5.000        \n",
            "   [0]  the                 0.004        10.268       -2.559       -5.439       -5.439       -17.596      5.000        \n",
            "   [1]  heard               0.003        0.000        0.000        0.000        0.000        -21.405      0.000        \n",
            "   [1]  how                 0.005        0.000        0.000        0.000        0.000        -21.983      0.000        \n",
            "   [1]  this                0.007        0.000        0.000        0.000        0.000        -20.090      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  first               0.462        0.000        0.000        0.000        -1.782       -3.894       0.000        \n",
            "   [1]  saw                 0.367        0.000        0.000        0.000        -2.017       -6.017       0.000        \n",
            "   [1]  c                   0.512        0.000        0.000        0.000        -2.283       -9.451       0.000        \n",
            "   [1]  est                 0.698        0.000        0.000        0.000        -2.583       -12.251      0.000        \n",
            "   [1]  arriv               0.608        0.000        0.000        0.000        -2.924       -15.920      0.000        \n",
            "   [0]  silence             0.777        13.411       -10.000      -0.253       -3.309       -7.082       3.773        \n",
            "   [0]  on                  0.741        3.551        -3.505       -0.300       -3.459       -7.472       4.013        \n",
            "   [0]  reached             0.387        9.529        -10.871      -0.950       -3.576       -8.571       4.995        \n",
            "   [0]  there               0.259        15.898       -6.002       -1.350       -2.972       -11.704      5.000        \n",
            "   [0]  are                 0.773        17.466       -3.506       -0.257       -1.836       -9.251       5.000        \n",
            "   [0]  strong              0.754        10.745       -8.029       -0.282       -1.787       -9.824       5.000        \n",
            "   [0]  but                 0.860        12.115       -4.227       -0.151       -1.704       -9.010       5.000        \n",
            "   [0]  s                   0.380        10.650       -4.013       -0.969       -1.757       -7.857       5.000        \n",
            "   [0]  trio                0.410        8.289        -8.782       -0.893       -0.893       -14.493      5.000        \n",
            "   [1]  ten                 0.150        0.000        0.000        0.000        0.000        -8.054       0.000        \n",
            "   [1]  years               0.059        0.000        0.000        0.000        0.000        -10.189      0.000        \n",
            "   [1]  ago                 0.132        0.000        0.000        0.000        0.000        -10.751      0.000        \n",
            "   [1]  and                 0.252        0.000        0.000        0.000        0.000        -10.487      0.000        \n",
            "   [1]  i                   0.445        0.000        0.000        0.000        0.000        -10.445      0.000        \n",
            "   [1]  was                 0.503        0.000        0.000        0.000        0.000        -10.553      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  seems               0.773        0.000        0.000        0.000        -7.823       -3.851       -0.000       \n",
            "   [1]  to                  0.623        0.000        0.000        0.000        -8.854       -10.910      0.000        \n",
            "   [1]  be                  0.596        0.000        0.000        0.000        -10.021      -8.381       -0.000       \n",
            "   [1]  and                 0.582        0.000        0.000        0.000        -11.342      -10.449      -0.000       \n",
            "   [1]  real                0.542        0.000        0.000        0.000        -12.836      -8.604       -0.000       \n",
            "   [1]  madonna             0.429        0.000        0.000        0.000        -14.528      -5.939       -0.000       \n",
            "   [1]  is                  0.757        0.000        0.000        0.000        -16.442      -6.694       -0.000       \n",
            "   [1]  the                 0.667        0.000        0.000        0.000        -18.609      -9.628       -0.000       \n",
            "   [1]  queen               0.370        0.000        0.000        0.000        -21.061      -10.028      -0.000       \n",
            "   [0]  veterans            0.257        4.185        -12.287      -1.360       -23.836      -9.636       -5.000       \n",
            "   [0]  is                  0.169        10.599       -3.946       -1.777       -25.438      -12.647      -5.000       \n",
            "   [0]  many                0.054        4.300        -5.287       -2.913       -26.779      -10.970      -5.000       \n",
            "   [0]  young               0.018        7.097        -7.374       -3.992       -27.011      -13.890      -5.000       \n",
            "   [0]  ago                 0.002        6.344        -5.894       -6.043       -26.052      -12.290      -5.000       \n",
            "   [0]  as                  0.002        3.444        -4.099       -6.022       -22.646      -15.741      -5.000       \n",
            "   [0]  other               0.001        3.464        -6.075       -6.898       -18.815      -16.016      -2.799       \n",
            "   [0]  and                 0.001        7.314        -3.096       -7.030       -13.487      -14.674      1.188        \n",
            "   [0]  the                 0.001        6.711        -1.236       -7.307       -7.307       -15.092      5.000        \n",
            "   [1]  be                  0.000        0.000        0.000        0.000        0.000        -14.684      0.000        \n",
            "   [1]  cause               0.001        0.000        0.000        0.000        0.000        -17.014      0.000        \n",
            "Samples\n",
            "Sample 0 .  br okay so i ve heard of the lodger realistic has this the that with wonderful the heard how this\n",
            "Sample 1 .  first saw c est arriv silence on reached there are strong but s trio ten years ago and i was\n",
            "Sample 2 .  seems to be and real madonna is the queen veterans is many young ago as other and the be cause\n",
            "\n",
            "\n",
            "targets[[8 0 311 5 157 502 3 0 611 3 2922 2363 4 7079 0 3964 3 5435 3364 36][2464 99 0 19 16 2 3713 2 15 0 153 8 0 1943 11 24 96 1283 0 19][1591 10 17 532 7 13 164 4 28 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[531 8 0 311 5 157 502 3 0 611]...][[1 1 1 1 0 0 0 0 0 0]...][[531 8 0 311 5 69848 69848 69848 69848 69848]...][[8 0 311 5 157 502 3 0 611 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[531 8 0 311 5 157 502 3 0 611]...][[1 1 1 1 0 0 0 0 0 0]...][[531 8 0 311 5 69848 69848 69848 69848 69848]...][[8 0 311 5 147 8 7 1115 3 969]...]\n",
            "targets[[1046 6596 16655 5 2 1930 4 106 58 15 0 1387 2174 743 54 12 358 54 515 3609][1585 45 161 4 80 15 0 991 9837 254 8 0 19 8 189 32 148 180 43580 15][84 10 465 38 35 744 19 15 2 49]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 1046 6596 16655 5 2 1930 4 106 58]...][[1 1 1 1 1 1 1 1 1 1]...][[9 1046 6596 16655 5 2 1930 4 106 58]...][[1046 6596 16655 5 2 1930 4 106 58 15]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 1046 6596 16655 5 2 1930 4 106 58]...][[1 1 1 1 1 1 1 1 1 1]...][[9 1046 6596 16655 5 2 1930 4 106 58]...][[1046 6596 16655 5 2 1930 4 106 58 15]...]\n",
            "targets[[103 295 13 180 671 15 10 832 827 487 16 29 151 7 13 513 33 1956 3718 157][3 0 250 98 9 27 123 110 70 785 22 532 11 7 203 76 126 696 4 7][0 117 3 0 1676 249 959 2183 992 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 103 295 13 180 671 15 10 832 827]...][[1 1 0 0 0 0 0 0 0 0]...][[9 103 295 69848 69848 69848 69848 69848 69848 69848]...][[103 295 13 180 671 15 10 832 827 487]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 103 295 13 180 671 15 10 832 827]...][[1 1 0 0 0 0 0 0 0 0]...][[9 103 295 69848 69848 69848 69848 69848 69848 69848]...][[103 295 20 1134 469 2 679 450 2539 1800]...]\n",
            "targets[[159 21 121 47 4 546 37 9 103 7 13 2 171 126 23 256 24976 73 89 21][5 284 9695 12 5010 184 680 17 43 2 522 3 668 15470 13932 3080 4498 3926 9600 4022][728 9247 520 3406 14 3937 26404 5 18072 154]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 159 21 121 47 4 546 37 9 103]...][[1 1 1 1 1 1 1 1 1 1]...][[9 159 21 121 47 4 546 37 9 103]...][[159 21 121 47 4 546 37 9 103 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 159 21 121 47 4 546 37 9 103]...][[1 1 1 1 1 1 1 1 1 1]...][[9 159 21 121 47 4 546 37 9 103]...][[159 21 121 47 4 546 37 9 103 7]...]\n",
            "targets[[10 17 45 108 1513 7 5 8 189 2 247 1820 17 1574 1932 8704 294 26 1001 12][113 215 320 476 40 51 7 84 211 44 85 3 2 738 9 67 353 1295 0 738][47 2 17 9 140 23 31 30 2 340]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[132 10 17 45 108 1513 7 5 8 189]...][[1 1 1 0 0 0 0 0 0 0]...][[132 10 17 45 69848 69848 69848 69848 69848 69848]...][[10 17 45 108 1513 7 5 8 189 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[132 10 17 45 108 1513 7 5 8 189]...][[1 1 1 0 0 0 0 0 0 0]...][[132 10 17 45 69848 69848 69848 69848 69848 69848]...][[10 17 45 23 360 946 2395 5679 16 1264]...]\n",
            "targets[[134 59 20 65 106 10 17 46 20 709 21 2 340 3 30581 34934 10 17 83 93][68 4592 22 0 1029 674 528 38 0 117 975 17 123 92 39 5 56 95 8 574][65 509 10 422 318 0 2726 7924 1388 6794]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[618 134 59 20 65 106 10 17 46 20]...][[1 1 1 1 1 1 1 1 1 1]...][[618 134 59 20 65 106 10 17 46 20]...][[134 59 20 65 106 10 17 46 20 709]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[618 134 59 20 65 106 10 17 46 20]...][[1 1 1 1 1 1 1 1 1 1]...][[618 134 59 20 65 106 10 17 46 20]...][[134 59 20 65 106 10 17 46 20 709]...]\n",
            "targets[[19 1470 3 3343 2395 12 298 5 2 480 910 39 12 56 145 3026 41 1269 18 0][17 45 2 742 3 74 156 1 0 109 27 2 742 3 1463 0 129 5 1157 1][5 2 145 4161 9 50 103 3 161 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 19 1470 3 3343 2395 12 298 5 2]...][[1 1 1 1 0 0 0 0 0 0]...][[0 19 1470 3 3343 69848 69848 69848 69848 69848]...][[19 1470 3 3343 2395 12 298 5 2 480]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 19 1470 3 3343 2395 12 298 5 2]...][[1 1 1 1 0 0 0 0 0 0]...][[0 19 1470 3 3343 69848 69848 69848 69848 69848]...][[19 1470 3 3343 3225 559 5087 1102 3 0]...]\n",
            "targets[[227 2504 5 0 1507 338 368 869 0 757 3 9783 2781 6454 4936 5 930 8 82 104][2 3054 3643 661 49 596 0 26522 2 173 2497 214 11 59 28 334 1343 11 149 10][140 23 2 669 340 3 3661 18 10 2879]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 227 2504 5 0 1507 338 368 869 0]...][[1 1 1 1 1 1 0 0 0 0]...][[0 227 2504 5 0 1507 338 69848 69848 69848]...][[227 2504 5 0 1507 338 368 869 0 757]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 227 2504 5 0 1507 338 368 869 0]...][[1 1 1 1 1 1 0 0 0 0]...][[0 227 2504 5 0 1507 338 69848 69848 69848]...][[227 2504 5 0 1507 338 0 125 75 3581]...]\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[1 1 1 1 1 1 1 1 1 1]...][[2 373 1 2 518 409 8 2 1040 346]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[1 1 1 1 1 1 1 1 1 1]...][[2 373 1 2 518 409 8 2 1040 346]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[1 1 1 1 1 1 1 1 1 1]...][[2 373 1 2 518 409 8 2 1040 346]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "global_step: 7520\n",
            " perplexity: 421.789\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            " percent of 3-grams captured: 0.340.\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            " percent of 2-grams captured: 0.651.\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            " percent of 4-grams captured: 0.110.\n",
            " geometric_avg: 0.290.\n",
            " arithmetic_avg: 0.367.\n",
            "global_step: 7520\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39336\n",
            " G train loss: -7.30221\n",
            "targets[[373 1 2 518 409 8 2 1040 346 391 1409 3 855 11842 1 148 24540 0 1497 3][50 106 2 49 2019 19 147 1 94 9 139 110 48 186 1213 528 190 10 5 29][84 1018 0 17 22 91 84 488 22 3685]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[1 1 1 1 1 1 1 1 1 1]...][[2 373 1 2 518 409 8 2 1040 346]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 373 1 2 518 409 8 2 1040 346]...][[1 1 1 1 1 1 1 1 1 1]...][[2 373 1 2 518 409 8 2 1040 346]...][[373 1 2 518 409 8 2 1040 346 391]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  mother              0.388        0.000        0.000        0.000        -4.165       -3.875       -0.000       \n",
            "   [1]  and                 0.714        0.000        0.000        0.000        -4.714       -12.638      0.000        \n",
            "   [1]  a                   0.630        0.000        0.000        0.000        -5.335       -8.490       0.000        \n",
            "   [1]  daughter            0.552        0.000        0.000        0.000        -6.039       -7.971       0.000        \n",
            "   [1]  live                0.612        0.000        0.000        0.000        -6.834       -10.818      0.000        \n",
            "   [1]  in                  0.574        0.000        0.000        0.000        -7.735       -8.698       0.000        \n",
            "   [1]  a                   0.583        0.000        0.000        0.000        -8.754       -8.005       -0.000       \n",
            "   [1]  large               0.677        0.000        0.000        0.000        -9.908       -7.032       -0.000       \n",
            "   [1]  home                0.705        0.000        0.000        0.000        -11.213      -7.037       -0.000       \n",
            "   [1]  playing             0.824        0.000        0.000        0.000        -12.691      -8.189       -0.000       \n",
            "   [0]  the                 0.445        8.908        -2.582       -0.810       -14.363      -8.293       -5.000       \n",
            "   [0]  student             0.210        8.870        -7.967       -1.563       -15.340      -8.079       -5.000       \n",
            "   [0]  bros                0.149        8.827        -8.100       -1.904       -15.592      -7.921       -5.000       \n",
            "   [0]  together            0.175        11.355       -8.007       -1.741       -15.492      -7.794       -5.000       \n",
            "   [0]  who                 0.050        3.425        -4.525       -3.001       -15.564      -7.721       -5.000       \n",
            "   [0]  pretty              0.038        5.857        -7.433       -3.279       -14.218      -10.310      -3.908       \n",
            "   [0]  fbi                 0.008        14.960       -9.440       -4.779       -12.380      -8.747       -3.633       \n",
            "   [0]  lemmon              0.005        4.467        -9.285       -5.368       -8.602       -14.622      5.000        \n",
            "   [0]  ideals              0.026        8.699        -11.838      -3.661       -3.661       -13.927      5.000        \n",
            "   [1]  of                  0.002        0.000        0.000        0.000        0.000        -14.329      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  can                 0.487        0.000        0.000        0.000        -8.222       -3.805       -0.000       \n",
            "   [1]  watch               0.516        0.000        0.000        0.000        -9.306       -14.272      0.000        \n",
            "   [1]  a                   0.417        0.000        0.000        0.000        -10.532      -6.604       -0.000       \n",
            "   [1]  good                0.635        0.000        0.000        0.000        -11.920      -7.117       -0.000       \n",
            "   [1]  gory                0.682        0.000        0.000        0.000        -13.491      -6.463       -0.000       \n",
            "   [1]  film                0.685        0.000        0.000        0.000        -15.269      -7.658       -0.000       \n",
            "   [0]  and                 0.452        7.166        -2.734       -0.794       -17.281      -7.269       -5.000       \n",
            "   [0]  film                0.160        4.955        -4.949       -1.835       -18.659      -7.143       -5.000       \n",
            "   [0]  of                  0.067        6.895        -3.114       -2.708       -19.040      -8.789       -5.000       \n",
            "   [0]  most                0.072        4.169        -6.197       -2.628       -18.485      -12.157      -5.000       \n",
            "   [0]  the                 0.018        10.364       -2.893       -4.030       -17.946      -10.422      -5.000       \n",
            "   [0]  average             0.020        11.297       -8.037       -3.895       -15.750      -12.261      -3.489       \n",
            "   [0]  movie               0.007        7.483        -3.279       -4.964       -13.417      -10.012      -3.405       \n",
            "   [0]  was                 0.007        9.923        -3.036       -4.932       -9.566       -11.068      1.501        \n",
            "   [0]  a                   0.005        9.722        -1.620       -5.245       -5.245       -9.598       4.352        \n",
            "   [1]  stuff               0.002        0.000        0.000        0.000        0.000        -11.308      0.000        \n",
            "   [1]  however             0.003        0.000        0.000        0.000        0.000        -13.172      0.000        \n",
            "   [1]  this                0.004        0.000        0.000        0.000        0.000        -12.118      0.000        \n",
            "   [1]  is                  0.004        0.000        0.000        0.000        0.000        -11.992      0.000        \n",
            "   [1]  one                 0.004        0.000        0.000        0.000        0.000        -11.346      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  first               0.627        0.000        0.000        0.000        -3.592       -3.974       0.000        \n",
            "   [1]  caught              0.635        0.000        0.000        0.000        -4.065       -8.484       0.000        \n",
            "   [1]  the                 0.507        0.000        0.000        0.000        -4.600       -7.065       0.000        \n",
            "   [1]  movie               0.545        0.000        0.000        0.000        -5.207       -7.128       0.000        \n",
            "   [1]  on                  0.691        0.000        0.000        0.000        -5.893       -8.284       0.000        \n",
            "   [1]  its                 0.606        0.000        0.000        0.000        -6.669       -8.168       0.000        \n",
            "   [1]  first               0.674        0.000        0.000        0.000        -7.548       -5.865       -0.000       \n",
            "   [1]  run                 0.811        0.000        0.000        0.000        -8.543       -7.346       -0.000       \n",
            "   [1]  on                  0.809        0.000        0.000        0.000        -9.669       -7.220       -0.000       \n",
            "   [0]  a                   0.454        9.090        -3.253       -0.790       -10.943      -7.495       -3.448       \n",
            "   [0]  personal            0.458        9.000        -6.927       -0.780       -11.490      -8.011       -3.480       \n",
            "   [0]  way                 0.548        8.968        -5.249       -0.601       -12.122      -7.052       -5.000       \n",
            "   [0]  that                0.362        11.839       -2.782       -1.017       -13.039      -8.154       -4.885       \n",
            "   [0]  of                  0.057        3.726        -5.386       -2.866       -13.606      -9.850       -3.755       \n",
            "   [0]  and                 0.032        6.659        -4.695       -3.457       -12.155      -11.604      -0.551       \n",
            "   [0]  this                0.016        9.435        -2.475       -4.106       -9.845       -9.407       -0.437       \n",
            "   [0]  success             0.038        5.278        -8.829       -3.265       -6.495       -7.811       1.316        \n",
            "   [0]  funny               0.026        6.829        -7.080       -3.656       -3.656       -8.346       4.690        \n",
            "   [1]  i                   0.032        0.000        0.000        0.000        0.000        -8.278       0.000        \n",
            "   [1]  thought             0.053        0.000        0.000        0.000        0.000        -7.389       0.000        \n",
            "Samples\n",
            "Sample 0 .  mother and a daughter live in a large home playing the student bros together who pretty fbi lemmon ideals of\n",
            "Sample 1 .  can watch a good gory film and film of most the average movie was a stuff however this is one\n",
            "Sample 2 .  first caught the movie on its first run on a personal way that of and this success funny i thought\n",
            "\n",
            "\n",
            "targets[[55 15 2 11782 22 47 45 551 37 229 4184 5515 8836 747 15 0 271 3 4184 3471][242 2245 4 66 30 0 1153 798 22 10 17 9 242 2 679 1932 340 1 9 50][17 13 497 32 67 108 12899 5563 8 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[653 55 15 2 11782 22 47 45 551 37]...][[1 1 1 1 1 1 0 0 0 0]...][[653 55 15 2 11782 22 47 69848 69848 69848]...][[55 15 2 11782 22 47 45 551 37 229]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[653 55 15 2 11782 22 47 45 551 37]...][[1 1 1 1 1 1 0 0 0 0]...][[653 55 15 2 11782 22 47 69848 69848 69848]...][[55 15 2 11782 22 47 2298 3577 193 4730]...]\n",
            "targets[[612 3417 1 21451 65 195 4 71 1 65 67 161 4 80 15 0 63 7 12 137][122 5 3920 7 926 1387 2174 848 14 69 14 1387 2174 503 147 9 121 10 122 241][43446 22 246 16 5083 8 0 3392 1 94]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 612 3417 1 21451 65 195 4 71 1]...][[1 1 1 1 1 1 1 1 0 0]...][[0 612 3417 1 21451 65 195 4 71 69848]...][[612 3417 1 21451 65 195 4 71 1 65]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 612 3417 1 21451 65 195 4 71 1]...][[1 1 1 1 1 1 1 1 0 0]...][[0 612 3417 1 21451 65 195 4 71 69848]...][[612 3417 1 21451 65 195 4 71 275 1490]...]\n",
            "targets[[38 88 3 7730 12 98 0 2229 411 3 4412 3573 5 2 589 0 2229 4789 3 2][27 329 898 16 154 4 168 55 98 9 27 113 77 5330 4 949 43 29 18 9][0 1416 3 26 115 3159 120 184 201 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2868 38 88 3 7730 12 98 0 2229 411]...][[1 1 1 1 1 1 0 0 0 0]...][[2868 38 88 3 7730 12 98 69848 69848 69848]...][[38 88 3 7730 12 98 0 2229 411 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2868 38 88 3 7730 12 98 0 2229 411]...][[1 1 1 1 1 1 0 0 0 0]...][[2868 38 88 3 7730 12 98 69848 69848 69848]...][[38 88 3 7730 12 98 15 0 74 128]...]\n",
            "targets[[156 74 1468 5888 743 1909 101 18 94 175 7 13 2 74 834 8 0 84 265 634][49 546 16 0 271 61 13 2 669 1446 6 6 0 225 13 53 49 14 13 0][6034 202 3 2299 762 5 1232 2814 4 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[74 156 74 1468 5888 743 1909 101 18 94]...][[1 1 0 0 0 0 0 0 0 0]...][[74 156 74 69848 69848 69848 69848 69848 69848 69848]...][[156 74 1468 5888 743 1909 101 18 94 175]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[74 156 74 1468 5888 743 1909 101 18 94]...][[1 1 0 0 0 0 0 0 0 0]...][[74 156 74 69848 69848 69848 69848 69848 69848 69848]...][[156 74 3450 62854 3 0 1899 5850 22 0]...]\n",
            "targets[[1 60 812 215 0 5722 227 311 7 13 37 49 70 68 5931 16 0 217 151 17029][13 48 523 1394 1 361 166 584 1975 141 27 252 12763 31 219 24 159 21 27 35][19 5 33 29 3 0 250 98 9 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[71 1 60 812 215 0 5722 227 311 7]...][[1 1 1 1 1 1 1 0 0 0]...][[71 1 60 812 215 0 5722 227 69848 69848]...][[1 60 812 215 0 5722 227 311 7 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[71 1 60 812 215 0 5722 227 311 7]...][[1 1 1 1 1 1 1 0 0 0]...][[71 1 60 812 215 0 5722 227 69848 69848]...][[1 60 812 215 0 5722 227 6732 225 9]...]\n",
            "targets[[5 2 903 81 177 134 709 21 131 75 22 258 5254 30 0 57 335 1024 0 444][1 6052 2466 4 28 2 847 725 36 0 3189 184 377 3 360 341 1116 3661 58 439][1985 1410 10 19 4 58 106 7 12 23]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 903 81 177 134 709 21 131]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 2 903 81 177 134 709 21 131]...][[5 2 903 81 177 134 709 21 131 75]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 903 81 177 134 709 21 131]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 2 903 81 177 134 709 21 131]...][[5 2 903 81 177 134 709 21 131 180]...]\n",
            "targets[[2909 1 520 5960 1357 10 5 241 2 65 1094 69 92 680 18 7 210 21 31 30][9 1018 2 3147 3 0 412 9 196 25 70 164 4 76 157 350 245 2752 1224 18][89 21 121 3 100 82 1802 19 167 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2083 2909 1 520 5960 1357 10 5 241 2]...][[1 0 0 0 0 0 0 0 0 0]...][[2083 2909 69848 69848 69848 69848 69848 69848 69848 69848]...][[2909 1 520 5960 1357 10 5 241 2 65]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2083 2909 1 520 5960 1357 10 5 241 2]...][[1 0 0 0 0 0 0 0 0 0]...][[2083 2909 69848 69848 69848 69848 69848 69848 69848 69848]...][[2909 12 4455 124 1066 37 85 8 30 100]...]\n",
            "targets[[9 89 21 121 47 12 2646 10 2799 984 41 0 798 22 10 1904 972 12 738 67][225 19 5 42 1043 74 1 2268 16 30 1856 0 153 6603 30314 2898 16 1481 44 2][6310 304 0 172 3 35 1171 1773 11 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1203 9 89 21 121 47 12 2646 10 2799]...][[1 1 1 1 1 1 0 0 0 0]...][[1203 9 89 21 121 47 12 69848 69848 69848]...][[9 89 21 121 47 12 2646 10 2799 984]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1203 9 89 21 121 47 12 2646 10 2799]...][[1 1 1 1 1 1 0 0 0 0]...][[1203 9 89 21 121 47 12 69848 69848 69848]...][[9 89 21 121 47 12 0 81 249 11]...]\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[1 1 1 1 1 1 1 1 0 0]...][[9 13 1262 671 33 10 17 9 27 69848]...][[13 1262 671 33 10 17 9 27 27 113]...]\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[1 1 1 1 1 1 1 1 0 0]...][[9 13 1262 671 33 10 17 9 27 69848]...][[13 1262 671 33 10 17 9 27 1059 1291]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[1 1 1 1 1 1 1 1 0 0]...][[9 13 1262 671 33 10 17 9 27 69848]...][[13 1262 671 33 10 17 9 27 37 2]...]\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "global_step: 7537\n",
            " perplexity: 421.776\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            " percent of 3-grams captured: 0.348.\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            " percent of 2-grams captured: 0.648.\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            " percent of 4-grams captured: 0.115.\n",
            " geometric_avg: 0.296.\n",
            " arithmetic_avg: 0.370.\n",
            "global_step: 7537\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39280\n",
            " G train loss: -7.29533\n",
            "targets[[13 1262 671 33 10 17 9 27 1059 1291 193 202 22 277 14 9 67 110 0 84][9 84 215 8434 13264 12 397 2835 0 773 20577 9 1147 30 18 0 227 969 228 10][389 596 10 19 445 0 412 885 7417 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[1 1 1 1 1 1 1 1 0 0]...][[9 13 1262 671 33 10 17 9 27 69848]...][[13 1262 671 33 10 17 9 27 1059 1291]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 1262 671 33 10 17 9 27 1059]...][[1 1 1 1 1 1 1 1 0 0]...][[9 13 1262 671 33 10 17 9 27 69848]...][[13 1262 671 33 10 17 9 27 123 4]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  was                 0.742        0.000        0.000        0.000        -9.540       -3.901       -0.000       \n",
            "   [1]  utterly             0.632        0.000        0.000        0.000        -10.797      -7.201       -0.000       \n",
            "   [1]  disappointed        0.655        0.000        0.000        0.000        -12.219      -11.519      -0.000       \n",
            "   [1]  by                  0.725        0.000        0.000        0.000        -13.830      -12.051      -0.000       \n",
            "   [1]  this                0.605        0.000        0.000        0.000        -15.652      -10.871      -0.000       \n",
            "   [1]  movie               0.711        0.000        0.000        0.000        -17.715      -7.539       -0.000       \n",
            "   [1]  i                   0.615        0.000        0.000        0.000        -20.049      -6.654       -0.000       \n",
            "   [1]  have                0.249        0.000        0.000        0.000        -22.691      -7.123       -0.000       \n",
            "   [0]  ever                0.584        7.392        -2.031       -0.539       -25.681      -8.400       -5.000       \n",
            "   [0]  to                  0.279        8.731        -1.881       -1.276       -28.456      -9.501       -5.000       \n",
            "   [0]  seen                0.011        8.270        -3.384       -4.533       -30.762      -9.675       -5.000       \n",
            "   [0]  so                  0.005        10.807       -5.057       -5.356       -29.685      -23.406      -5.000       \n",
            "   [0]  a                   0.001        5.043        -1.680       -6.988       -27.535      -19.112      -5.000       \n",
            "   [0]  good                0.001        5.645        -2.774       -6.998       -23.255      -21.318      -1.937       \n",
            "   [0]  but                 0.001        5.562        -4.249       -6.904       -18.399      -20.517      2.117        \n",
            "   [0]  i                   0.001        1.134        -1.134       -6.884       -13.010      -19.775      5.000        \n",
            "   [0]  have                0.001        2.717        -1.919       -6.934       -6.934       -19.592      5.000        \n",
            "   [1]  seen                0.002        0.000        0.000        0.000        0.000        -18.662      0.000        \n",
            "   [1]  the                 0.002        0.000        0.000        0.000        0.000        -17.341      0.000        \n",
            "   [1]  first               0.006        0.000        0.000        0.000        0.000        -16.309      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  i                   0.314        0.000        0.000        0.000        -12.949      -4.073       -0.000       \n",
            "   [1]  first               0.456        0.000        0.000        0.000        -14.656      -7.640       -0.000       \n",
            "   [1]  saw                 0.906        0.000        0.000        0.000        -16.587      -10.455      -0.000       \n",
            "   [1]  zhang               0.513        0.000        0.000        0.000        -18.773      -10.820      -0.000       \n",
            "   [0]  viel                0.170        11.582       -14.323      -1.774       -21.246      -7.979       -5.000       \n",
            "   [0]  was                 0.069        3.336        -3.367       -2.673       -22.038      -7.837       -5.000       \n",
            "   [0]  that                0.018        7.752        -4.386       -4.004       -21.918      -13.060      -5.000       \n",
            "   [0]  again               0.021        10.583       -6.768       -3.886       -20.275      -11.112      -5.000       \n",
            "   [0]  your                0.012        3.187        -7.190       -4.417       -18.548      -10.553      -5.000       \n",
            "   [0]  hold                0.010        8.355        -8.305       -4.656       -15.994      -8.140       -5.000       \n",
            "   [0]  the                 0.009        14.459       -3.353       -4.723       -12.832      -5.981       -5.000       \n",
            "   [0]  sydney              0.007        8.024        -9.961       -4.932       -9.178       -8.159       -1.019       \n",
            "   [0]  film                0.008        10.647       -4.175       -4.805       -4.805       -8.114       3.309        \n",
            "   [1]  all                 0.005        0.000        0.000        0.000        0.000        -8.248       0.000        \n",
            "   [1]  but                 0.005        0.000        0.000        0.000        0.000        -5.849       0.000        \n",
            "   [1]  the                 0.003        0.000        0.000        0.000        0.000        -6.592       0.000        \n",
            "   [1]  last                0.005        0.000        0.000        0.000        0.000        -6.160       0.000        \n",
            "   [1]  30                  0.010        0.000        0.000        0.000        0.000        -5.317       0.000        \n",
            "   [1]  minutes             0.280        0.000        0.000        0.000        0.000        -4.425       0.000        \n",
            "   [1]  this                0.209        0.000        0.000        0.000        0.000        -7.343       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  came                0.865        0.000        0.000        0.000        -7.685       -3.727       -0.000       \n",
            "   [1]  across              0.908        0.000        0.000        0.000        -8.697       -5.724       -0.000       \n",
            "   [1]  this                0.719        0.000        0.000        0.000        -9.843       -10.620      0.000        \n",
            "   [1]  film                0.599        0.000        0.000        0.000        -11.141      -9.751       -0.000       \n",
            "   [1]  under               0.507        0.000        0.000        0.000        -12.609      -10.560      -0.000       \n",
            "   [1]  the                 0.577        0.000        0.000        0.000        -14.270      -9.235       -0.000       \n",
            "   [1]  title               0.639        0.000        0.000        0.000        -16.151      -8.214       -0.000       \n",
            "   [1]  hot                 0.728        0.000        0.000        0.000        -18.279      -11.010      -0.000       \n",
            "   [1]  sweat               0.759        0.000        0.000        0.000        -20.688      -10.458      -0.000       \n",
            "   [1]  at                  0.688        0.000        0.000        0.000        -23.414      -10.136      -0.000       \n",
            "   [1]  my                  0.682        0.000        0.000        0.000        -26.500      -8.383       -0.000       \n",
            "   [0]  elder               0.073        6.583        -11.474      -2.623       -29.992      -7.367       -5.000       \n",
            "   [0]  s                   0.068        7.497        -4.483       -2.681       -30.975      -11.531      -5.000       \n",
            "   [0]  mildly              0.011        8.898        -8.505       -4.518       -32.022      -12.407      -5.000       \n",
            "   [0]  tales               0.001        2.677        -9.108       -6.903       -31.129      -13.880      -5.000       \n",
            "   [0]  judy                0.001        10.220       -11.023      -7.239       -27.418      -14.830      -5.000       \n",
            "   [0]  fits                0.001        5.258        -10.008      -6.831       -22.838      -14.048      -5.000       \n",
            "   [0]  sure                0.001        5.090        -7.390       -7.093       -18.117      -12.458      -5.000       \n",
            "   [0]  i                   0.001        5.879        -2.813       -6.922       -12.477      -11.285      -1.192       \n",
            "   [0]  d                   0.002        10.243       -4.095       -6.287       -6.287       -11.859      5.000        \n",
            "Samples\n",
            "Sample 0 .  was utterly disappointed by this movie i have ever to seen so a good but i have seen the first\n",
            "Sample 1 .  i first saw zhang viel was that again your hold the sydney film all but the last 30 minutes this\n",
            "Sample 2 .  came across this film under the title hot sweat at my elder s mildly tales judy fits sure i d\n",
            "\n",
            "\n",
            "targets[[5 2 2271 17 0 1080 6613 1319 5 630 3 268 7 5 6 6 37 259 4 22479][17 12 3615 274 2 81 460 2421 15 91 1637 1958 867 1323 51 9 6258 0 797 9][89 21 387 587 3 10 162 100 266 17202]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 2271 17 0 1080 6613 1319 5]...][[1 1 1 1 1 0 0 0 0 0]...][[10 5 2 2271 17 0 69848 69848 69848 69848]...][[5 2 2271 17 0 1080 6613 1319 5 630]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 2271 17 0 1080 6613 1319 5]...][[1 1 1 1 1 0 0 0 0 0]...][[10 5 2 2271 17 0 69848 69848 69848 69848]...][[5 2 2271 17 0 88 2283 46 11 58]...]\n",
            "targets[[5 29 3 146 115 104 11 29 635 22 0 5392 24245 9 254 7 11 95 0 277][2037 25 254 8 160 728 484 5 39 2 5259 69 32 30 1103 6621 588 99 29052 78][141 28 21541 16 2853 4 12212 29 3 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 29 3 146 115 104 11 29 635]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 29 3 146 115 104 11 69848 69848]...][[5 29 3 146 115 104 11 29 635 22]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 29 3 146 115 104 11 29 635]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 29 3 146 115 104 11 69848 69848]...][[5 29 3 146 115 104 11 13 53 186]...]\n",
            "targets[[5 2 81 17 18 39 96 28 52 43 11279 1388 39 141 28 52 135 3 47 32][96 53292 3 3598 3 6847 24193 2054 1064 42 535 2 4352 7 6 6 46 7 67 2305][80 23 353 100 1037 46 20 723 21 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 81 17 18 39 96 28 52]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 2 81 17 18 39 96 28 69848]...][[5 2 81 17 18 39 96 28 52 43]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 81 17 18 39 96 28 52]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 2 81 17 18 39 96 28 69848]...][[5 2 81 17 18 39 96 28 19 4]...]\n",
            "targets[[0 189 11 7 13 29 3 0 173 98 11 9 123 5567 2 3292 119 7594 7594 13634][35 6345 340 3 1140 1 407 664 104 9 215 56 5753 8 1716 4 106 10 19 9][5 0 441 3 609 19 11 529 1871 104]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1374 0 189 11 7 13 29 3 0 173]...][[1 1 1 1 1 0 0 0 0 0]...][[1374 0 189 11 7 13 69848 69848 69848 69848]...][[0 189 11 7 13 29 3 0 173 98]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1374 0 189 11 7 13 29 3 0 173]...][[1 1 1 1 1 0 0 0 0 0]...][[1374 0 189 11 7 13 69848 69848 69848 69848]...][[0 189 11 7 13 2 271 20 27 4]...]\n",
            "targets[[5 35 221 4093 734 1855 203 66 16 30 2220 18 0 646 2405 339 5 23 97 49][10428 4709 304 62993 476 2 336 1068 2181 16 2917 1609 1 1925 13302 42 99 62 7290 1002][2 3879 23028 181 1352 9 254 10 19 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 35 221 4093 734 1855 203 66 16]...][[1 1 0 0 0 0 0 0 0 0]...][[7 5 35 69848 69848 69848 69848 69848 69848 69848]...][[5 35 221 4093 734 1855 203 66 16 30]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 35 221 4093 734 1855 203 66 16]...][[1 1 0 0 0 0 0 0 0 0]...][[7 5 35 69848 69848 69848 69848 69848 69848 69848]...][[5 35 52 151 9 59 65 550 44 100]...]\n",
            "targets[[5 213 2246 51 2 1141 11656 55 2 411 1 0 1714 5 802 4 298 8 10 411][872 17 3 30 57 69 241 23 18 426 0 88 6984 22 60 114 143 8 0 1752][0 1022 8 10 738 4385 0 109 32 83]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 213 2246 51 2 1141 11656 55 2]...][[1 1 1 1 1 1 1 1 1 1]...][[7 5 213 2246 51 2 1141 11656 55 2]...][[5 213 2246 51 2 1141 11656 55 2 411]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 213 2246 51 2 1141 11656 55 2]...][[1 1 1 1 1 1 1 1 1 1]...][[7 5 213 2246 51 2 1141 11656 55 2]...][[5 213 2246 51 2 1141 11656 55 2 411]...]\n",
            "targets[[9 198 10 2 81 678 3875 85 7 65 1784 2 171 3 3867 11 9 1317 367 0][3069 45 211 44 15 35 7047 3 13142 2519 233 3961 12 0 10974 1 587 233 94 27][27 110 440 246 19 4957 3 10 63 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 9 198 10 2 81 678 3875 85 7]...][[1 1 1 1 0 0 0 0 0 0]...][[591 9 198 10 2 69848 69848 69848 69848 69848]...][[9 198 10 2 81 678 3875 85 7 65]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 9 198 10 2 81 678 3875 85 7]...][[1 1 1 1 0 0 0 0 0 0]...][[591 9 198 10 2 69848 69848 69848 69848 69848]...][[9 198 10 2 1504 1146 11 59 139 161]...]\n",
            "targets[[88 104 92 8 338 25 10 19 67 2 765 2513 3 1088 3703 4 7 58 37 9][66 104 38 10 51 0 1893 58804 2 403 16 6517 1 1160 4 1722 17359 70 66 0][1217 5 35 2475 11805 16 1976 112 10282 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 88 104 92 8 338 25 10 19 67]...][[1 1 1 1 1 1 1 1 0 0]...][[14 88 104 92 8 338 25 10 19 69848]...][[88 104 92 8 338 25 10 19 67 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 88 104 92 8 338 25 10 19 67]...][[1 1 1 1 1 1 1 1 0 0]...][[14 88 104 92 8 338 25 10 19 69848]...][[88 104 92 8 338 25 10 19 162 7]...]\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 0 117 2499 19 123 92 7 69848]...][[5 0 117 2499 19 123 92 7 242 47]...]\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 0 117 2499 19 123 92 7 69848]...][[5 0 117 2499 19 123 92 7 1886 52]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 0 117 2499 19 123 92 7 69848]...][[5 0 117 2499 19 123 92 7 12 53]...]\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "global_step: 7554\n",
            " perplexity: 421.872\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            " percent of 3-grams captured: 0.331.\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            " percent of 2-grams captured: 0.646.\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            " percent of 4-grams captured: 0.111.\n",
            " geometric_avg: 0.287.\n",
            " arithmetic_avg: 0.363.\n",
            "global_step: 7554\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39221\n",
            " G train loss: -7.90809\n",
            "targets[[5 0 117 2499 19 123 92 7 1886 52 94 47 7 195 31 0 4076 2555 16 179][4326 12 673 3342 1 5576 5 208 2 813 29 3 60 519 1177 1 147 429 7 45][53 413 807 17 36 2563 46 20 112 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 0 117 2499 19 123 92 7 69848]...][[5 0 117 2499 19 123 92 7 1886 52]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 117 2499 19 123 92 7 1886]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 0 117 2499 19 123 92 7 69848]...][[5 0 117 2499 19 123 92 7 12 4025]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  is                  0.662        0.000        0.000        0.000        -4.964       -4.005       -0.000       \n",
            "   [1]  the                 0.596        0.000        0.000        0.000        -5.618       -9.577       0.000        \n",
            "   [1]  best                0.587        0.000        0.000        0.000        -6.358       -13.550      0.000        \n",
            "   [1]  mob                 0.586        0.000        0.000        0.000        -7.196       -12.527      0.000        \n",
            "   [1]  film                0.470        0.000        0.000        0.000        -8.144       -11.120      0.000        \n",
            "   [1]  ever                0.595        0.000        0.000        0.000        -9.218       -11.965      0.000        \n",
            "   [1]  made                0.582        0.000        0.000        0.000        -10.432      -11.472      0.000        \n",
            "   [1]  it                  0.523        0.000        0.000        0.000        -11.807      -15.503      0.000        \n",
            "   [0]  s                   0.470        9.113        -2.031       -0.755       -13.363      -9.471       -3.892       \n",
            "   [0]  hilariously         0.391        5.172        -9.141       -0.940       -14.269      -13.162      -1.108       \n",
            "   [0]  out                 0.149        7.299        -5.082       -1.903       -15.086      -11.439      -3.647       \n",
            "   [0]  or                  0.067        5.408        -5.142       -2.710       -14.919      -13.464      -1.455       \n",
            "   [0]  a                   0.033        4.244        -2.858       -3.426       -13.818      -12.926      -0.892       \n",
            "   [0]  rated               0.062        9.005        -8.771       -2.776       -11.762      -11.246      -0.516       \n",
            "   [0]  action              0.052        5.296        -6.735       -2.964       -10.170      -7.714       -2.456       \n",
            "   [0]  ground              0.025        3.326        -10.052      -3.681       -8.155       -9.437       1.282        \n",
            "   [0]  incomprehensible    0.006        9.801        -10.985      -5.064       -5.064       -9.057       3.992        \n",
            "   [1]  nominated           0.003        0.000        0.000        0.000        0.000        -11.259      0.000        \n",
            "   [1]  for                 0.005        0.000        0.000        0.000        0.000        -11.482      0.000        \n",
            "   [1]  things              0.015        0.000        0.000        0.000        0.000        -9.844       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  austin              0.640        0.000        0.000        0.000        -3.006       -4.137       0.000        \n",
            "   [1]  s                   0.797        0.000        0.000        0.000        -3.402       -8.762       0.000        \n",
            "   [1]  novel               0.799        0.000        0.000        0.000        -3.850       -6.087       0.000        \n",
            "   [1]  pride               0.657        0.000        0.000        0.000        -4.357       -14.346      0.000        \n",
            "   [1]  and                 0.619        0.000        0.000        0.000        -4.931       -7.635       0.000        \n",
            "   [1]  prejudice           0.618        0.000        0.000        0.000        -5.581       -7.087       0.000        \n",
            "   [1]  is                  0.619        0.000        0.000        0.000        -6.317       -6.384       0.000        \n",
            "   [1]  without             0.607        0.000        0.000        0.000        -7.149       -8.036       0.000        \n",
            "   [1]  a                   0.608        0.000        0.000        0.000        -8.091       -7.954       -0.000       \n",
            "   [1]  doubt               0.619        0.000        0.000        0.000        -9.157       -7.670       -0.000       \n",
            "   [1]  one                 0.513        0.000        0.000        0.000        -10.364      -8.957       -0.000       \n",
            "   [0]  with                0.165        0.462        -4.673       -1.805       -11.730      -10.398      -1.332       \n",
            "   [0]  the                 0.138        4.749        -0.748       -1.982       -11.233      -12.535      1.302        \n",
            "   [0]  greatest            0.071        4.875        -5.896       -2.644       -10.470      -11.974      1.505        \n",
            "   [0]  have                0.114        7.749        -8.502       -2.173       -8.857       -12.976      4.119        \n",
            "   [0]  quite               0.124        5.044        -5.735       -2.084       -7.565       -9.384       1.819        \n",
            "   [0]  few                 0.235        7.766        -7.514       -1.447       -6.204       -9.501       3.297        \n",
            "   [0]  for                 0.190        10.872       -3.312       -1.660       -5.383       -9.882       4.498        \n",
            "   [0]  the                 0.170        3.870        -0.616       -1.772       -4.214       -7.661       3.448        \n",
            "   [0]  story               0.063        9.212        -3.112       -2.763       -2.763       -7.826       5.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  very                0.770        0.000        0.000        0.000        -1.752       -4.220       0.000        \n",
            "   [1]  entertaining        0.692        0.000        0.000        0.000        -1.983       -11.911      0.000        \n",
            "   [1]  suspense            0.606        0.000        0.000        0.000        -2.244       -11.656      0.000        \n",
            "   [1]  movie               0.567        0.000        0.000        0.000        -2.540       -10.459      0.000        \n",
            "   [1]  from                0.572        0.000        0.000        0.000        -2.875       -7.996       0.000        \n",
            "   [1]  germany             0.530        0.000        0.000        0.000        -3.254       -7.433       0.000        \n",
            "   [1]  if                  0.745        0.000        0.000        0.000        -3.682       -9.152       0.000        \n",
            "   [1]  you                 0.808        0.000        0.000        0.000        -4.168       -10.605      0.000        \n",
            "   [1]  love                0.687        0.000        0.000        0.000        -4.717       -5.290       0.000        \n",
            "   [0]  fatty               0.563        3.101        -11.757      -0.575       -5.338       -7.623       2.285        \n",
            "   [0]  ourselves           0.675        8.740        -10.115      -0.393       -5.392       -8.972       3.581        \n",
            "   [0]  in                  0.707        10.759       -2.576       -0.347       -5.658       -7.974       2.316        \n",
            "   [0]  los                 0.858        7.499        -9.387       -0.153       -6.011       -6.914       0.903        \n",
            "   [0]  alyson              0.580        10.079       -10.166      -0.545       -6.629       -8.529       1.900        \n",
            "   [0]  are                 0.492        6.559        -6.008       -0.709       -6.886       -13.323      5.000        \n",
            "   [0]  to                  0.433        4.596        -6.005       -0.838       -6.991       -16.631      5.000        \n",
            "   [0]  thought             0.036        6.382        -4.807       -3.317       -6.964       -10.088      3.124        \n",
            "   [0]  won                 0.016        7.048        -9.532       -4.128       -4.128       -21.447      5.000        \n",
            "   [1]  it                  0.009        0.000        0.000        0.000        0.000        -19.911      0.000        \n",
            "   [1]  gives               0.006        0.000        0.000        0.000        0.000        -12.966      0.000        \n",
            "Samples\n",
            "Sample 0 .  is the best mob film ever made it s hilariously out or a rated action ground incomprehensible nominated for things\n",
            "Sample 1 .  austin s novel pride and prejudice is without a doubt one with the greatest have quite few for the story\n",
            "Sample 2 .  very entertaining suspense movie from germany if you love fatty ourselves in los alyson are to thought won it gives\n",
            "\n",
            "\n",
            "targets[[17 1072 71 36 0 1940 194 6207 587 3 0 342 8 0 378 25 4698 1604 1 18975][5 446 1452 44053 8 82 6056 3 0 19 9 103 11 24 203 28 4625 44053 0 1137][215 15383 12 1969 23 4 194 602 16 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 1072 71 36 0 1940 194 6207 587]...][[1 1 1 1 1 1 1 0 0 0]...][[10 17 1072 71 36 0 1940 194 69848 69848]...][[17 1072 71 36 0 1940 194 6207 587 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 1072 71 36 0 1940 194 6207 587]...][[1 1 1 1 1 1 1 0 0 0]...][[10 17 1072 71 36 0 1940 194 69848 69848]...][[17 1072 71 36 0 1940 194 87 49 16]...]\n",
            "targets[[69 408 17 3 0 1582 12 4 10 249 10 17 83 1017 127 659 58 152 20 83][1022 6 6 8 160 728 1287 27001 31241 6024 5 6407 11 40 568 0 38145 1841 27001 284][366 10 5 607 264 48 3 0 657 204]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 69 408 17 3 0 1582 12 4 10]...][[1 1 1 1 1 0 0 0 0 0]...][[29 69 408 17 3 0 69848 69848 69848 69848]...][[69 408 17 3 0 1582 12 4 10 249]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 69 408 17 3 0 1582 12 4 10]...][[1 1 1 1 1 0 0 0 0 0]...][[29 69 408 17 3 0 69848 69848 69848 69848]...][[69 408 17 3 0 817 5 2 11225 5487]...]\n",
            "targets[[69 9 139 110 2 171 447 72 10 7 12 6161 91 64 3093 220 25 0 275 1549][17777 429 9 50 138 143 4 6813 82 98 233 10 11656 55 60 2412 20299 399 14 2][0 7935 159 21 80 685 58 8 0 129]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[431 69 9 139 110 2 171 447 72 10]...][[1 1 1 1 1 1 1 1 1 1]...][[431 69 9 139 110 2 171 447 72 10]...][[69 9 139 110 2 171 447 72 10 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[431 69 9 139 110 2 171 447 72 10]...][[1 1 1 1 1 1 1 1 1 1]...][[431 69 9 139 110 2 171 447 72 10]...][[69 9 139 110 2 171 447 72 10 7]...]\n",
            "targets[[51 20 196 10 19 202 420 21 93 334 266 128 269 0 19665 1294 4 122 178 87][5 2 6349 28884 17 11 515 15 48 81 181 375 180 49 1032 1 48 201 97 0][7 4 6669 11900 4 599 0 2988 15655 844]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[42 51 20 196 10 19 202 420 21 93]...][[1 1 1 1 1 1 1 0 0 0]...][[42 51 20 196 10 19 202 420 69848 69848]...][[51 20 196 10 19 202 420 21 93 334]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[42 51 20 196 10 19 202 420 21 93]...][[1 1 1 1 1 1 1 0 0 0]...][[42 51 20 196 10 19 202 420 69848 69848]...][[51 20 196 10 19 202 420 21 56 595]...]\n",
            "targets[[5 2 822 19 16 30 2220 7 45 1204 1 79 45 0 504 1246 4 93 20 1535][1337 33 11540 415 34 4584 90 22 7556 2005 31 40 2075 6 6 0 7835 25 53 49][6 287 71 380 20 8475 5 2 640 11]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10088 5 2 822 19 16 30 2220 7 45]...][[1 0 0 0 0 0 0 0 0 0]...][[10088 5 69848 69848 69848 69848 69848 69848 69848 69848]...][[5 2 822 19 16 30 2220 7 45 1204]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10088 5 2 822 19 16 30 2220 7 45]...][[1 0 0 0 0 0 0 0 0 0]...][[10088 5 69848 69848 69848 69848 69848 69848 69848 69848]...][[5 2 2409 2139 2668 1655 42 0 122 5]...]\n",
            "targets[[4559 5352 752 8 0 4261 5 4442 2 29052 2147 15 26 231 51 26 1426 291 158 435][29 5758 303 540 36 2 2276 6573 19 18 10 29 5 29 3 26 12533 12868 0 1069][105 454 350 4 2692 0 1249 11 32 25]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 4559 5352 752 8 0 4261 5 4442 2]...][[1 0 0 0 0 0 0 0 0 0]...][[2 4559 69848 69848 69848 69848 69848 69848 69848 69848]...][[4559 5352 752 8 0 4261 5 4442 2 29052]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 4559 5352 752 8 0 4261 5 4442 2]...][[1 0 0 0 0 0 0 0 0 0]...][[2 4559 69848 69848 69848 69848 69848 69848 69848 69848]...][[4559 3 9950 4254 13 5285 3 0 17 17]...]\n",
            "targets[[304 9 50 66 7 14 2 858 304 14 69 14 35 6494 2967 19 1527 15 16380 10357][69043 4294 22 260 5 38 149 2 1178 3467 64218 6518 1362 78 2 432 3 30509 4294 12][3949 45 2 95 3 951 547 43 536 208]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 304 9 50 66 7 14 2 858 304]...][[1 1 1 1 1 1 1 1 1 1]...][[10 304 9 50 66 7 14 2 858 304]...][[304 9 50 66 7 14 2 858 304 14]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 304 9 50 66 7 14 2 858 304]...][[1 1 1 1 1 1 1 1 1 1]...][[10 304 9 50 66 7 14 2 858 304]...][[304 9 50 66 7 14 2 858 304 14]...]\n",
            "targets[[3340 3015 3 0 10446 0 1465 1724 637 43 0 13144 451 3 4821 10446 8 17170 13 645][35 1857 1 608 33331 5521 3 0 368 673 9 80 656 75 59 535 8280 43 15 1935][1178 6676 6586 10168 480 4679 8 0 1068 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[8 3340 3015 3 0 10446 0 1465 1724 637]...][[1 1 1 1 1 1 1 1 1 1]...][[8 3340 3015 3 0 10446 0 1465 1724 637]...][[3340 3015 3 0 10446 0 1465 1724 637 43]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[8 3340 3015 3 0 10446 0 1465 1724 637]...][[1 1 1 1 1 1 1 1 1 1]...][[8 3340 3015 3 0 10446 0 1465 1724 637]...][[3340 3015 3 0 10446 0 1465 1724 637 43]...]\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[1 1 1 1 1 1 0 0 0 0]...][[9 65 470 4 38 10 17 69848 69848 69848]...][[65 470 4 38 10 17 1652 2 250 1505]...]\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[1 1 1 1 1 1 0 0 0 0]...][[9 65 470 4 38 10 17 69848 69848 69848]...][[65 470 4 38 10 17 18 7 13 42]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[1 1 1 1 1 1 0 0 0 0]...][[9 65 470 4 38 10 17 69848 69848 69848]...][[65 470 4 38 10 17 18 0 11656 469]...]\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "global_step: 7571\n",
            " perplexity: 420.700\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            " percent of 3-grams captured: 0.348.\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            " percent of 2-grams captured: 0.639.\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            " percent of 4-grams captured: 0.127.\n",
            " geometric_avg: 0.304.\n",
            " arithmetic_avg: 0.371.\n",
            "global_step: 7571\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39212\n",
            " G train loss: -7.80810\n",
            "targets[[65 470 4 38 10 17 18 7 13 42 54404 0 116 13 3104 5646 0 109 13 612][196 7 13 2 186 49 17 0 116 13 49 1 0 63 13 69 585 7 12 29][13 8 2 394 95 194 167 0 276 389]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[1 1 1 1 1 1 0 0 0 0]...][[9 65 470 4 38 10 17 69848 69848 69848]...][[65 470 4 38 10 17 18 7 13 42]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 470 4 38 10 17 18 7 13]...][[1 1 1 1 1 1 0 0 0 0]...][[9 65 470 4 38 10 17 69848 69848 69848]...][[65 470 4 38 10 17 16 0 206 340]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  really              0.494        0.000        0.000        0.000        -8.067       -3.832       -0.000       \n",
            "   [1]  wanted              0.529        0.000        0.000        0.000        -9.130       -5.755       -0.000       \n",
            "   [1]  to                  0.478        0.000        0.000        0.000        -10.333      -6.133       -0.000       \n",
            "   [1]  like                0.756        0.000        0.000        0.000        -11.695      -6.627       -0.000       \n",
            "   [1]  this                0.783        0.000        0.000        0.000        -13.236      -6.386       -0.000       \n",
            "   [1]  movie               0.530        0.000        0.000        0.000        -14.980      -7.412       -0.000       \n",
            "   [0]  for                 0.453        4.389        -3.163       -0.792       -16.954      -7.799       -5.000       \n",
            "   [0]  the                 0.385        3.838        -1.424       -0.956       -18.291      -8.217       -5.000       \n",
            "   [0]  original            0.558        6.216        -4.299       -0.583       -19.620      -6.809       -5.000       \n",
            "   [0]  fan                 0.071        7.078        -4.086       -2.647       -21.546      -6.581       -5.000       \n",
            "   [0]  characters          0.026        19.154       -7.724       -3.660       -21.389      -11.609      -5.000       \n",
            "   [0]  of                  0.011        3.112        -2.697       -4.474       -20.065      -9.959       -5.000       \n",
            "   [0]  so                  0.004        5.677        -5.801       -5.543       -17.646      -11.104      -5.000       \n",
            "   [0]  it                  0.001        4.914        -3.272       -7.551       -13.698      -12.800      -0.898       \n",
            "   [0]  more                0.001        13.769       -8.302       -6.957       -6.957       -13.027      5.000        \n",
            "   [1]  hammy               0.001        0.000        0.000        0.000        0.000        -13.316      0.000        \n",
            "   [1]  the                 0.001        0.000        0.000        0.000        0.000        -11.921      0.000        \n",
            "   [1]  plot                0.002        0.000        0.000        0.000        0.000        -12.167      0.000        \n",
            "   [1]  was                 0.003        0.000        0.000        0.000        0.000        -9.818       0.000        \n",
            "   [1]  annoying            0.026        0.000        0.000        0.000        0.000        -9.602       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  thought             0.725        0.000        0.000        0.000        -0.642       -4.149       0.000        \n",
            "   [1]  it                  0.687        0.000        0.000        0.000        -0.727       -9.276       0.000        \n",
            "   [1]  was                 0.601        0.000        0.000        0.000        -0.823       -6.709       0.000        \n",
            "   [1]  a                   0.573        0.000        0.000        0.000        -0.931       -9.139       0.000        \n",
            "   [1]  pretty              0.607        0.000        0.000        0.000        -1.054       -8.177       0.000        \n",
            "   [1]  good                0.435        0.000        0.000        0.000        -1.192       -9.072       0.000        \n",
            "   [1]  movie               0.714        0.000        0.000        0.000        -1.350       -8.130       0.000        \n",
            "   [1]  the                 0.413        0.000        0.000        0.000        -1.527       -10.303      0.000        \n",
            "   [1]  acting              0.684        0.000        0.000        0.000        -1.729       -9.193       0.000        \n",
            "   [0]  is                  0.793        2.479        -1.976       -0.232       -1.957       -10.003      5.000        \n",
            "   [0]  only                0.668        4.086        -4.618       -0.403       -1.952       -8.958       5.000        \n",
            "   [0]  interesting         0.740        8.174        -5.064       -0.301       -1.753       -11.584      5.000        \n",
            "   [0]  but                 0.845        2.075        -3.609       -0.169       -1.643       -11.393      5.000        \n",
            "   [0]  it                  0.923        9.922        -2.487       -0.080       -1.669       -9.748       5.000        \n",
            "   [0]  s                   0.942        1.768        -1.381       -0.059       -1.799       -9.126       5.000        \n",
            "   [0]  very                0.945        5.838        -2.753       -0.056       -1.968       -11.229      5.000        \n",
            "   [0]  great               0.826        9.574        -2.719       -0.191       -2.164       -11.117      5.000        \n",
            "   [0]  years               0.107        5.641        -5.658       -2.232       -2.232       -11.455      5.000        \n",
            "   [1]  s                   0.028        0.000        0.000        0.000        0.000        -17.116      0.000        \n",
            "   [1]  one                 0.024        0.000        0.000        0.000        0.000        -20.630      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  was                 0.750        0.000        0.000        0.000        -7.843       -4.169       -0.000       \n",
            "   [1]  in                  0.639        0.000        0.000        0.000        -8.877       -8.813       -0.000       \n",
            "   [1]  a                   0.627        0.000        0.000        0.000        -10.047      -10.598      0.000        \n",
            "   [1]  terrible            0.680        0.000        0.000        0.000        -11.371      -6.301       -0.000       \n",
            "   [1]  way                 0.562        0.000        0.000        0.000        -12.869      -9.332       -0.000       \n",
            "   [1]  long                0.692        0.000        0.000        0.000        -14.565      -7.098       -0.000       \n",
            "   [1]  before              0.675        0.000        0.000        0.000        -16.484      -8.583       -0.000       \n",
            "   [1]  the                 0.433        0.000        0.000        0.000        -18.656      -8.447       -0.000       \n",
            "   [0]  cerebral            0.308        6.802        -10.008      -1.179       -21.115      -8.364       -5.000       \n",
            "   [0]  film                0.052        7.636        -5.076       -2.966       -22.563      -8.222       -5.000       \n",
            "   [0]  dvd                 0.066        14.243       -8.055       -2.711       -22.180      -12.737      -5.000       \n",
            "   [0]  serves              0.033        4.870        -9.979       -3.400       -22.034      -11.900      -5.000       \n",
            "   [0]  world               0.011        3.698        -8.992       -4.510       -21.089      -9.320       -5.000       \n",
            "   [0]  gibson              0.007        8.977        -9.375       -4.931       -18.764      -10.860      -5.000       \n",
            "   [0]  fact                0.003        7.459        -8.754       -5.890       -15.656      -10.232      -5.000       \n",
            "   [0]  i                   0.002        11.110       -2.615       -6.024       -11.053      -12.852      1.799        \n",
            "   [0]  rented              0.003        11.548       -4.945       -5.691       -5.691       -13.434      5.000        \n",
            "   [1]  hitler              0.006        0.000        0.000        0.000        0.000        -12.427      0.000        \n",
            "   [1]  people              0.001        0.000        0.000        0.000        0.000        -9.761       0.000        \n",
            "   [1]  with                0.002        0.000        0.000        0.000        0.000        -10.280      0.000        \n",
            "Samples\n",
            "Sample 0 .  really wanted to like this movie for the original fan characters of so it more hammy the plot was annoying\n",
            "Sample 1 .  thought it was a pretty good movie the acting is only interesting but it s very great years s one\n",
            "Sample 2 .  was in a terrible way long before the cerebral film dvd serves world gibson fact i rented hitler people with\n",
            "\n",
            "\n",
            "targets[[2736 4 106 10 19 31 21041 427 22 8093 20946 1 1042 6403 1 254 7 4 28 29][1394 5 323 0 156 25 1604 1 62 101 27 375 3 573 9 509 0 84 315 541][17 9 856 2 49 436 18 7 13 73]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 2736 4 106 10 19 31 21041 427 22]...][[1 1 1 0 0 0 0 0 0 0]...][[9 2736 4 106 69848 69848 69848 69848 69848 69848]...][[2736 4 106 10 19 31 21041 427 22 8093]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 2736 4 106 10 19 31 21041 427 22]...][[1 1 1 0 0 0 0 0 0 0]...][[9 2736 4 106 69848 69848 69848 69848 69848 69848]...][[2736 4 106 0 17 1 9 140 38 73]...]\n",
            "targets[[242 37 1298 3782 672 391 131 14 9 67 64 110 0 178 339 1 2993 22 6721 357][3 0 9702 5 33 229 29 3 0 88 10081 1 2678 633 1409 123 1016 7 210 21][131 98 1 6653 42579 0 82 806 22 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 37 1298 3782 672 391 131 14 9]...][[1 1 1 1 1 1 1 1 1 0]...][[9 242 37 1298 3782 672 391 131 14 9]...][[242 37 1298 3782 672 391 131 14 9 67]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 37 1298 3782 672 391 131 14 9]...][[1 1 1 1 1 1 1 1 1 0]...][[9 242 37 1298 3782 672 391 131 14 9]...][[242 37 1298 3782 672 391 131 14 9 64]...]\n",
            "targets[[42 195 226 149 10 34616 17 46 11 12 47 20 50 651 7 7 562 4 28 29][0 501 173 154 9 27 35305 3 0 184 477 30 3 0 1187 104 27 77 1213 119][1591 10 19 4120 649 696 4 0 49 261]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 42 195 226 149 10 34616 17 46 11]...][[1 1 0 0 0 0 0 0 0 0]...][[9 42 195 69848 69848 69848 69848 69848 69848 69848]...][[42 195 226 149 10 34616 17 46 11 12]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 42 195 226 149 10 34616 17 46 11]...][[1 1 0 0 0 0 0 0 0 0]...][[9 42 195 69848 69848 69848 69848 69848 69848 69848]...][[42 195 4 212 60 1247 181 2146 443 498]...]\n",
            "targets[[0 13 194 1 2212 2 173 2887 2565 135 1 23 73 332 1697 36 2340 2 115 705][1535 6779 79 92 8 8165 18 15 2 385 177 1 2 6043 270 10 5 2 19 43][17 5 42 1043 658 221 174 130 45 48]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3 0 13 194 1 2212 2 173 2887 2565]...][[1 0 0 0 0 0 0 0 0 0]...][[3 0 69848 69848 69848 69848 69848 69848 69848 69848]...][[0 13 194 1 2212 2 173 2887 2565 135]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3 0 13 194 1 2212 2 173 2887 2565]...][[1 0 0 0 0 0 0 0 0 0]...][[3 0 69848 69848 69848 69848 69848 69848 69848 69848]...][[0 17 5 28 322 1 690 0 74 8]...]\n",
            "targets[[15 0 474 11498 2 125 1109 26 582 12 461 714 11735 4 2491 111 2881 1 9 382][3 0 742 37 229 5845 4 0 459 6603 2909 4957 2732 729 5 804 9400 4 12313 4302][45 4 28 29 3 0 88 43937 1000 98]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[349 15 0 474 11498 2 125 1109 26 582]...][[1 1 1 1 1 1 1 1 1 0]...][[349 15 0 474 11498 2 125 1109 26 582]...][[15 0 474 11498 2 125 1109 26 582 12]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[349 15 0 474 11498 2 125 1109 26 582]...][[1 1 1 1 1 1 1 1 1 0]...][[349 15 0 474 11498 2 125 1109 26 582]...][[15 0 474 11498 2 125 1109 26 582 807]...]\n",
            "targets[[38 0 321 514 0 109 18 0 2368 5 394 4 198 35 502 0 289 102 4693 26][4829 20878 18434 3447 5433 1 31982 11141 314 8 0 4116 3 831 1621 2 7627 201 427 22][204 4141 14 29 3 0 360 753 8 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 38 0 321 514 0 109 18 0 2368]...][[1 1 1 0 0 0 0 0 0 0]...][[9 38 0 321 69848 69848 69848 69848 69848 69848]...][[38 0 321 514 0 109 18 0 2368 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 38 0 321 514 0 109 18 0 2368]...][[1 1 1 0 0 0 0 0 0 0]...][[9 38 0 321 69848 69848 69848 69848 69848 69848]...][[38 0 321 3 299 10 19 678 17 0]...]\n",
            "targets[[673 5 0 14633 29303 8124 18 0 12038 1 21717 3 9179 20296 5 229 52 72 11 7][5468 280 286 195 62 355 292 1 874 4 93 2 17 0 442 19 5 2538 1374 2][140 2 340 3 7649 98 18 21946 9 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 673 5 0 14633 29303 8124 18 0 12038]...][[1 1 0 0 0 0 0 0 0 0]...][[0 673 5 69848 69848 69848 69848 69848 69848 69848]...][[673 5 0 14633 29303 8124 18 0 12038 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 673 5 0 14633 29303 8124 18 0 12038]...][[1 1 0 0 0 0 0 0 0 0]...][[0 673 5 69848 69848 69848 69848 69848 69848 69848]...][[673 5 2 414 9 389 21 4 77 66]...]\n",
            "targets[[323 63 3 12678 5 408 33 33 2959 17228 543 3 50919 1 7 12 65 2 49 63][103 114 3216 5 2 81 17 7 12 97 74 11 7 5 42 2 246 17 1 83][109 3 1504 37215 17084 58 11 212 0 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 323 63 3 12678 5 408 33 33 2959]...][[1 1 0 0 0 0 0 0 0 0]...][[0 323 63 69848 69848 69848 69848 69848 69848 69848]...][[323 63 3 12678 5 408 33 33 2959 17228]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 323 63 3 12678 5 408 33 33 2959]...][[1 1 0 0 0 0 0 0 0 0]...][[0 323 63 69848 69848 69848 69848 69848 69848 69848]...][[323 63 16 408 75 1 163 257 236 28]...]\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[1 1 1 1 1 1 0 0 0 0]...][[161 5611 52 72 537 0 372 69848 69848 69848]...][[5611 52 72 537 0 372 36 0 3355 5]...]\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[1 1 1 1 1 1 0 0 0 0]...][[161 5611 52 72 537 0 372 69848 69848 69848]...][[5611 52 72 537 0 372 25 42 4160 2400]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[1 1 1 1 1 1 0 0 0 0]...][[161 5611 52 72 537 0 372 69848 69848 69848]...][[5611 52 72 537 0 372 4921 11 4886 2901]...]\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "global_step: 7588\n",
            " perplexity: 419.918\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            " percent of 3-grams captured: 0.344.\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            " percent of 2-grams captured: 0.629.\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            " percent of 4-grams captured: 0.109.\n",
            " geometric_avg: 0.287.\n",
            " arithmetic_avg: 0.361.\n",
            "global_step: 7588\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39237\n",
            " G train loss: -7.93742\n",
            "targets[[5611 52 72 537 0 372 25 42 4160 2400 7977 12 324 31 0 457 3 0 19 0][24799 14083 3828 23 58 49 16 0 2922 12307 55 0 346 965 37 32 810 9511 7797 7][7 13 29 3 0 117 98 9 27 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[1 1 1 1 1 1 0 0 0 0]...][[161 5611 52 72 537 0 372 69848 69848 69848]...][[5611 52 72 537 0 372 25 42 4160 2400]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[161 5611 52 72 537 0 372 25 42 4160]...][[1 1 1 1 1 1 0 0 0 0]...][[161 5611 52 72 537 0 372 69848 69848 69848]...][[5611 52 72 537 0 372 13 0 641 1029]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  counts              0.521        0.000        0.000        0.000        -9.915       -3.787       -0.000       \n",
            "   [1]  more                0.593        0.000        0.000        0.000        -11.222      -10.342      -0.000       \n",
            "   [1]  than                0.477        0.000        0.000        0.000        -12.701      -12.555      -0.000       \n",
            "   [1]  blood               0.708        0.000        0.000        0.000        -14.374      -7.368       -0.000       \n",
            "   [1]  the                 0.651        0.000        0.000        0.000        -16.269      -6.820       -0.000       \n",
            "   [1]  rest                0.411        0.000        0.000        0.000        -18.412      -7.430       -0.000       \n",
            "   [0]  was                 0.190        5.099        -3.744       -1.661       -20.839      -8.282       -5.000       \n",
            "   [0]  the                 0.121        6.913        -1.319       -2.110       -21.704      -12.402      -5.000       \n",
            "   [0]  somewhat            0.030        11.350       -7.976       -3.507       -22.177      -10.807      -5.000       \n",
            "   [0]  cover               0.006        11.415       -7.915       -5.073       -21.130      -10.028      -5.000       \n",
            "   [0]  about               0.006        14.813       -4.079       -5.094       -18.173      -12.134      -5.000       \n",
            "   [0]  games               0.023        6.994        -10.124      -3.751       -14.803      -9.742       -5.000       \n",
            "   [0]  who                 0.014        10.448       -4.193       -4.236       -12.508      -8.125       -4.382       \n",
            "   [0]  never               0.018        7.828        -5.255       -4.006       -9.362       -7.812       -1.549       \n",
            "   [0]  be                  0.002        5.864        -3.225       -6.062       -6.062       -6.681       0.620        \n",
            "   [1]  beginning           0.001        0.000        0.000        0.000        0.000        -14.635      0.000        \n",
            "   [1]  of                  0.003        0.000        0.000        0.000        0.000        -12.511      0.000        \n",
            "   [1]  the                 0.003        0.000        0.000        0.000        0.000        -9.251       0.000        \n",
            "   [1]  film                0.004        0.000        0.000        0.000        0.000        -8.042       0.000        \n",
            "   [1]  the                 0.003        0.000        0.000        0.000        0.000        -8.300       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  baggy               0.519        0.000        0.000        0.000        -13.469      -3.941       -0.000       \n",
            "   [0]  i                   0.492        15.206       -4.270       -0.710       -15.244      -5.947       -5.000       \n",
            "   [0]  survive             0.342        12.377       -8.333       -1.073       -16.450      -6.202       -5.000       \n",
            "   [0]  this                0.136        5.837        -1.008       -1.996       -17.402      -8.784       -5.000       \n",
            "   [0]  good                0.049        8.180        -6.364       -3.011       -17.437      -9.000       -5.000       \n",
            "   [0]  especially          0.043        5.866        -7.899       -3.141       -16.327      -10.418      -5.000       \n",
            "   [0]  movies              0.008        4.151        -5.943       -4.810       -14.924      -10.120      -4.804       \n",
            "   [0]  so                  0.015        4.328        -5.957       -4.227       -11.446      -12.565      1.119        \n",
            "   [0]  clearly             0.015        10.005       -8.688       -4.232       -8.171       -11.733      3.562        \n",
            "   [0]  made                0.012        15.725       -6.392       -4.459       -4.459       -10.646      5.000        \n",
            "   [1]  up                  0.004        0.000        0.000        0.000        0.000        -11.269      0.000        \n",
            "   [1]  the                 0.004        0.000        0.000        0.000        0.000        -10.627      0.000        \n",
            "   [1]  home                0.006        0.000        0.000        0.000        0.000        -10.996      0.000        \n",
            "   [1]  front               0.012        0.000        0.000        0.000        0.000        -10.330      0.000        \n",
            "   [1]  so                  0.014        0.000        0.000        0.000        0.000        -9.525       0.000        \n",
            "   [1]  they                0.034        0.000        0.000        0.000        0.000        -10.351      0.000        \n",
            "   [1]  buy                 0.140        0.000        0.000        0.000        0.000        -8.652       0.000        \n",
            "   [1]  bonds               0.547        0.000        0.000        0.000        0.000        -7.439       0.000        \n",
            "   [1]  circuit             0.549        0.000        0.000        0.000        0.000        -8.874       0.000        \n",
            "   [1]  it                  0.698        0.000        0.000        0.000        0.000        -9.745       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  it                  0.453        0.000        0.000        0.000        -3.985       -4.112       0.000        \n",
            "   [0]  point               0.437        1.467        -10.412      -0.829       -4.511       -5.616       1.105        \n",
            "   [0]  like                0.446        5.388        -5.777       -0.808       -4.167       -6.051       1.884        \n",
            "   [0]  the                 0.363        5.556        -1.888       -1.015       -3.802       -6.218       2.416        \n",
            "   [0]  pilot               0.439        8.468        -8.523       -0.824       -3.155       -6.907       3.752        \n",
            "   [0]  that                0.391        8.207        -3.393       -0.938       -2.638       -7.051       4.413        \n",
            "   [0]  one                 0.459        8.164        -5.275       -0.778       -1.924       -6.873       4.950        \n",
            "   [0]  remains             0.681        2.668        -9.432       -0.384       -1.297       -6.982       5.000        \n",
            "   [0]  map                 0.604        6.010        -11.914      -0.504       -1.034       -7.621       5.000        \n",
            "   [0]  is                  0.549        9.943        -2.953       -0.600       -0.600       -8.596       5.000        \n",
            "   [1]  well                0.517        0.000        0.000        0.000        0.000        -8.582       0.000        \n",
            "   [1]  pirates             0.045        0.000        0.000        0.000        0.000        -6.886       0.000        \n",
            "   [1]  of                  0.438        0.000        0.000        0.000        0.000        -10.346      0.000        \n",
            "   [1]  the                 0.420        0.000        0.000        0.000        0.000        -6.961       0.000        \n",
            "   [1]  caribbean           0.666        0.000        0.000        0.000        0.000        -6.946       0.000        \n",
            "   [1]  is                  0.620        0.000        0.000        0.000        0.000        -7.288       0.000        \n",
            "   [1]  first               0.387        0.000        0.000        0.000        0.000        -7.909       0.000        \n",
            "   [1]  then                0.510        0.000        0.000        0.000        0.000        -13.173      0.000        \n",
            "   [1]  dark                0.579        0.000        0.000        0.000        0.000        -9.013       0.000        \n",
            "   [1]  prince              0.700        0.000        0.000        0.000        0.000        -7.493       0.000        \n",
            "Samples\n",
            "Sample 0 .  counts more than blood the rest was the somewhat cover about games who never be beginning of the film the\n",
            "Sample 1 .  baggy i survive this good especially movies so clearly made up the home front so they buy bonds circuit it\n",
            "Sample 2 .  it point like the pilot that one remains map is well pirates of the caribbean is first then dark prince\n",
            "\n",
            "\n",
            "targets[[140 213 2 115 222 4135 3 92 16 246 98 18 10 5 2 49 29 7 12 35][125 12 6070 1150 1894 526 3183 5 0 15749 109 8 10 19 18 0 3113 2018 3 417][29952 3 2 114 1070 4 1624 3067 4 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 140 213 2 115 222 4135 3 92 16]...][[1 1 1 0 0 0 0 0 0 0]...][[9 140 213 2 69848 69848 69848 69848 69848 69848]...][[140 213 2 115 222 4135 3 92 16 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 140 213 2 115 222 4135 3 92 16]...][[1 1 1 0 0 0 0 0 0 0]...][[9 140 213 2 69848 69848 69848 69848 69848 69848]...][[140 213 2 117 667 3 35 101 101 9]...]\n",
            "targets[[497 9 92 0 1414 3 3657 55 10 17 31 60 711 2255 1045 427 22 91 1029 624][481 9 13 3814 4 10 19 193 85 3 0 500 3 0 63 1 0 986 279 37][16 1408 1984 2411 575 117 434 1 117 877]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[497 497 9 92 0 1414 3 3657 55 10]...][[1 1 1 1 1 1 1 0 0 0]...][[497 497 9 92 0 1414 3 3657 69848 69848]...][[497 9 92 0 1414 3 3657 55 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[497 497 9 92 0 1414 3 3657 55 10]...][[1 1 1 1 1 1 1 0 0 0]...][[497 497 9 92 0 1414 3 3657 69848 69848]...][[497 9 92 0 1414 3 3657 1 7 5]...]\n",
            "targets[[139 226 48 166 8 12983 37 9 67 35 2906 1754 11 12983 25 2 176 16688 506 15][0 412 283 8 1138 741 4 560 127 1352 5 35468 41 39748 36 157 2586 2275 6 6][72 318 2983 11203 304 292 241 16 0 53]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 139 226 48 166 8 12983 37 9 67]...][[1 1 1 1 1 0 0 0 0 0]...][[9 139 226 48 166 8 69848 69848 69848 69848]...][[139 226 48 166 8 12983 37 9 67 35]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 139 226 48 166 8 12983 37 9 67]...][[1 1 1 1 1 0 0 0 0 0]...][[9 139 226 48 166 8 69848 69848 69848 69848]...][[139 226 48 166 8 1177 164 645 8 81]...]\n",
            "targets[[2 574 161 50 28 250 72 149 10 17 9 113 693 11 131 2282 36 574 34 92][1544 43 30 11 5 10 151 5 565 0 156 27 1246 32 42 89 21 306 8014 4][140 23 251 47 3326 71 78 0 443 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 574 161 50 28 250 72 149 10]...][[1 1 1 1 1 1 1 1 1 0]...][[47 2 574 161 50 28 250 72 149 10]...][[2 574 161 50 28 250 72 149 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 574 161 50 28 250 72 149 10]...][[1 1 1 1 1 1 1 1 1 0]...][[47 2 574 161 50 28 250 72 149 10]...][[2 574 161 50 28 250 72 149 10 17]...]\n",
            "targets[[5 2 871 17 4 690 43 9 89 21 27 100 5242 3 60 1440 43 0 434 18][139 110 2 171 3 104 18 10 5 710 0 29 15 0 30 57 250 405 79 3187][143 8 377 51 20 59 76 2 2212 10390]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23993 5 2 871 17 4 690 43 9 89]...][[1 1 1 1 1 1 1 1 0 0]...][[23993 5 2 871 17 4 690 43 9 69848]...][[5 2 871 17 4 690 43 9 89 21]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23993 5 2 871 17 4 690 43 9 89]...][[1 1 1 1 1 1 1 1 0 0]...][[23993 5 2 871 17 4 690 43 9 69848]...][[5 2 871 17 4 690 43 9 113 93]...]\n",
            "targets[[109 3 10 394 19 5 37 4220 9 139 278 0 1250 1831 55 85 9 140 7140 46][17 13 352 97 862 1 686 60 595 1648 696 4 1081 1 6549 646 2283 41 0 75][65 470 4 38 10 19 7 67 894 5819]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 109 3 10 394 19 5 37 4220 9]...][[1 1 1 1 1 1 1 1 0 0]...][[0 109 3 10 394 19 5 37 4220 69848]...][[109 3 10 394 19 5 37 4220 9 139]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 109 3 10 394 19 5 37 4220 9]...][[1 1 1 1 1 1 1 1 0 0]...][[0 109 3 10 394 19 5 37 4220 69848]...][[109 3 10 394 19 5 37 4220 1 338]...]\n",
            "targets[[233 9 254 44 43 773 885 2813 2455 9 67 77 1716 4 66 7 18 9 113 118][467 0 1734 246 202 1 13 65 261 931 4 10 18 32 793 4 80 97 73 6][7 41 23 70 139 110 104 38 10 29]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[123 233 9 254 44 43 773 885 2813 2455]...][[1 1 1 1 1 1 1 0 0 0]...][[123 233 9 254 44 43 773 885 69848 69848]...][[233 9 254 44 43 773 885 2813 2455 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[123 233 9 254 44 43 773 885 2813 2455]...][[1 1 1 1 1 1 1 0 0 0]...][[123 233 9 254 44 43 773 885 69848 69848]...][[233 9 254 44 43 773 885 1064 23 29]...]\n",
            "targets[[242 2 200 340 3 11686 9565 12 98 257 0 2622 10 17 5 2 172 3 60 355][0 125 1 26 989 1564 0 8607 1911 5482 237 132 23 14 9227 14 26 11370 479 8][13 0 250 17 9 215 31 56191 1 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 2 200 340 3 11686 9565 12 98]...][[1 1 1 1 1 1 1 1 1 1]...][[9 242 2 200 340 3 11686 9565 12 98]...][[242 2 200 340 3 11686 9565 12 98 257]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 2 200 340 3 11686 9565 12 98]...][[1 1 1 1 1 1 1 1 1 1]...][[9 242 2 200 340 3 11686 9565 12 98]...][[242 2 200 340 3 11686 9565 12 98 257]...]\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 1 1 1 1 1 1 1 1 0]...][[31 0 457 70 50 66 1102 3 4895 739]...][[0 457 70 50 66 1102 3 4895 739 18]...]\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 1 1 1 1 1 1 1 1 0]...][[31 0 457 70 50 66 1102 3 4895 739]...][[0 457 70 50 66 1102 3 4895 739 1077]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 1 1 1 1 1 1 1 1 0]...][[31 0 457 70 50 66 1102 3 4895 739]...][[0 457 70 50 66 1102 3 4895 739 1]...]\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "global_step: 7605\n",
            " perplexity: 418.863\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            " percent of 3-grams captured: 0.339.\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            " percent of 2-grams captured: 0.646.\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            " percent of 4-grams captured: 0.108.\n",
            " geometric_avg: 0.287.\n",
            " arithmetic_avg: 0.364.\n",
            "global_step: 7605\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39232\n",
            " G train loss: -7.73342\n",
            "targets[[0 457 70 50 66 1102 3 4895 739 1077 1 6059 4925 550 10 5 74 7 12 2][1473 285 2 12231 44 18 2780 1141 22 0 2504 16 2 1479 461 34 45 2 13938 433][140 2 200 340 3 3585 98 1 4733 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 1 1 1 1 1 1 1 1 0]...][[31 0 457 70 50 66 1102 3 4895 739]...][[0 457 70 50 66 1102 3 4895 739 1077]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 70 50 66 1102 3 4895 739]...][[1 1 1 1 1 1 1 1 1 0]...][[31 0 457 70 50 66 1102 3 4895 739]...][[0 457 70 50 66 1102 3 4895 739 7641]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  the                 0.677        0.000        0.000        0.000        -4.374       -3.887       -0.000       \n",
            "   [1]  beginning           0.710        0.000        0.000        0.000        -4.950       -9.363       0.000        \n",
            "   [1]  we                  0.613        0.000        0.000        0.000        -5.603       -9.013       0.000        \n",
            "   [1]  can                 0.649        0.000        0.000        0.000        -6.341       -8.043       0.000        \n",
            "   [1]  see                 0.658        0.000        0.000        0.000        -7.177       -11.410      0.000        \n",
            "   [1]  members             0.542        0.000        0.000        0.000        -8.122       -7.320       -0.000       \n",
            "   [1]  of                  0.640        0.000        0.000        0.000        -9.193       -9.221       0.000        \n",
            "   [1]  troma               0.554        0.000        0.000        0.000        -10.404      -6.465       -0.000       \n",
            "   [1]  team                0.393        0.000        0.000        0.000        -11.775      -9.918       -0.000       \n",
            "   [0]  psychedelic         0.245        8.359        -10.719      -1.405       -13.327      -12.763      -0.564       \n",
            "   [0]  sedate              0.179        3.914        -12.113      -1.722       -13.493      -17.276      3.783        \n",
            "   [0]  and                 0.140        8.934        -3.034       -1.965       -13.322      -19.024      5.000        \n",
            "   [0]  your                0.090        10.270       -6.477       -2.410       -12.854      -11.803      -1.051       \n",
            "   [0]  children            0.072        9.107        -7.891       -2.632       -11.819      -9.315       -2.504       \n",
            "   [0]  in                  0.095        5.414        -4.019       -2.357       -10.398      -9.256       -1.143       \n",
            "   [0]  what                0.062        5.748        -5.837       -2.778       -9.101       -8.528       -0.573       \n",
            "   [0]  various             0.025        6.201        -8.778       -3.700       -7.157       -8.831       1.675        \n",
            "   [0]  75                  0.020        5.440        -10.098      -3.912       -3.912       -13.323      5.000        \n",
            "   [1]  s                   0.015        0.000        0.000        0.000        0.000        -12.020      0.000        \n",
            "   [1]  a                   0.006        0.000        0.000        0.000        0.000        -13.237      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  woods               0.526        0.000        0.000        0.000        -9.645       -4.215       -0.000       \n",
            "   [1]  plays               0.382        0.000        0.000        0.000        -10.916      -8.901       -0.000       \n",
            "   [1]  a                   0.612        0.000        0.000        0.000        -12.354      -11.400      -0.000       \n",
            "   [0]  springs             0.364        12.908       -11.848      -1.010       -13.983      -8.978       -5.000       \n",
            "   [0]  director            0.332        6.428        -6.570       -1.102       -14.682      -8.975       -5.000       \n",
            "   [0]  team                0.427        5.241        -7.989       -0.851       -15.369      -8.993       -5.000       \n",
            "   [0]  executive           0.354        9.830        -9.219       -1.038       -16.431      -7.795       -5.000       \n",
            "   [0]  opens               0.313        8.339        -8.285       -1.163       -17.421      -6.354       -5.000       \n",
            "   [0]  are                 0.006        4.718        -5.102       -5.122       -18.401      -6.957       -5.000       \n",
            "   [0]  a                   0.005        2.561        -1.924       -5.220       -15.029      -14.914      -0.115       \n",
            "   [0]  certain             0.002        11.902       -7.153       -6.186       -11.102      -12.470      1.368        \n",
            "   [0]  zombies             0.004        4.885        -8.921       -5.563       -5.563       -11.874      5.000        \n",
            "   [1]  a                   0.005        0.000        0.000        0.000        0.000        -8.646       0.000        \n",
            "   [1]  serial              0.012        0.000        0.000        0.000        0.000        -7.687       0.000        \n",
            "   [1]  killer              0.063        0.000        0.000        0.000        0.000        -5.597       0.000        \n",
            "   [1]  who                 0.099        0.000        0.000        0.000        0.000        -7.431       0.000        \n",
            "   [1]  has                 0.294        0.000        0.000        0.000        0.000        -7.223       0.000        \n",
            "   [1]  a                   0.402        0.000        0.000        0.000        0.000        -7.289       0.000        \n",
            "   [1]  vendetta            0.794        0.000        0.000        0.000        0.000        -6.161       0.000        \n",
            "   [1]  against             0.933        0.000        0.000        0.000        0.000        -6.858       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  m                   0.422        0.000        0.000        0.000        -7.263       -4.313       -0.000       \n",
            "   [1]  a                   0.506        0.000        0.000        0.000        -8.220       -6.247       -0.000       \n",
            "   [1]  big                 0.387        0.000        0.000        0.000        -9.303       -5.510       -0.000       \n",
            "   [1]  fan                 0.542        0.000        0.000        0.000        -10.529      -5.712       -0.000       \n",
            "   [1]  of                  0.517        0.000        0.000        0.000        -11.917      -8.146       -0.000       \n",
            "   [1]  giallo              0.135        0.000        0.000        0.000        -13.487      -7.368       -0.000       \n",
            "   [0]  eva                 0.362        4.807        -11.131      -1.017       -15.265      -7.519       -5.000       \n",
            "   [0]  but                 0.474        2.323        -4.075       -0.747       -16.126      -8.706       -5.000       \n",
            "   [0]  comedy              0.264        9.899        -7.690       -1.332       -17.405      -8.000       -5.000       \n",
            "   [0]  burroughs           0.255        3.376        -13.041      -1.365       -18.191      -10.296      -5.000       \n",
            "   [0]  hauer               0.016        6.128        -12.804      -4.124       -19.044      -10.588      -5.000       \n",
            "   [0]  el                  0.006        9.467        -9.632       -5.149       -16.886      -13.684      -3.202       \n",
            "   [0]  director            0.009        6.016        -6.183       -4.734       -13.284      -14.424      1.141        \n",
            "   [0]  essentially         0.007        8.155        -10.172      -4.900       -9.677       -11.203      1.526        \n",
            "   [0]  poster              0.004        3.805        -9.346       -5.406       -5.406       -9.516       4.110        \n",
            "   [1]  director            0.009        0.000        0.000        0.000        0.000        -10.066      0.000        \n",
            "   [1]  bava                0.003        0.000        0.000        0.000        0.000        -8.635       0.000        \n",
            "   [1]  but                 0.003        0.000        0.000        0.000        0.000        -9.032       0.000        \n",
            "   [1]  this                0.006        0.000        0.000        0.000        0.000        -8.767       0.000        \n",
            "   [1]  film                0.006        0.000        0.000        0.000        0.000        -7.163       0.000        \n",
            "Samples\n",
            "Sample 0 .  the beginning we can see members of troma team psychedelic sedate and your children in what various 75 s a\n",
            "Sample 1 .  woods plays a springs director team executive opens are a certain zombies a serial killer who has a vendetta against\n",
            "Sample 2 .  m a big fan of giallo eva but comedy burroughs hauer el director essentially poster director bava but this film\n",
            "\n",
            "\n",
            "targets[[5 2 81 637 19 100 340 3 508 4486 141 197 2 1005 3 10 1373 19 153 1917][8470 5 8403 15 2 13860 3 21923 1 1497 8621 187 385 423 161 188 4 3919 0 2958][20 38 7 41 23 10 5 2 7514 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 81 637 19 100 340 3 508]...][[1 1 1 1 1 1 1 1 1 1]...][[10 5 2 81 637 19 100 340 3 508]...][[5 2 81 637 19 100 340 3 508 4486]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 81 637 19 100 340 3 508]...][[1 1 1 1 1 1 1 1 1 1]...][[10 5 2 81 637 19 100 340 3 508]...][[5 2 81 637 19 100 340 3 508 4486]...]\n",
            "targets[[5 554 15815 520 2964 5 2 394 279 767 18 7 12 297 9 159 21 58 169 86][15201 132 3163 2 20221 8 35 158 1280 1838 5 2776 33 0 1474 1 18319 51 24 5373][215 10 19 227 311 8 2 4285 2683 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 554 15815 520 2964 5 2 394 279]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 554 15815 520 2964 5 2 394 69848]...][[5 554 15815 520 2964 5 2 394 279 767]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 554 15815 520 2964 5 2 394 279]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 554 15815 520 2964 5 2 394 69848]...][[5 554 15815 520 2964 5 2 394 3778 231]...]\n",
            "targets[[37 11 13 2 838 721 2843 18 7 150 21 517 85 10 17 1784 0 9957 186 245][9 159 21 27 303 6443 18 196 9 207 31 219 367 12188 3193 9 38 42 43 238][322 17 111 283 5 323 36 0 13366 5690]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1167 37 11 13 2 838 721 2843 18 7]...][[1 1 1 1 1 1 1 1 1 1]...][[1167 37 11 13 2 838 721 2843 18 7]...][[37 11 13 2 838 721 2843 18 7 150]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1167 37 11 13 2 838 721 2843 18 7]...][[1 1 1 1 1 1 1 1 1 1]...][[1167 37 11 13 2 838 721 2843 18 7]...][[37 11 13 2 838 721 2843 18 7 150]...]\n",
            "targets[[12 2 49 1080 1024 7 12 2 4162 3 1592 1939 12 1185 503 1966 1 2 3354 298][2127 223 162 0 5325 276 2127 168 38 35 1984 1465 1724 19 9 1653 10 17 21111 22937][2 3503 3 2119 7052 1847 10 487 5 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[128 12 2 49 1080 1024 7 12 2 4162]...][[1 1 1 1 1 0 0 0 0 0]...][[128 12 2 49 1080 1024 69848 69848 69848 69848]...][[12 2 49 1080 1024 7 12 2 4162 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[128 12 2 49 1080 1024 7 12 2 4162]...][[1 1 1 1 1 0 0 0 0 0]...][[128 12 2 49 1080 1024 69848 69848 69848 69848]...][[12 2 49 1080 1024 8 0 19 5 0]...]\n",
            "targets[[139 64 545 4 1658 6 6 51 2 19 6152 11 7 45 2 522 3 8508 381 303][23 1863 4 238 11 286 34 45 358 10 17 2 1153 738 45 4 136 32 25 3235][397 239 157 17 43 764 33 286 34 45]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 139 64 545 4 1658 6 6 51 2]...][[1 1 1 1 1 1 1 1 1 1]...][[9 139 64 545 4 1658 6 6 51 2]...][[139 64 545 4 1658 6 6 51 2 19]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 139 64 545 4 1658 6 6 51 2]...][[1 1 1 1 1 1 1 1 1 1]...][[9 139 64 545 4 1658 6 6 51 2]...][[139 64 545 4 1658 6 6 51 2 19]...]\n",
            "targets[[368 36 0 125 34 529 178 0 21285 6384 8 9734 30644 0 63 1109 10670 39111 520 3406][17 5 2 737 502 3 137 9 66 2 171 8 1855 2 9548 3 1705 7481 292 33][17587 2030 199 10 19 1 0 84 7528 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[157 368 36 0 125 34 529 178 0 21285]...][[1 1 1 1 1 1 1 0 0 0]...][[157 368 36 0 125 34 529 178 69848 69848]...][[368 36 0 125 34 529 178 0 21285 6384]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[157 368 36 0 125 34 529 178 0 21285]...][[1 1 1 1 1 1 1 0 0 0]...][[157 368 36 0 125 34 529 178 69848 69848]...][[368 36 0 125 34 529 178 87 673 44]...]\n",
            "targets[[74 225 74 156 1 2 1795 8 6661 25 52 2058 11 0 178 1341 98 3 0 3392][31293 13 6905 4 314 8 105 104 11 68 14 1679 14 0 20593 1744 0 6505 1 10][239 157 354 26649 19 11 150 21 749 55]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 74 225 74 156 1 2 1795 8 6661]...][[1 1 1 1 1 1 0 0 0 0]...][[2 74 225 74 156 1 2 69848 69848 69848]...][[74 225 74 156 1 2 1795 8 6661 25]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 74 225 74 156 1 2 1795 8 6661]...][[1 1 1 1 1 1 0 0 0 0]...][[2 74 225 74 156 1 2 69848 69848 69848]...][[74 225 74 156 1 2 692 0 3127 13]...]\n",
            "targets[[5162 5 2 1000 19 9 50 21 136 7 100 44035 94 11 7 302 265 99 2 2623][3 0 74 829 22 10 4183 1658 2455 3 0 578 330 16 29 41 52 3 0 1057][246 3586 2208 0 109 3 7237 4333 14 1323]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[16903 5162 5 2 1000 19 9 50 21 136]...][[1 1 1 1 1 1 1 0 0 0]...][[16903 5162 5 2 1000 19 9 50 69848 69848]...][[5162 5 2 1000 19 9 50 21 136 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[16903 5162 5 2 1000 19 9 50 21 136]...][[1 1 1 1 1 1 1 0 0 0]...][[16903 5162 5 2 1000 19 9 50 69848 69848]...][[5162 5 2 1000 19 9 50 21 1173 2757]...]\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[1 1 0 0 0 0 0 0 0 0]...][[1321 5826 9716 69848 69848 69848 69848 69848 69848 69848]...][[5826 9716 992 18182 5 98 111 0 173 965]...]\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[1 1 0 0 0 0 0 0 0 0]...][[1321 5826 9716 69848 69848 69848 69848 69848 69848 69848]...][[5826 9716 1721 550 6884 2 941 12 531 1621]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[1 1 0 0 0 0 0 0 0 0]...][[1321 5826 9716 69848 69848 69848 69848 69848 69848 69848]...][[5826 9716 6825 35168 19549 42 10000 15 283 0]...]\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "global_step: 7622\n",
            " perplexity: 418.874\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            " percent of 3-grams captured: 0.365.\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            " percent of 2-grams captured: 0.637.\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            " percent of 4-grams captured: 0.122.\n",
            " geometric_avg: 0.305.\n",
            " arithmetic_avg: 0.375.\n",
            "global_step: 7622\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39217\n",
            " G train loss: -7.78285\n",
            "targets[[5826 9716 1721 550 6884 2 941 12 531 1621 1281 181 24 12 23 356 245 6388 5 2][83 198 20 105 996 16 149 10 832 827 13416 43 2 10337 5593 11 5199 4 8071 44][422 141 27 77 3308 196 44 440 214 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[1 1 0 0 0 0 0 0 0 0]...][[1321 5826 9716 69848 69848 69848 69848 69848 69848 69848]...][[5826 9716 1721 550 6884 2 941 12 531 1621]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 5826 9716 1721 550 6884 2 941 12 531]...][[1 1 0 0 0 0 0 0 0 0]...][[1321 5826 9716 69848 69848 69848 69848 69848 69848 69848]...][[5826 9716 6765 2550 1497 72 8666 44685 46 3]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  chow                0.592        0.000        0.000        0.000        -2.344       -4.021       0.000        \n",
            "   [1]  yun                 0.767        0.000        0.000        0.000        -2.652       -12.682      0.000        \n",
            "   [0]  tightly             0.619        8.689        -9.701       -0.479       -3.002       -8.676       5.000        \n",
            "   [0]  code                0.803        7.871        -9.588       -0.219       -2.855       -9.060       5.000        \n",
            "   [0]  murders             0.976        12.301       -8.859       -0.024       -2.983       -10.124      5.000        \n",
            "   [0]  than                0.938        4.542        -7.150       -0.064       -3.349       -8.740       5.000        \n",
            "   [0]  travelling          0.943        8.808        -10.305      -0.059       -3.717       -10.296      5.000        \n",
            "   [0]  rn                  0.807        4.252        -13.892      -0.214       -4.141       -9.492       5.000        \n",
            "   [0]  if                  0.747        9.341        -7.347       -0.292       -4.444       -10.453      5.000        \n",
            "   [0]  of                  0.433        11.609       -6.187       -0.838       -4.699       -10.422      5.000        \n",
            "   [0]  bit                 0.013        9.561        -8.962       -4.370       -4.370       -11.005      5.000        \n",
            "   [1]  action              0.024        0.000        0.000        0.000        0.000        -17.009      0.000        \n",
            "   [1]  he                  0.007        0.000        0.000        0.000        0.000        -13.382      0.000        \n",
            "   [1]  s                   0.021        0.000        0.000        0.000        0.000        -12.189      0.000        \n",
            "   [1]  not                 0.034        0.000        0.000        0.000        0.000        -11.420      0.000        \n",
            "   [1]  wrong               0.184        0.000        0.000        0.000        0.000        -10.497      0.000        \n",
            "   [1]  hard                0.274        0.000        0.000        0.000        0.000        -9.878       0.000        \n",
            "   [1]  boiled              0.763        0.000        0.000        0.000        0.000        -7.977       0.000        \n",
            "   [1]  is                  0.572        0.000        0.000        0.000        0.000        -9.525       0.000        \n",
            "   [1]  a                   0.591        0.000        0.000        0.000        0.000        -10.031      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  will                0.671        0.000        0.000        0.000        -10.828      -4.191       -0.000       \n",
            "   [1]  give                0.679        0.000        0.000        0.000        -12.255      -10.835      -0.000       \n",
            "   [1]  you                 0.711        0.000        0.000        0.000        -13.870      -6.358       -0.000       \n",
            "   [1]  two                 0.547        0.000        0.000        0.000        -15.698      -6.669       -0.000       \n",
            "   [1]  reasons             0.645        0.000        0.000        0.000        -17.767      -7.525       -0.000       \n",
            "   [1]  for                 0.505        0.000        0.000        0.000        -20.108      -11.523      -0.000       \n",
            "   [1]  watching            0.436        0.000        0.000        0.000        -22.758      -10.795      -0.000       \n",
            "   [0]  my                  0.589        2.530        -4.468       -0.529       -25.757      -11.149      -5.000       \n",
            "   [0]  entertaining        0.014        8.078        -7.117       -4.275       -28.552      -9.647       -5.000       \n",
            "   [0]  all                 0.010        7.786        -5.756       -4.580       -27.476      -13.329      -5.000       \n",
            "   [0]  but                 0.010        13.501       -3.835       -4.651       -25.913      -12.521      -5.000       \n",
            "   [0]  many                0.007        5.088        -6.432       -5.005       -24.064      -10.650      -5.000       \n",
            "   [0]  nobody              0.002        4.182        -10.235      -6.015       -21.571      -9.731       -5.000       \n",
            "   [0]  and                 0.002        12.667       -2.639       -6.273       -17.606      -10.035      -5.000       \n",
            "   [0]  it                  0.002        12.015       -2.907       -6.329       -12.826      -9.798       -3.029       \n",
            "   [0]  do                  0.001        5.984        -5.107       -7.354       -7.354       -8.977       1.623        \n",
            "   [1]  threatens           0.001        0.000        0.000        0.000        0.000        -11.106      0.000        \n",
            "   [1]  to                  0.002        0.000        0.000        0.000        0.000        -10.649      0.000        \n",
            "   [1]  wipe                0.008        0.000        0.000        0.000        0.000        -9.987       0.000        \n",
            "   [1]  out                 0.047        0.000        0.000        0.000        0.000        -8.078       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  episode             0.648        0.000        0.000        0.000        -2.784       -4.256       0.000        \n",
            "   [1]  should              0.433        0.000        0.000        0.000        -3.151       -7.421       0.000        \n",
            "   [1]  have                0.795        0.000        0.000        0.000        -3.566       -14.673      0.000        \n",
            "   [1]  been                0.683        0.000        0.000        0.000        -4.036       -9.438       0.000        \n",
            "   [1]  carefully           0.668        0.000        0.000        0.000        -4.568       -9.804       0.000        \n",
            "   [1]  thought             0.623        0.000        0.000        0.000        -5.170       -9.476       0.000        \n",
            "   [1]  out                 0.633        0.000        0.000        0.000        -5.851       -9.016       0.000        \n",
            "   [1]  several             0.603        0.000        0.000        0.000        -6.622       -9.880       0.000        \n",
            "   [1]  times               0.569        0.000        0.000        0.000        -7.495       -7.935       0.000        \n",
            "   [1]  and                 0.438        0.000        0.000        0.000        -8.483       -9.411       0.000        \n",
            "   [0]  s                   0.110        7.197        -2.503       -2.208       -9.600       -9.059       -0.542       \n",
            "   [0]  make                0.145        11.198       -6.457       -1.928       -8.367       -16.026      5.000        \n",
            "   [0]  how                 0.320        11.751       -5.448       -1.140       -7.287       -10.801      3.514        \n",
            "   [0]  insignificant       0.215        3.766        -12.820      -1.537       -6.957       -10.382      3.424        \n",
            "   [0]  exactly             0.199        3.318        -9.993       -1.612       -6.135       -10.377      4.242        \n",
            "   [0]  the                 0.170        8.905        -1.762       -1.770       -5.119       -10.597      5.000        \n",
            "   [0]  performances        0.466        7.209        -8.073       -0.763       -3.790       -10.133      5.000        \n",
            "   [0]  in                  0.309        4.051        -3.563       -1.175       -3.425       -8.227       4.801        \n",
            "   [0]  series              0.078        8.958        -7.343       -2.547       -2.547       -9.893       5.000        \n",
            "   [1]  of                  0.108        0.000        0.000        0.000        0.000        -16.705      0.000        \n",
            "Samples\n",
            "Sample 0 .  chow yun tightly code murders than travelling rn if of bit action he s not wrong hard boiled is a\n",
            "Sample 1 .  will give you two reasons for watching my entertaining all but many nobody and it do threatens to wipe out\n",
            "Sample 2 .  episode should have been carefully thought out several times and s make how insignificant exactly the performances in series of\n",
            "\n",
            "\n",
            "targets[[9 242 142 2 706 245 8373 340 9 140 2009 5334 10 0 117 1855 17 123 190 9][21 121 47 30 0 3474 13 43 30 8 30 9 4105 43 3119 60 57 149 10 119][1115 416 157 29 6 6 132 22 35 11553]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[416 9 242 142 2 706 245 8373 340 9]...][[1 1 1 1 1 1 0 0 0 0]...][[416 9 242 142 2 706 245 69848 69848 69848]...][[9 242 142 2 706 245 8373 340 9 140]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[416 9 242 142 2 706 245 8373 340 9]...][[1 1 1 1 1 1 0 0 0 0]...][[416 9 242 142 2 706 245 69848 69848 69848]...][[9 242 142 2 706 245 7 0 530 11]...]\n",
            "targets[[1773 0 981 5 23 0 250 17 123 92 56 11 2823 59 27 4 138 4 2 19][0 460 8509 1 13026 1586 0 105 82 104 33 8462 15788 11 9 139 110 0 153 10721][3 50924 4608 732 4 191 265 8 2 21045]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2236 1773 0 981 5 23 0 250 17 123]...][[1 1 1 1 1 1 1 0 0 0]...][[2236 1773 0 981 5 23 0 250 69848 69848]...][[1773 0 981 5 23 0 250 17 123 92]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2236 1773 0 981 5 23 0 250 17 123]...][[1 1 1 1 1 1 1 0 0 0]...][[2236 1773 0 981 5 23 0 250 69848 69848]...][[1773 0 981 5 23 0 250 43 0 1340]...]\n",
            "targets[[425 1197 71 10 378 1 9 203 136 7 5 775 0 12847 179 9 27 1059 110 9][353 0 298 2 1307 167 9 307 10 92 16 246 17 0 5924 141 27 2815 71 47][17 42 968 97 1043 379 9 50 21 58]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 425 1197 71 10 378 1 9 203 136]...][[1 1 1 0 0 0 0 0 0 0]...][[60 425 1197 71 69848 69848 69848 69848 69848 69848]...][[425 1197 71 10 378 1 9 203 136 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 425 1197 71 10 378 1 9 203 136]...][[1 1 1 0 0 0 0 0 0 0]...][[60 425 1197 71 69848 69848 69848 69848 69848 69848]...][[425 1197 71 55 0 117 22 9 242 30]...]\n",
            "targets[[1530 366 15 7342 10 5 23 145 7 5 2 246 17 15 156 427 22 47 13 1003][50 21 262 9 453 60 57 149 10 1243 9 118 85 4648 10730 529 7 35 21127 678][452 45 213 77 29 3 60 519 458 202]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[84 1530 366 15 7342 10 5 23 145 7]...][[1 1 1 1 1 1 1 1 0 0]...][[84 1530 366 15 7342 10 5 23 145 69848]...][[1530 366 15 7342 10 5 23 145 7 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[84 1530 366 15 7342 10 5 23 145 7]...][[1 1 1 1 1 1 1 1 0 0]...][[84 1530 366 15 7342 10 5 23 145 69848]...][[1530 366 15 7342 10 5 23 145 29 10]...]\n",
            "targets[[72 29 153 45 1715 11 0 414 4300 95 3 37872 127 101 4 1624 807 5 4 278][12 23 2 666 631 561 8 10 348 2716 69 92 3054 2908 1543 790 5 35 41316 2356][4137 5634 282 5146 4 31516 12 40914 14 11]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[52 72 29 153 45 1715 11 0 414 4300]...][[1 1 1 1 1 1 1 1 1 0]...][[52 72 29 153 45 1715 11 0 414 4300]...][[72 29 153 45 1715 11 0 414 4300 95]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[52 72 29 153 45 1715 11 0 414 4300]...][[1 1 1 1 1 1 1 1 1 0]...][[52 72 29 153 45 1715 11 0 414 4300]...][[72 29 153 45 1715 11 0 414 4300 5]...]\n",
            "targets[[13 65 671 15 10 17 7 13 2 14217 18481 225 354 22 102 954 1 194 22 1346][10 19 13 38 19780 0 2730 9 67 8 60 844 12 1073 16 463 629 4175 261 3281][0 314 3 0 19 8 1315 3 84 5002]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 65 671 15 10 17 7 13 2]...][[1 0 0 0 0 0 0 0 0 0]...][[9 13 69848 69848 69848 69848 69848 69848 69848 69848]...][[13 65 671 15 10 17 7 13 2 14217]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 13 65 671 15 10 17 7 13 2]...][[1 0 0 0 0 0 0 0 0 0]...][[9 13 69848 69848 69848 69848 69848 69848 69848 69848]...][[13 35 751 5284 8 10 564 74 0 1244]...]\n",
            "targets[[25 658 104 65 658 104 1 39 5 2419 531 7 5 95 97 194 39 5 56 237][120 0 3336 9 2021 0 170 151 157 6438 5286 0 43632 10025 1289 12 9628 0 455 1141][10 298 4779 2814 4 0 298 94 70 50]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[21293 25 658 104 65 658 104 1 39 5]...][[1 1 1 1 0 0 0 0 0 0]...][[21293 25 658 104 65 69848 69848 69848 69848 69848]...][[25 658 104 65 658 104 1 39 5 2419]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[21293 25 658 104 65 658 104 1 39 5]...][[1 1 1 1 0 0 0 0 0 0]...][[21293 25 658 104 65 69848 69848 69848 69848 69848]...][[25 658 104 65 29 7289 22 36 2385 2352]...]\n",
            "targets[[67 0 1718 3 2 53401 3082 68473 549 3 2 246 2299 202 3 60 1700 34 67 400][10406 1 245 3357 0 492 3 0 116 8567 1 444 1482 292 4 1006 2 2536 2511 436][20 1632 16 1328 5 192 4 93 255 182]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 67 0 1718 3 2 53401 3082 68473 549]...][[1 1 1 1 1 1 1 1 1 1]...][[9 67 0 1718 3 2 53401 3082 68473 549]...][[67 0 1718 3 2 53401 3082 68473 549 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 67 0 1718 3 2 53401 3082 68473 549]...][[1 1 1 1 1 1 1 1 1 1]...][[9 67 0 1718 3 2 53401 3082 68473 549]...][[67 0 1718 3 2 53401 3082 68473 549 3]...]\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[1 1 1 1 0 0 0 0 0 0]...][[7 203 27 77 440 69848 69848 69848 69848 69848]...][[203 27 77 440 223 85 60 4612 637 888]...]\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[1 1 1 1 0 0 0 0 0 0]...][[7 203 27 77 440 69848 69848 69848 69848 69848]...][[203 27 77 440 154 99 7 13 645 37]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[1 1 1 1 0 0 0 0 0 0]...][[7 203 27 77 440 69848 69848 69848 69848 69848]...][[203 27 77 440 738 7 188 248 52 154]...]\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "global_step: 7639\n",
            " perplexity: 418.586\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            " percent of 3-grams captured: 0.313.\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            " percent of 2-grams captured: 0.624.\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            " percent of 4-grams captured: 0.107.\n",
            " geometric_avg: 0.275.\n",
            " arithmetic_avg: 0.348.\n",
            "global_step: 7639\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39212\n",
            " G train loss: -7.95085\n",
            "targets[[203 27 77 440 154 99 7 13 645 37 89 21 121 134 7 13 31 0 98 18][17 5 37 948 7 5 221 2863 126 542 14 2724 1947 0 24994 817 10 487 494 4][429 195 545 270 55 22 5074 643 277 2255]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[1 1 1 1 0 0 0 0 0 0]...][[7 203 27 77 440 69848 69848 69848 69848 69848]...][[203 27 77 440 154 99 7 13 645 37]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 203 27 77 440 154 99 7 13 645]...][[1 1 1 1 0 0 0 0 0 0]...][[7 203 27 77 440 69848 69848 69848 69848 69848]...][[203 27 77 440 3 1346 4314 374 1 13637]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  must                0.339        0.000        0.000        0.000        -15.711      -3.981       -0.000       \n",
            "   [1]  have                0.593        0.000        0.000        0.000        -17.781      -11.150      -0.000       \n",
            "   [1]  been                0.792        0.000        0.000        0.000        -20.124      -7.737       -0.000       \n",
            "   [1]  several             0.588        0.000        0.000        0.000        -22.776      -10.207      -0.000       \n",
            "   [0]  of                  0.484        4.972        -2.511       -0.726       -25.777      -6.581       -5.000       \n",
            "   [0]  unbelievable        0.053        7.875        -8.705       -2.945       -28.353      -6.390       -5.000       \n",
            "   [0]  downhill            0.014        3.289        -9.966       -4.263       -28.756      -17.841      -5.000       \n",
            "   [0]  stupid              0.003        4.712        -8.254       -5.730       -27.720      -18.477      -5.000       \n",
            "   [0]  and                 0.002        8.725        -3.220       -6.065       -24.888      -17.787      -5.000       \n",
            "   [0]  populate            0.003        5.638        -12.765      -5.917       -21.304      -15.816      -5.000       \n",
            "   [0]  boot                0.002        8.343        -10.220      -6.043       -17.415      -13.639      -3.775       \n",
            "   [0]  from                0.001        6.536        -4.108       -6.604       -12.870      -14.518      1.648        \n",
            "   [0]  from                0.001        9.112        -6.263       -7.092       -7.092       -14.571      5.000        \n",
            "   [1]  why                 0.001        0.000        0.000        0.000        0.000        -16.720      0.000        \n",
            "   [1]  it                  0.001        0.000        0.000        0.000        0.000        -14.824      0.000        \n",
            "   [1]  was                 0.001        0.000        0.000        0.000        0.000        -13.930      0.000        \n",
            "   [1]  at                  0.002        0.000        0.000        0.000        0.000        -15.254      0.000        \n",
            "   [1]  the                 0.002        0.000        0.000        0.000        0.000        -14.881      0.000        \n",
            "   [1]  movies              0.003        0.000        0.000        0.000        0.000        -12.413      0.000        \n",
            "   [1]  but                 0.004        0.000        0.000        0.000        0.000        -14.630      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  movie               0.530        0.000        0.000        0.000        -11.030      -4.490       -0.000       \n",
            "   [1]  is                  0.632        0.000        0.000        0.000        -12.484      -12.805      0.000        \n",
            "   [1]  so                  0.577        0.000        0.000        0.000        -14.129      -8.849       -0.000       \n",
            "   [1]  weird               0.454        0.000        0.000        0.000        -15.991      -12.021      -0.000       \n",
            "   [1]  it                  0.716        0.000        0.000        0.000        -18.098      -10.337      -0.000       \n",
            "   [1]  is                  0.490        0.000        0.000        0.000        -20.483      -8.048       -0.000       \n",
            "   [1]  almost              0.536        0.000        0.000        0.000        -23.182      -10.292      -0.000       \n",
            "   [0]  best                0.127        12.783       -7.646       -2.062       -26.237      -9.940       -5.000       \n",
            "   [0]  those               0.102        6.877        -7.648       -2.279       -27.361      -16.619      -5.000       \n",
            "   [0]  the                 0.016        8.556        -2.035       -4.120       -28.387      -13.094      -5.000       \n",
            "   [0]  film                0.009        8.686        -2.468       -4.662       -27.465      -13.951      -5.000       \n",
            "   [0]  is                  0.007        11.797       -2.484       -4.998       -25.808      -14.608      -5.000       \n",
            "   [0]  watched             0.003        12.544       -6.388       -5.681       -23.552      -11.034      -5.000       \n",
            "   [0]  s                   0.001        1.767        -5.752       -7.432       -20.225      -16.774      -3.451       \n",
            "   [0]  bad                 0.000        15.663       -3.971       -7.608       -14.479      -17.838      3.359        \n",
            "   [0]  the                 0.000        9.110        -2.028       -7.776       -7.776       -13.376      5.000        \n",
            "   [1]  this                0.000        0.000        0.000        0.000        0.000        -13.539      0.000        \n",
            "   [1]  flick               0.001        0.000        0.000        0.000        0.000        -12.899      0.000        \n",
            "   [1]  tries               0.001        0.000        0.000        0.000        0.000        -13.052      0.000        \n",
            "   [1]  to                  0.003        0.000        0.000        0.000        0.000        -11.011      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  finally             0.631        0.000        0.000        0.000        -14.206      -3.852       -0.000       \n",
            "   [1]  got                 0.687        0.000        0.000        0.000        -16.078      -6.777       -0.000       \n",
            "   [1]  myself              0.368        0.000        0.000        0.000        -18.196      -7.708       -0.000       \n",
            "   [0]  it                  0.193        10.541       -3.225       -1.642       -20.594      -6.590       -5.000       \n",
            "   [0]  was                 0.150        9.338        -1.538       -1.895       -21.449      -8.464       -5.000       \n",
            "   [0]  at                  0.174        5.535        -5.851       -1.748       -22.130      -9.294       -5.000       \n",
            "   [0]  much                0.022        11.335       -4.744       -3.826       -23.068      -9.596       -5.000       \n",
            "   [0]  if                  0.011        11.339       -5.128       -4.531       -21.778      -14.826      -5.000       \n",
            "   [0]  i                   0.004        13.854       -0.949       -5.427       -19.520      -16.308      -3.212       \n",
            "   [0]  felt                0.004        11.741       -4.965       -5.539       -15.950      -16.142      0.192        \n",
            "   [0]  this                0.002        5.571        -2.306       -6.079       -11.783      -15.951      4.168        \n",
            "   [0]  movie               0.002        5.433        -0.889       -6.456       -6.456       -14.139      5.000        \n",
            "   [1]  could               0.001        0.000        0.000        0.000        0.000        -14.795      0.000        \n",
            "   [1]  find                0.002        0.000        0.000        0.000        0.000        -14.415      0.000        \n",
            "   [1]  movies              0.002        0.000        0.000        0.000        0.000        -11.840      0.000        \n",
            "   [1]  not                 0.004        0.000        0.000        0.000        0.000        -13.086      0.000        \n",
            "   [1]  available           0.006        0.000        0.000        0.000        0.000        -9.979       0.000        \n",
            "   [1]  to                  0.006        0.000        0.000        0.000        0.000        -9.571       0.000        \n",
            "   [1]  me                  0.021        0.000        0.000        0.000        0.000        -9.805       0.000        \n",
            "   [1]  in                  0.076        0.000        0.000        0.000        0.000        -8.680       0.000        \n",
            "Samples\n",
            "Sample 0 .  must have been several of unbelievable downhill stupid and populate boot from from why it was at the movies but\n",
            "Sample 1 .  movie is so weird it is almost best those the film is watched s bad the this flick tries to\n",
            "Sample 2 .  finally got myself it was at much if i felt this movie could find movies not available to me in\n",
            "\n",
            "\n",
            "targets[[321 5 2 53 1228 412 0 19 45 2 613 3049 8 3761 230 4 7 18 7 5][763 339 3 54572 27459 12 1556 7 12 43 2 112 1620 199 323 24905 39983 8804 25226 1][215 10 17 22 735 1048 797 51 7 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 321 5 2 53 1228 412 0 19 45]...][[1 1 1 1 1 1 1 1 0 0]...][[0 321 5 2 53 1228 412 0 19 69848]...][[321 5 2 53 1228 412 0 19 45 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 321 5 2 53 1228 412 0 19 45]...][[1 1 1 1 1 1 1 1 0 0]...][[0 321 5 2 53 1228 412 0 19 69848]...][[321 5 2 53 1228 412 0 19 13 711]...]\n",
            "targets[[71 15347 13 2 1446 9 856 52 3 2 1543 3985 19 264 30 81 156 27 92 2947][109 12 4368 65 7 2525 0 1269 61 5 4 1624 2 11358 16 0 769 1785 6 6][3 30 10 17 210 21 2 605 1521 46]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4 71 15347 13 2 1446 9 856 52 3]...][[1 1 1 0 0 0 0 0 0 0]...][[4 71 15347 13 69848 69848 69848 69848 69848 69848]...][[71 15347 13 2 1446 9 856 52 3 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4 71 15347 13 2 1446 9 856 52 3]...][[1 1 1 0 0 0 0 0 0 0]...][[4 71 15347 13 69848 69848 69848 69848 69848 69848]...][[71 15347 13 2961 72 397 565 15 0 231]...]\n",
            "targets[[5 437 0 250 19 9 27 123 110 8 60 114 14 229 14 9 242 1856 7 274][233 0 84 57 9 215 10 17 9 27 467 7 58 1078 7 13 2 360 341 17][5 35 7692 774 565 17 2483 311 30 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 437 0 250 19 9 27 123 110]...][[1 1 1 1 1 1 0 0 0 0]...][[10 5 437 0 250 19 9 69848 69848 69848]...][[5 437 0 250 19 9 27 123 110 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 437 0 250 19 9 27 123 110]...][[1 1 1 1 1 1 0 0 0 0]...][[10 5 437 0 250 19 9 69848 69848 69848]...][[5 437 0 250 19 9 215 10 2486 39]...]\n",
            "targets[[1397 16 0 44577 10 17 141 28 2618 816 16 701 1 21811 3 100 4677 31 100 616][1066 88 3 2 2040 578 8 0 75 12 7642 3 2562 9 230 11 10 17 406 35][33 147 70 30 121 11 0 217 16485 694]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[74 1397 16 0 44577 10 17 141 28 2618]...][[1 1 0 0 0 0 0 0 0 0]...][[74 1397 16 69848 69848 69848 69848 69848 69848 69848]...][[1397 16 0 44577 10 17 141 28 2618 816]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[74 1397 16 0 44577 10 17 141 28 2618]...][[1 1 0 0 0 0 0 0 0 0]...][[74 1397 16 69848 69848 69848 69848 69848 69848 69848]...][[1397 16 3 225 43 0 2269 45 81 1227]...]\n",
            "targets[[250 1 8984 370 3 75 34 65 4231 4 121 126 0 177 27 1408 4076 199 90 7][285 2 243 34 1366 747 4 138 1192 51 1063 8050 1970 55 15 40 54 5266 945 4172][70 65 365 100 52 10604 1243 22 0 941]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 250 1 8984 370 3 75 34 65 4231]...][[1 1 1 1 0 0 0 0 0 0]...][[0 250 1 8984 370 69848 69848 69848 69848 69848]...][[250 1 8984 370 3 75 34 65 4231 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 250 1 8984 370 3 75 34 65 4231]...][[1 1 1 1 0 0 0 0 0 0]...][[0 250 1 8984 370 69848 69848 69848 69848 69848]...][[250 1 8984 370 4942 1696 22 705 349 208]...]\n",
            "targets[[42 307 60 3097 8629 175 22 3685 9 50 23 1572 87 108 214 9 27 110 7 9][36 160 728 5 2 17 11 113 2012 7 12 1438 56 517 87 108 214 20 66 0][12 212 4 857 256 353 48 3 0 798]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 42 307 60 3097 8629 175 22 3685 9]...][[1 1 1 1 1 1 1 0 0 0]...][[9 42 307 60 3097 8629 175 22 69848 69848]...][[42 307 60 3097 8629 175 22 3685 9 50]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 42 307 60 3097 8629 175 22 3685 9]...][[1 1 1 1 1 1 1 0 0 0]...][[9 42 307 60 3097 8629 175 22 69848 69848]...][[42 307 60 3097 8629 175 22 2343 13868 7]...]\n",
            "targets[[5 241 60 1628 869 848 9 84 307 7 85 7 13 36 0 5000 3 0 5916 1][20 367 2917 6385 98 10 29 5 2 203 40 1215 5 81 14 69 14 40 116 6][112 461 9124 98 32 25 81 247 4 106]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10091 5 241 60 1628 869 848 9 84 307]...][[1 0 0 0 0 0 0 0 0 0]...][[10091 5 69848 69848 69848 69848 69848 69848 69848 69848]...][[5 241 60 1628 869 848 9 84 307 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10091 5 241 60 1628 869 848 9 84 307]...][[1 0 0 0 0 0 0 0 0 0]...][[10091 5 69848 69848 69848 69848 69848 69848 69848 69848]...][[5 0 57 13 2 876 1554 2 153 9484]...]\n",
            "targets[[27 64 110 422 105 61 13 1933 14 0 354 22 0 28500 422 111 32 307 0 13931][182 4 366 33 7342 9 242 2 9237 58 152 9 89 21 1046 15 2 171 3 0][13 53 671 15 2804 2126 9 27 77 35]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 27 64 110 422 105 61 13 1933 14]...][[1 1 1 1 0 0 0 0 0 0]...][[9 27 64 110 422 69848 69848 69848 69848 69848]...][[27 64 110 422 105 61 13 1933 14 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 27 64 110 422 105 61 13 1933 14]...][[1 1 1 1 0 0 0 0 0 0]...][[9 27 64 110 422 69848 69848 69848 69848 69848]...][[27 64 110 422 0 217 98 9 113 112]...]\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[1 1 1 0 0 0 0 0 0 0]...][[4831 4881 3905 12 69848 69848 69848 69848 69848 69848]...][[4881 3905 12 2386 2711 1 107 506 1 37]...]\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[1 1 1 0 0 0 0 0 0 0]...][[4831 4881 3905 12 69848 69848 69848 69848 69848 69848]...][[4881 3905 12 88 1571 237 1 1675 698 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[1 1 1 0 0 0 0 0 0 0]...][[4831 4881 3905 12 69848 69848 69848 69848 69848 69848]...][[4881 3905 12 1171 1227 9 169 43 0 155]...]\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "global_step: 7656\n",
            " perplexity: 418.923\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            " percent of 3-grams captured: 0.345.\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            " percent of 2-grams captured: 0.651.\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            " percent of 4-grams captured: 0.118.\n",
            " geometric_avg: 0.298.\n",
            " arithmetic_avg: 0.371.\n",
            "global_step: 7656\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39170\n",
            " G train loss: -7.97850\n",
            "targets[[4881 3905 12 88 1571 237 1 1675 698 0 243 45 654 8 2 173 294 40 590 9][0 245 6388 1141 547 3 20634 15617 1 4172 7852 27 13139 4 443 38 2 1670 8 2][1426 291 158 396 33927 5 1448 36 2292 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[1 1 1 0 0 0 0 0 0 0]...][[4831 4881 3905 12 69848 69848 69848 69848 69848 69848]...][[4881 3905 12 88 1571 237 1 1675 698 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4831 4881 3905 12 88 1571 237 1 1675 698]...][[1 1 1 0 0 0 0 0 0 0]...][[4831 4881 3905 12 69848 69848 69848 69848 69848 69848]...][[4881 3905 12 409 4 7663 4 3698 579 22]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  meryl               0.616        0.000        0.000        0.000        -2.698       -3.832       0.000        \n",
            "   [1]  streep              0.887        0.000        0.000        0.000        -3.053       -10.495      0.000        \n",
            "   [1]  s                   0.654        0.000        0.000        0.000        -3.455       -2.997       -0.000       \n",
            "   [0]  live                0.568        6.758        -7.714       -0.566       -3.911       -6.782       2.872        \n",
            "   [0]  to                  0.656        9.474        -2.692       -0.422       -3.786       -5.330       1.544        \n",
            "   [0]  powered             0.562        8.923        -11.294      -0.576       -3.807       -6.251       2.444        \n",
            "   [0]  to                  0.446        3.462        -3.440       -0.808       -3.657       -10.052      5.000        \n",
            "   [0]  props               0.384        9.456        -10.676      -0.958       -3.224       -7.378       4.153        \n",
            "   [0]  taken               0.341        8.664        -8.312       -1.074       -2.565       -9.430       5.000        \n",
            "   [0]  on                  0.473        2.500        -4.334       -0.748       -1.687       -11.191      5.000        \n",
            "   [0]  a                   0.515        8.705        -2.000       -0.664       -1.062       -6.511       5.000        \n",
            "   [0]  propaganda          0.637        9.127        -9.486       -0.451       -0.451       -8.459       5.000        \n",
            "   [1]  turned              0.840        0.000        0.000        0.000        0.000        -6.743       0.000        \n",
            "   [1]  in                  0.796        0.000        0.000        0.000        0.000        -6.227       0.000        \n",
            "   [1]  a                   0.832        0.000        0.000        0.000        0.000        -6.979       0.000        \n",
            "   [1]  few                 0.887        0.000        0.000        0.000        0.000        -8.090       0.000        \n",
            "   [1]  during              0.919        0.000        0.000        0.000        0.000        -7.351       0.000        \n",
            "   [1]  her                 0.948        0.000        0.000        0.000        0.000        -5.695       0.000        \n",
            "   [1]  career              0.996        0.000        0.000        0.000        0.000        -6.814       0.000        \n",
            "   [1]  i                   0.995        0.000        0.000        0.000        0.000        -7.855       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  the                 0.311        0.000        0.000        0.000        -5.954       -4.193       -0.000       \n",
            "   [1]  hard                0.514        0.000        0.000        0.000        -6.739       -8.310       0.000        \n",
            "   [1]  boiled              0.582        0.000        0.000        0.000        -7.627       -6.848       -0.000       \n",
            "   [1]  detective           0.534        0.000        0.000        0.000        -8.632       -8.613       -0.000       \n",
            "   [1]  stories             0.534        0.000        0.000        0.000        -9.769       -8.693       -0.000       \n",
            "   [1]  of                  0.490        0.000        0.000        0.000        -11.057      -10.636      -0.000       \n",
            "   [1]  dashiell            0.554        0.000        0.000        0.000        -12.514      -6.194       -0.000       \n",
            "   [1]  hammett             0.576        0.000        0.000        0.000        -14.163      -9.030       -0.000       \n",
            "   [1]  and                 0.551        0.000        0.000        0.000        -16.029      -11.768      -0.000       \n",
            "   [1]  raymond             0.600        0.000        0.000        0.000        -18.141      -10.142      -0.000       \n",
            "   [1]  chandler            0.453        0.000        0.000        0.000        -20.532      -11.212      -0.000       \n",
            "   [0]  made                0.063        6.604        -6.855       -2.767       -23.237      -11.759      -5.000       \n",
            "   [0]  james               0.083        15.266       -7.776       -2.492       -23.168      -10.885      -5.000       \n",
            "   [0]  ii                  0.034        6.000        -7.615       -3.374       -23.401      -11.453      -5.000       \n",
            "   [0]  threatening         0.023        7.316        -12.065      -3.788       -22.666      -9.846       -5.000       \n",
            "   [0]  to                  0.011        6.596        -4.333       -4.533       -21.365      -11.911      -5.000       \n",
            "   [0]  an                  0.006        3.746        -5.036       -5.199       -19.050      -9.897       -5.000       \n",
            "   [0]  daily               0.003        8.958        -8.237       -5.882       -15.676      -10.277      -5.000       \n",
            "   [0]  aboriginal          0.002        4.079        -13.524      -6.316       -11.085      -12.026      0.941        \n",
            "   [0]  through             0.005        4.683        -6.707       -5.397       -5.397       -11.998      5.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  seven               0.562        0.000        0.000        0.000        -9.075       -4.078       -0.000       \n",
            "   [1]  year                0.575        0.000        0.000        0.000        -10.271      -9.318       -0.000       \n",
            "   [1]  old                 0.530        0.000        0.000        0.000        -11.624      -13.923      0.000        \n",
            "   [1]  boy                 0.692        0.000        0.000        0.000        -13.156      -10.749      -0.000       \n",
            "   [1]  omi                 0.527        0.000        0.000        0.000        -14.890      -9.742       -0.000       \n",
            "   [1]  is                  0.463        0.000        0.000        0.000        -16.852      -12.359      -0.000       \n",
            "   [0]  an                  0.537        7.713        -3.193       -0.621       -19.072      -11.532      -5.000       \n",
            "   [0]  shame               0.046        9.966        -8.021       -3.081       -20.883      -10.019      -5.000       \n",
            "   [0]  rated               0.050        10.252       -9.032       -2.997       -20.147      -13.520      -5.000       \n",
            "   [0]  destroy             0.017        3.469        -10.411      -4.080       -19.411      -11.107      -5.000       \n",
            "   [0]  one                 0.019        9.474        -5.859       -3.985       -17.351      -12.610      -4.741       \n",
            "   [0]  team                0.016        3.494        -9.305       -4.152       -15.128      -10.580      -4.548       \n",
            "   [0]  a                   0.010        5.424        -3.708       -4.576       -12.423      -10.865      -1.558       \n",
            "   [0]  demolishing         0.012        9.812        -12.509      -4.460       -8.881       -11.325      2.445        \n",
            "   [0]  who                 0.007        3.044        -4.356       -5.003       -5.003       -10.545      5.000        \n",
            "   [1]  ottawa              0.003        0.000        0.000        0.000        0.000        -11.410      0.000        \n",
            "   [1]  nobody              0.006        0.000        0.000        0.000        0.000        -10.026      0.000        \n",
            "   [1]  is                  0.007        0.000        0.000        0.000        0.000        -9.678       0.000        \n",
            "   [1]  told                0.020        0.000        0.000        0.000        0.000        -11.087      0.000        \n",
            "   [1]  that                0.023        0.000        0.000        0.000        0.000        -9.662       0.000        \n",
            "Samples\n",
            "Sample 0 .  meryl streep s live to powered to props taken on a propaganda turned in a few during her career i\n",
            "Sample 1 .  the hard boiled detective stories of dashiell hammett and raymond chandler made james ii threatening to an daily aboriginal through\n",
            "Sample 2 .  seven year old boy omi is an shame rated destroy one team a demolishing who ottawa nobody is told that\n",
            "\n",
            "\n",
            "targets[[646 5 23 53 49 1 9 140 767 16 11 18 10 17 5 29 3 0 8714 9][27 2 619 425 34 5 3999 107 1435 78 2 620 15 35 14721 34 45 2 194 2609][27 307 10 17 1 8 0 84 163 228]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 646 5 23 53 49 1 9 140 767]...][[1 1 0 0 0 0 0 0 0 0]...][[60 646 5 69848 69848 69848 69848 69848 69848 69848]...][[646 5 23 53 49 1 9 140 767 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 646 5 23 53 49 1 9 140 767]...][[1 1 0 0 0 0 0 0 0 0]...][[60 646 5 69848 69848 69848 69848 69848 69848 69848]...][[646 5 11 120 77 0 1904 190 11 9]...]\n",
            "targets[[1156 9964 19679 12754 1 7190 13498 1 513 33 4976 20663 5 2 81 184 19 15 745 3][215 10 19 440 154 602 1704 2487 1 9 1147 0 271 3 0 17 47 551 99 54][178 1253 12 2554 963 3025 5 2375 1 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4636 1156 9964 19679 12754 1 7190 13498 1 513]...][[1 1 1 1 1 1 1 1 1 1]...][[4636 1156 9964 19679 12754 1 7190 13498 1 513]...][[1156 9964 19679 12754 1 7190 13498 1 513 33]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4636 1156 9964 19679 12754 1 7190 13498 1 513]...][[1 1 1 1 1 1 1 1 1 1]...][[4636 1156 9964 19679 12754 1 7190 13498 1 513]...][[1156 9964 19679 12754 1 7190 13498 1 513 33]...]\n",
            "targets[[14362 17 650 246 768 8 2348 499 120 30 18355 393 8 0 653 904 61 5 81 23][215 10 22 3857 1 67 353 8 440 738 1177 11 10 13 2 1931 984 3 35 881][27 2260 55 884 12314 23329 193 0 3707 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 14362 17 650 246 768 8 2348 499 120]...][[1 1 0 0 0 0 0 0 0 0]...][[10 14362 17 69848 69848 69848 69848 69848 69848 69848]...][[14362 17 650 246 768 8 2348 499 120 30]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 14362 17 650 246 768 8 2348 499 120]...][[1 1 0 0 0 0 0 0 0 0]...][[10 14362 17 69848 69848 69848 69848 69848 69848 69848]...][[14362 17 371 870 8 0 17058 15 1039 41]...]\n",
            "targets[[21 138 66 10 19 31 219 89 21 46 20 148 2 527 41 46 20 424 0 84][19 5 2 114 46934 2571 3 29 125 12 1068 3 26 466 9043 4 0 75 1265 1][7593 203 66 46 20 25 35 2362 340 38]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[89 21 138 66 10 19 31 219 89 21]...][[1 1 1 1 1 0 0 0 0 0]...][[89 21 138 66 10 19 69848 69848 69848 69848]...][[21 138 66 10 19 31 219 89 21 46]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[89 21 138 66 10 19 31 219 89 21]...][[1 1 1 1 1 0 0 0 0 0]...][[89 21 138 66 10 19 69848 69848 69848 69848]...][[21 138 66 10 19 429 31 1241 18 46]...]\n",
            "targets[[75 122 9 140 1125 1 27 77 149 0 122 233 9 13 1750 7 1646 60 2407 889][19 45 49 101 15 322 347 36 0 177 577 14902 5 23250 4640 14 0 493 21262 7338][9 387 0 1359 3 11188 729 9 113 2755]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[158 75 122 9 140 1125 1 27 77 149]...][[1 1 1 1 1 0 0 0 0 0]...][[158 75 122 9 140 1125 69848 69848 69848 69848]...][[75 122 9 140 1125 1 27 77 149 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[158 75 122 9 140 1125 1 27 77 149]...][[1 1 1 1 1 0 0 0 0 0]...][[158 75 122 9 140 1125 69848 69848 69848 69848]...][[75 122 9 140 1125 446 300 47 0 117]...]\n",
            "targets[[25 105 179 11 749 44 8 10 19 0 2810 125 252 33 5019 14570 1 0 31213 11930][8 30 10 5 241 8 60 351 463 1177 654 17 9 437 467 0 298 51 9 353][27 110 10 119 163 214 8 463 483 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[39 25 105 179 11 749 44 8 10 19]...][[1 1 1 1 1 1 1 0 0 0]...][[39 25 105 179 11 749 44 8 69848 69848]...][[25 105 179 11 749 44 8 10 19 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[39 25 105 179 11 749 44 8 10 19]...][[1 1 1 1 1 1 1 0 0 0]...][[39 25 105 179 11 749 44 8 69848 69848]...][[25 105 179 11 749 44 8 3658 7 13]...]\n",
            "targets[[7184 285 13293 17005 2233 3699 1 52 72 2 115 8340 294 0 370 2032 416 17005 5 2][60 568 1 9 418 4 66 10 17 70 2736 7 3002 85 2 7 288 21 29 3][1293 63 2982 22 0 935 3 14622 3 49206]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[780 7184 285 13293 17005 2233 3699 1 52 72]...][[1 1 1 1 1 1 1 1 1 1]...][[780 7184 285 13293 17005 2233 3699 1 52 72]...][[7184 285 13293 17005 2233 3699 1 52 72 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[780 7184 285 13293 17005 2233 3699 1 52 72]...][[1 1 1 1 1 1 1 1 1 1]...][[780 7184 285 13293 17005 2233 3699 1 52 72]...][[7184 285 13293 17005 2233 3699 1 52 72 2]...]\n",
            "targets[[187 0 2511 1720 3 1047 30862 0 1535 2107 15 5100 34 10662 62 423 85 2 1325 702][1264 17 123 7 13 2 49 321 15 49 35600 839 2097 35600 67 437 161 4 80 0][47 0 1104 3 10 3920 1470 68 259 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[427 187 0 2511 1720 3 1047 30862 0 1535]...][[1 1 1 1 1 1 1 1 0 0]...][[427 187 0 2511 1720 3 1047 30862 0 69848]...][[187 0 2511 1720 3 1047 30862 0 1535 2107]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[427 187 0 2511 1720 3 1047 30862 0 1535]...][[1 1 1 1 1 1 1 1 0 0]...][[427 187 0 2511 1720 3 1047 30862 0 69848]...][[187 0 2511 1720 3 1047 30862 0 2051 403]...]\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 1 1 1 1 1 1 1 0 0]...][[165 221 283 9 1818 89 21 940 22 69848]...][[221 283 9 1818 89 21 940 22 151 11]...]\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 1 1 1 1 1 1 1 0 0]...][[165 221 283 9 1818 89 21 940 22 69848]...][[221 283 9 1818 89 21 940 22 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 1 1 1 1 1 1 1 0 0]...][[165 221 283 9 1818 89 21 940 22 69848]...][[221 283 9 1818 89 21 940 22 0 321]...]\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "global_step: 7673\n",
            " perplexity: 419.635\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            " percent of 3-grams captured: 0.360.\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            " percent of 2-grams captured: 0.647.\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            " percent of 4-grams captured: 0.113.\n",
            " geometric_avg: 0.297.\n",
            " arithmetic_avg: 0.373.\n",
            "global_step: 7673\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39133\n",
            " G train loss: -7.90662\n",
            "targets[[221 283 9 1818 89 21 940 22 104 9 723 21 110 30 0 95 144 18 233 9][5 42 29 3 146 3256 2446 28 540 328 2684 6540 92 8 1916 9 80 23 121 134][1 338 67 77 22 0 5257 14 0 6498]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 1 1 1 1 1 1 1 0 0]...][[165 221 283 9 1818 89 21 940 22 69848]...][[221 283 9 1818 89 21 940 22 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[165 221 283 9 1818 89 21 940 22 104]...][[1 1 1 1 1 1 1 1 0 0]...][[165 221 283 9 1818 89 21 940 22 69848]...][[221 283 9 1818 89 21 940 22 300 35]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  almost              0.671        0.000        0.000        0.000        -9.668       -4.085       -0.000       \n",
            "   [1]  everything          0.651        0.000        0.000        0.000        -10.942      -5.627       -0.000       \n",
            "   [1]  i                   0.658        0.000        0.000        0.000        -12.384      -6.076       -0.000       \n",
            "   [1]  normally            0.645        0.000        0.000        0.000        -14.015      -7.095       -0.000       \n",
            "   [1]  don                 0.590        0.000        0.000        0.000        -15.862      -7.368       -0.000       \n",
            "   [1]  t                   0.632        0.000        0.000        0.000        -17.953      -7.588       -0.000       \n",
            "   [1]  comment             0.430        0.000        0.000        0.000        -20.318      -6.842       -0.000       \n",
            "   [1]  on                  0.504        0.000        0.000        0.000        -22.996      -8.800       -0.000       \n",
            "   [0]  said                0.260        7.327        -8.115       -1.346       -26.026      -8.708       -5.000       \n",
            "   [0]  an                  0.209        1.811        -6.707       -1.563       -27.932      -9.933       -5.000       \n",
            "   [0]  actors              0.016        11.245       -6.825       -4.161       -29.844      -9.510       -5.000       \n",
            "   [0]  of                  0.005        8.599        -3.465       -5.271       -29.067      -12.422      -5.000       \n",
            "   [0]  this                0.005        9.871        -2.152       -5.342       -26.932      -14.312      -5.000       \n",
            "   [0]  movies              0.001        4.730        -4.378       -7.060       -24.436      -10.324      -5.000       \n",
            "   [0]  has                 0.001        4.163        -4.540       -6.989       -19.666      -15.004      -4.662       \n",
            "   [0]  i                   0.000        9.129        -2.747       -7.606       -14.347      -11.731      -2.616       \n",
            "   [0]  had                 0.000        14.254       -3.639       -7.629       -7.629       -13.764      5.000        \n",
            "   [1]  but                 0.001        0.000        0.000        0.000        0.000        -11.804      0.000        \n",
            "   [1]  since               0.001        0.000        0.000        0.000        0.000        -12.647      0.000        \n",
            "   [1]  i                   0.001        0.000        0.000        0.000        0.000        -13.882      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  is                  0.689        0.000        0.000        0.000        -1.219       -3.830       0.000        \n",
            "   [1]  just                0.658        0.000        0.000        0.000        -1.380       -10.887      0.000        \n",
            "   [1]  one                 0.621        0.000        0.000        0.000        -1.561       -8.004       0.000        \n",
            "   [1]  of                  0.585        0.000        0.000        0.000        -1.767       -10.211      0.000        \n",
            "   [1]  those               0.568        0.000        0.000        0.000        -2.000       -9.558       0.000        \n",
            "   [1]  pro                 0.501        0.000        0.000        0.000        -2.264       -11.726      0.000        \n",
            "   [1]  tend                0.566        0.000        0.000        0.000        -2.562       -11.403      0.000        \n",
            "   [1]  be                  0.071        0.000        0.000        0.000        -2.900       -12.622      0.000        \n",
            "   [1]  art                 0.258        0.000        0.000        0.000        -3.282       -22.808      0.000        \n",
            "   [0]  is                  0.399        7.287        -5.620       -0.919       -3.714       -17.662      5.000        \n",
            "   [0]  it                  0.252        9.806        -3.982       -1.380       -3.164       -14.747      5.000        \n",
            "   [0]  played              0.533        10.952       -6.955       -0.629       -2.019       -15.102      5.000        \n",
            "   [0]  amparo              0.421        6.290        -14.392      -0.865       -1.573       -11.437      5.000        \n",
            "   [0]  to                  0.635        3.218        -3.314       -0.455       -0.802       -12.289      5.000        \n",
            "   [0]  length              0.909        10.655       -10.071      -0.096       -0.393       -12.281      5.000        \n",
            "   [0]  griffith            0.857        6.147        -9.194       -0.154       -0.336       -8.923       5.000        \n",
            "   [0]  men                 0.834        8.736        -7.657       -0.181       -0.206       -9.691       5.000        \n",
            "   [0]  re                  0.972        6.970        -9.288       -0.028       -0.028       -9.607       5.000        \n",
            "   [1]  know                0.976        0.000        0.000        0.000        0.000        -10.462      0.000        \n",
            "   [1]  why                 0.992        0.000        0.000        0.000        0.000        -11.881      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  and                 0.470        0.000        0.000        0.000        -8.241       -4.108       -0.000       \n",
            "   [1]  hollywood           0.413        0.000        0.000        0.000        -9.327       -7.563       -0.000       \n",
            "   [1]  had                 0.423        0.000        0.000        0.000        -10.556      -9.172       -0.000       \n",
            "   [0]  still               0.351        5.441        -6.232       -1.047       -11.947      -7.761       -4.186       \n",
            "   [0]  best                0.283        6.379        -6.428       -1.262       -12.337      -6.295       -5.000       \n",
            "   [0]  the                 0.214        1.859        -1.859       -1.541       -12.535      -10.952      -1.583       \n",
            "   [0]  life                0.104        9.466        -4.764       -2.260       -12.442      -9.577       -2.866       \n",
            "   [0]  wanting             0.087        4.297        -9.884       -2.447       -11.524      -12.242      0.718        \n",
            "   [0]  in                  0.030        2.587        -3.490       -3.519       -10.273      -11.715      1.442        \n",
            "   [0]  his                 0.069        14.725       -4.858       -2.680       -7.644       -11.440      3.796        \n",
            "   [0]  flaws               0.041        7.698        -8.050       -3.184       -5.618       -10.207      4.589        \n",
            "   [0]  into                0.064        3.979        -7.439       -2.755       -2.755       -11.313      5.000        \n",
            "   [1]  cinematic           0.049        0.000        0.000        0.000        0.000        -9.998       0.000        \n",
            "   [1]  world               0.052        0.000        0.000        0.000        0.000        -11.176      0.000        \n",
            "   [1]  for                 0.034        0.000        0.000        0.000        0.000        -10.450      0.000        \n",
            "   [1]  a                   0.035        0.000        0.000        0.000        0.000        -10.545      0.000        \n",
            "   [1]  little              0.048        0.000        0.000        0.000        0.000        -10.576      0.000        \n",
            "   [1]  over                0.070        0.000        0.000        0.000        0.000        -9.489       0.000        \n",
            "   [1]  a                   0.051        0.000        0.000        0.000        0.000        -10.359      0.000        \n",
            "   [1]  decade              0.056        0.000        0.000        0.000        0.000        -10.866      0.000        \n",
            "Samples\n",
            "Sample 0 .  almost everything i normally don t comment on said an actors of this movies has i had but since i\n",
            "Sample 1 .  is just one of those pro tend be art is it played amparo to length griffith men re know why\n",
            "Sample 2 .  and hollywood had still best the life wanting in his flaws into cinematic world for a little over a decade\n",
            "\n",
            "\n",
            "targets[[12 0 250 17 20 139 123 110 8 127 114 42 2682 143 1 103 43 7 80 20][17 5 8366 37 360 7 6462 0 1648 3 30 4415 87 374 80 0 1155 3 10 17][5 2 53 49 458 61 971 48 160 756]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 12 0 250 17 20 139 123 110 8]...][[1 1 1 1 1 1 1 0 0 0]...][[47 12 0 250 17 20 139 123 69848 69848]...][[12 0 250 17 20 139 123 110 8 127]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 12 0 250 17 20 139 123 110 8]...][[1 1 1 1 1 1 1 0 0 0]...][[47 12 0 250 17 20 139 123 69848 69848]...][[12 0 250 17 20 139 123 110 10 69]...]\n",
            "targets[[242 2 245 1960 3591 18 9 96 23 749 4576 933 15 0 1727 2 69 1202 18 1089][3823 16 0 1558 3 10 19 14 2 8233 9 13 23 1824 11 39 13 20191 8 0][6 650 959 45 0 2157 1 0 281 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 2 245 1960 3591 18 9 96 23]...][[1 1 1 1 1 1 1 1 0 0]...][[9 242 2 245 1960 3591 18 9 96 69848]...][[242 2 245 1960 3591 18 9 96 23 749]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 2 245 1960 3591 18 9 96 23]...][[1 1 1 1 1 1 1 1 0 0]...][[9 242 2 245 1960 3591 18 9 96 69848]...][[242 2 245 1960 3591 18 9 96 28 262]...]\n",
            "targets[[45 65 226 7 0 24423 5 35 181 17 31 7 117 7 45 283 35 181 487 784][215 21600 983 22 1901 29 311 9 196 0 17 13 49 0 101 68 212 1 790 13][9 67 303 1943 16 10 17 538 7 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[5817 45 65 226 7 0 24423 5 35 181]...][[1 1 1 0 0 0 0 0 0 0]...][[5817 45 65 226 69848 69848 69848 69848 69848 69848]...][[45 65 226 7 0 24423 5 35 181 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[5817 45 65 226 7 0 24423 5 35 181]...][[1 1 1 0 0 0 0 0 0 0]...][[5817 45 65 226 69848 69848 69848 69848 69848 69848]...][[45 65 226 328 3 193 7268 6322 3 2]...]\n",
            "targets[[2 1157 4601 10 5 4 1922 3229 2080 2312 1838 8208 1 1832 1882 0 1120 68 335 22230][10 17 0 2099 13290 8 45 2 81 3880 2 105 45759 36 0 3239 32 89 21 93][17 406 30 7 45 4 198 8 0 84]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 1157 4601 10 5 4 1922 3229 2080]...][[1 1 1 0 0 0 0 0 0 0]...][[47 2 1157 4601 69848 69848 69848 69848 69848 69848]...][[2 1157 4601 10 5 4 1922 3229 2080 2312]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 1157 4601 10 5 4 1922 3229 2080]...][[1 1 1 0 0 0 0 0 0 0]...][[47 2 1157 4601 69848 69848 69848 69848 69848 69848]...][[2 1157 4601 2404 4810 8 462 6363 107 1238]...]\n",
            "targets[[188 4 27 2 6622 3 259 3856 4 5313 26 779 10 19 1905 15 7471 1 32313 3773][112 0 5045 3 39727 3926 646 2289 39700 1 3412 26586 25 30 822 14 62 5572 101 60][42512 13 35 7388 102 4558 14 69 14 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[12935 188 4 27 2 6622 3 259 3856 4]...][[1 1 1 1 1 1 1 1 1 1]...][[12935 188 4 27 2 6622 3 259 3856 4]...][[188 4 27 2 6622 3 259 3856 4 5313]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[12935 188 4 27 2 6622 3 259 3856 4]...][[1 1 1 1 1 1 1 1 1 1]...][[12935 188 4 27 2 6622 3 259 3856 4]...][[188 4 27 2 6622 3 259 3856 4 5313]...]\n",
            "targets[[2908 8 0 2888 184 2621 11 6706 0 8158 3 127 711 378 1045 0 1250 11222 7407 1278][9 42 2065 11 39 5 2 122 52 2338 1 1618 72 115 2838 1 9 38 7 0][397 19 33 2264 1 16969 622 166 9 147]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[157 2908 8 0 2888 184 2621 11 6706 0]...][[1 1 1 1 1 1 1 0 0 0]...][[157 2908 8 0 2888 184 2621 11 69848 69848]...][[2908 8 0 2888 184 2621 11 6706 0 8158]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[157 2908 8 0 2888 184 2621 11 6706 0]...][[1 1 1 1 1 1 1 0 0 0]...][[157 2908 8 0 2888 184 2621 11 69848 69848]...][[2908 8 0 2888 184 2621 11 7 15964 240]...]\n",
            "targets[[9 50 387 53 69 134 108 75 59 722 10 17 30 3 0 101 352 1704 384 84][242 147 2441 14462 13012 5 29 3 764 12 88 13722 3278 1035 58687 13 49 0 117 61951][2 81 17 33 15515 20850 15 4831 0 117]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 9 50 387 53 69 134 108 75 59]...][[1 1 0 0 0 0 0 0 0 0]...][[147 9 50 69848 69848 69848 69848 69848 69848 69848]...][[9 50 387 53 69 134 108 75 59 722]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 9 50 387 53 69 134 108 75 59]...][[1 1 0 0 0 0 0 0 0 0]...][[147 9 50 69848 69848 69848 69848 69848 69848 69848]...][[9 50 38 1065 55 14 10 17 4 366]...]\n",
            "targets[[2 81 279 4 27 8 142 35 379 63 6 6 0 19 1 91 369 190 5 180][425 3 1867 529 71 10 17 2 425 3 1867 5 147 8 2 1511 68 2 739 3][1900 307 10 17 85 9 467 149 20905 17605]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 81 279 4 27 8 142 35 379]...][[1 1 1 1 1 1 0 0 0 0]...][[47 2 81 279 4 27 8 69848 69848 69848]...][[2 81 279 4 27 8 142 35 379 63]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 81 279 4 27 8 142 35 379]...][[1 1 1 1 1 1 0 0 0 0]...][[47 2 81 279 4 27 8 69848 69848 69848]...][[2 81 279 4 27 8 193 0 8304 125]...]\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[1 1 1 1 1 1 1 1 1 1]...][[147 10 5 29 3 200 12 117 685 12]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[1 1 1 1 1 1 1 1 1 1]...][[147 10 5 29 3 200 12 117 685 12]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[1 1 1 1 1 1 1 1 1 1]...][[147 10 5 29 3 200 12 117 685 12]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "global_step: 7690\n",
            " perplexity: 419.373\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            " percent of 3-grams captured: 0.323.\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            " percent of 2-grams captured: 0.632.\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            " percent of 4-grams captured: 0.109.\n",
            " geometric_avg: 0.281.\n",
            " arithmetic_avg: 0.354.\n",
            "global_step: 7690\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39180\n",
            " G train loss: -8.17872\n",
            "targets[[10 5 29 3 200 12 117 685 12 666 209 8 7321 3182 78 105 16 0 1248 66453][204 23 28 0 29 4 738 10 17 85 99 3595 228 3 1051 3203 1 3057 9 654][1959 2087 47 1117 2166 491 4 106 41 58]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[1 1 1 1 1 1 1 1 1 1]...][[147 10 5 29 3 200 12 117 685 12]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 10 5 29 3 200 12 117 685 12]...][[1 1 1 1 1 1 1 1 1 1]...][[147 10 5 29 3 200 12 117 685 12]...][[10 5 29 3 200 12 117 685 12 666]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  this                0.025        0.000        0.000        0.000        -1.291       -4.306       0.000        \n",
            "   [1]  is                  0.275        0.000        0.000        0.000        -1.462       -8.846       0.000        \n",
            "   [1]  one                 0.461        0.000        0.000        0.000        -1.654       -11.233      0.000        \n",
            "   [1]  of                  0.393        0.000        0.000        0.000        -1.872       -13.699      0.000        \n",
            "   [1]  big                 0.485        0.000        0.000        0.000        -2.119       -15.619      0.000        \n",
            "   [1]  s                   0.520        0.000        0.000        0.000        -2.398       -18.820      0.000        \n",
            "   [1]  best                0.456        0.000        0.000        0.000        -2.714       -14.548      0.000        \n",
            "   [1]  jack                0.494        0.000        0.000        0.000        -3.072       -13.079      0.000        \n",
            "   [1]  s                   0.532        0.000        0.000        0.000        -3.477       -12.932      0.000        \n",
            "   [1]  single              0.558        0.000        0.000        0.000        -3.935       -12.758      0.000        \n",
            "   [1]  role                0.758        0.000        0.000        0.000        -4.453       -11.987      0.000        \n",
            "   [0]  or                  0.525        3.224        -4.983       -0.645       -5.040       -11.690      5.000        \n",
            "   [0]  a                   0.403        12.924       -2.197       -0.910       -4.975       -10.765      5.000        \n",
            "   [0]  film                0.456        11.451       -3.527       -0.784       -4.601       -10.753      5.000        \n",
            "   [0]  i                   0.337        7.438        -2.501       -1.089       -4.320       -9.269       4.950        \n",
            "   [0]  did                 0.553        12.850       -4.921       -0.593       -3.657       -9.482       5.000        \n",
            "   [0]  watched             0.203        5.213        -4.651       -1.592       -3.468       -8.428       4.961        \n",
            "   [0]  this                0.416        2.102        -1.485       -0.878       -2.123       -9.914       5.000        \n",
            "   [0]  movie               0.498        13.446       -0.762       -0.697       -1.409       -8.909       5.000        \n",
            "   [0]  the                 0.447        19.246       -3.530       -0.806       -0.806       -9.288       5.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  may                 0.643        0.000        0.000        0.000        -14.004      -3.894       -0.000       \n",
            "   [1]  not                 0.521        0.000        0.000        0.000        -15.849      -10.238      -0.000       \n",
            "   [1]  be                  0.508        0.000        0.000        0.000        -17.938      -1.117       -0.000       \n",
            "   [0]  this                0.205        2.477        -2.621       -1.584       -20.302      -5.495       -5.000       \n",
            "   [0]  film                0.127        3.632        -2.226       -2.060       -21.184      -6.254       -5.000       \n",
            "   [0]  i                   0.035        3.533        -2.279       -3.359       -21.644      -6.717       -5.000       \n",
            "   [0]  hadn                0.059        9.157        -6.171       -2.824       -20.695      -7.280       -5.000       \n",
            "   [0]  enjoyed             0.010        10.695       -5.259       -4.595       -20.225      -7.558       -5.000       \n",
            "   [0]  some                0.016        7.638        -4.674       -4.165       -17.690      -11.253      -5.000       \n",
            "   [0]  film                0.004        5.612        -4.898       -5.575       -15.308      -8.380       -5.000       \n",
            "   [0]  but                 0.004        6.023        -3.314       -5.530       -11.015      -11.440      0.425        \n",
            "   [0]  them                0.002        12.238       -6.785       -6.208       -6.208       -9.541       3.332        \n",
            "   [1]  minutes             0.001        0.000        0.000        0.000        0.000        -12.088      0.000        \n",
            "   [1]  of                  0.002        0.000        0.000        0.000        0.000        -12.423      0.000        \n",
            "   [1]  pure                0.002        0.000        0.000        0.000        0.000        -10.995      0.000        \n",
            "   [1]  boredom             0.005        0.000        0.000        0.000        0.000        -9.900       0.000        \n",
            "   [1]  and                 0.009        0.000        0.000        0.000        0.000        -8.962       0.000        \n",
            "   [1]  stupidity           0.007        0.000        0.000        0.000        0.000        -8.101       0.000        \n",
            "   [1]  i                   0.005        0.000        0.000        0.000        0.000        -9.248       0.000        \n",
            "   [1]  turned              0.005        0.000        0.000        0.000        0.000        -9.299       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  regular             0.562        0.000        0.000        0.000        -8.697       -4.179       -0.000       \n",
            "   [1]  teens               0.546        0.000        0.000        0.000        -9.843       -8.525       -0.000       \n",
            "   [1]  what                0.404        0.000        0.000        0.000        -11.140      -7.146       -0.000       \n",
            "   [0]  s                   0.478        12.137       -2.760       -0.738       -12.608      -7.451       -5.000       \n",
            "   [0]  one                 0.443        9.913        -3.202       -0.814       -13.434      -8.670       -4.765       \n",
            "   [0]  of                  0.646        10.906       -0.650       -0.438       -14.283      -9.350       -4.933       \n",
            "   [0]  depth               0.275        8.711        -9.184       -1.290       -15.670      -7.409       -5.000       \n",
            "   [0]  a                   0.081        9.141        -5.398       -2.514       -16.275      -8.688       -5.000       \n",
            "   [0]  effect              0.017        8.619        -8.609       -4.069       -15.574      -9.699       -5.000       \n",
            "   [0]  of                  0.007        7.873        -1.798       -4.920       -13.021      -12.627      -0.394       \n",
            "   [0]  time                0.008        11.036       -5.747       -4.769       -9.169       -13.241      4.072        \n",
            "   [0]  in                  0.007        4.652        -3.298       -4.979       -4.979       -10.797      5.000        \n",
            "   [1]  some                0.009        0.000        0.000        0.000        0.000        -9.711       0.000        \n",
            "   [1]  spoilt              0.022        0.000        0.000        0.000        0.000        -9.214       0.000        \n",
            "   [1]  brat                0.009        0.000        0.000        0.000        0.000        -8.901       0.000        \n",
            "   [1]  who                 0.007        0.000        0.000        0.000        0.000        -9.705       0.000        \n",
            "   [1]  they                0.005        0.000        0.000        0.000        0.000        -10.473      0.000        \n",
            "   [1]  have                0.005        0.000        0.000        0.000        0.000        -9.502       0.000        \n",
            "   [1]  nothing             0.005        0.000        0.000        0.000        0.000        -8.399       0.000        \n",
            "   [1]  common              0.003        0.000        0.000        0.000        0.000        -9.761       0.000        \n",
            "Samples\n",
            "Sample 0 .  this is one of big s best jack s single role or a film i did watched this movie the\n",
            "Sample 1 .  may not be this film i hadn enjoyed some film but them minutes of pure boredom and stupidity i turned\n",
            "Sample 2 .  regular teens what s one of depth a effect of time in some spoilt brat who they have nothing common\n",
            "\n",
            "\n",
            "targets[[618 604 103 3 134 255 59 198 10 17 2 163 163 251 70 30 27 263 1355 8][5284 1832 1882 36180 13 969 154 158 97 158 16 0 172 2 17248 5240 1175 34 59 93][1022 1404 6 6 9 140 503 60 84 738]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 618 604 103 3 134 255 59 198 10]...][[1 1 0 0 0 0 0 0 0 0]...][[9 618 604 69848 69848 69848 69848 69848 69848 69848]...][[618 604 103 3 134 255 59 198 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 618 604 103 3 134 255 59 198 10]...][[1 1 0 0 0 0 0 0 0 0]...][[9 618 604 69848 69848 69848 69848 69848 69848 69848]...][[618 604 121 172 5443 3998 8 0 590 3322]...]\n",
            "targets[[17 65 3796 1911 17415 5 1349 8 0 19 26 960 1136 24 5 142 2 688 1630 1743][76 2 1992 44 3 0 108 101 22 0 122 469 2750 25587 604 345 18 712 26 894][12 23 42 11 10 5 2 74 17 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 65 3796 1911 17415 5 1349 8 0]...][[1 1 0 0 0 0 0 0 0 0]...][[10 17 65 69848 69848 69848 69848 69848 69848 69848]...][[17 65 3796 1911 17415 5 1349 8 0 19]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 65 3796 1911 17415 5 1349 8 0]...][[1 1 0 0 0 0 0 0 0 0]...][[10 17 65 69848 69848 69848 69848 69848 69848 69848]...][[17 65 2 81 553 7 10 111 9 672]...]\n",
            "targets[[179 28 58826 323 208 107 81 11 5 0 1565 61 9 242 2650 128 144 2 17 9589][64 82 19 1374 11279 1388 11 45 142 35 922 3 12393 5 22 0 1934 193 104 845][721 823 2908 8 0 202 2 858 7911 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[50 179 28 58826 323 208 107 81 11 5]...][[1 1 1 1 1 1 1 1 1 1]...][[50 179 28 58826 323 208 107 81 11 5]...][[179 28 58826 323 208 107 81 11 5 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[50 179 28 58826 323 208 107 81 11 5]...][[1 1 1 1 1 1 1 1 1 1]...][[50 179 28 58826 323 208 107 81 11 5]...][[179 28 58826 323 208 107 81 11 5 0]...]\n",
            "targets[[48 3 0 116 5 2014 0 17 1203 702 3 0 1735 3 2 81 5203 4 28 555][50 350 4 28 10308 9 50 350 4 28 1799 9 50 350 4 28 155 30 3 131][580 459 2190 44 3 163 6 6 0 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[264 48 3 0 116 5 2014 0 17 1203]...][[1 1 1 1 1 0 0 0 0 0]...][[264 48 3 0 116 5 69848 69848 69848 69848]...][[48 3 0 116 5 2014 0 17 1203 702]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[264 48 3 0 116 5 2014 0 17 1203]...][[1 1 1 1 1 0 0 0 0 0]...][[264 48 3 0 116 5 69848 69848 69848 69848]...][[48 3 0 116 5 77 2126 6928 2 9012]...]\n",
            "targets[[215 160 728 9 112 20 490 1 467 7 9 13 65 261 931 4 318 10 99 149][288 21 2 340 3 318 10 17 31 30 18 51 60 19653 446 71 1 300 54 67][16810 16 0 12189 16810 16 0 17 7 12]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 160 728 9 112 20 490 1 467]...][[1 1 1 1 1 0 0 0 0 0]...][[9 215 160 728 9 112 69848 69848 69848 69848]...][[215 160 728 9 112 20 490 1 467 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 160 728 9 112 20 490 1 467]...][[1 1 1 1 1 0 0 0 0 0]...][[9 215 160 728 9 112 69848 69848 69848 69848]...][[215 160 728 9 112 149 0 250 17 51]...]\n",
            "targets[[103 11 862 185 8 0 9678 64955 172 3 62 485 295 1200 1625 7778 42 2 115 222][96 28 11 60 112 3 1116 928 104 8 746 406 71 2 7221 18 9 993 10 19][5 270 9 121 43 35355 1 4918 18 56]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 103 11 862 185 8 0 9678 64955 172]...][[1 1 1 1 1 1 1 1 1 1]...][[9 103 11 862 185 8 0 9678 64955 172]...][[103 11 862 185 8 0 9678 64955 172 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 103 11 862 185 8 0 9678 64955 172]...][[1 1 1 1 1 1 1 1 1 1]...][[9 103 11 862 185 8 0 9678 64955 172]...][[103 11 862 185 8 0 9678 64955 172 3]...]\n",
            "targets[[137 1749 1 297 5 4247 1237 87 4 1176 7 1 1481 7 292 208 235 7 6784 5][17 5 427 22 7740 117 10934 33 45442 38311 1 13 513 33 24172 193 322 241 83 28][141 28 542 167 9 366 11 9 140 23]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[503 137 1749 1 297 5 4247 1237 87 4]...][[1 1 1 1 1 1 1 0 0 0]...][[503 137 1749 1 297 5 4247 1237 69848 69848]...][[137 1749 1 297 5 4247 1237 87 4 1176]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[503 137 1749 1 297 5 4247 1237 87 4]...][[1 1 1 1 1 1 1 0 0 0]...][[503 137 1749 1 297 5 4247 1237 69848 69848]...][[137 1749 1 297 5 4247 1237 4 106 98]...]\n",
            "targets[[5 37 504 9 42 467 174 670 54 45 123 226 3386 1 6970 5320 12 6123 460 4924][12 37 73 356 15 10 17 9 1184 121 111 4 366 84 431 56 870 9 80 121][267 1990 356 8 10 7978 2510 3 1243 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3281 5 37 504 9 42 467 174 670 54]...][[1 1 1 1 1 1 1 1 0 0]...][[3281 5 37 504 9 42 467 174 670 69848]...][[5 37 504 9 42 467 174 670 54 45]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3281 5 37 504 9 42 467 174 670 54]...][[1 1 1 1 1 1 1 1 0 0]...][[3281 5 37 504 9 42 467 174 670 69848]...][[5 37 504 9 42 467 174 670 15 421]...]\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[1 1 1 1 1 1 1 1 1 1]...][[35 276 4743 491 4 1738 2 1437 22 2]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[1 1 1 1 1 1 1 1 1 1]...][[35 276 4743 491 4 1738 2 1437 22 2]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[1 1 1 1 1 1 1 1 1 1]...][[35 276 4743 491 4 1738 2 1437 22 2]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "global_step: 7707\n",
            " perplexity: 418.853\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            " percent of 3-grams captured: 0.333.\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            " percent of 2-grams captured: 0.641.\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            " percent of 4-grams captured: 0.112.\n",
            " geometric_avg: 0.288.\n",
            " arithmetic_avg: 0.362.\n",
            "global_step: 7707\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39134\n",
            " G train loss: -8.48653\n",
            "targets[[276 4743 491 4 1738 2 1437 22 2 2727 958 37 24 45 286 13287 86 1 26 939][483 99 318 29307 14030 9 242 133 8 4313 11 100 522 3 75 59 1143 37 73 57][112 2 19 11 150 21 0 109 1 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[1 1 1 1 1 1 1 1 1 1]...][[35 276 4743 491 4 1738 2 1437 22 2]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 276 4743 491 4 1738 2 1437 22 2]...][[1 1 1 1 1 1 1 1 1 1]...][[35 276 4743 491 4 1738 2 1437 22 2]...][[276 4743 491 4 1738 2 1437 22 2 2727]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  american            0.182        0.000        0.000        0.000        -1.580       -4.299       0.000        \n",
            "   [1]  businessman         0.463        0.000        0.000        0.000        -1.789       -7.224       0.000        \n",
            "   [1]  wants               0.647        0.000        0.000        0.000        -2.024       -7.470       0.000        \n",
            "   [1]  to                  0.516        0.000        0.000        0.000        -2.291       -7.709       0.000        \n",
            "   [1]  build               0.529        0.000        0.000        0.000        -2.593       -9.930       0.000        \n",
            "   [1]  a                   0.542        0.000        0.000        0.000        -2.935       -8.509       0.000        \n",
            "   [1]  hotel               0.593        0.000        0.000        0.000        -3.321       -7.750       0.000        \n",
            "   [1]  on                  0.639        0.000        0.000        0.000        -3.759       -8.654       0.000        \n",
            "   [1]  a                   0.579        0.000        0.000        0.000        -4.254       -8.289       0.000        \n",
            "   [1]  remote              0.697        0.000        0.000        0.000        -4.815       -7.351       0.000        \n",
            "   [1]  island              0.759        0.000        0.000        0.000        -5.449       -11.669      0.000        \n",
            "   [0]  they                0.619        5.879        -5.502       -0.479       -6.167       -14.010      5.000        \n",
            "   [0]  ve                  0.585        6.906        -5.602       -0.535       -6.438       -10.503      4.065        \n",
            "   [0]  another             0.429        5.198        -7.734       -0.847       -6.680       -10.671      3.991        \n",
            "   [0]  old                 0.318        8.891        -6.638       -1.145       -6.602       -8.904       2.301        \n",
            "   [0]  and                 0.325        12.785       -4.053       -1.125       -6.177       -8.960       2.783        \n",
            "   [0]  not                 0.384        7.957        -5.360       -0.956       -5.718       -9.200       3.483        \n",
            "   [0]  mess                0.364        5.513        -9.565       -1.011       -5.389       -9.140       3.751        \n",
            "   [0]  s                   0.073        5.022        -5.686       -2.612       -4.955       -9.930       4.975        \n",
            "   [0]  other               0.071        8.925        -5.484       -2.652       -2.652       -20.467      5.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  days                0.176        0.000        0.000        0.000        -9.818       -3.753       -0.000       \n",
            "   [1]  after               0.689        0.000        0.000        0.000        -11.112      -17.820      0.000        \n",
            "   [0]  realize             0.341        6.615        -10.508      -1.076       -12.576      -11.280      -1.296       \n",
            "   [0]  it                  0.387        16.165       -3.665       -0.950       -13.016      -12.400      -0.616       \n",
            "   [0]  is                  0.226        12.322       -1.651       -1.488       -13.656      -11.310      -2.346       \n",
            "   [0]  a                   0.182        5.406        -1.154       -1.701       -13.772      -13.049      -0.723       \n",
            "   [0]  way                 0.109        10.870       -5.105       -2.218       -13.662      -12.191      -1.471       \n",
            "   [0]  is                  0.075        7.732        -4.361       -2.595       -12.951      -12.931      -0.020       \n",
            "   [0]  the                 0.036        4.916        -1.379       -3.333       -11.721      -12.641      0.920        \n",
            "   [0]  order               0.008        10.912       -9.346       -4.795       -9.493       -12.709      3.217        \n",
            "   [0]  we                  0.005        3.096        -5.785       -5.316       -5.316       -14.054      5.000        \n",
            "   [1]  any                 0.005        0.000        0.000        0.000        0.000        -14.412      0.000        \n",
            "   [1]  group               0.011        0.000        0.000        0.000        0.000        -12.561      0.000        \n",
            "   [1]  of                  0.052        0.000        0.000        0.000        0.000        -12.504      0.000        \n",
            "   [1]  people              0.151        0.000        0.000        0.000        0.000        -10.324      0.000        \n",
            "   [1]  would               0.175        0.000        0.000        0.000        0.000        -10.062      0.000        \n",
            "   [1]  spend               0.292        0.000        0.000        0.000        0.000        -11.293      0.000        \n",
            "   [1]  so                  0.176        0.000        0.000        0.000        0.000        -9.749       0.000        \n",
            "   [1]  much                0.675        0.000        0.000        0.000        0.000        -12.213      0.000        \n",
            "   [1]  time                0.410        0.000        0.000        0.000        0.000        -10.488      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  love                0.547        0.000        0.000        0.000        -6.676       -3.951       -0.000       \n",
            "   [1]  a                   0.433        0.000        0.000        0.000        -7.556       -7.182       -0.000       \n",
            "   [0]  vote                0.418        4.135        -9.142       -0.872       -8.552       -6.329       -2.223       \n",
            "   [0]  to                  0.535        2.470        -2.900       -0.625       -8.692       -7.256       -1.436       \n",
            "   [0]  already             0.357        7.583        -7.299       -1.031       -9.129       -7.416       -1.714       \n",
            "   [0]  a                   0.163        5.884        -2.588       -1.813       -9.166       -8.361       -0.805       \n",
            "   [0]  huge                0.173        6.460        -4.532       -1.753       -8.321       -8.646       0.325        \n",
            "   [0]  moments             0.146        6.359        -7.388       -1.921       -7.435       -7.020       -0.415       \n",
            "   [0]  a                   0.077        2.352        -5.113       -2.568       -6.240       -8.876       2.636        \n",
            "   [0]  musical             0.139        5.666        -8.000       -1.972       -4.156       -9.655       5.000        \n",
            "   [0]  and                 0.084        5.394        -2.408       -2.472       -2.472       -7.403       4.931        \n",
            "   [1]  and                 0.050        0.000        0.000        0.000        0.000        -7.917       0.000        \n",
            "   [1]  the                 0.031        0.000        0.000        0.000        0.000        -9.908       0.000        \n",
            "   [1]  interest            0.069        0.000        0.000        0.000        0.000        -11.231      0.000        \n",
            "   [1]  in                  0.080        0.000        0.000        0.000        0.000        -8.637       0.000        \n",
            "   [1]  it                  0.119        0.000        0.000        0.000        0.000        -9.326       0.000        \n",
            "   [1]  to                  0.216        0.000        0.000        0.000        0.000        -7.736       0.000        \n",
            "   [1]  the                 0.368        0.000        0.000        0.000        0.000        -8.179       0.000        \n",
            "   [1]  audience            0.616        0.000        0.000        0.000        0.000        -8.126       0.000        \n",
            "   [1]  this                0.700        0.000        0.000        0.000        0.000        -7.865       0.000        \n",
            "Samples\n",
            "Sample 0 .  american businessman wants to build a hotel on a remote island they ve another old and not mess s other\n",
            "Sample 1 .  days after realize it is a way is the order we any group of people would spend so much time\n",
            "Sample 2 .  love a vote to already a huge moments a musical and and the interest in it to the audience this\n",
            "\n",
            "\n",
            "targets[[50 23 262 32 446 10 8438 223 118 0 153 58 1392 4 106 0 84 8438 10 19][32806 99 39897 389 143 15 15317 8 39897 61 13 3526 99 39897 6 6 0 19 5 2][591 10 204 28 3856 911 18 7 12 30]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 50 23 262 32 446 10 8438 223 118]...][[1 1 1 0 0 0 0 0 0 0]...][[9 50 23 262 69848 69848 69848 69848 69848 69848]...][[50 23 262 32 446 10 8438 223 118 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 50 23 262 32 446 10 8438 223 118]...][[1 1 1 0 0 0 0 0 0 0]...][[9 50 23 262 69848 69848 69848 69848 69848 69848]...][[50 23 262 387 20 64 49 1 9 96]...]\n",
            "targets[[5 404 64 99 154 1372 11 70 50 168 143 1 66 146 399 34 25 371 399 14][140 23 1085 251 47 4 93 3 10 19 9 1725 9 365 4 667 7 31 219 282][307 3571 691 52 214 11 30 60 355 278]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 404 64 99 154 1372 11 70 50]...][[1 1 1 1 1 0 0 0 0 0]...][[7 5 404 64 99 154 69848 69848 69848 69848]...][[5 404 64 99 154 1372 11 70 50 168]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 404 64 99 154 1372 11 70 50]...][[1 1 1 1 1 0 0 0 0 0]...][[7 5 404 64 99 154 69848 69848 69848 69848]...][[5 404 64 99 154 2 360 19 3 4053]...]\n",
            "targets[[7 16 30 0 996 1067 8 0 82 11566 0 116 13 74 0 109 934 3169 292 87][47 9 67 555 1 353 3 10 17 9 13 248 1027 4 169 2 3074 63 3 1668][5582 246 17 3 0 1325 13 2 1659 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1653 7 16 30 0 996 1067 8 0 82]...][[1 1 1 1 0 0 0 0 0 0]...][[1653 7 16 30 0 69848 69848 69848 69848 69848]...][[7 16 30 0 996 1067 8 0 82 11566]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1653 7 16 30 0 996 1067 8 0 82]...][[1 1 1 1 0 0 0 0 0 0]...][[1653 7 16 30 0 69848 69848 69848 69848 69848]...][[7 16 30 0 206 17 50 21 1208 11]...]\n",
            "targets[[653 717 5 2 2102 2 2382 2925 199 1306 1 0 1378 96 27 1435 178 78 0 17][3199 1348 115 17 4 28 251 18 2 4083 2967 29 9088 6426 3198 8 10 407 4848 16][13 133 2 1178 1 67 401 23 400 26]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 653 717 5 2 2102 2 2382 2925 199]...][[1 1 1 1 0 0 0 0 0 0]...][[0 653 717 5 2 69848 69848 69848 69848 69848]...][[653 717 5 2 2102 2 2382 2925 199 1306]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 653 717 5 2 2102 2 2382 2925 199]...][[1 1 1 1 0 0 0 0 0 0]...][[0 653 717 5 2 69848 69848 69848 69848 69848]...][[653 717 5 2 4835 166 755 40367 22990 153]...]\n",
            "targets[[0 7343 1707 1602 550 105 10368 3 0 95 78 0 17 9 389 16 0 1048 10 186][120 7243 5 2 69 326 19 11 188 2 222 1182 22 0 39607 31 214 0 17 747][9 215 5924 3 10 17 9 196 11 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 0 7343 1707 1602 550 105 10368 3 0]...][[1 1 1 1 1 1 1 1 1 1]...][[14 0 7343 1707 1602 550 105 10368 3 0]...][[0 7343 1707 1602 550 105 10368 3 0 95]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 0 7343 1707 1602 550 105 10368 3 0]...][[1 1 1 1 1 1 1 1 1 1]...][[14 0 7343 1707 1602 550 105 10368 3 0]...][[0 7343 1707 1602 550 105 10368 3 0 95]...]\n",
            "targets[[50 3213 2 363 3 454 259 4 2131 8 1 1165 22 0 27025 3 2 155 975 17][20 148 2 80 106 0 17 82 72 11 9 59 113 1478 4 255 11 32 141 106][17 5 53 155 38 51 11 37909 1773 3334]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 50 3213 2 363 3 454 259 4 2131]...][[1 1 1 0 0 0 0 0 0 0]...][[9 50 3213 2 69848 69848 69848 69848 69848 69848]...][[50 3213 2 363 3 454 259 4 2131 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 50 3213 2 363 3 454 259 4 2131]...][[1 1 1 0 0 0 0 0 0 0]...][[9 50 3213 2 69848 69848 69848 69848 69848 69848]...][[50 3213 2 1344 97 108 1039 3101 3269 7000]...]\n",
            "targets[[1 2471 4 60 84 738 287 71 366 33 674 11 0 17 5 23 273 149 925 20][99 745 3 245 166 2916 207 2 1166 13844 45 2 49 411 433 572 9584 200 5709 2689][75 136 32 112 286 11 32 112 62 231]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[5113 1 2471 4 60 84 738 287 71 366]...][[1 1 1 0 0 0 0 0 0 0]...][[5113 1 2471 4 69848 69848 69848 69848 69848 69848]...][[1 2471 4 60 84 738 287 71 366 33]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[5113 1 2471 4 60 84 738 287 71 366]...][[1 1 1 0 0 0 0 0 0 0]...][[5113 1 2471 4 69848 69848 69848 69848 69848 69848]...][[1 2471 4 198 14 30 1292 34 215 10]...]\n",
            "targets[[255 332 1327 11 1882 1769 13 23 165 22 1599 8 6634 15 0 372 3 0 177 30][37 24 12 23 2 414 2985 33 0 129 3 0 17 70 80 854 42 2 115 43][5 53 1247 16 2 19 4 1359 4 779]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[118 255 332 1327 11 1882 1769 13 23 165]...][[1 1 1 1 1 1 0 0 0 0]...][[118 255 332 1327 11 1882 1769 69848 69848 69848]...][[255 332 1327 11 1882 1769 13 23 165 22]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[118 255 332 1327 11 1882 1769 13 23 165]...][[1 1 1 1 1 1 0 0 0 0]...][[118 255 332 1327 11 1882 1769 69848 69848 69848]...][[255 332 1327 11 1882 1769 1225 5309 778 18]...]\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 1 1 1 1 0 0 0 0 0]...][[1321 46 20 27 2 115 69848 69848 69848 69848]...][[46 20 27 2 115 17 39 68 14 1197]...]\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 1 1 1 1 0 0 0 0 0]...][[1321 46 20 27 2 115 69848 69848 69848 69848]...][[46 20 27 2 115 119 35 541 4 496]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 1 1 1 1 0 0 0 0 0]...][[1321 46 20 27 2 115 69848 69848 69848 69848]...][[46 20 27 2 115 301 3 0 117 3]...]\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "global_step: 7724\n",
            " perplexity: 418.517\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            " percent of 3-grams captured: 0.339.\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            " percent of 2-grams captured: 0.635.\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            " percent of 4-grams captured: 0.111.\n",
            " geometric_avg: 0.288.\n",
            " arithmetic_avg: 0.362.\n",
            "global_step: 7724\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39178\n",
            " G train loss: -8.36217\n",
            "targets[[46 20 27 2 115 119 35 541 4 496 1 169 2856 4 28 97 1094 9 207 1478][467 10 17 7 12 371 1185 554 155 6288 1799 7 162 56 266 4 380 43 0 10047][17 50 2222 4 28 2 360 360 341 600]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 1 1 1 1 0 0 0 0 0]...][[1321 46 20 27 2 115 69848 69848 69848 69848]...][[46 20 27 2 115 119 35 541 4 496]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1321 46 20 27 2 115 119 35 541 4]...][[1 1 1 1 1 0 0 0 0 0]...][[1321 46 20 27 2 115 69848 69848 69848 69848]...][[46 20 27 2 115 19 18 10 5 2]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  if                  0.508        0.000        0.000        0.000        -1.954       -3.849       0.000        \n",
            "   [1]  you                 0.497        0.000        0.000        0.000        -2.211       -8.730       0.000        \n",
            "   [1]  have                0.670        0.000        0.000        0.000        -2.502       -5.656       0.000        \n",
            "   [1]  a                   0.548        0.000        0.000        0.000        -2.832       -7.600       0.000        \n",
            "   [1]  little              0.614        0.000        0.000        0.000        -3.205       -7.532       0.000        \n",
            "   [0]  film                0.419        9.159        -3.213       -0.870       -3.628       -5.378       1.751        \n",
            "   [0]  but                 0.512        8.869        -2.746       -0.670       -3.121       -8.871       5.000        \n",
            "   [0]  this                0.452        11.475       -3.287       -0.793       -2.774       -7.481       4.707        \n",
            "   [0]  is                  0.615        10.996       -1.298       -0.486       -2.242       -7.288       5.000        \n",
            "   [0]  a                   0.630        10.588       -1.112       -0.461       -1.988       -7.546       5.000        \n",
            "   [0]  backdrop            0.550        8.686        -8.565       -0.598       -1.728       -7.163       5.000        \n",
            "   [0]  but                 0.560        10.615       -3.763       -0.579       -1.278       -9.892       5.000        \n",
            "   [0]  it                  0.657        13.494       -2.519       -0.420       -0.791       -8.229       5.000        \n",
            "   [0]  is                  0.657        7.564        -1.322       -0.419       -0.419       -6.746       5.000        \n",
            "   [1]  be                  0.068        0.000        0.000        0.000        0.000        -8.512       0.000        \n",
            "   [1]  too                 0.145        0.000        0.000        0.000        0.000        -18.084      0.000        \n",
            "   [1]  exciting            0.386        0.000        0.000        0.000        0.000        -11.386      0.000        \n",
            "   [1]  i                   0.373        0.000        0.000        0.000        0.000        -8.564       0.000        \n",
            "   [1]  d                   0.511        0.000        0.000        0.000        0.000        -8.277       0.000        \n",
            "   [1]  suggest             0.637        0.000        0.000        0.000        0.000        -7.325       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  loved               0.666        0.000        0.000        0.000        -11.999      -3.919       -0.000       \n",
            "   [1]  this                0.788        0.000        0.000        0.000        -13.580      -10.658      -0.000       \n",
            "   [1]  movie               0.502        0.000        0.000        0.000        -15.369      -5.554       -0.000       \n",
            "   [0]  is                  0.270        3.475        -3.893       -1.310       -17.395      -7.753       -5.000       \n",
            "   [0]  the                 0.191        7.709        -1.665       -1.653       -18.204      -10.760      -5.000       \n",
            "   [0]  kid                 0.021        6.912        -4.468       -3.848       -18.732      -11.228      -5.000       \n",
            "   [0]  one                 0.025        11.721       -6.470       -3.686       -16.845      -14.081      -2.765       \n",
            "   [0]  of                  0.036        10.850       -2.041       -3.314       -14.894      -12.628      -2.266       \n",
            "   [0]  the                 0.058        7.772        -0.685       -2.843       -13.106      -11.387      -1.719       \n",
            "   [0]  concept             0.018        10.294       -7.374       -4.023       -11.616      -9.206       -2.409       \n",
            "   [0]  the                 0.012        10.717       -4.045       -4.437       -8.593       -11.942      3.349        \n",
            "   [0]  unusual             0.009        8.027        -8.068       -4.703       -4.703       -12.528      5.000        \n",
            "   [1]  makes               0.014        0.000        0.000        0.000        0.000        -12.091      0.000        \n",
            "   [1]  no                  0.014        0.000        0.000        0.000        0.000        -12.020      0.000        \n",
            "   [1]  sense               0.059        0.000        0.000        0.000        0.000        -10.747      0.000        \n",
            "   [1]  to                  0.035        0.000        0.000        0.000        0.000        -11.758      0.000        \n",
            "   [1]  tell                0.160        0.000        0.000        0.000        0.000        -11.725      0.000        \n",
            "   [1]  about               0.097        0.000        0.000        0.000        0.000        -10.602      0.000        \n",
            "   [1]  the                 0.069        0.000        0.000        0.000        0.000        -10.574      0.000        \n",
            "   [1]  contents            0.092        0.000        0.000        0.000        0.000        -10.156      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  movie               0.513        0.000        0.000        0.000        -1.860       -3.993       0.000        \n",
            "   [1]  can                 0.473        0.000        0.000        0.000        -2.105       -12.331      0.000        \n",
            "   [1]  claim               0.478        0.000        0.000        0.000        -2.383       -13.271      0.000        \n",
            "   [1]  to                  0.751        0.000        0.000        0.000        -2.697       -12.076      0.000        \n",
            "   [1]  be                  0.653        0.000        0.000        0.000        -3.052       -12.958      0.000        \n",
            "   [1]  a                   0.570        0.000        0.000        0.000        -3.455       -11.645      0.000        \n",
            "   [0]  big                 0.558        5.920        -4.788       -0.583       -3.910       -10.508      5.000        \n",
            "   [0]  friends             0.485        6.292        -6.755       -0.724       -3.766       -9.774       5.000        \n",
            "   [0]  urban               0.502        5.728        -9.472       -0.689       -3.443       -11.083      5.000        \n",
            "   [0]  years               0.800        8.577        -5.125       -0.223       -3.116       -8.929       5.000        \n",
            "   [0]  as                  0.657        4.559        -4.658       -0.420       -3.275       -10.843      5.000        \n",
            "   [0]  the                 0.552        7.626        -1.565       -0.594       -3.230       -9.641       5.000        \n",
            "   [0]  monumental          0.567        8.869        -10.023      -0.568       -2.984       -10.408      5.000        \n",
            "   [0]  horror              0.512        8.219        -5.965       -0.670       -2.734       -9.703       5.000        \n",
            "   [0]  myself              0.097        7.504        -9.069       -2.337       -2.337       -9.883       5.000        \n",
            "   [1]  actually            0.108        0.000        0.000        0.000        0.000        -13.083      0.000        \n",
            "   [1]  any                 0.052        0.000        0.000        0.000        0.000        -11.056      0.000        \n",
            "   [1]  talent              0.108        0.000        0.000        0.000        0.000        -10.372      0.000        \n",
            "   [1]  even                0.176        0.000        0.000        0.000        0.000        -10.129      0.000        \n",
            "   [1]  though              0.351        0.000        0.000        0.000        0.000        -9.405       0.000        \n",
            "Samples\n",
            "Sample 0 .  if you have a little film but this is a backdrop but it is be too exciting i d suggest\n",
            "Sample 1 .  loved this movie is the kid one of the concept the unusual makes no sense to tell about the contents\n",
            "Sample 2 .  movie can claim to be a big friends urban years as the monumental horror myself actually any talent even though\n",
            "\n",
            "\n",
            "targets[[9 215 10 22 1901 9 10431 7 13 36 0 4383 0 848 5 2 222 7258 1 0][46 0 19 68 23 3 1053 8 392 10 5 35 322 95 4 76 35 15316 3 0][5 42 29 670 16 10 19 3920 0 153]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[51 9 215 10 22 1901 9 10431 7 13]...][[1 1 1 1 1 1 1 1 1 1]...][[51 9 215 10 22 1901 9 10431 7 13]...][[9 215 10 22 1901 9 10431 7 13 36]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[51 9 215 10 22 1901 9 10431 7 13]...][[1 1 1 1 1 1 1 1 1 1]...][[51 9 215 10 22 1901 9 10431 7 13]...][[9 215 10 22 1901 9 10431 7 13 36]...]\n",
            "targets[[5 2 641 734 201 43 2 703 276 363 3138 105 13002 483 578 15 40 701 8 1547][286 83 191 105 3384 156 1 93 2 447 434 0 297 1641 3 10 19 5 11 7][5 3979 427 22 0 990 3 0 206 1001]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 641 734 201 43 2 703 276]...][[1 1 1 1 0 0 0 0 0 0]...][[10 5 2 641 734 69848 69848 69848 69848 69848]...][[5 2 641 734 201 43 2 703 276 363]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 641 734 201 43 2 703 276]...][[1 1 1 1 0 0 0 0 0 0]...][[10 5 2 641 734 69848 69848 69848 69848 69848]...][[5 2 641 734 1521 541 0 17 9 123]...]\n",
            "targets[[217 738 5 2 1250 18 46 39 123 13 2 17 11 932 7363 10 13 7 9 96][76 65 1520 3 98 38 739 764 18 10 969 291 158 17 150 21 58 198 791 16][103 11 580 12 1270 39 13 137 13762 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 217 738 5 2 1250 18 46 39 123]...][[1 1 1 1 1 1 1 1 1 1]...][[10 217 738 5 2 1250 18 46 39 123]...][[217 738 5 2 1250 18 46 39 123 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 217 738 5 2 1250 18 46 39 123]...][[1 1 1 1 1 1 1 1 1 1]...][[10 217 738 5 2 1250 18 46 39 123]...][[217 738 5 2 1250 18 46 39 123 13]...]\n",
            "targets[[329 4 28 294 0 19891 3 4275 11 7 1003 2 2855 16 1516 183 1967 20 865 143][0 28137 13 2 81 122 9 13 1408 154 158 51 7 3319 60 1231 59 106 7 15][1386 5 2 360 341 276 184 17 11 805]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 329 4 28 294 0 19891 3 4275 11]...][[1 1 1 1 1 1 1 1 1 1]...][[7 329 4 28 294 0 19891 3 4275 11]...][[329 4 28 294 0 19891 3 4275 11 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 329 4 28 294 0 19891 3 4275 11]...][[1 1 1 1 1 1 1 1 1 1]...][[7 329 4 28 294 0 19891 3 4275 11]...][[329 4 28 294 0 19891 3 4275 11 7]...]\n",
            "targets[[20 25 2 200 340 3 11631 10764 20 236 58 367 10 17 873 89 21 1143 127 57][243 113 2767 664 473 0 17 54 17039 174 344 1 2152 30 208 2 222 3 1242 1487][50 21 262 87 1153 0 829 16 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 25 2 200 340 3 11631 10764 20]...][[1 1 1 1 0 0 0 0 0 0]...][[46 20 25 2 200 69848 69848 69848 69848 69848]...][[20 25 2 200 340 3 11631 10764 20 236]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 25 2 200 340 3 11631 10764 20]...][[1 1 1 1 0 0 0 0 0 0]...][[46 20 25 2 200 69848 69848 69848 69848 69848]...][[20 25 2 200 879 684 98 68 2199 35]...]\n",
            "targets[[17 5 35 1121 1 1262 6204 667 3 1560 1087 1 0 1104 9351 9 13 1520 15 0][3 60 30 57 1628 104 123 42 323 370 3 417 1487 2457 1204 1648 0 63 3124 14][12647 2591 5371 8 0 2304 5 2 1224 1056]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 5 35 1121 1 1262 6204 667 3]...][[1 1 1 1 1 1 1 0 0 0]...][[10 17 5 35 1121 1 1262 6204 69848 69848]...][[17 5 35 1121 1 1262 6204 667 3 1560]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 5 35 1121 1 1262 6204 667 3]...][[1 1 1 1 1 1 1 0 0 0]...][[10 17 5 35 1121 1 1262 6204 69848 69848]...][[17 5 35 1121 1 1262 6204 225 111 12]...]\n",
            "targets[[2 17 11 499 15 0 19430 3 105 4073 2187 50 21 28 30 74 6 6 0 834][122 123 0 101 25 1149 60 2753 25 11318 0 1868 1 8611 0 2293 1212 18 46325 5][11 562 4 10 231 32 1810 0 217 189]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 2 17 11 499 15 0 19430 3 105]...][[1 1 1 1 0 0 0 0 0 0]...][[147 2 17 11 499 69848 69848 69848 69848 69848]...][[2 17 11 499 15 0 19430 3 105 4073]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[147 2 17 11 499 15 0 19430 3 105]...][[1 1 1 1 0 0 0 0 0 0]...][[147 2 17 11 499 69848 69848 69848 69848 69848]...][[2 17 11 499 7 5 2 35 170 483]...]\n",
            "targets[[653 16695 319 71 43173 15 2807 31 62 18414 0 5999 339 3 0 31025 9653 0 18101 15052][84 1826 10 17 150 21 168 38 2 880 81 29 99 30 2 2917 1609 98 15 64][31505 13 165 0 229 52 3428 22675 3 268]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 653 16695 319 71 43173 15 2807 31 62]...][[1 1 1 1 1 1 1 1 0 0]...][[0 653 16695 319 71 43173 15 2807 31 69848]...][[653 16695 319 71 43173 15 2807 31 62 18414]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 653 16695 319 71 43173 15 2807 31 62]...][[1 1 1 1 1 1 1 1 0 0]...][[0 653 16695 319 71 43173 15 2807 31 69848]...][[653 16695 319 71 43173 15 2807 31 1089 8]...]\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[1 1 1 1 1 1 1 1 1 1]...][[2 371 337 63 15 2 1534 43 20239 112]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[1 1 1 1 1 1 1 1 1 1]...][[2 371 337 63 15 2 1534 43 20239 112]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[1 1 1 1 1 1 1 1 1 1]...][[2 371 337 63 15 2 1534 43 20239 112]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "global_step: 7741\n",
            " perplexity: 418.524\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            " percent of 3-grams captured: 0.316.\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            " percent of 2-grams captured: 0.643.\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            " percent of 4-grams captured: 0.112.\n",
            " geometric_avg: 0.283.\n",
            " arithmetic_avg: 0.357.\n",
            "global_step: 7741\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39128\n",
            " G train loss: -8.91292\n",
            "targets[[371 337 63 15 2 1534 43 20239 112 4471 10 1055 577 2146 19 10 13 257 1055 85][113 188 4 11642 71 87 74 104 50 165 28 18 10 5 35 2449 4 1648 87 124][194 602 9 1065 60 990 14 4 47 40013]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[1 1 1 1 1 1 1 1 1 1]...][[2 371 337 63 15 2 1534 43 20239 112]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 371 337 63 15 2 1534 43 20239 112]...][[1 1 1 1 1 1 1 1 1 1]...][[2 371 337 63 15 2 1534 43 20239 112]...][[371 337 63 15 2 1534 43 20239 112 4471]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  truly               0.425        0.000        0.000        0.000        -2.005       -4.229       0.000        \n",
            "   [1]  nice                0.812        0.000        0.000        0.000        -2.270       -6.949       0.000        \n",
            "   [1]  story               0.866        0.000        0.000        0.000        -2.569       -6.765       0.000        \n",
            "   [1]  with                0.782        0.000        0.000        0.000        -2.907       -9.519       0.000        \n",
            "   [1]  a                   0.785        0.000        0.000        0.000        -3.290       -10.913      0.000        \n",
            "   [1]  moral               0.762        0.000        0.000        0.000        -3.724       -10.455      0.000        \n",
            "   [1]  about               0.720        0.000        0.000        0.000        -4.215       -9.286       0.000        \n",
            "   [1]  brotherly           0.724        0.000        0.000        0.000        -4.770       -10.369      0.000        \n",
            "   [1]  love                0.689        0.000        0.000        0.000        -5.399       -10.525      0.000        \n",
            "   [1]  describes           0.507        0.000        0.000        0.000        -6.110       -10.305      0.000        \n",
            "   [0]  a                   0.439        5.149        -3.640       -0.823       -6.916       -11.343      4.427        \n",
            "   [0]  peckinpaugh         0.574        7.732        -15.178      -0.556       -6.895       -11.631      4.736        \n",
            "   [0]  mr                  0.678        7.778        -8.411       -0.388       -7.175       -9.789       2.614        \n",
            "   [0]  lugosi              0.304        8.581        -8.669       -1.190       -7.681       -10.312      2.631        \n",
            "   [0]  exquisite           0.429        6.102        -11.779      -0.847       -7.347       -10.665      3.318        \n",
            "   [0]  who                 0.425        6.995        -4.024       -0.856       -7.356       -9.413       2.057        \n",
            "   [0]  it                  0.258        4.861        -6.750       -1.354       -7.356       -11.101      3.745        \n",
            "   [0]  guess               0.038        8.407        -7.986       -3.262       -6.793       -9.816       3.022        \n",
            "   [0]  to                  0.018        11.517       -2.358       -3.996       -3.996       -14.096      5.000        \n",
            "   [1]  because             0.005        0.000        0.000        0.000        0.000        -14.301      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  never               0.664        0.000        0.000        0.000        -6.877       -4.232       -0.000       \n",
            "   [1]  seems               0.651        0.000        0.000        0.000        -7.784       -5.273       -0.000       \n",
            "   [1]  to                  0.604        0.000        0.000        0.000        -8.809       -7.725       -0.000       \n",
            "   [1]  amaze               0.574        0.000        0.000        0.000        -9.970       -6.147       -0.000       \n",
            "   [1]  me                  0.548        0.000        0.000        0.000        -11.284      -8.512       -0.000       \n",
            "   [1]  how                 0.518        0.000        0.000        0.000        -12.771      -9.331       -0.000       \n",
            "   [1]  bad                 0.594        0.000        0.000        0.000        -14.454      -6.708       -0.000       \n",
            "   [1]  films               0.477        0.000        0.000        0.000        -16.359      -8.451       -0.000       \n",
            "   [1]  can                 0.623        0.000        0.000        0.000        -18.514      -10.340      -0.000       \n",
            "   [0]  not                 0.476        5.994        -4.841       -0.742       -20.954      -9.746       -5.000       \n",
            "   [0]  stuck               0.046        4.454        -8.862       -3.086       -22.876      -7.544       -5.000       \n",
            "   [0]  and                 0.023        3.495        -3.025       -3.784       -22.398      -17.663      -4.735       \n",
            "   [0]  the                 0.015        2.529        -1.107       -4.184       -21.066      -13.187      -5.000       \n",
            "   [0]  opinion             0.009        6.075        -6.041       -4.693       -19.107      -14.091      -5.000       \n",
            "   [0]  right               0.007        7.607        -8.068       -4.919       -16.314      -17.270      0.956        \n",
            "   [0]  in                  0.009        12.109       -3.687       -4.693       -12.897      -14.644      1.747        \n",
            "   [0]  people              0.009        5.416        -5.223       -4.694       -9.285       -13.356      4.071        \n",
            "   [0]  he                  0.006        13.218       -4.432       -5.196       -5.196       -13.325      5.000        \n",
            "   [1]  how                 0.005        0.000        0.000        0.000        0.000        -14.497      0.000        \n",
            "   [1]  does                0.008        0.000        0.000        0.000        0.000        -14.292      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  long                0.747        0.000        0.000        0.000        -1.555       -3.700       0.000        \n",
            "   [1]  ago                 0.714        0.000        0.000        0.000        -1.760       -5.953       0.000        \n",
            "   [1]  i                   0.686        0.000        0.000        0.000        -1.992       -12.361      0.000        \n",
            "   [1]  wrote               0.716        0.000        0.000        0.000        -2.255       -11.841      0.000        \n",
            "   [1]  my                  0.762        0.000        0.000        0.000        -2.552       -10.902      0.000        \n",
            "   [1]  ideas               0.707        0.000        0.000        0.000        -2.888       -10.651      0.000        \n",
            "   [1]  as                  0.500        0.000        0.000        0.000        -3.269       -8.836       0.000        \n",
            "   [1]  to                  0.325        0.000        0.000        0.000        -3.700       -10.386      0.000        \n",
            "   [0]  see                 0.598        7.163        -2.609       -0.515       -4.187       -8.093       3.906        \n",
            "   [0]  in                  0.244        17.537       -3.820       -1.410       -4.157       -7.338       3.181        \n",
            "   [0]  the                 0.210        10.292       -1.658       -1.560       -3.109       -9.905       5.000        \n",
            "   [0]  late                0.417        10.906       -5.475       -0.874       -1.752       -8.215       5.000        \n",
            "   [0]  video               0.773        10.883       -5.920       -0.258       -0.994       -6.875       5.000        \n",
            "   [0]  back                0.906        7.043        -6.282       -0.099       -0.833       -7.392       5.000        \n",
            "   [0]  that                0.736        7.461        -2.467       -0.306       -0.830       -8.845       5.000        \n",
            "   [0]  lied                0.731        9.200        -12.181      -0.314       -0.593       -9.106       5.000        \n",
            "   [0]  but                 0.729        3.991        -4.202       -0.317       -0.317       -8.335       5.000        \n",
            "   [1]  superman            0.745        0.000        0.000        0.000        0.000        -8.358       0.000        \n",
            "   [1]  cinema              0.774        0.000        0.000        0.000        0.000        -8.829       0.000        \n",
            "   [1]  s                   0.514        0.000        0.000        0.000        0.000        -9.009       0.000        \n",
            "Samples\n",
            "Sample 0 .  truly nice story with a moral about brotherly love describes a peckinpaugh mr lugosi exquisite who it guess to because\n",
            "Sample 1 .  never seems to amaze me how bad films can not stuck and the opinion right in people he how does\n",
            "Sample 2 .  long ago i wrote my ideas as to see in the late video back that lied but superman cinema s\n",
            "\n",
            "\n",
            "targets[[84 3 0 5715 895 1987 5 2 222 263 72 0 82 104 3 0 202 18 7 12][10 17 5 226 15 2 56 390 177 0 116 5 351 2490 0 156 141 28 358 2411][13 29 3 0 19303 55 16 0 310 1465]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 3 0 5715 895 1987 5 2 222]...][[1 1 1 1 1 1 1 0 0 0]...][[0 84 3 0 5715 895 1987 5 69848 69848]...][[84 3 0 5715 895 1987 5 2 222 263]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 3 0 5715 895 1987 5 2 222]...][[1 1 1 1 1 1 1 0 0 0]...][[0 84 3 0 5715 895 1987 5 69848 69848]...][[84 3 0 5715 895 1987 5 29 24 437]...]\n",
            "targets[[2 453 3 57 1 0 29 314 9 529 13 16 0 1561 7 13 2 53 49 1561][5 29 3 1669 12 117 104 3 7366 1 397 14 2 2939 1019 124 0 19 1443 18911][70 865 144 720 228 3 379 675 207 743]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 453 3 57 1 0 29 314 9]...][[1 0 0 0 0 0 0 0 0 0]...][[47 2 69848 69848 69848 69848 69848 69848 69848 69848]...][[2 453 3 57 1 0 29 314 9 529]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 453 3 57 1 0 29 314 9]...][[1 0 0 0 0 0 0 0 0 0]...][[47 2 69848 69848 69848 69848 69848 69848 69848 69848]...][[2 17 122 39 12 8658 427 10190 65995 7333]...]\n",
            "targets[[3246 104 930 0 11401 3 259 4 783 1181 31 0 2287 3 3315 388 4 706 41 58][13 73 73 126 72 9 196 7 13 164 4 28 4204 155 1 23 736 8 0 95][3457 15 10 17 141 28 5349 4 29 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[108 3246 104 930 0 11401 3 259 4 783]...][[1 1 1 1 1 1 1 1 1 1]...][[108 3246 104 930 0 11401 3 259 4 783]...][[3246 104 930 0 11401 3 259 4 783 1181]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[108 3246 104 930 0 11401 3 259 4 783]...][[1 1 1 1 1 1 1 1 1 1]...][[108 3246 104 930 0 11401 3 259 4 783]...][[3246 104 930 0 11401 3 259 4 783 1181]...]\n",
            "targets[[307 10 17 227 311 22 29 3 0 957 3136 667 4278 1 132 149 7 9 927 3580][243 20748 3906 2 3043 29 2015 31 4728 4900 11 2 2931 45 3000 0 75 8 300 3043][45 12684 60 1356 4627 9 282 196 11 31425]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 307 10 17 227 311 22 29 3 0]...][[1 1 1 1 1 1 1 1 1 1]...][[9 307 10 17 227 311 22 29 3 0]...][[307 10 17 227 311 22 29 3 0 957]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 307 10 17 227 311 22 29 3 0]...][[1 1 1 1 1 1 1 1 1 1]...][[9 307 10 17 227 311 22 29 3 0]...][[307 10 17 227 311 22 29 3 0 957]...]\n",
            "targets[[3 0 117 201 202 4 123 211 44 3 2838 947 38868 31141 58005 1 1255 34097 25 1349][1046 15 30 0 12410 9 418 144 2 889 3 17508 149 10 19 7 67 2 2478 5438][8864 1 3173 1484 199 15252 1 2 7880 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 117 201 202 4 123 211 44]...][[1 1 1 1 1 0 0 0 0 0]...][[29 3 0 117 201 202 69848 69848 69848 69848]...][[3 0 117 201 202 4 123 211 44 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 117 201 202 4 123 211 44]...][[1 1 1 1 1 0 0 0 0 0]...][[29 3 0 117 201 202 69848 69848 69848 69848]...][[3 0 117 201 202 2 17 5 5 29]...]\n",
            "targets[[103 11 50 2731 55 10 122 43 14 69 14 238 1734 19906 204 28 0 250 151 4][165 67 303 1943 16 10 17 51 149 7 8 0 443 31 2 19 1322 8 20395 0][215 10 19 34907 22 15615 1 418 4 66]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 103 11 50 2731 55 10 122 43 14]...][[1 1 1 1 1 1 0 0 0 0]...][[9 103 11 50 2731 55 10 69848 69848 69848]...][[103 11 50 2731 55 10 122 43 14 69]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 103 11 50 2731 55 10 122 43 14]...][[1 1 1 1 1 1 0 0 0 0]...][[9 103 11 50 2731 55 10 69848 69848 69848]...][[103 11 50 2731 55 10 17 210 21 303]...]\n",
            "targets[[2661 218 4 304 29 3 26 1247 49 216 558 8 2 1479 427 718 0 194 621 1771][140 2009 5875 0 18804 128 2 222 1 136 9 509 10 190 0 1084 5 65 64 164][3 30 287 71 42 136 9 50 21 749]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4212 2661 218 4 304 29 3 26 1247 49]...][[1 1 0 0 0 0 0 0 0 0]...][[4212 2661 218 69848 69848 69848 69848 69848 69848 69848]...][[2661 218 4 304 29 3 26 1247 49 216]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4212 2661 218 4 304 29 3 26 1247 49]...][[1 1 0 0 0 0 0 0 0 0]...][[4212 2661 218 69848 69848 69848 69848 69848 69848 69848]...][[2661 218 211 8 4685 13346 24653 5787 58909 102]...]\n",
            "targets[[122 1597 0 5995 3 0 14638 2 1238 3 417 1161 75 622 1294 13 2481 37 32 68][2 394 17 0 116 13 74 0 1821 13 74 0 655 13 74 0 946 13 74 0][1018 10 3896 22 3685 1 9 207 38 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 122 1597 0 5995 3 0 14638 2 1238]...][[1 1 1 1 1 0 0 0 0 0]...][[10 122 1597 0 5995 3 69848 69848 69848 69848]...][[122 1597 0 5995 3 0 14638 2 1238 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 122 1597 0 5995 3 0 14638 2 1238]...][[1 1 1 1 1 0 0 0 0 0]...][[10 122 1597 0 5995 3 69848 69848 69848 69848]...][[122 1597 0 5995 3 127 2903 949 10 268]...]\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 0 64 17 11 60 312 1 9]...][[5 0 64 17 11 60 312 1 9 1385]...]\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 0 64 17 11 60 312 1 9]...][[5 0 64 17 11 60 312 1 9 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 0 64 17 11 60 312 1 9]...][[5 0 64 17 11 60 312 1 9 242]...]\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "global_step: 7758\n",
            " perplexity: 417.984\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            " percent of 3-grams captured: 0.336.\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            " percent of 2-grams captured: 0.650.\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            " percent of 4-grams captured: 0.108.\n",
            " geometric_avg: 0.287.\n",
            " arithmetic_avg: 0.365.\n",
            "global_step: 7758\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39172\n",
            " G train loss: -8.74518\n",
            "targets[[5 0 64 17 11 60 312 1 9 27 123 2518 44 22 475 2144 70 215 7 8][215 7 31 0 33993 15 2 425 8 0 122 497 6356 13 884 31 0 143 3 0][10 5 2 994 7 5 2 4588 19 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 0 64 17 11 60 312 1 9]...][[5 0 64 17 11 60 312 1 9 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 64 17 11 60 312 1 9]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 0 64 17 11 60 312 1 9]...][[5 0 64 17 11 60 312 1 9 402]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  is                  0.723        0.000        0.000        0.000        -0.875       -3.714       0.000        \n",
            "   [1]  the                 0.591        0.000        0.000        0.000        -0.991       -10.291      0.000        \n",
            "   [1]  only                0.526        0.000        0.000        0.000        -1.121       -14.668      0.000        \n",
            "   [1]  movie               0.528        0.000        0.000        0.000        -1.269       -8.369       0.000        \n",
            "   [1]  that                0.536        0.000        0.000        0.000        -1.436       -8.338       0.000        \n",
            "   [1]  my                  0.514        0.000        0.000        0.000        -1.625       -6.481       0.000        \n",
            "   [1]  wife                0.661        0.000        0.000        0.000        -1.839       -5.777       0.000        \n",
            "   [1]  and                 0.410        0.000        0.000        0.000        -2.082       -5.538       0.000        \n",
            "   [1]  i                   0.559        0.000        0.000        0.000        -2.356       -5.574       0.000        \n",
            "   [0]  remember            0.598        2.886        -5.154       -0.514       -2.667       -5.894       3.227        \n",
            "   [0]  this                0.521        3.435        -2.468       -0.653       -2.437       -4.965       2.529        \n",
            "   [0]  movie               0.479        12.706       -1.365       -0.735       -2.019       -5.981       3.962        \n",
            "   [0]  on                  0.579        5.807        -3.888       -0.546       -1.453       -6.139       4.686        \n",
            "   [0]  the                 0.593        5.849        -0.656       -0.522       -1.026       -5.810       4.784        \n",
            "   [0]  last                0.910        8.073        -5.333       -0.094       -0.570       -5.484       4.914        \n",
            "   [0]  concert             0.958        9.247        -9.376       -0.043       -0.539       -4.559       4.020        \n",
            "   [0]  great               0.760        6.597        -7.239       -0.274       -0.561       -6.117       5.000        \n",
            "   [0]  and                 0.723        9.977        -3.279       -0.324       -0.324       -8.140       5.000        \n",
            "   [1]  it                  0.724        0.000        0.000        0.000        0.000        -8.090       0.000        \n",
            "   [1]  in                  0.811        0.000        0.000        0.000        0.000        -6.642       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  saw                 0.795        0.000        0.000        0.000        -6.794       -4.102       -0.000       \n",
            "   [1]  it                  0.658        0.000        0.000        0.000        -7.689       -12.026      0.000        \n",
            "   [1]  at                  0.599        0.000        0.000        0.000        -8.703       -7.935       -0.000       \n",
            "   [1]  the                 0.590        0.000        0.000        0.000        -9.850       -7.466       -0.000       \n",
            "   [1]  kodak               0.640        0.000        0.000        0.000        -11.147      -6.049       -0.000       \n",
            "   [1]  with                0.606        0.000        0.000        0.000        -12.616      -9.201       -0.000       \n",
            "   [1]  a                   0.661        0.000        0.000        0.000        -14.279      -9.035       -0.000       \n",
            "   [1]  friend              0.634        0.000        0.000        0.000        -16.161      -8.793       -0.000       \n",
            "   [1]  in                  0.524        0.000        0.000        0.000        -18.290      -7.877       -0.000       \n",
            "   [0]  probably            0.197        1.692        -7.572       -1.623       -20.701      -6.892       -5.000       \n",
            "   [0]  a                   0.042        7.759        -2.168       -3.176       -21.592      -11.136      -5.000       \n",
            "   [0]  one                 0.018        7.130        -4.012       -4.008       -20.843      -10.213      -5.000       \n",
            "   [0]  very                0.012        11.530       -5.800       -4.445       -19.054      -10.354      -5.000       \n",
            "   [0]  good                0.014        7.672        -3.251       -4.250       -16.534      -10.965      -5.000       \n",
            "   [0]  that                0.012        9.687        -4.144       -4.435       -13.903      -11.233      -2.670       \n",
            "   [0]  i                   0.013        5.230        -1.833       -4.328       -10.715      -9.874       -0.841       \n",
            "   [0]  thought             0.020        10.012       -3.333       -3.908       -7.229       -9.340       2.111        \n",
            "   [0]  when                0.023        6.725        -4.859       -3.758       -3.758       -8.588       4.830        \n",
            "   [1]  of                  0.014        0.000        0.000        0.000        0.000        -9.539       0.000        \n",
            "   [1]  the                 0.011        0.000        0.000        0.000        0.000        -9.905       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  this                0.429        0.000        0.000        0.000        -9.236       -4.305       -0.000       \n",
            "   [0]  movie               0.521        2.325        -0.953       -0.653       -10.453      -9.366       -1.087       \n",
            "   [0]  a                   0.577        3.179        -3.179       -0.550       -11.092      -9.408       -1.684       \n",
            "   [0]  give                0.225        7.758        -9.139       -1.493       -11.931      -9.394       -2.537       \n",
            "   [0]  that                0.060        3.892        -3.098       -2.813       -11.813      -12.069      0.256        \n",
            "   [0]  contracting         0.087        4.585        -16.396      -2.446       -10.187      -14.004      3.818        \n",
            "   [0]  as                  0.105        4.589        -4.544       -2.250       -8.761       -12.349      3.588        \n",
            "   [0]  i                   0.138        12.634       -4.142       -1.984       -7.368       -12.594      5.000        \n",
            "   [0]  ve                  0.128        8.595        -3.970       -2.060       -6.094       -12.224      5.000        \n",
            "   [0]  anyone              0.010        12.340       -7.362       -4.566       -4.566       -10.781      5.000        \n",
            "   [1]  br                  0.024        0.000        0.000        0.000        0.000        -14.427      0.000        \n",
            "   [1]  slater              0.000        0.000        0.000        0.000        0.000        -16.667      0.000        \n",
            "   [1]  gives               0.000        0.000        0.000        0.000        0.000        -28.514      0.000        \n",
            "   [1]  an                  0.000        0.000        0.000        0.000        0.000        -25.436      0.000        \n",
            "   [1]  excellent           0.000        0.000        0.000        0.000        0.000        -22.827      0.000        \n",
            "   [1]  performance         0.000        0.000        0.000        0.000        0.000        -22.427      0.000        \n",
            "   [1]  of                  0.000        0.000        0.000        0.000        0.000        -19.372      0.000        \n",
            "   [1]  the                 0.000        0.000        0.000        0.000        0.000        -20.878      0.000        \n",
            "   [1]  schizoid            0.000        0.000        0.000        0.000        0.000        -17.948      0.000        \n",
            "   [1]  loner               0.000        0.000        0.000        0.000        0.000        -17.921      0.000        \n",
            "Samples\n",
            "Sample 0 .  is the only movie that my wife and i remember this movie on the last concert great and it in\n",
            "Sample 1 .  saw it at the kodak with a friend in probably a one very good that i thought when of the\n",
            "Sample 2 .  this movie a give that contracting as i ve anyone br slater gives an excellent performance of the schizoid loner\n",
            "\n",
            "\n",
            "targets[[203 28 6101 146 483 16 259 137 160 6 6 29 142 1115 61 13 1676 793 33 388][9 84 215 755 3 2 821 143 8 0 1289 12 22 729 9 67 56 321 10 13][7643 16 2 363 3 154 41 37 9 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[16797 203 28 6101 146 483 16 259 137 160]...][[1 1 1 1 1 1 1 1 0 0]...][[16797 203 28 6101 146 483 16 259 137 69848]...][[203 28 6101 146 483 16 259 137 160 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[16797 203 28 6101 146 483 16 259 137 160]...][[1 1 1 1 1 1 1 1 0 0]...][[16797 203 28 6101 146 483 16 259 137 69848]...][[203 28 6101 146 483 16 259 137 601 114]...]\n",
            "targets[[38 4 103 3 545 14 2 125 3 4651 2 21275 1 14345 11787 22 2757 5282 1 0][17 188 4 27 2 171 3 75 674 7 5 29 3 0 88 1758 3 30 57 99][729 274 38 4 9962 44 421 8981 1 80]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 38 4 103 3 545 14 2 125 3]...][[1 0 0 0 0 0 0 0 0 0]...][[9 38 69848 69848 69848 69848 69848 69848 69848 69848]...][[38 4 103 3 545 14 2 125 3 4651]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 38 4 103 3 545 14 2 125 3]...][[1 0 0 0 0 0 0 0 0 0]...][[9 38 69848 69848 69848 69848 69848 69848 69848 69848]...][[38 126 1121 449 1205 0 74 58 23 29]...]\n",
            "targets[[5 37 73 11 50 28 300 43 10 19 7 5 23 127 737 16500 3 268 39 5][780 60270 6 6 0 153 1 543 3 9523 902 0 153 3 331 89 21 560 402 6][5 0 244 3 609 11 7286 4 0 10268]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[39 5 37 73 11 50 28 300 43 10]...][[1 1 1 0 0 0 0 0 0 0]...][[39 5 37 73 69848 69848 69848 69848 69848 69848]...][[5 37 73 11 50 28 300 43 10 19]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[39 5 37 73 11 50 28 300 43 10]...][[1 1 1 0 0 0 0 0 0 0]...][[39 5 37 73 69848 69848 69848 69848 69848 69848]...][[5 37 73 286 4 67 137 8 51 4]...]\n",
            "targets[[19 5 0 13574 3411 3 174 74 17 997 123 585 29 3 0 250 1 4463 3 30][13 53 671 8 0 63 344 3 10 19 0 177 118 35 5398 301 15 35 119 2674][12682 12682 12682 42 51 20 196 20 68 2295]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 0 13574 3411 3 174 74 17]...][[1 1 1 1 0 0 0 0 0 0]...][[10 19 5 0 13574 69848 69848 69848 69848 69848]...][[19 5 0 13574 3411 3 174 74 17 997]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 0 13574 3411 3 174 74 17]...][[1 1 1 1 0 0 0 0 0 0]...][[10 19 5 0 13574 69848 69848 69848 69848 69848]...][[19 5 0 13574 5325 55642 8832 33 49 1]...]\n",
            "targets[[1401 16 2 19 5 23 1316 3 0 390 3544 5381 758 10 31 30 2326 255 1716 4][17 13 437 379 0 17 724 78 18269 221 1240 1 42 418 4314 36 39 10 17 5][64 82 738 3 10 17 14 3 10 1309]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 1401 16 2 19 5 23 1316 3 0]...][[1 1 1 0 0 0 0 0 0 0]...][[10 1401 16 2 69848 69848 69848 69848 69848 69848]...][[1401 16 2 19 5 23 1316 3 0 390]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 1401 16 2 19 5 23 1316 3 0]...][[1 1 1 0 0 0 0 0 0 0]...][[10 1401 16 2 69848 69848 69848 69848 69848 69848]...][[1401 16 2 19 53 19 30 0 795 31]...]\n",
            "targets[[67 4 28 29 3 0 250 104 123 51 2141 274 55 1 8058 5 15 2 742 3][17 719 0 17 2 1080 226 108 214 8 0 472 3 443 7 5 3428 128 14 69][9 59 38 4 563 60 12422 31 0 2007]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 67 4 28 29 3 0 250 104 123]...][[1 1 0 0 0 0 0 0 0 0]...][[10 67 4 69848 69848 69848 69848 69848 69848 69848]...][[67 4 28 29 3 0 250 104 123 51]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 67 4 28 29 3 0 250 104 123]...][[1 1 0 0 0 0 0 0 0 0]...][[10 67 4 69848 69848 69848 69848 69848 69848 69848]...][[67 4 262 4 28 161 8 85 8 30]...]\n",
            "targets[[1022 6 6 2 15449 1125 291 158 396 7745 2 53 1009 1125 291 158 234 1 852 24][23 110 10 19 8 43 844 154 9 242 133 1520 15 7 12 245 3357 1550 1 4321][27 7688 67 7688 4 37149 16 105 2688 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3199 1022 6 6 2 15449 1125 291 158 396]...][[1 1 1 1 1 0 0 0 0 0]...][[3199 1022 6 6 2 15449 69848 69848 69848 69848]...][[1022 6 6 2 15449 1125 291 158 396 7745]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3199 1022 6 6 2 15449 1125 291 158 396]...][[1 1 1 1 1 0 0 0 0 0]...][[3199 1022 6 6 2 15449 69848 69848 69848 69848]...][[1022 6 6 2 15449 4 64 816 3857 31]...]\n",
            "targets[[5 606 47 9 118 132 149 10 17 9 307 0 4175 1375 7 59 129 525 69847 69847][30 10 528 164 185 31 0 561 15 13832 9 139 672 2938 4 26 224 149 0 1055][54 886 764 12 351 889 1025 314 33 391]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[11 5 606 47 9 118 132 149 10 17]...][[1 1 1 0 0 0 0 0 0 0]...][[11 5 606 47 69848 69848 69848 69848 69848 69848]...][[5 606 47 9 118 132 149 10 17 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[11 5 606 47 9 118 132 149 10 17]...][[1 1 1 0 0 0 0 0 0 0]...][[11 5 606 47 69848 69848 69848 69848 69848 69848]...][[5 606 47 10 0 17 13 97 7782 18]...]\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[1 1 1 1 1 1 1 0 0 0]...][[9 389 85 9 555 7 13 2 69848 69848]...][[389 85 9 555 7 13 2 30620 33 6450]...]\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[1 1 1 1 1 1 1 0 0 0]...][[9 389 85 9 555 7 13 2 69848 69848]...][[389 85 9 555 7 13 2 1484 199 6963]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[1 1 1 1 1 1 1 0 0 0]...][[9 389 85 9 555 7 13 2 69848 69848]...][[389 85 9 555 7 13 2 81 13888 3]...]\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "global_step: 7775\n",
            " perplexity: 418.440\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            " percent of 3-grams captured: 0.327.\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            " percent of 2-grams captured: 0.645.\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            " percent of 4-grams captured: 0.104.\n",
            " geometric_avg: 0.280.\n",
            " arithmetic_avg: 0.359.\n",
            "global_step: 7775\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39154\n",
            " G train loss: -9.01478\n",
            "targets[[389 85 9 555 7 13 2 1484 199 6963 0 1341 9687 0 1 9379 9 2464 85 7][5 35 212 297 63 3 10475 3541 7721 34 8793 3 107 35 51 24 13 2 493 357][103 10 17 5 117 7870 55 14 1109 852]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[1 1 1 1 1 1 1 0 0 0]...][[9 389 85 9 555 7 13 2 69848 69848]...][[389 85 9 555 7 13 2 1484 199 6963]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 389 85 9 555 7 13 2 1484 199]...][[1 1 1 1 1 1 1 0 0 0]...][[9 389 85 9 555 7 13 2 69848 69848]...][[389 85 9 555 7 13 2 183 10526 341]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  came                0.568        0.000        0.000        0.000        -2.215       -3.907       0.000        \n",
            "   [1]  because             0.557        0.000        0.000        0.000        -2.507       -11.302      0.000        \n",
            "   [1]  i                   0.546        0.000        0.000        0.000        -2.837       -15.792      0.000        \n",
            "   [1]  heard               0.563        0.000        0.000        0.000        -3.211       -14.654      0.000        \n",
            "   [1]  it                  0.630        0.000        0.000        0.000        -3.634       -13.384      0.000        \n",
            "   [1]  was                 0.462        0.000        0.000        0.000        -4.113       -11.573      0.000        \n",
            "   [1]  a                   0.446        0.000        0.000        0.000        -4.655       -10.506      0.000        \n",
            "   [0]  young               0.577        9.830        -5.795       -0.549       -5.268       -11.474      5.000        \n",
            "   [0]  blurred             0.614        8.300        -12.044      -0.487       -5.340       -10.028      4.688        \n",
            "   [0]  budget              0.333        10.168       -6.994       -1.100       -5.493       -9.217       3.724        \n",
            "   [0]  time                0.293        4.554        -5.283       -1.228       -4.971       -10.357      5.000        \n",
            "   [0]  and                 0.315        11.002       -2.487       -1.156       -4.236       -10.801      5.000        \n",
            "   [0]  seeing              0.334        12.112       -6.961       -1.096       -3.486       -10.581      5.000        \n",
            "   [0]  a                   0.361        3.042        -4.129       -1.020       -2.705       -10.940      5.000        \n",
            "   [0]  explored            0.422        7.968        -11.166      -0.863       -1.908       -9.266       5.000        \n",
            "   [0]  who                 0.307        10.832       -5.280       -1.182       -1.182       -7.709       5.000        \n",
            "   [1]  i                   0.155        0.000        0.000        0.000        0.000        -9.374       0.000        \n",
            "   [1]  stayed              0.074        0.000        0.000        0.000        0.000        -11.193      0.000        \n",
            "   [1]  because             0.074        0.000        0.000        0.000        0.000        -12.416      0.000        \n",
            "   [1]  it                  0.181        0.000        0.000        0.000        0.000        -11.390      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  is                  0.663        0.000        0.000        0.000        -0.557       -3.696       0.000        \n",
            "   [1]  an                  0.676        0.000        0.000        0.000        -0.631       -9.793       0.000        \n",
            "   [1]  interesting         0.715        0.000        0.000        0.000        -0.714       -7.555       0.000        \n",
            "   [1]  true                0.641        0.000        0.000        0.000        -0.808       -4.893       0.000        \n",
            "   [1]  story               0.757        0.000        0.000        0.000        -0.914       -6.510       0.000        \n",
            "   [1]  of                  0.589        0.000        0.000        0.000        -1.035       -9.388       0.000        \n",
            "   [1]  archie              0.626        0.000        0.000        0.000        -1.171       -8.912       0.000        \n",
            "   [0]  except              0.532        9.703        -7.832       -0.631       -1.326       -8.722       5.000        \n",
            "   [0]  look                0.642        11.838       -8.513       -0.444       -0.786       -10.111      5.000        \n",
            "   [0]  for                 0.904        4.945        -3.967       -0.100       -0.388       -7.657       5.000        \n",
            "   [0]  about               0.905        12.489       -6.105       -0.100       -0.325       -8.945       5.000        \n",
            "   [0]  a                   0.920        5.664        -2.458       -0.084       -0.255       -9.084       5.000        \n",
            "   [0]  musical             0.949        8.395        -7.872       -0.052       -0.195       -10.156      5.000        \n",
            "   [0]  and                 0.942        7.064        -2.382       -0.060       -0.161       -8.705       5.000        \n",
            "   [0]  u                   0.979        6.925        -8.596       -0.021       -0.115       -9.976       5.000        \n",
            "   [0]  and                 0.899        4.349        -3.002       -0.106       -0.106       -9.110       5.000        \n",
            "   [1]  was                 0.855        0.000        0.000        0.000        0.000        -10.634      0.000        \n",
            "   [1]  a                   0.821        0.000        0.000        0.000        0.000        -10.580      0.000        \n",
            "   [1]  child               0.919        0.000        0.000        0.000        0.000        -10.355      0.000        \n",
            "   [1]  until               0.810        0.000        0.000        0.000        0.000        -7.081       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  think               0.723        0.000        0.000        0.000        -3.866       -3.878       0.000        \n",
            "   [1]  this                0.677        0.000        0.000        0.000        -4.375       -10.381      0.000        \n",
            "   [1]  movie               0.696        0.000        0.000        0.000        -4.951       -9.539       0.000        \n",
            "   [1]  is                  0.677        0.000        0.000        0.000        -5.604       -11.389      0.000        \n",
            "   [1]  best                0.651        0.000        0.000        0.000        -6.342       -8.373       0.000        \n",
            "   [1]  summed              0.495        0.000        0.000        0.000        -7.178       -17.859      0.000        \n",
            "   [1]  up                  0.807        0.000        0.000        0.000        -8.124       -13.985      0.000        \n",
            "   [0]  it                  0.311        4.283        -2.990       -1.169       -9.195       -9.376       0.181        \n",
            "   [0]  s                   0.533        9.951        -1.765       -0.629       -9.084       -9.766       0.682        \n",
            "   [0]  6                   0.374        10.162       -7.797       -0.983       -9.569       -8.927       -0.642       \n",
            "   [0]  swimming            0.198        7.006        -12.635      -1.619       -9.718       -9.869       0.152        \n",
            "   [0]  of                  0.057        8.101        -2.703       -2.865       -9.166       -10.989      1.823        \n",
            "   [0]  imo                 0.146        15.496       -13.074      -1.926       -7.131       -9.864       2.733        \n",
            "   [0]  works               0.068        5.919        -8.681       -2.687       -5.891       -9.117       3.226        \n",
            "   [0]  to                  0.107        6.548        -3.501       -2.232       -3.626       -10.054      5.000        \n",
            "   [0]  step                0.206        8.618        -9.338       -1.578       -1.578       -8.333       5.000        \n",
            "   [1]  a                   0.141        0.000        0.000        0.000        0.000        -8.403       0.000        \n",
            "   [1]  river               0.130        0.000        0.000        0.000        0.000        -8.910       0.000        \n",
            "   [1]  runs                0.159        0.000        0.000        0.000        0.000        -8.093       0.000        \n",
            "   [1]  through             0.236        0.000        0.000        0.000        0.000        -8.481       0.000        \n",
            "Samples\n",
            "Sample 0 .  came because i heard it was a young blurred budget time and seeing a explored who i stayed because it\n",
            "Sample 1 .  is an interesting true story of archie except look for about a musical and u and was a child until\n",
            "Sample 2 .  think this movie is best summed up it s 6 swimming of imo works to step a river runs through\n",
            "\n",
            "\n",
            "targets[[1012 10424 5 143 15 74 46190 1 56 266 16 1847 99 89 21534 12 972 1541 1012 3][67 60 5242 43 157 112 63 9137 6992 3516 169 1202 1 3300 144 1146 6583 1 7 12][229 14 705 298 1470 138 10 29 5 44]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1541 1012 10424 5 143 15 74 46190 1 56]...][[1 1 1 1 1 1 1 1 1 1]...][[1541 1012 10424 5 143 15 74 46190 1 56]...][[1012 10424 5 143 15 74 46190 1 56 266]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1541 1012 10424 5 143 15 74 46190 1 56]...][[1 1 1 1 1 1 1 1 1 1]...][[1541 1012 10424 5 143 15 74 46190 1 56]...][[1012 10424 5 143 15 74 46190 1 56 266]...]\n",
            "targets[[488 5 2 81 181 17 15 81 156 81 109 1 2 450 11 65 515 35 181 19][7085 7983 17069 55 180 2 222 3 6926 51 10 19 13 84 107 645 88 1336 85 3][4 875 6 6 10 17 141 28 0 989]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3540 488 5 2 81 181 17 15 81 156]...][[1 1 1 1 1 1 1 0 0 0]...][[3540 488 5 2 81 181 17 15 69848 69848]...][[488 5 2 81 181 17 15 81 156 81]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3540 488 5 2 81 181 17 15 81 156]...][[1 1 1 1 1 1 1 0 0 0]...][[3540 488 5 2 81 181 17 15 69848 69848]...][[488 5 2 81 181 17 15 2 2062 13]...]\n",
            "targets[[12 1746 1406 5 35 1623 441 3 184 8 1315 3 834 967 1 919 18 2770 15 35][3 0 88 348 98 9 139 110 0 684 535 181 5 630 1 1407 109 47 109 0][13 0 250 17 9 139 123 110 9 382]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[54254 12 1746 1406 5 35 1623 441 3 184]...][[1 1 1 1 1 1 1 1 1 1]...][[54254 12 1746 1406 5 35 1623 441 3 184]...][[12 1746 1406 5 35 1623 441 3 184 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[54254 12 1746 1406 5 35 1623 441 3 184]...][[1 1 1 1 1 1 1 1 1 1]...][[54254 12 1746 1406 5 35 1623 441 3 184]...][[12 1746 1406 5 35 1623 441 3 184 8]...]\n",
            "targets[[5 0 666 88 913 202 9 27 123 307 22 729 7578 1887 4247 1571 7 45 2464 15][10705 5 2 2319 842 7 45 193 2 583 63 1 48 1623 1356 2479 4 383 0 507][182 2 1212 17 41 58 2 4593 8937 1570]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[18835 5 0 666 88 913 202 9 27 123]...][[1 1 1 1 1 1 1 1 0 0]...][[18835 5 0 666 88 913 202 9 27 69848]...][[5 0 666 88 913 202 9 27 123 307]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[18835 5 0 666 88 913 202 9 27 123]...][[1 1 1 1 1 1 1 1 0 0]...][[18835 5 0 666 88 913 202 9 27 69848]...][[5 0 666 88 913 202 9 27 215 1291]...]\n",
            "targets[[592 4 367 734 1256 1 144 0 154 27 110 48 81 692 1541 1292 186 243 4 390][1090 8674 1832 3269 14 2 10326 1130 11417 2141 20150 124 54 133 76 166 14 26 312 3199][139 793 4 38 10 19 65 8 149 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 592 4 367 734 1256 1 144 0 154]...][[1 1 1 1 1 1 1 1 1 1]...][[9 592 4 367 734 1256 1 144 0 154]...][[592 4 367 734 1256 1 144 0 154 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 592 4 367 734 1256 1 144 0 154]...][[1 1 1 1 1 1 1 1 1 1]...][[9 592 4 367 734 1256 1 144 0 154]...][[592 4 367 734 1256 1 144 0 154 27]...]\n",
            "targets[[371 230 74 16 0 177 888 11 13 571 8 235 10 434 47 96 27 77 2 1875][12 245 4 262 99 1073 2779 154 70 1968 55 15 10 432 3 1356 1243 0 206 13][11 0 105 897 798 16 10 19 25 36]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 371 230 74 16 0 177 888 11 13]...][[1 0 0 0 0 0 0 0 0 0]...][[9 371 69848 69848 69848 69848 69848 69848 69848 69848]...][[371 230 74 16 0 177 888 11 13 571]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 371 230 74 16 0 177 888 11 13]...][[1 0 0 0 0 0 0 0 0 0]...][[9 371 69848 69848 69848 69848 69848 69848 69848 69848]...][[371 5406 5927 7524 264 11 20 123 28 147]...]\n",
            "targets[[29 3 146 98 111 30 3 0 2013 510 68 8 0 1561 475 736 1 65 23 53][25 37 108 683 9 182 4 359 4 1652 10 17 18 50 21 65 80 11 50 9][307 10 17 99 149 6662 1279 1 0 920]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[157 29 3 146 98 111 30 3 0 2013]...][[1 0 0 0 0 0 0 0 0 0]...][[157 29 69848 69848 69848 69848 69848 69848 69848 69848]...][[29 3 146 98 111 30 3 0 2013 510]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[157 29 3 146 98 111 30 3 0 2013]...][[1 0 0 0 0 0 0 0 0 0]...][[157 29 69848 69848 69848 69848 69848 69848 69848 69848]...][[29 484 13 1364 396 44 10094 18288 33 3]...]\n",
            "targets[[254 10 2 53 2278 19 8 11 0 361 2635 25 1616 208 1510 612 1 0 1127 5][188 4 28 29 3 146 202 11 27 77 400 8 0 34808 3 57 99 7 12 18023][3 0 117 3344 9 27 123 110 10 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 254 10 2 53 2278 19 8 11 0]...][[1 1 1 1 1 1 0 0 0 0]...][[9 254 10 2 53 2278 19 69848 69848 69848]...][[254 10 2 53 2278 19 8 11 0 361]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 254 10 2 53 2278 19 8 11 0]...][[1 1 1 1 1 1 0 0 0 0]...][[9 254 10 2 53 2278 19 69848 69848 69848]...][[254 10 2 53 2278 19 34 250 10 17]...]\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[1 1 1 1 1 1 1 0 0 0]...][[0 84 202 3 400 4211 120 15 69848 69848]...][[84 202 3 400 4211 120 15 8597 308 224]...]\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[1 1 1 1 1 1 1 0 0 0]...][[0 84 202 3 400 4211 120 15 69848 69848]...][[84 202 3 400 4211 120 15 2 3729 1207]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[1 1 1 1 1 1 1 0 0 0]...][[0 84 202 3 400 4211 120 15 69848 69848]...][[84 202 3 400 4211 120 15 1692 2 385]...]\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "global_step: 7792\n",
            " perplexity: 418.443\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            " percent of 3-grams captured: 0.322.\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            " percent of 2-grams captured: 0.651.\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            " percent of 4-grams captured: 0.087.\n",
            " geometric_avg: 0.263.\n",
            " arithmetic_avg: 0.353.\n",
            "global_step: 7792\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39129\n",
            " G train loss: -8.85245\n",
            "targets[[84 202 3 400 4211 120 15 2 3729 1207 1 1366 29460 8 1069 10 204 27 278 48][17 5 730 4 0 304 5343 27776 1325 408 33 10670 7117 0 109 3 2 1212 312 1][69 69 32773 42944 5 29 3 0 1536 156]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[1 1 1 1 1 1 1 0 0 0]...][[0 84 202 3 400 4211 120 15 69848 69848]...][[84 202 3 400 4211 120 15 2 3729 1207]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 202 3 400 4211 120 15 2 3729]...][[1 1 1 1 1 1 1 0 0 0]...][[0 84 202 3 400 4211 120 15 69848 69848]...][[84 202 3 400 4211 120 15 0 101 2242]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  first               0.584        0.000        0.000        0.000        -2.241       -4.108       0.000        \n",
            "   [1]  series              0.638        0.000        0.000        0.000        -2.537       -6.605       0.000        \n",
            "   [1]  of                  0.686        0.000        0.000        0.000        -2.871       -8.161       0.000        \n",
            "   [1]  lost                0.573        0.000        0.000        0.000        -3.249       -7.619       0.000        \n",
            "   [1]  kicked              0.683        0.000        0.000        0.000        -3.677       -6.600       0.000        \n",
            "   [1]  off                 0.605        0.000        0.000        0.000        -4.162       -7.019       0.000        \n",
            "   [1]  with                0.483        0.000        0.000        0.000        -4.711       -7.815       0.000        \n",
            "   [0]  the                 0.395        2.031        -1.166       -0.929       -5.331       -7.821       2.489        \n",
            "   [0]  characters          0.411        9.708        -4.444       -0.890       -4.983       -7.844       2.862        \n",
            "   [0]  forest              0.343        10.529       -10.767      -1.070       -4.632       -7.399       2.766        \n",
            "   [0]  and                 0.259        1.850        -1.850       -1.350       -4.032       -7.131       3.099        \n",
            "   [0]  it                  0.269        10.008       -3.948       -1.313       -3.036       -7.951       4.915        \n",
            "   [0]  is                  0.398        18.531       -1.087       -0.920       -1.950       -6.233       4.283        \n",
            "   [0]  often               0.563        5.507        -7.385       -0.575       -1.166       -7.789       5.000        \n",
            "   [0]  actually            0.703        11.812       -8.089       -0.352       -0.669       -7.398       5.000        \n",
            "   [0]  a                   0.699        5.154        -2.314       -0.358       -0.358       -7.696       5.000        \n",
            "   [1]  may                 0.695        0.000        0.000        0.000        0.000        -7.365       0.000        \n",
            "   [1]  have                0.803        0.000        0.000        0.000        0.000        -9.179       0.000        \n",
            "   [1]  put                 0.770        0.000        0.000        0.000        0.000        -6.395       0.000        \n",
            "   [1]  some                0.741        0.000        0.000        0.000        0.000        -7.678       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  movie               0.334        0.000        0.000        0.000        -6.465       -3.940       -0.000       \n",
            "   [1]  is                  0.648        0.000        0.000        0.000        -7.316       -11.039      0.000        \n",
            "   [1]  similar             0.613        0.000        0.000        0.000        -8.281       -8.896       0.000        \n",
            "   [1]  to                  0.825        0.000        0.000        0.000        -9.372       -4.554       -0.000       \n",
            "   [0]  checked             0.215        2.853        -9.924       -1.536       -10.607      -6.817       -3.789       \n",
            "   [0]  to                  0.377        9.459        -2.325       -0.976       -10.266      -7.637       -2.629       \n",
            "   [0]  anyone              0.498        10.353       -6.773       -0.698       -10.514      -8.309       -2.205       \n",
            "   [0]  she                 0.362        14.500       -6.722       -1.017       -11.109      -10.296      -0.813       \n",
            "   [0]  during              0.165        12.143       -8.395       -1.801       -11.423      -10.224      -1.199       \n",
            "   [0]  awesome             0.064        7.173        -7.876       -2.754       -10.890      -10.554      -0.335       \n",
            "   [0]  afraid              0.020        4.034        -9.716       -3.936       -9.208       -10.716      1.508        \n",
            "   [0]  why                 0.030        14.582       -6.690       -3.516       -5.967       -9.779       3.812        \n",
            "   [0]  it                  0.062        12.974       -2.480       -2.774       -2.774       -6.576       3.802        \n",
            "   [1]  the                 0.032        0.000        0.000        0.000        0.000        -5.813       0.000        \n",
            "   [1]  plot                0.047        0.000        0.000        0.000        0.000        -7.720       0.000        \n",
            "   [1]  of                  0.034        0.000        0.000        0.000        0.000        -5.909       0.000        \n",
            "   [1]  a                   0.058        0.000        0.000        0.000        0.000        -7.182       0.000        \n",
            "   [1]  ghost               0.150        0.000        0.000        0.000        0.000        -8.112       0.000        \n",
            "   [1]  wife                0.176        0.000        0.000        0.000        0.000        -7.220       0.000        \n",
            "   [1]  and                 0.146        0.000        0.000        0.000        0.000        -8.119       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  well                0.291        0.000        0.000        0.000        -9.670       -4.126       -0.000       \n",
            "   [1]  well                0.545        0.000        0.000        0.000        -10.945      -6.933       -0.000       \n",
            "   [1]  satish              0.558        0.000        0.000        0.000        -12.387      -7.040       -0.000       \n",
            "   [1]  kaushik             0.469        0.000        0.000        0.000        -14.019      -8.274       -0.000       \n",
            "   [0]  such                0.548        2.428        -7.844       -0.602       -15.867      -8.689       -5.000       \n",
            "   [0]  of                  0.041        4.967        -5.404       -3.192       -17.276      -8.199       -5.000       \n",
            "   [0]  suburban            0.028        4.543        -9.756       -3.575       -15.940      -18.352      2.412        \n",
            "   [0]  die                 0.123        4.093        -9.644       -2.092       -13.994      -13.077      -0.917       \n",
            "   [0]  many                0.057        11.185       -7.177       -2.871       -13.471      -11.350      -2.121       \n",
            "   [0]  very                0.023        6.738        -5.775       -3.780       -11.997      -11.338      -0.659       \n",
            "   [0]  my                  0.019        6.318        -4.797       -3.975       -9.300       -12.276      2.977        \n",
            "   [0]  favorite            0.031        10.359       -5.098       -3.477       -6.027       -12.307      5.000        \n",
            "   [0]  movies              0.056        8.782        -4.390       -2.885       -2.885       -11.777      5.000        \n",
            "   [1]  at                  0.078        0.000        0.000        0.000        0.000        -10.737      0.000        \n",
            "   [1]  least               0.717        0.000        0.000        0.000        0.000        -8.572       0.000        \n",
            "   [1]  in                  0.675        0.000        0.000        0.000        0.000        -12.294      0.000        \n",
            "   [1]  some                0.729        0.000        0.000        0.000        0.000        -10.231      0.000        \n",
            "   [1]  films               0.624        0.000        0.000        0.000        0.000        -11.029      0.000        \n",
            "   [1]  he                  0.535        0.000        0.000        0.000        0.000        -11.557      0.000        \n",
            "   [1]  was                 0.519        0.000        0.000        0.000        0.000        -10.303      0.000        \n",
            "Samples\n",
            "Sample 0 .  first series of lost kicked off with the characters forest and it is often actually a may have put some\n",
            "Sample 1 .  movie is similar to checked to anyone she during awesome afraid why it the plot of a ghost wife and\n",
            "Sample 2 .  well well satish kaushik such of suburban die many very my favorite movies at least in some films he was\n",
            "\n",
            "\n",
            "targets[[59 27 358 10 17 2 308 44 3 163 46 7 1189 21 16 1575 23528 12 237 1][206 17 13 23 0 117 17 123 18 7 13 2 1131 2707 18 0 662 5 2 37][1354 15294 26 158 1112 8 2 19 11 15294]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 59 27 358 10 17 2 308 44 3]...][[1 1 1 0 0 0 0 0 0 0]...][[9 59 27 358 69848 69848 69848 69848 69848 69848]...][[59 27 358 10 17 2 308 44 3 163]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 59 27 358 10 17 2 308 44 3]...][[1 1 1 0 0 0 0 0 0 0]...][[9 59 27 358 69848 69848 69848 69848 69848 69848]...][[59 27 358 4 110 2 1758 341 350 21]...]\n",
            "targets[[184 19 11 13 92 36 2 4550 19 11 13 593 976 1 67 160 135 1296 7 45][2409 160 314 2153 1112 4 2 160 474 16 2 1424 366 99 2 1578 5292 1162 866 26][3 2823 45 108 81 1429 4 7 49 181]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4100 184 19 11 13 92 36 2 4550 19]...][[1 1 1 1 1 1 0 0 0 0]...][[4100 184 19 11 13 92 36 69848 69848 69848]...][[184 19 11 13 92 36 2 4550 19 11]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[4100 184 19 11 13 92 36 2 4550 19]...][[1 1 1 1 1 1 0 0 0 0]...][[4100 184 19 11 13 92 36 69848 69848 69848]...][[184 19 11 13 92 36 98 8 26 315]...]\n",
            "targets[[254 43 0 17 1463 33 2206 36 75 11 7 288 21 737 959 11 193 362 1 1532][27 37 108 355 34 112 10 17 9 139 555 1878 75 2222 7 14 29 3 62 2753][69 2034 143 8 4818 10 19 1886 2 73]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 254 43 0 17 1463 33 2206 36 75]...][[1 0 0 0 0 0 0 0 0 0]...][[9 254 69848 69848 69848 69848 69848 69848 69848 69848]...][[254 43 0 17 1463 33 2206 36 75 11]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 254 43 0 17 1463 33 2206 36 75]...][[1 0 0 0 0 0 0 0 0 0]...][[9 254 69848 69848 69848 69848 69848 69848 69848 69848]...][[254 10 5 28 91 447 43 0 170 279]...]\n",
            "targets[[2 4699 19 33 6962 55041 31 7 12 57 8 4818 51 142 2 3127 13 1587 44 3][268 20 3413 28 2 14400 4 367 48 75 12 1175 20 121 11 46 20 2045 15 90][529 10 2 678 3 796 399 6 6 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[13 2 4699 19 33 6962 55041 31 7 12]...][[1 1 1 1 1 1 0 0 0 0]...][[13 2 4699 19 33 6962 55041 69848 69848 69848]...][[2 4699 19 33 6962 55041 31 7 12 57]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[13 2 4699 19 33 6962 55041 31 7 12]...][[1 1 1 1 1 1 0 0 0 0]...][[13 2 4699 19 33 6962 55041 69848 69848 69848]...][[2 4699 19 33 6962 55041 5 0 2272 7519]...]\n",
            "targets[[8368 317 5 2 53 46422 17 8 189 29 3 0 250 9 27 123 110 9 509 0][109 2 3240 1278 45 0 6622 3 7731 26 8085 26 57575 1411 86 445 14253 1 24 525][171 3 75 465 4 27 424 0 19 37]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[66626 8368 317 5 2 53 46422 17 8 189]...][[1 1 1 1 1 1 1 0 0 0]...][[66626 8368 317 5 2 53 46422 17 69848 69848]...][[8368 317 5 2 53 46422 17 8 189 29]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[66626 8368 317 5 2 53 46422 17 8 189]...][[1 1 1 1 1 1 1 0 0 0]...][[66626 8368 317 5 2 53 46422 17 69848 69848]...][[8368 317 5 2 53 46422 17 39 150 44]...]\n",
            "targets[[3 0 14308 1536 1 1094 2272 1314 123 92 7 45 113 2034 0 397 659 7 18513 1020][42 215 38319 4120 22 7814 9 13 1986 278 120 33 0 412 18 0 17 5 323 1][42 1779 149 10 122 1 60 1637 5 133]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 14308 1536 1 1094 2272 1314 123]...][[1 1 1 1 1 1 1 1 1 1]...][[29 3 0 14308 1536 1 1094 2272 1314 123]...][[3 0 14308 1536 1 1094 2272 1314 123 92]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 14308 1536 1 1094 2272 1314 123]...][[1 1 1 1 1 1 1 1 1 1]...][[29 3 0 14308 1536 1 1094 2272 1314 123]...][[3 0 14308 1536 1 1094 2272 1314 123 92]...]\n",
            "targets[[84 555 2 1771 1470 36 0 3148 3 0 18123 24610 1 53972 11 353 0 298 9 196][1865 509 10 17 85 39 13 2 1749 7041 8 0 116 0 503 13 351 2490 601 35006][389 128 1 353 0 829 167 9 307 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 2 1771 1470 36 0 3148 3]...][[1 1 1 1 1 1 1 1 0 0]...][[9 84 555 2 1771 1470 36 0 3148 69848]...][[84 555 2 1771 1470 36 0 3148 3 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 2 1771 1470 36 0 3148 3]...][[1 1 1 1 1 1 1 1 0 0]...][[9 84 555 2 1771 1470 36 0 3148 69848]...][[84 555 2 1771 1470 36 0 3148 0 963]...]\n",
            "targets[[5 35 554 69 4409 69 408 69 896 1 69 92 19 0 405 8 193 91 2842 5977][604 262 30 9 140 884 43 10 17 269 36 75 34 2222 7 13 323 1 69 226][5 142 2 13121 839 896 408 1 513 15]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 35 554 69 4409 69 408 69 896]...][[1 1 1 1 1 0 0 0 0 0]...][[10 5 35 554 69 4409 69848 69848 69848 69848]...][[5 35 554 69 4409 69 408 69 896 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 35 554 69 4409 69 408 69 896]...][[1 1 1 1 1 0 0 0 0 0]...][[10 5 35 554 69 4409 69848 69848 69848 69848]...][[5 35 554 69 4409 29 1 146 7700 9]...]\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 0 88 1211 19 9 27 69848 69848]...][[5 0 88 1211 19 9 27 56 0 872]...]\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 0 88 1211 19 9 27 69848 69848]...][[5 0 88 1211 19 9 27 110 8 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 0 88 1211 19 9 27 69848 69848]...][[5 0 88 1211 19 9 27 27 38 0]...]\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "global_step: 7809\n",
            " perplexity: 417.854\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            " percent of 3-grams captured: 0.332.\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            " percent of 2-grams captured: 0.632.\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            " percent of 4-grams captured: 0.104.\n",
            " geometric_avg: 0.279.\n",
            " arithmetic_avg: 0.356.\n",
            "global_step: 7809\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39113\n",
            " G train loss: -8.58134\n",
            "targets[[5 0 88 1211 19 9 27 110 8 2 194 57 46 20 38 10 17 138 818 7442][3 2 3063 945 527 34 747 4 2132 36748 1 2025 4 0 1395 652 3 26 160 303][27121 65 4231 4 28 11120 16 10 371 19940]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 0 88 1211 19 9 27 69848 69848]...][[5 0 88 1211 19 9 27 110 8 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 88 1211 19 9 27 110 8]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 0 88 1211 19 9 27 69848 69848]...][[5 0 88 1211 19 9 27 113 92 4]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  is                  0.602        0.000        0.000        0.000        -2.272       -3.898       0.000        \n",
            "   [1]  the                 0.578        0.000        0.000        0.000        -2.571       -9.163       0.000        \n",
            "   [1]  most                0.618        0.000        0.000        0.000        -2.910       -14.052      0.000        \n",
            "   [1]  disturbing          0.448        0.000        0.000        0.000        -3.293       -9.996       0.000        \n",
            "   [1]  film                0.539        0.000        0.000        0.000        -3.727       -11.947      0.000        \n",
            "   [1]  i                   0.445        0.000        0.000        0.000        -4.218       -13.456      0.000        \n",
            "   [1]  have                0.607        0.000        0.000        0.000        -4.774       -12.796      0.000        \n",
            "   [0]  never               0.562        2.902        -3.190       -0.576       -5.403       -11.605      5.000        \n",
            "   [0]  made                0.867        7.596        -5.725       -0.143       -5.464       -12.702      5.000        \n",
            "   [0]  to                  0.894        2.382        -1.650       -0.112       -6.022       -11.901      5.000        \n",
            "   [0]  has                 0.522        6.894        -7.489       -0.650       -6.689       -8.962       2.273        \n",
            "   [0]  a                   0.472        10.388       -1.376       -0.751       -6.835       -18.249      5.000        \n",
            "   [0]  barely              0.367        8.050        -8.711       -1.002       -6.886       -12.629      5.000        \n",
            "   [0]  for                 0.159        7.054        -4.092       -1.836       -6.660       -11.479      4.820        \n",
            "   [0]  childhood           0.104        5.614        -10.357      -2.263       -5.459       -13.170      5.000        \n",
            "   [0]  disturbing          0.027        4.095        -10.014      -3.618       -3.618       -10.206      5.000        \n",
            "   [1]  movie               0.056        0.000        0.000        0.000        0.000        -13.074      0.000        \n",
            "   [1]  go                  0.037        0.000        0.000        0.000        0.000        -9.691       0.000        \n",
            "   [1]  rent                0.017        0.000        0.000        0.000        0.000        -9.889       0.000        \n",
            "   [1]  bastard             0.006        0.000        0.000        0.000        0.000        -9.804       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  of                  0.492        0.000        0.000        0.000        -13.026      -3.916       -0.000       \n",
            "   [1]  a                   0.431        0.000        0.000        0.000        -14.743      -10.719      -0.000       \n",
            "   [1]  spoiled             0.718        0.000        0.000        0.000        -16.685      -9.265       -0.000       \n",
            "   [1]  rich                0.683        0.000        0.000        0.000        -18.884      -9.227       -0.000       \n",
            "   [1]  kid                 0.346        0.000        0.000        0.000        -21.373      -7.550       -0.000       \n",
            "   [0]  in                  0.415        4.271        -3.209       -0.880       -24.189      -7.997       -5.000       \n",
            "   [0]  enjoyable           0.070        9.850        -8.543       -2.656       -26.380      -7.932       -5.000       \n",
            "   [0]  ago                 0.012        4.634        -7.633       -4.384       -26.850      -10.086      -5.000       \n",
            "   [0]  portrays            0.007        11.689       -9.381       -4.980       -25.426      -13.278      -5.000       \n",
            "   [0]  in                  0.003        14.795       -3.254       -5.745       -23.141      -10.568      -5.000       \n",
            "   [0]  always              0.002        5.115        -8.551       -6.125       -19.689      -12.411      -5.000       \n",
            "   [0]  the                 0.002        10.080       -2.822       -6.477       -15.351      -13.075      -2.276       \n",
            "   [0]  action              0.004        11.192       -6.710       -5.556       -10.043      -13.037      2.993        \n",
            "   [0]  star                0.006        4.596        -6.367       -5.079       -5.079       -10.860      5.000        \n",
            "   [1]  student             0.006        0.000        0.000        0.000        0.000        -9.456       0.000        \n",
            "   [1]  body                0.005        0.000        0.000        0.000        0.000        -10.234      0.000        \n",
            "   [1]  of                  0.006        0.000        0.000        0.000        0.000        -10.181      0.000        \n",
            "   [1]  his                 0.009        0.000        0.000        0.000        0.000        -9.945       0.000        \n",
            "   [1]  new                 0.017        0.000        0.000        0.000        0.000        -9.204       0.000        \n",
            "   [1]  high                0.012        0.000        0.000        0.000        0.000        -8.118       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  tessari             0.690        0.000        0.000        0.000        -2.587       -3.996       0.000        \n",
            "   [1]  really              0.635        0.000        0.000        0.000        -2.928       -5.715       0.000        \n",
            "   [1]  ought               0.706        0.000        0.000        0.000        -3.314       -8.390       0.000        \n",
            "   [1]  to                  0.618        0.000        0.000        0.000        -3.751       -7.455       0.000        \n",
            "   [1]  be                  0.588        0.000        0.000        0.000        -4.245       -8.098       0.000        \n",
            "   [1]  applauded           0.629        0.000        0.000        0.000        -4.804       -12.087      0.000        \n",
            "   [1]  for                 0.644        0.000        0.000        0.000        -5.438       -8.343       0.000        \n",
            "   [1]  this                0.614        0.000        0.000        0.000        -6.154       -8.269       0.000        \n",
            "   [1]  truly               0.648        0.000        0.000        0.000        -6.965       -10.376      0.000        \n",
            "   [1]  proficient          0.605        0.000        0.000        0.000        -7.883       -9.460       0.000        \n",
            "   [1]  but                 0.563        0.000        0.000        0.000        -8.922       -8.048       -0.000       \n",
            "   [0]  crashes             0.662        7.819        -11.060      -0.412       -10.097      -8.314       -1.783       \n",
            "   [0]  overreaching        0.364        9.281        -11.910      -1.011       -10.961      -8.057       -2.905       \n",
            "   [0]  dunbar              0.224        10.868       -11.815      -1.495       -11.262      -12.119      0.857        \n",
            "   [0]  whirlygirl          0.114        10.510       -11.907      -2.174       -11.054      -12.648      1.594        \n",
            "   [0]  i                   0.088        9.483        -6.738       -2.425       -10.051      -12.787      2.736        \n",
            "   [0]  found               0.072        13.063       -4.952       -2.629       -8.631       -10.002      1.371        \n",
            "   [0]  starchaser          0.071        10.235       -12.996      -2.642       -6.793       -8.499       1.707        \n",
            "   [0]  familiarly          0.079        9.376        -12.062      -2.536       -4.697       -10.418      5.000        \n",
            "   [0]  materialises        0.087        7.460        -12.187      -2.446       -2.446       -9.732       5.000        \n",
            "Samples\n",
            "Sample 0 .  is the most disturbing film i have never made to has a barely for childhood disturbing movie go rent bastard\n",
            "Sample 1 .  of a spoiled rich kid in enjoyable ago portrays in always the action star student body of his new high\n",
            "Sample 2 .  tessari really ought to be applauded for this truly proficient but crashes overreaching dunbar whirlygirl i found starchaser familiarly materialises\n",
            "\n",
            "\n",
            "targets[[215 10 19 31 0 13021 2004 19 1322 9 13 1184 482 4 783 4344 144 0 194 2212][2271 637 513 33 1882 41153 5 2 989 211 297 16 75 11 367 4 3143 11636 7791 7][140 770 11 255 571 15 0 369 3 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[42 215 10 19 31 0 13021 2004 19 1322]...][[1 1 1 1 1 1 1 1 1 1]...][[42 215 10 19 31 0 13021 2004 19 1322]...][[215 10 19 31 0 13021 2004 19 1322 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[42 215 10 19 31 0 13021 2004 19 1322]...][[1 1 1 1 1 1 1 1 1 1]...][[42 215 10 19 31 0 13021 2004 19 1322]...][[215 10 19 31 0 13021 2004 19 1322 9]...]\n",
            "targets[[246 17 339 3 2559 6953 12 368 276 63 33250 36 0 298 8 108 741 190 10 5][2 825 246 17 11 124 23 38113 35005 0 613 1708 3 1278 14237 16704 5 2873 1 0][47 5 10 5421 45 92 142 368 104 38]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 246 17 339 3 2559 6953 12 368 276]...][[1 1 1 1 1 1 1 0 0 0]...][[0 246 17 339 3 2559 6953 12 69848 69848]...][[246 17 339 3 2559 6953 12 368 276 63]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 246 17 339 3 2559 6953 12 368 276]...][[1 1 1 1 1 1 1 0 0 0]...][[0 246 17 339 3 2559 6953 12 69848 69848]...][[246 17 339 3 2559 6953 12 322 766 954]...]\n",
            "targets[[8424 33890 47 5 873 2 53 1562 17 17688 10131 12 407 2535 14 2 74 534 13 30819][227 4317 5 2 17 43 0 5420 3 1389 16 928 1087 52 3978 928 9489 18 4742 22][141 28 60 244 3 17 58 46 7 2144]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6567 8424 33890 47 5 873 2 53 1562 17]...][[1 1 1 1 0 0 0 0 0 0]...][[6567 8424 33890 47 5 69848 69848 69848 69848 69848]...][[8424 33890 47 5 873 2 53 1562 17 17688]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6567 8424 33890 47 5 873 2 53 1562 17]...][[1 1 1 1 0 0 0 0 0 0]...][[6567 8424 33890 47 5 69848 69848 69848 69848 69848]...][[8424 33890 47 5 357 141 25 75 1149 6]...]\n",
            "targets[[84 353 4793 12 3102 12 4203 673 8 60 13951 1208 472 713 1 9 509 174 3186 1942][5 1003 4 28 2 680 18 0 310 1514 8 95 97 108 1265 31 0 12865 3 0][3 0 1606 5998 150 21 211 22 357 1783]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 353 4793 12 3102 12 4203 673 8]...][[1 1 1 0 0 0 0 0 0 0]...][[9 84 353 4793 69848 69848 69848 69848 69848 69848]...][[84 353 4793 12 3102 12 4203 673 8 60]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 353 4793 12 3102 12 4203 673 8]...][[1 1 1 0 0 0 0 0 0 0]...][[9 84 353 4793 69848 69848 69848 69848 69848 69848]...][[84 353 4793 11 0 669 57506 0 1461 2136]...]\n",
            "targets[[324 3 0 34 12 4476 13023 4441 2032 13 748 1841 9 254 37 108 4032 199 7384 1518][19 5 43 2 4034 125 4 548 1 26 2284 8 2 95 3 10504 863 0 19 2544][175 153 1252 279 543 3152 4340 1528 33644 45]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 324 3 0 34 12 4476 13023 4441 2032]...][[1 1 1 1 1 1 1 1 1 1]...][[0 324 3 0 34 12 4476 13023 4441 2032]...][[324 3 0 34 12 4476 13023 4441 2032 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 324 3 0 34 12 4476 13023 4441 2032]...][[1 1 1 1 1 1 1 1 1 1]...][[0 324 3 0 34 12 4476 13023 4441 2032]...][[324 3 0 34 12 4476 13023 4441 2032 13]...]\n",
            "targets[[307 10 1593 10 249 1 94 65731 16 60 568 4 66 10 24 165 1514 12124 294 135][6813 0 8938 3 2145 1389 22 19 8 13107 643 16 316 472 3423 70 148 147 31 3780][249 311 8 0 451 3 35 12331 522 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 307 10 1593 10 249 1 94 65731 16]...][[1 1 0 0 0 0 0 0 0 0]...][[9 307 10 69848 69848 69848 69848 69848 69848 69848]...][[307 10 1593 10 249 1 94 65731 16 60]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 307 10 1593 10 249 1 94 65731 16]...][[1 1 0 0 0 0 0 0 0 0]...][[9 307 10 69848 69848 69848 69848 69848 69848 69848]...][[307 10 19 14 2 711 766 17 9 27]...]\n",
            "targets[[52 741 72 29 51 9 215 1579 223 3899 9 196 7 59 28 0 276 32 59 922][44 38 440 104 167 7 2666 24688 48055 76 127 528 1 0 1806 17 22860 2190 494 4][17 13 497 327 278 7 13 37 74 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[8 52 741 72 29 51 9 215 1579 223]...][[1 1 1 1 1 1 1 1 1 0]...][[8 52 741 72 29 51 9 215 1579 223]...][[52 741 72 29 51 9 215 1579 223 3899]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[8 52 741 72 29 51 9 215 1579 223]...][[1 1 1 1 1 1 1 1 1 0]...][[8 52 741 72 29 51 9 215 1579 223]...][[52 741 72 29 51 9 215 1579 223 10]...]\n",
            "targets[[589 7672 1518 1505 21 92 2 19 8 2 291 1 2 315 85 9 300 37 1 6487][5 2 19 11 45 30 0 756 3 2 713 2 869 546 29 0 63 11 65 3032][41894 6065 0 289 102 3 0 41894 252 33]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[56 589 7672 1518 1505 21 92 2 19 8]...][[1 1 1 1 1 1 1 1 0 0]...][[56 589 7672 1518 1505 21 92 2 19 69848]...][[589 7672 1518 1505 21 92 2 19 8 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[56 589 7672 1518 1505 21 92 2 19 8]...][[1 1 1 1 1 1 1 1 0 0]...][[56 589 7672 1518 1505 21 92 2 19 69848]...][[589 7672 1518 1505 21 92 2 19 22 0]...]\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[1 1 1 0 0 0 0 0 0 0]...][[3857 471 5 23 69848 69848 69848 69848 69848 69848]...][[471 5 23 64 137 338 292 2 555 795]...]\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[1 1 1 0 0 0 0 0 0 0]...][[3857 471 5 23 69848 69848 69848 69848 69848 69848]...][[471 5 23 74 1101 4 3862 2124 184 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[1 1 1 0 0 0 0 0 0 0]...][[3857 471 5 23 69848 69848 69848 69848 69848 69848]...][[471 5 23 28 49 201 11 7 96 9148]...]\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "global_step: 7826\n",
            " perplexity: 417.252\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            " percent of 3-grams captured: 0.359.\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            " percent of 2-grams captured: 0.646.\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            " percent of 4-grams captured: 0.116.\n",
            " geometric_avg: 0.300.\n",
            " arithmetic_avg: 0.374.\n",
            "global_step: 7826\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39084\n",
            " G train loss: -8.54332\n",
            "targets[[471 5 23 74 1101 4 3862 2124 184 7 274 0 457 1 2450 3 258 519 184 314][89 21 103 100 1837 8 338 472 4939 14 194 14 577 6375 118 358 88 3 0 849][17 13 53 777 7 13 4610 1 155 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[1 1 1 0 0 0 0 0 0 0]...][[3857 471 5 23 69848 69848 69848 69848 69848 69848]...][[471 5 23 74 1101 4 3862 2124 184 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3857 471 5 23 74 1101 4 3862 2124 184]...][[1 1 1 0 0 0 0 0 0 0]...][[3857 471 5 23 69848 69848 69848 69848 69848 69848]...][[471 5 23 74 17 7 12 519 17 32]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  b                   0.512        0.000        0.000        0.000        -10.390      -4.107       -0.000       \n",
            "   [1]  is                  0.545        0.000        0.000        0.000        -11.759      -5.454       -0.000       \n",
            "   [1]  not                 0.483        0.000        0.000        0.000        -13.309      -12.753      -0.000       \n",
            "   [0]  bad                 0.527        5.452        -5.452       -0.641       -15.063      -11.041      -4.022       \n",
            "   [0]  movie               0.136        8.948        -4.624       -1.992       -16.322      -8.573       -5.000       \n",
            "   [0]  it                  0.126        2.021        -2.505       -2.068       -16.219      -10.242      -5.000       \n",
            "   [0]  s                   0.151        11.725       -2.311       -1.889       -16.015      -9.103       -5.000       \n",
            "   [0]  favorite            0.028        7.482        -6.226       -3.562       -15.987      -7.960       -5.000       \n",
            "   [0]  movie               0.037        6.137        -4.200       -3.287       -14.062      -15.007      0.944        \n",
            "   [0]  they                0.019        2.425        -5.393       -3.940       -12.196      -10.937      -1.258       \n",
            "   [0]  offers              0.007        8.381        -9.315       -4.997       -9.344       -9.586       0.242        \n",
            "   [0]  is                  0.007        1.882        -5.627       -4.920       -4.920       -10.035      5.000        \n",
            "   [1]  beginning           0.004        0.000        0.000        0.000        0.000        -8.903       0.000        \n",
            "   [1]  and                 0.003        0.000        0.000        0.000        0.000        -10.216      0.000        \n",
            "   [1]  birth               0.004        0.000        0.000        0.000        0.000        -9.419       0.000        \n",
            "   [1]  of                  0.017        0.000        0.000        0.000        0.000        -9.449       0.000        \n",
            "   [1]  our                 0.031        0.000        0.000        0.000        0.000        -8.178       0.000        \n",
            "   [1]  favorite            0.137        0.000        0.000        0.000        0.000        -8.017       0.000        \n",
            "   [1]  horror              0.189        0.000        0.000        0.000        0.000        -8.928       0.000        \n",
            "   [1]  star                0.124        0.000        0.000        0.000        0.000        -7.731       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  don                 0.547        0.000        0.000        0.000        -7.965       -4.121       -0.000       \n",
            "   [1]  t                   0.596        0.000        0.000        0.000        -9.015       -11.119      0.000        \n",
            "   [1]  think               0.512        0.000        0.000        0.000        -10.203      -2.980       -0.000       \n",
            "   [1]  any                 0.607        0.000        0.000        0.000        -11.547      -5.959       -0.000       \n",
            "   [1]  player              0.558        0.000        0.000        0.000        -13.069      -7.057       -0.000       \n",
            "   [1]  in                  0.466        0.000        0.000        0.000        -14.791      -8.040       -0.000       \n",
            "   [0]  lawrence            0.192        7.357        -10.039      -1.651       -16.740      -8.169       -5.000       \n",
            "   [0]  with                0.105        6.990        -5.027       -2.253       -17.078      -10.274      -5.000       \n",
            "   [0]  its                 0.177        10.879       -5.769       -1.734       -16.778      -8.653       -5.000       \n",
            "   [0]  when                0.090        6.216        -6.780       -2.411       -17.027      -7.029       -5.000       \n",
            "   [0]  on                  0.032        8.576        -4.427       -3.437       -16.543      -8.116       -5.000       \n",
            "   [0]  2                   0.078        5.393        -7.103       -2.549       -14.832      -9.126       -5.000       \n",
            "   [0]  remarkable          0.010        8.818        -9.791       -4.638       -13.902      -6.952       -5.000       \n",
            "   [0]  it                  0.005        11.304       -3.602       -5.337       -10.485      -11.586      1.101        \n",
            "   [0]  i                   0.003        5.496        -4.698       -5.826       -5.826       -12.090      5.000        \n",
            "   [1]  given               0.004        0.000        0.000        0.000        0.000        -12.601      0.000        \n",
            "   [1]  most                0.002        0.000        0.000        0.000        0.000        -8.967       0.000        \n",
            "   [1]  of                  0.014        0.000        0.000        0.000        0.000        -9.206       0.000        \n",
            "   [1]  the                 0.018        0.000        0.000        0.000        0.000        -5.874       0.000        \n",
            "   [1]  weak                0.007        0.000        0.000        0.000        0.000        -6.460       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  movie               0.482        0.000        0.000        0.000        -4.185       -3.860       -0.000       \n",
            "   [1]  was                 0.775        0.000        0.000        0.000        -4.736       -12.571      0.000        \n",
            "   [1]  very                0.735        0.000        0.000        0.000        -5.360       -8.473       0.000        \n",
            "   [1]  moving              0.900        0.000        0.000        0.000        -6.067       -9.490       0.000        \n",
            "   [0]  movie               0.485        4.171        -4.730       -0.723       -6.866       -9.512       2.646        \n",
            "   [0]  i                   0.544        6.906        -2.066       -0.609       -6.953       -11.124      4.172        \n",
            "   [0]  think               0.604        12.246       -4.392       -0.503       -7.180       -7.542       0.362        \n",
            "   [0]  a                   0.400        4.354        -3.407       -0.917       -7.556       -7.182       -0.375       \n",
            "   [0]  one                 0.197        5.623        -4.198       -1.626       -7.514       -9.886       2.371        \n",
            "   [0]  on                  0.166        5.494        -4.517       -1.795       -6.664       -8.060       1.396        \n",
            "   [0]  it                  0.137        1.242        -3.288       -1.986       -5.511       -11.033      5.000        \n",
            "   [0]  he                  0.092        10.428       -4.509       -2.391       -3.990       -9.852       5.000        \n",
            "   [0]  also                0.164        8.508        -6.381       -1.809       -1.809       -10.014      5.000        \n",
            "   [1]  the                 0.123        0.000        0.000        0.000        0.000        -9.811       0.000        \n",
            "   [1]  scenery             0.174        0.000        0.000        0.000        0.000        -10.374      0.000        \n",
            "   [1]  was                 0.200        0.000        0.000        0.000        0.000        -8.633       0.000        \n",
            "   [1]  absolutely          0.368        0.000        0.000        0.000        0.000        -7.739       0.000        \n",
            "   [1]  beautiful           0.745        0.000        0.000        0.000        0.000        -7.121       0.000        \n",
            "   [1]  peter               0.587        0.000        0.000        0.000        0.000        -9.291       0.000        \n",
            "   [1]  faulk               0.238        0.000        0.000        0.000        0.000        -8.154       0.000        \n",
            "Samples\n",
            "Sample 0 .  b is not bad movie it s favorite movie they offers is beginning and birth of our favorite horror star\n",
            "Sample 1 .  don t think any player in lawrence with its when on 2 remarkable it i given most of the weak\n",
            "Sample 2 .  movie was very moving movie i think a one on it he also the scenery was absolutely beautiful peter faulk\n",
            "\n",
            "\n",
            "targets[[5 2 337 636 0 63 13 615 1 67 2 337 271 2 203 8 60 660 0 176][17 5 29 3 0 173 46 23 0 64 13380 369 11 9 50 230 2378 3 7 702][203 27 509 7 9 2464 55 357 223 242]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 2 337 636 0 63 13 615 1]...][[1 1 0 0 0 0 0 0 0 0]...][[7 5 2 69848 69848 69848 69848 69848 69848 69848]...][[5 2 337 636 0 63 13 615 1 67]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 2 337 636 0 63 13 615 1]...][[1 1 0 0 0 0 0 0 0 0]...][[7 5 2 69848 69848 69848 69848 69848 69848 69848]...][[5 2 2109 0 1539 15469 13 20 182 2]...]\n",
            "targets[[5 35 379 19 9814 12780 1099 7 12 2088 2 1214 19 0 1419 621 1384 36 35 9657][10 487 22 227 17771 16 0 795 41 2919 57 509 7 37 73 9 5555 0 277 10][3 60 8080 1910 5 149 10 880 339 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 35 379 19 9814 12780 1099 7 12]...][[1 1 1 1 1 1 1 1 1 1]...][[10 5 35 379 19 9814 12780 1099 7 12]...][[5 35 379 19 9814 12780 1099 7 12 2088]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 35 379 19 9814 12780 1099 7 12]...][[1 1 1 1 1 1 1 1 1 1]...][[10 5 35 379 19 9814 12780 1099 7 12]...][[5 35 379 19 9814 12780 1099 7 12 2088]...]\n",
            "targets[[50392 12048 11697 5 0 84 6835 17 3 1178 9112 4522 1 1232 5 23 43 26343 25179 41][0 400 3170 13 283 0 5924 11402 7 59 28 7 5 23 404 20 169 11 88 3][20 182 4 66 2 17 43 179 11 83]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[207 50392 12048 11697 5 0 84 6835 17 3]...][[1 1 1 1 1 1 1 1 1 1]...][[207 50392 12048 11697 5 0 84 6835 17 3]...][[50392 12048 11697 5 0 84 6835 17 3 1178]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[207 50392 12048 11697 5 0 84 6835 17 3]...][[1 1 1 1 1 1 1 1 1 1]...][[207 50392 12048 11697 5 0 84 6835 17 3]...][[50392 12048 11697 5 0 84 6835 17 3 1178]...]\n",
            "targets[[50 21 387 134 10 17 13 113 278 22 277 41 31 219 378 9 723 21 58 110][171 3 75 89 21 103 5095 12 5143 19 5 30 11 49 18 9 203 987 9 103][20 121 51 2 19 45 20 1 5 413]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 50 21 387 134 10 17 13 113 278]...][[1 1 1 1 1 1 0 0 0 0]...][[9 50 21 387 134 10 17 69848 69848 69848]...][[50 21 387 134 10 17 13 113 278 22]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 50 21 387 134 10 17 13 113 278]...][[1 1 1 1 1 1 0 0 0 0]...][[9 50 21 387 134 10 17 69848 69848 69848]...][[50 21 387 134 10 17 1 2057 5 925]...]\n",
            "targets[[105 5 248 3616 16 10 1 7 64 218 11 73 85 3 5637 1 2386 0 109 5][17 5 43 14 2139 14 557 65653 1693 4 13556 10 17 5 113 155 7 12 272 0][82 390 16 5858 15025 5 15380 4 1521 287]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 105 5 248 3616 16 10 1 7 64]...][[1 1 1 0 0 0 0 0 0 0]...][[2 105 5 248 69848 69848 69848 69848 69848 69848]...][[105 5 248 3616 16 10 1 7 64 218]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 105 5 248 3616 16 10 1 7 64]...][[1 1 1 0 0 0 0 0 0 0]...][[2 105 5 248 69848 69848 69848 69848 69848 69848]...][[105 5 248 1344 1 242 45624 2 2466 348]...]\n",
            "targets[[275 200 341 2598 427 794 3661 8 2 3431 9897 5700 538 92 2 4427 590 2101 4 3141][3233 45 92 0 88 53910 24124 5695 462 894 115 19 9 103 9 139 123 110 69 272][5921 1 966 15206 1810 73 126 819 72 47]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[99 275 200 341 2598 427 794 3661 8 2]...][[1 1 1 0 0 0 0 0 0 0]...][[99 275 200 341 69848 69848 69848 69848 69848 69848]...][[275 200 341 2598 427 794 3661 8 2 3431]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[99 275 200 341 2598 427 794 3661 8 2]...][[1 1 1 0 0 0 0 0 0 0]...][[99 275 200 341 69848 69848 69848 69848 69848 69848]...][[275 200 341 3 30 6393 2 29 11 12]...]\n",
            "targets[[1059 1918 0 84 7059 3935 2192 1568 36 60 3297 9 418 144 30 0 2354 84 546 0][402 4090 55 544 4 106 10 17 22 246 51 9 13 2 527 7 1788 0 574 44][242 2 81 340 3 0 1734 3707 1 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[256 1059 1918 0 84 7059 3935 2192 1568 36]...][[1 1 1 1 1 1 0 0 0 0]...][[256 1059 1918 0 84 7059 3935 69848 69848 69848]...][[1059 1918 0 84 7059 3935 2192 1568 36 60]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[256 1059 1918 0 84 7059 3935 2192 1568 36]...][[1 1 1 1 1 1 0 0 0 0]...][[256 1059 1918 0 84 7059 3935 69848 69848 69848]...][[1059 1918 0 84 7059 3935 45 2 594 2871]...]\n",
            "targets[[1022 6 6 0 797 13 1050 15 75 1027 47 10 434 96 27 4039 77 46 358 52][597 75 597 46 20 1203 1239 10 2 49 17 137 5 6416 356 15 20 0 116 0][195 2 277 366 149 31 41619 1 1454 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1004 1022 6 6 0 797 13 1050 15 75]...][[1 1 1 1 1 0 0 0 0 0]...][[1004 1022 6 6 0 797 69848 69848 69848 69848]...][[1022 6 6 0 797 13 1050 15 75 1027]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1004 1022 6 6 0 797 13 1050 15 75]...][[1 1 1 1 1 0 0 0 0 0]...][[1004 1022 6 6 0 797 69848 69848 69848 69848]...][[1022 6 6 0 797 13 157 12050 1614 15]...]\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[1 0 0 0 0 0 0 0 0 0]...][[9 242 69848 69848 69848 69848 69848 69848 69848 69848]...][[242 1594 4 66 1014 57397 1 4367 15 2]...]\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[1 0 0 0 0 0 0 0 0 0]...][[9 242 69848 69848 69848 69848 69848 69848 69848 69848]...][[242 715 10 202 2 163 23 85 3 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[1 0 0 0 0 0 0 0 0 0]...][[9 242 69848 69848 69848 69848 69848 69848 69848 69848]...][[242 269 23 122 7 5 2 74 340 458]...]\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "global_step: 7843\n",
            " perplexity: 417.259\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            " percent of 3-grams captured: 0.368.\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            " percent of 2-grams captured: 0.652.\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            " percent of 4-grams captured: 0.112.\n",
            " geometric_avg: 0.300.\n",
            " arithmetic_avg: 0.377.\n",
            "global_step: 7843\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39068\n",
            " G train loss: -8.76814\n",
            "targets[[242 715 10 202 2 163 23 85 3 0 109 34 12 8789 18 16 0 1136 12319 1][89 21 182 4 198 10 308 314 9 470 4 38 7 18 7 1201 22 37 108 5611][5 241 29 3 0 250 98 9 27 123]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[1 0 0 0 0 0 0 0 0 0]...][[9 242 69848 69848 69848 69848 69848 69848 69848 69848]...][[242 715 10 202 2 163 23 85 3 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 715 10 202 2 163 23 85 3]...][[1 0 0 0 0 0 0 0 0 0]...][[9 242 69848 69848 69848 69848 69848 69848 69848 69848]...][[242 2 88 449 43 0 117 212 63 3159]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  am                  0.680        0.000        0.000        0.000        -19.163      -4.362       -0.000       \n",
            "   [0]  a                   0.533        6.265        -3.504       -0.629       -21.688      -8.109       -5.000       \n",
            "   [0]  most                0.024        8.414        -5.013       -3.729       -23.835      -5.761       -5.000       \n",
            "   [0]  laugh               0.020        6.772        -9.128       -3.889       -22.756      -15.277      -5.000       \n",
            "   [0]  about               0.016        4.677        -3.073       -4.146       -21.353      -12.524      -5.000       \n",
            "   [0]  the                 0.012        6.395        -1.621       -4.441       -19.474      -10.891      -5.000       \n",
            "   [0]  best                0.008        8.822        -4.422       -4.841       -17.014      -9.372       -5.000       \n",
            "   [0]  interesting         0.003        7.179        -6.612       -5.874       -13.777      -8.889       -4.888       \n",
            "   [0]  story               0.006        3.501        -5.209       -5.070       -8.945       -9.480       0.535        \n",
            "   [0]  knock               0.012        3.729        -10.737      -4.386       -4.386       -8.355       3.970        \n",
            "   [1]  plot                0.014        0.000        0.000        0.000        0.000        -8.274       0.000        \n",
            "   [1]  who                 0.014        0.000        0.000        0.000        0.000        -8.715       0.000        \n",
            "   [1]  s                   0.013        0.000        0.000        0.000        0.000        -9.725       0.000        \n",
            "   [1]  noticing            0.043        0.000        0.000        0.000        0.000        -9.098       0.000        \n",
            "   [1]  but                 0.049        0.000        0.000        0.000        0.000        -8.531       0.000        \n",
            "   [1]  for                 0.030        0.000        0.000        0.000        0.000        -8.066       0.000        \n",
            "   [1]  the                 0.034        0.000        0.000        0.000        0.000        -8.204       0.000        \n",
            "   [1]  incredible          0.019        0.000        0.000        0.000        0.000        -7.698       0.000        \n",
            "   [1]  allure              0.031        0.000        0.000        0.000        0.000        -7.365       0.000        \n",
            "   [1]  and                 0.039        0.000        0.000        0.000        0.000        -7.398       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  don                 0.505        0.000        0.000        0.000        -4.989       -3.739       -0.000       \n",
            "   [1]  t                   0.599        0.000        0.000        0.000        -5.647       -14.362      0.000        \n",
            "   [1]  want                0.657        0.000        0.000        0.000        -6.391       -6.621       0.000        \n",
            "   [1]  to                  0.729        0.000        0.000        0.000        -7.233       -7.629       0.000        \n",
            "   [1]  give                0.810        0.000        0.000        0.000        -8.186       -8.046       -0.000       \n",
            "   [0]  on                  0.249        2.161        -4.603       -1.389       -9.265       -8.293       -0.972       \n",
            "   [0]  the                 0.293        6.905        -1.911       -1.227       -8.914       -8.625       -0.290       \n",
            "   [0]  storyline           0.233        7.259        -6.853       -1.459       -8.700       -9.257       0.557        \n",
            "   [0]  future              0.247        3.780        -9.633       -1.398       -8.196       -9.312       1.117        \n",
            "   [0]  the                 0.215        9.118        -4.211       -1.538       -7.694       -8.792       1.098        \n",
            "   [0]  charlie             0.188        11.533       -9.380       -1.674       -6.967       -10.177      3.209        \n",
            "   [0]  comedian            0.066        7.532        -8.747       -2.711       -5.991       -7.620       1.629        \n",
            "   [0]  of                  0.139        4.729        -3.339       -1.975       -3.713       -13.173      5.000        \n",
            "   [0]  the                 0.140        6.257        -2.019       -1.967       -1.967       -8.260       5.000        \n",
            "   [1]  it                  0.073        0.000        0.000        0.000        0.000        -8.786       0.000        \n",
            "   [1]  failed              0.102        0.000        0.000        0.000        0.000        -8.434       0.000        \n",
            "   [1]  on                  0.241        0.000        0.000        0.000        0.000        -6.520       0.000        \n",
            "   [1]  so                  0.183        0.000        0.000        0.000        0.000        -8.209       0.000        \n",
            "   [1]  many                0.700        0.000        0.000        0.000        0.000        -6.184       0.000        \n",
            "   [1]  counts              0.866        0.000        0.000        0.000        0.000        -5.595       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  is                  0.613        0.000        0.000        0.000        -22.541      -4.059       -0.000       \n",
            "   [0]  a                   0.512        4.978        -1.419       -0.670       -25.511      -11.931      -5.000       \n",
            "   [0]  most                0.035        4.381        -4.587       -3.346       -28.114      -11.584      -5.000       \n",
            "   [0]  movie               0.007        5.334        -1.578       -5.019       -28.032      -15.918      -5.000       \n",
            "   [0]  movie               0.003        5.151        -3.712       -5.718       -26.045      -18.057      -5.000       \n",
            "   [0]  have                0.004        10.450       -8.256       -5.577       -23.006      -14.752      -5.000       \n",
            "   [0]  pits                0.003        9.437        -11.422      -5.959       -19.726      -12.723      -5.000       \n",
            "   [0]  that                0.003        3.502        -3.237       -5.698       -15.580      -11.845      -3.735       \n",
            "   [0]  he                  0.005        5.805        -5.488       -5.395       -11.185      -9.897       -1.287       \n",
            "   [0]  make                0.001        5.403        -4.477       -6.552       -6.552       -8.728       2.176        \n",
            "   [1]  seen                0.001        0.000        0.000        0.000        0.000        -11.710      0.000        \n",
            "   [1]  jessica             0.001        0.000        0.000        0.000        0.000        -11.355      0.000        \n",
            "   [1]  simpson             0.002        0.000        0.000        0.000        0.000        -11.931      0.000        \n",
            "   [1]  not                 0.002        0.000        0.000        0.000        0.000        -8.659       0.000        \n",
            "   [1]  only                0.003        0.000        0.000        0.000        0.000        -8.839       0.000        \n",
            "   [1]  lacks               0.004        0.000        0.000        0.000        0.000        -7.100       0.000        \n",
            "   [1]  any                 0.014        0.000        0.000        0.000        0.000        -7.365       0.000        \n",
            "   [1]  acting              0.070        0.000        0.000        0.000        0.000        -6.517       0.000        \n",
            "   [1]  skill               0.102        0.000        0.000        0.000        0.000        -7.460       0.000        \n",
            "   [1]  but                 0.080        0.000        0.000        0.000        0.000        -8.256       0.000        \n",
            "Samples\n",
            "Sample 0 .  am a most laugh about the best interesting story knock plot who s noticing but for the incredible allure and\n",
            "Sample 1 .  don t want to give on the storyline future the charlie comedian of the it failed on so many counts\n",
            "Sample 2 .  is a most movie movie have pits that he make seen jessica simpson not only lacks any acting skill but\n",
            "\n",
            "\n",
            "targets[[9 42 195 144 149 10 29 9 27 4 136 11 10 17 45 4 28 29 3 0][28450 611 5879 389 44 8 5247 1480 427 22 0 928 38194 729 122 11 672 143 8 0][10 17 13 23 606 708 5451 7 13 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[69 9 42 195 144 149 10 29 9 27]...][[1 1 1 1 1 1 1 0 0 0]...][[69 9 42 195 144 149 10 29 69848 69848]...][[9 42 195 144 149 10 29 9 27 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[69 9 42 195 144 149 10 29 9 27]...][[1 1 1 1 1 1 1 0 0 0]...][[69 9 42 195 144 149 10 29 69848 69848]...][[9 42 195 144 149 10 29 1 725 2]...]\n",
            "targets[[50 9 136 43 1426 7222 69 9 307 22 2 2766 36 8802 4 6015 1 14 11 2766][10 17 5 161 305 9 449 31 255 34 550 7 12 0 872 766 436 123 7 12][260 5674 5 2 557 1141 15 2 1539 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 50 9 136 43 1426 7222 69 9 307]...][[1 1 1 0 0 0 0 0 0 0]...][[47 50 9 136 69848 69848 69848 69848 69848 69848]...][[50 9 136 43 1426 7222 69 9 307 22]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 50 9 136 43 1426 7222 69 9 307]...][[1 1 1 0 0 0 0 0 0 0]...][[47 50 9 136 69848 69848 69848 69848 69848 69848]...][[50 9 136 39 13 2 88 19 1 1243]...]\n",
            "targets[[1736 1 26 115 812 4027 25 3666 4 138 4 3784 12 265 16 9245 2218 18 17860 7976][12 237 221 92 1259 0 260 7 288 21 30 74 9 42 103 0 9865 209 13 356][723 21 239 353 0 3433 13599 298 10 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1183 1736 1 26 115 812 4027 25 3666 4]...][[1 1 1 1 1 1 1 1 0 0]...][[1183 1736 1 26 115 812 4027 25 3666 69848]...][[1736 1 26 115 812 4027 25 3666 4 138]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1183 1736 1 26 115 812 4027 25 3666 4]...][[1 1 1 1 1 1 1 1 0 0]...][[1183 1736 1 26 115 812 4027 25 3666 69848]...][[1736 1 26 115 812 4027 25 3666 10 1076]...]\n",
            "targets[[12 871 4 15546 3 2 95 8 61 10 19 150 21 1981 28 7 0 503 0 116][60 412 968 2 115 11679 58 152 10 19 150 21 13900 15 2 669 341 1 1258 552][17 5 4203 7 702 0 63 3 451 634]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 871 4 15546 3 2 95 8 61]...][[1 1 1 1 0 0 0 0 0 0]...][[7 12 871 4 15546 69848 69848 69848 69848 69848]...][[12 871 4 15546 3 2 95 8 61 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 871 4 15546 3 2 95 8 61]...][[1 1 1 1 0 0 0 0 0 0]...][[7 12 871 4 15546 69848 69848 69848 69848 69848]...][[12 871 4 15546 1 29 22 11 141 38]...]\n",
            "targets[[18 10 17 5 394 7 6462 127 1648 31 174 479 1449 100 145 4328 1 9 6887 20][14454 0 2664 16 897 5238 12610 9 2191 596 131 798 134 25 32 30 37 613 7 12][435 34 4231 4 121 126 1591 10 36 7051]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[767 18 10 17 5 394 7 6462 127 1648]...][[1 1 1 1 1 1 1 1 1 1]...][[767 18 10 17 5 394 7 6462 127 1648]...][[18 10 17 5 394 7 6462 127 1648 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[767 18 10 17 5 394 7 6462 127 1648]...][[1 1 1 1 1 1 1 1 1 1]...][[767 18 10 17 5 394 7 6462 127 1648]...][[18 10 17 5 394 7 6462 127 1648 31]...]\n",
            "targets[[11 60 640 5 2 3512 3 0 1023 24551 12959 9 481 9 121 2 171 52 43 11][2731 55 0 109 3 13458 451 8 2 363 3 7351 13458 5 2 963 1376 15 2 1693][1845 15 959 12 69 542 4153 3 3062 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1078 11 60 640 5 2 3512 3 0 1023]...][[1 0 0 0 0 0 0 0 0 0]...][[1078 11 69848 69848 69848 69848 69848 69848 69848 69848]...][[11 60 640 5 2 3512 3 0 1023 24551]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1078 11 60 640 5 2 3512 3 0 1023]...][[1 0 0 0 0 0 0 0 0 0]...][[1078 11 69848 69848 69848 69848 69848 69848 69848 69848]...][[11 80 26315 9964 12 115 991 869 4116 16]...]\n",
            "targets[[1170 1430 1022 37 89 21 15622 185 97 229 97 927 46 20 89 21 182 4 121 47][5 33 229 29 3 0 250 98 9 27 123 110 0 336 305 290 349 15 0 336][27 307 4020 1236 16 52 72 2645 154 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 1170 1430 1022 37 89 21 15622 185 97]...][[1 1 1 1 1 1 0 0 0 0]...][[10 1170 1430 1022 37 89 21 69848 69848 69848]...][[1170 1430 1022 37 89 21 15622 185 97 229]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 1170 1430 1022 37 89 21 15622 185 97]...][[1 1 1 1 1 1 0 0 0 0]...][[10 1170 1430 1022 37 89 21 69848 69848 69848]...][[1170 1430 1022 37 89 21 37 335 523 249]...]\n",
            "targets[[96 1184 383 545 36 352 15504 120 41 42 1559 120 10 7408 18 9 874 4 1335 7][1262 348 42 85 10 19 5 263 36 0 648 184 1412 9 89 21 121 87 255 96][371 81 92 16 246 98 8 60 660 30]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 96 1184 383 545 36 352 15504 120 41]...][[1 1 1 1 1 0 0 0 0 0]...][[9 96 1184 383 545 36 69848 69848 69848 69848]...][[96 1184 383 545 36 352 15504 120 41 42]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 96 1184 383 545 36 352 15504 120 41]...][[1 1 1 1 1 0 0 0 0 0]...][[9 96 1184 383 545 36 69848 69848 69848 69848]...][[96 1184 383 545 36 1407 164 4 2 1476]...]\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[1 1 1 1 1 1 1 1 1 0]...][[14553 210 21 2 414 19 165 1225 740 107]...][[210 21 2 414 19 165 1225 740 107 1061]...]\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[1 1 1 1 1 1 1 1 1 0]...][[14553 210 21 2 414 19 165 1225 740 107]...][[210 21 2 414 19 165 1225 740 107 414]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[1 1 1 1 1 1 1 1 1 0]...][[14553 210 21 2 414 19 165 1225 740 107]...][[210 21 2 414 19 165 1225 740 107 84]...]\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "global_step: 7860\n",
            " perplexity: 416.997\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            " percent of 3-grams captured: 0.322.\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            " percent of 2-grams captured: 0.652.\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            " percent of 4-grams captured: 0.117.\n",
            " geometric_avg: 0.291.\n",
            " arithmetic_avg: 0.364.\n",
            "global_step: 7860\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39057\n",
            " G train loss: -8.45278\n",
            "targets[[210 21 2 414 19 165 1225 740 107 414 18 1321 10 17 210 21 2 1223 352 9][3895 755 3 2 363 3536 4 0 4131 3473 1 1410 44 0 1282 13 23 606 14 6364][21 28 4374 33 238 11 20 27 123 353]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[1 1 1 1 1 1 1 1 1 0]...][[14553 210 21 2 414 19 165 1225 740 107]...][[210 21 2 414 19 165 1225 740 107 414]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14553 210 21 2 414 19 165 1225 740 107]...][[1 1 1 1 1 1 1 1 1 0]...][[14553 210 21 2 414 19 165 1225 740 107]...][[210 21 2 414 19 165 1225 740 107 3797]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  isn                 0.657        0.000        0.000        0.000        -2.312       -3.982       0.000        \n",
            "   [1]  t                   0.583        0.000        0.000        0.000        -2.617       -18.392      0.000        \n",
            "   [1]  a                   0.584        0.000        0.000        0.000        -2.962       -13.729      0.000        \n",
            "   [1]  perfect             0.557        0.000        0.000        0.000        -3.352       -9.905       0.000        \n",
            "   [1]  film                0.691        0.000        0.000        0.000        -3.793       -7.014       0.000        \n",
            "   [1]  actually            0.664        0.000        0.000        0.000        -4.293       -8.545       0.000        \n",
            "   [1]  nowhere             0.700        0.000        0.000        0.000        -4.859       -8.465       0.000        \n",
            "   [1]  near                0.634        0.000        0.000        0.000        -5.499       -6.874       0.000        \n",
            "   [1]  being               0.519        0.000        0.000        0.000        -6.224       -6.615       0.000        \n",
            "   [0]  trio                0.410        7.686        -9.449       -0.892       -7.044       -8.376       1.332        \n",
            "   [0]  mixing              0.274        4.464        -10.580      -1.294       -6.963       -7.220       0.258        \n",
            "   [0]  demonic             0.245        9.504        -11.298      -1.405       -6.415       -7.401       0.985        \n",
            "   [0]  installment         0.185        6.640        -9.410       -1.685       -5.670       -8.426       2.755        \n",
            "   [0]  it                  0.170        6.955        -5.257       -1.770       -4.510       -8.436       3.926        \n",
            "   [0]  is                  0.415        6.797        -1.736       -0.879       -3.101       -8.347       5.000        \n",
            "   [0]  hit                 0.358        7.818        -7.524       -1.028       -2.515       -8.559       5.000        \n",
            "   [0]  and                 0.296        2.908        -2.976       -1.217       -1.683       -8.065       5.000        \n",
            "   [0]  then                0.591        9.309        -6.309       -0.527       -0.527       -8.086       5.000        \n",
            "   [1]  either              0.559        0.000        0.000        0.000        0.000        -6.265       0.000        \n",
            "   [1]  i                   0.460        0.000        0.000        0.000        0.000        -8.018       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  captivating         0.517        0.000        0.000        0.000        -9.773       -3.899       -0.000       \n",
            "   [1]  tale                0.547        0.000        0.000        0.000        -11.061      -9.445       -0.000       \n",
            "   [1]  of                  0.577        0.000        0.000        0.000        -12.519      -7.642       -0.000       \n",
            "   [1]  a                   0.731        0.000        0.000        0.000        -14.169      -4.058       -0.000       \n",
            "   [1]  couple              0.681        0.000        0.000        0.000        -16.036      -6.435       -0.000       \n",
            "   [1]  returning           0.131        0.000        0.000        0.000        -18.149      -5.511       -0.000       \n",
            "   [0]  alone               0.233        5.102        -8.245       -1.459       -20.541      -7.452       -5.000       \n",
            "   [0]  of                  0.040        2.849        -2.840       -3.212       -21.596      -9.115       -5.000       \n",
            "   [0]  blair               0.014        10.190       -10.197      -4.241       -20.807      -12.286      -5.000       \n",
            "   [0]  benjamin            0.102        11.057       -10.121      -2.278       -18.748      -10.799      -5.000       \n",
            "   [0]  with                0.041        2.457        -4.408       -3.195       -18.641      -9.364       -5.000       \n",
            "   [0]  murderer            0.011        9.175        -9.002       -4.467       -17.481      -9.074       -5.000       \n",
            "   [0]  and                 0.005        5.735        -2.455       -5.362       -14.729      -11.841      -2.888       \n",
            "   [0]  still               0.005        1.839        -7.048       -5.362       -10.602      -13.148      2.546        \n",
            "   [0]  done                0.003        9.151        -6.645       -5.930       -5.930       -11.057      5.000        \n",
            "   [1]  was                 0.002        0.000        0.000        0.000        0.000        -11.324      0.000        \n",
            "   [1]  not                 0.002        0.000        0.000        0.000        0.000        -11.045      0.000        \n",
            "   [1]  exactly             0.005        0.000        0.000        0.000        0.000        -9.922       0.000        \n",
            "   [1]  as                  0.006        0.000        0.000        0.000        0.000        -8.429       0.000        \n",
            "   [1]  advertised          0.002        0.000        0.000        0.000        0.000        -10.894      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  t                   0.568        0.000        0.000        0.000        -1.969       -4.316       0.000        \n",
            "   [1]  be                  0.582        0.000        0.000        0.000        -2.228       -20.862      0.000        \n",
            "   [1]  fooled              0.620        0.000        0.000        0.000        -2.522       -18.503      0.000        \n",
            "   [1]  by                  0.795        0.000        0.000        0.000        -2.854       -14.581      0.000        \n",
            "   [1]  anything            0.669        0.000        0.000        0.000        -3.230       -12.092      0.000        \n",
            "   [1]  that                0.630        0.000        0.000        0.000        -3.656       -10.639      0.000        \n",
            "   [0]  s                   0.373        3.167        -2.994       -0.986       -4.138       -10.375      5.000        \n",
            "   [0]  a                   0.209        7.302        -2.301       -1.567       -3.567       -9.881       5.000        \n",
            "   [0]  sad                 0.474        10.270       -7.593       -0.746       -2.264       -10.312      5.000        \n",
            "   [0]  series              0.735        10.232       -5.750       -0.308       -1.718       -9.483       5.000        \n",
            "   [0]  in                  0.588        4.753        -3.664       -0.531       -1.597       -10.874      5.000        \n",
            "   [0]  this                0.656        2.880        -2.880       -0.422       -1.206       -9.853       5.000        \n",
            "   [0]  film                0.675        1.599        -1.962       -0.393       -0.888       -8.861       5.000        \n",
            "   [0]  dc                  0.718        6.805        -11.992      -0.331       -0.559       -8.440       5.000        \n",
            "   [0]  cheap               0.772        9.091        -8.836       -0.259       -0.259       -8.692       5.000        \n",
            "   [1]  how                 0.674        0.000        0.000        0.000        0.000        -7.347       0.000        \n",
            "   [1]  good                0.848        0.000        0.000        0.000        0.000        -8.195       0.000        \n",
            "   [1]  someone             0.938        0.000        0.000        0.000        0.000        -8.622       0.000        \n",
            "   [1]  has                 0.940        0.000        0.000        0.000        0.000        -8.387       0.000        \n",
            "   [1]  said                0.954        0.000        0.000        0.000        0.000        -8.483       0.000        \n",
            "Samples\n",
            "Sample 0 .  isn t a perfect film actually nowhere near being trio mixing demonic installment it is hit and then either i\n",
            "Sample 1 .  captivating tale of a couple returning alone of blair benjamin with murderer and still done was not exactly as advertised\n",
            "Sample 2 .  t be fooled by anything that s a sad series in this film dc cheap how good someone has said\n",
            "\n",
            "\n",
            "targets[[67 0 1421 4 106 10 17 33 801 3 2 1912 11 9 27 1918 8 3815 1 9][203 5751 4 3995 1370 817 98 18 10 19 5 65 42 1043 379 74 305 290 58 447][5 2 81 17 16 30 2220 91 0 63]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 67 0 1421 4 106 10 17 33 801]...][[1 1 0 0 0 0 0 0 0 0]...][[9 67 0 69848 69848 69848 69848 69848 69848 69848]...][[67 0 1421 4 106 10 17 33 801 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 67 0 1421 4 106 10 17 33 801]...][[1 1 0 0 0 0 0 0 0 0]...][[9 67 0 69848 69848 69848 69848 69848 69848 69848]...][[67 0 17 0 314 122 1526 18 10 63]...]\n",
            "targets[[35 6330 842 7 13 2 2069 2269 1 99 2 194 752 1307 9 4098 545 22 0 9763][200 599 8 13702 317 2779 13702 30447 55116 50809 10209 1846 0 81 39624 3562 773 13401 12 227][763 10 17 44 22 194 958 111 9 2164]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 35 6330 842 7 13 2 2069 2269 1]...][[1 1 1 1 0 0 0 0 0 0]...][[47 35 6330 842 7 69848 69848 69848 69848 69848]...][[35 6330 842 7 13 2 2069 2269 1 99]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 35 6330 842 7 13 2 2069 2269 1]...][[1 1 1 1 0 0 0 0 0 0]...][[47 35 6330 842 7 69848 69848 69848 69848 69848]...][[35 6330 842 7 25 92 8 263 16 2]...]\n",
            "targets[[1022 1135 3 11092 6 6 10 17 3776 2 4673 11 88 2484 2230 439 608 490 9 1779][5 29 3 0 117 104 11 9 27 123 307 7 45 2 53 583 716 15 135 3][13 642 22 1234 463 8 1844 22 463 796]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1022 1022 1135 3 11092 6 6 10 17 3776]...][[1 1 1 1 1 1 0 0 0 0]...][[1022 1022 1135 3 11092 6 6 69848 69848 69848]...][[1022 1135 3 11092 6 6 10 17 3776 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1022 1022 1135 3 11092 6 6 10 17 3776]...][[1 1 1 1 1 1 0 0 0 0]...][[1022 1022 1135 3 11092 6 6 69848 69848 69848]...][[1022 1135 3 11092 6 6 10 19 5 29]...]\n",
            "targets[[5 35 4462 1282 185 1718 2847 8642 5996 1 2106 20641 166 120 3 29 157 1 25 924][17 5 1338 0 109 5 2202 1764 0 95 70 138 143 4 66 47 551 15 253 3][224 5 33 11944 15190 36 0 2598 304 47]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 35 4462 1282 185 1718 2847 8642 5996]...][[1 1 1 1 1 1 0 0 0 0]...][[7 5 35 4462 1282 185 1718 69848 69848 69848]...][[5 35 4462 1282 185 1718 2847 8642 5996 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 5 35 4462 1282 185 1718 2847 8642 5996]...][[1 1 1 1 1 1 0 0 0 0]...][[7 5 35 4462 1282 185 1718 69848 69848 69848]...][[5 35 4462 1282 185 1718 0 822 116 13]...]\n",
            "targets[[2 397 4336 17 8 0 368 1839 46729 8030 629 3975 3092 6 6 9 386 21 136 73][19 21259 16692 83 1017 127 573 473 45 23 77 642 22 276 246 16 2 2040 29 130][30807 12 1605 1437 5 2 414 502 3 87]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 397 4336 17 8 0 368 1839 46729]...][[1 1 1 1 0 0 0 0 0 0]...][[47 2 397 4336 17 69848 69848 69848 69848 69848]...][[2 397 4336 17 8 0 368 1839 46729 8030]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 2 397 4336 17 8 0 368 1839 46729]...][[1 1 1 1 0 0 0 0 0 0]...][[47 2 397 4336 17 69848 69848 69848 69848 69848]...][[2 397 4336 17 5 2 1077 800 49 259]...]\n",
            "targets[[425 3 1867 1448 10 4 71 16 12762 85 9 106 2 171 3 681 184 104 38 24][50 9 169 10 22 246 175 70 2021 32 559 1234 700 120 8 258 344 55 3 6168][13 2 394 17 0 547 25 119 13064 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 425 3 1867 1448 10 4 71 16 12762]...][[1 0 0 0 0 0 0 0 0 0]...][[2 425 69848 69848 69848 69848 69848 69848 69848 69848]...][[425 3 1867 1448 10 4 71 16 12762 85]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 425 3 1867 1448 10 4 71 16 12762]...][[1 0 0 0 0 0 0 0 0 0]...][[2 425 69848 69848 69848 69848 69848 69848 69848 69848]...][[425 2580 1 13 2432 17 727 15 126 4040]...]\n",
            "targets[[17 672 44 14 137 315 1094 18 0 82 1001 228 3 0 19 13 2 605 453 39][19 624 13 273 0 1686 3 0 277 7 5034 15 1302 796 36 3270 791 66 0 1908][98 25 42 1003 4 28 2 81 845 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 672 44 14 137 315 1094 18 0]...][[1 1 0 0 0 0 0 0 0 0]...][[10 17 672 69848 69848 69848 69848 69848 69848 69848]...][[17 672 44 14 137 315 1094 18 0 82]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 672 44 14 137 315 1094 18 0]...][[1 1 0 0 0 0 0 0 0 0]...][[10 17 672 69848 69848 69848 69848 69848 69848 69848]...][[17 672 358 3758 43 69 2 669 1177 95]...]\n",
            "targets[[80 20 76 51 20 1451 2 11287 3 675 12 15 2 22109 1821 1 2 522 3 101][10 210 21 0 7719 3 1305 23702 1528 1388 18 2 49 201 15 8282 558 16 3406 1518][9 112 10 19 123 233 9 215 7 31]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 80 20 76 51 20 1451 2 11287 3]...][[1 1 1 1 1 0 0 0 0 0]...][[47 80 20 76 51 20 69848 69848 69848 69848]...][[80 20 76 51 20 1451 2 11287 3 675]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 80 20 76 51 20 1451 2 11287 3]...][[1 1 1 1 1 0 0 0 0 0]...][[47 80 20 76 51 20 69848 69848 69848 69848]...][[80 20 76 51 20 13 71 40 69 0]...]\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[1 1 1 1 1 1 1 0 0 0]...][[473 0 3988 1 407 3821 8286 5421 69848 69848]...][[0 3988 1 407 3821 8286 5421 33 17 3]...]\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[1 1 1 1 1 1 1 0 0 0]...][[473 0 3988 1 407 3821 8286 5421 69848 69848]...][[0 3988 1 407 3821 8286 5421 13 5363 1267]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[1 1 1 1 1 1 1 0 0 0]...][[473 0 3988 1 407 3821 8286 5421 69848 69848]...][[0 3988 1 407 3821 8286 5421 13286 3234 5337]...]\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "global_step: 7877\n",
            " perplexity: 416.050\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            " percent of 3-grams captured: 0.339.\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            " percent of 2-grams captured: 0.655.\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            " percent of 4-grams captured: 0.110.\n",
            " geometric_avg: 0.290.\n",
            " arithmetic_avg: 0.368.\n",
            "global_step: 7877\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39023\n",
            " G train loss: -8.33487\n",
            "targets[[0 3988 1 407 3821 8286 5421 13 5363 1267 14 29 3 0 872 184 964 123 4 1656][1 1588 8433 198 49 347 14 105 14897 556 292 4 8071 44 0 2507 1238 0 366 3][22 12 160 7553 31 459 11205 22 38298 205]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[1 1 1 1 1 1 1 0 0 0]...][[473 0 3988 1 407 3821 8286 5421 69848 69848]...][[0 3988 1 407 3821 8286 5421 13 5363 1267]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[473 0 3988 1 407 3821 8286 5421 13 5363]...][[1 1 1 1 1 1 1 0 0 0]...][[473 0 3988 1 407 3821 8286 5421 69848 69848]...][[0 3988 1 407 3821 8286 5421 1435 0 68105]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  the                 0.599        0.000        0.000        0.000        -4.620       -4.276       -0.000       \n",
            "   [1]  seventies           0.595        0.000        0.000        0.000        -5.229       -8.240       0.000        \n",
            "   [1]  and                 0.670        0.000        0.000        0.000        -5.918       -7.860       0.000        \n",
            "   [1]  early               0.666        0.000        0.000        0.000        -6.697       -8.459       0.000        \n",
            "   [1]  eighties            0.773        0.000        0.000        0.000        -7.580       -6.839       -0.000       \n",
            "   [1]  tobe                0.477        0.000        0.000        0.000        -8.579       -8.133       -0.000       \n",
            "   [1]  hooper              0.874        0.000        0.000        0.000        -9.709       -12.100      0.000        \n",
            "   [0]  drawn               0.768        4.116        -9.462       -0.264       -10.989      -10.392      -0.597       \n",
            "   [0]  the                 0.123        11.545       -3.125       -2.095       -12.139      -10.614      -1.525       \n",
            "   [0]  netflixed           0.083        10.307       -13.932      -2.487       -11.367      -17.230      5.000        \n",
            "   [0]  3                   0.163        4.633        -7.951       -1.813       -10.050      -11.660      1.610        \n",
            "   [0]  of                  0.098        5.671        -2.938       -2.322       -9.322       -12.727      3.405        \n",
            "   [0]  companies           0.154        6.389        -10.545      -1.869       -7.923       -12.170      4.247        \n",
            "   [0]  in                  0.103        3.449        -3.078       -2.274       -6.853       -12.244      5.000        \n",
            "   [0]  the                 0.118        9.378        -1.357       -2.141       -5.181       -10.813      5.000        \n",
            "   [0]  unbearable          0.032        6.229        -9.940       -3.441       -3.441       -10.248      5.000        \n",
            "   [1]  directors           0.057        0.000        0.000        0.000        0.000        -12.482      0.000        \n",
            "   [1]  ever                0.041        0.000        0.000        0.000        0.000        -11.149      0.000        \n",
            "   [1]  to                  0.038        0.000        0.000        0.000        0.000        -11.923      0.000        \n",
            "   [1]  grace               0.120        0.000        0.000        0.000        0.000        -8.797       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  and                 0.495        0.000        0.000        0.000        -0.864       -4.297       0.000        \n",
            "   [1]  christian           0.571        0.000        0.000        0.000        -0.978       -6.461       0.000        \n",
            "   [1]  bale                0.668        0.000        0.000        0.000        -1.106       -4.811       0.000        \n",
            "   [1]  give                0.435        0.000        0.000        0.000        -1.252       -7.436       0.000        \n",
            "   [1]  good                0.246        0.000        0.000        0.000        -1.417       -7.845       0.000        \n",
            "   [0]  films               0.857        8.489        -5.648       -0.154       -1.604       -9.490       5.000        \n",
            "   [0]  from                0.819        3.701        -3.927       -0.200       -1.641       -9.483       5.000        \n",
            "   [0]  people              0.769        5.796        -6.674       -0.263       -1.631       -8.167       5.000        \n",
            "   [0]  murder              0.830        14.252       -8.620       -0.186       -1.548       -7.868       5.000        \n",
            "   [0]  todd                0.907        8.613        -9.462       -0.098       -1.542       -8.940       5.000        \n",
            "   [0]  that                0.800        7.353        -4.983       -0.223       -1.634       -8.764       5.000        \n",
            "   [0]  s                   0.824        6.791        -1.652       -0.194       -1.597       -8.359       5.000        \n",
            "   [0]  a                   0.692        14.444       -2.648       -0.368       -1.588       -8.574       5.000        \n",
            "   [0]  700                 0.251        12.200       -10.566      -1.381       -1.381       -8.961       5.000        \n",
            "   [1]  the                 0.181        0.000        0.000        0.000        0.000        -11.088      0.000        \n",
            "   [1]  dragon              0.159        0.000        0.000        0.000        0.000        -11.112      0.000        \n",
            "   [1]  race                0.115        0.000        0.000        0.000        0.000        -10.435      0.000        \n",
            "   [1]  the                 0.120        0.000        0.000        0.000        0.000        -10.739      0.000        \n",
            "   [1]  start               0.219        0.000        0.000        0.000        0.000        -9.924       0.000        \n",
            "   [1]  of                  0.223        0.000        0.000        0.000        0.000        -9.648       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  on                  0.684        0.000        0.000        0.000        -1.562       -3.964       0.000        \n",
            "   [1]  s                   0.545        0.000        0.000        0.000        -1.767       -6.374       0.000        \n",
            "   [1]  new                 0.522        0.000        0.000        0.000        -2.000       -10.315      0.000        \n",
            "   [1]  schedule            0.473        0.000        0.000        0.000        -2.264       -8.276       0.000        \n",
            "   [1]  at                  0.659        0.000        0.000        0.000        -2.562       -8.421       0.000        \n",
            "   [1]  4                   0.568        0.000        0.000        0.000        -2.900       -7.598       0.000        \n",
            "   [1]  pm                  0.778        0.000        0.000        0.000        -3.282       -7.984       0.000        \n",
            "   [1]  on                  0.609        0.000        0.000        0.000        -3.714       -7.138       0.000        \n",
            "   [1]  weekdays            0.902        0.000        0.000        0.000        -4.204       -6.252       0.000        \n",
            "   [0]  montage             0.721        8.290        -11.879      -0.327       -4.758       -9.876       5.000        \n",
            "   [0]  into                0.131        6.553        -5.953       -2.031       -5.015       -10.529      5.000        \n",
            "   [0]  a                   0.120        11.517       -1.618       -2.117       -3.377       -9.353       5.000        \n",
            "   [0]  small               0.466        8.504        -5.237       -0.763       -1.426       -8.301       5.000        \n",
            "   [0]  stage               0.793        8.996        -8.080       -0.232       -0.750       -7.233       5.000        \n",
            "   [0]  in                  0.786        7.941        -3.470       -0.241       -0.586       -9.249       5.000        \n",
            "   [0]  a                   0.778        8.642        -1.661       -0.251       -0.391       -7.900       5.000        \n",
            "   [0]  big                 0.914        6.752        -5.323       -0.090       -0.159       -9.500       5.000        \n",
            "   [0]  folks               0.925        7.741        -8.738       -0.077       -0.077       -7.974       5.000        \n",
            "   [1]  followed            0.827        0.000        0.000        0.000        0.000        -8.932       0.000        \n",
            "   [1]  by                  0.909        0.000        0.000        0.000        0.000        -9.022       0.000        \n",
            "Samples\n",
            "Sample 0 .  the seventies and early eighties tobe hooper drawn the netflixed 3 of companies in the unbearable directors ever to grace\n",
            "Sample 1 .  and christian bale give good films from people murder todd that s a 700 the dragon race the start of\n",
            "Sample 2 .  on s new schedule at 4 pm on weekdays montage into a small stage in a big folks followed by\n",
            "\n",
            "\n",
            "targets[[1470 38 8251 12 0 9567 5 427 22 0 1188 601 673 0 9567 1156 4843 786 9747 1386][678 18058 53 49 815 20 96 138 44 16 2 6514 296 758 31 30 2326 6 6 29][172 3 0 6287 3 0 768 3 7335 11730]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 1470 38 8251 12 0 9567 5 427 22]...][[1 1 1 1 1 0 0 0 0 0]...][[10 1470 38 8251 12 0 69848 69848 69848 69848]...][[1470 38 8251 12 0 9567 5 427 22 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 1470 38 8251 12 0 9567 5 427 22]...][[1 1 1 1 1 0 0 0 0 0]...][[10 1470 38 8251 12 0 69848 69848 69848 69848]...][[1470 38 8251 12 0 8503 5542 5 234 1450]...]\n",
            "targets[[2119 742 3 609 80 661 2 2200 1 758 7 31 30 2287 586 0 281 16 137 52][44 0 12248 969 30 9406 258 1107 768 7553 2 1151 3850 926 105 16648 84 44107 1 1083][7390 23 16 0 1909 41 146 34 512 62]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[475 2119 742 3 609 80 661 2 2200 1]...][[1 1 1 1 1 1 1 1 0 0]...][[475 2119 742 3 609 80 661 2 2200 69848]...][[2119 742 3 609 80 661 2 2200 1 758]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[475 2119 742 3 609 80 661 2 2200 1]...][[1 1 1 1 1 1 1 1 0 0]...][[475 2119 742 3 609 80 661 2 2200 69848]...][[2119 742 3 609 80 661 2 2200 1 263]...]\n",
            "targets[[987 11 9 13 1435 4 10 19 33 10730 12 1517 738 1570 2019 869 1545 46 7 96][139 353 0 829 1 9 121 60 660 5 14834 37 8 60 1146 660 0 160 2726 2142][9 50 21 262 10 17 195 92 4572 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 987 11 9 13 1435 4 10 19 33]...][[1 1 1 1 1 1 1 1 1 1]...][[9 987 11 9 13 1435 4 10 19 33]...][[987 11 9 13 1435 4 10 19 33 10730]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 987 11 9 13 1435 4 10 19 33]...][[1 1 1 1 1 1 1 1 1 1]...][[9 987 11 9 13 1435 4 10 19 33]...][[987 11 9 13 1435 4 10 19 33 10730]...]\n",
            "targets[[20 89 21 333 256 127 1399 26847 15 94 20 386 21 333 10 17 22 0 82 495][10 5 0 6221 1128 37 272 7 12 57 16 58 0 1420 477 4 76 2 3122 55][322 17 29 3 0 117 9 139 110 1338]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 89 21 333 256 127 1399 26847 15]...][[1 1 1 1 1 1 1 0 0 0]...][[46 20 89 21 333 256 127 1399 69848 69848]...][[20 89 21 333 256 127 1399 26847 15 94]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 89 21 333 256 127 1399 26847 15]...][[1 1 1 1 1 1 1 0 0 0]...][[46 20 89 21 333 256 127 1399 69848 69848]...][[20 89 21 333 256 127 1399 50 21 7094]...]\n",
            "targets[[140 133 1014 23 9 140 133 2224 60 545 47 0 220 13 9 1184 195 2 5299 10][736 370 3 675 12 23 58 29 1010 344 4 23243 0 14765 3700 162 157 173 4546 5743][40987 5 29 3 0 88 3078 55956 3534 9177]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 140 133 1014 23 9 140 133 2224 60]...][[1 1 1 1 1 1 1 1 1 1]...][[9 140 133 1014 23 9 140 133 2224 60]...][[140 133 1014 23 9 140 133 2224 60 545]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 140 133 1014 23 9 140 133 2224 60]...][[1 1 1 1 1 1 1 1 1 1]...][[9 140 133 1014 23 9 140 133 2224 60]...][[140 133 1014 23 9 140 133 2224 60 545]...]\n",
            "targets[[50 21 1652 42 87 74 10 17 5 9 89 21 456 11 32 241 1066 43 2 3102][45 4 28 29 3 0 117 3 0 4638 104 11 9 139 123 110 0 109 5 2][65 467 0 122 9 419 32 148 103 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[683 50 21 1652 42 87 74 10 17 5]...][[1 1 1 1 1 1 1 1 0 0]...][[683 50 21 1652 42 87 74 10 17 69848]...][[50 21 1652 42 87 74 10 17 5 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[683 50 21 1652 42 87 74 10 17 5]...][[1 1 1 1 1 1 1 1 0 0]...][[683 50 21 1652 42 87 74 10 17 69848]...][[50 21 1652 42 87 74 10 17 7 9]...]\n",
            "targets[[149 0 84 3575 228 3 10 21010 7161 3 821 15037 9 31991 4769 11 9 207 77 599][64 1059 254 44 11 7569 1286 25329 12 673 67 77 654 78 2 246 17 33 959 1][5 29836 4 73 37 4653 4 106 9 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[99 149 0 84 3575 228 3 10 21010 7161]...][[1 1 1 1 1 1 0 0 0 0]...][[99 149 0 84 3575 228 3 69848 69848 69848]...][[149 0 84 3575 228 3 10 21010 7161 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[99 149 0 84 3575 228 3 10 21010 7161]...][[1 1 1 1 1 1 0 0 0 0]...][[99 149 0 84 3575 228 3 69848 69848 69848]...][[149 0 84 3575 228 3 155 116 99 121]...]\n",
            "targets[[0 2413 10829 499 8 38874 8 1210 764 111 105 5452 1922 1644 26505 2272 761 11333 25 43][17 5 730 4 2720 724 1 0 8438 3340 18 7 12 79 73 52 2063 72 193 1][165 424 10 17 251 0 116 13 1060 39]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[18577 0 2413 10829 499 8 38874 8 1210 764]...][[1 1 1 1 0 0 0 0 0 0]...][[18577 0 2413 10829 499 69848 69848 69848 69848 69848]...][[0 2413 10829 499 8 38874 8 1210 764 111]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[18577 0 2413 10829 499 8 38874 8 1210 764]...][[1 1 1 1 0 0 0 0 0 0]...][[18577 0 2413 10829 499 69848 69848 69848 69848 69848]...][[0 2413 10829 499 14 35 23950 5510 13 2]...]\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 1 1 1 1 0 0 0 0 0]...][[46 20 38 832 827 1890 69848 69848 69848 69848]...][[20 38 832 827 1890 18 11 3419 761 3]...]\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 1 1 1 1 0 0 0 0 0]...][[46 20 38 832 827 1890 69848 69848 69848 69848]...][[20 38 832 827 1890 1 2291 4749 94 20]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 1 1 1 1 0 0 0 0 0]...][[46 20 38 832 827 1890 69848 69848 69848 69848]...][[20 38 832 827 1890 1 13 121 29 17]...]\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "global_step: 7894\n",
            " perplexity: 416.495\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            " percent of 3-grams captured: 0.336.\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            " percent of 2-grams captured: 0.657.\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            " percent of 4-grams captured: 0.114.\n",
            " geometric_avg: 0.293.\n",
            " arithmetic_avg: 0.369.\n",
            "global_step: 7894\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.39028\n",
            " G train loss: -8.37401\n",
            "targets[[20 38 832 827 1890 1 2291 4749 94 20 83 112 10 17 6 6 0 305 290 25][267 4 0 69 29 97 108 214 14 1859 34 45 110 0 206 115 7267 83 230 5721][36607 46 20 159 21 58 7155 31 11 390]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 1 1 1 1 0 0 0 0 0]...][[46 20 38 832 827 1890 69848 69848 69848 69848]...][[20 38 832 827 1890 1 2291 4749 94 20]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 832 827 1890 1 2291 4749 94]...][[1 1 1 1 1 0 0 0 0 0]...][[46 20 38 832 827 1890 69848 69848 69848 69848]...][[20 38 832 827 1890 11 17 111 10 17]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  you                 0.499        0.000        0.000        0.000        -4.490       -4.175       -0.000       \n",
            "   [1]  like                0.497        0.000        0.000        0.000        -5.081       -6.099       0.000        \n",
            "   [1]  sci                 0.583        0.000        0.000        0.000        -5.751       -6.988       0.000        \n",
            "   [1]  fi                  0.982        0.000        0.000        0.000        -6.509       -5.897       -0.000       \n",
            "   [1]  monsters            0.157        0.000        0.000        0.000        -7.366       0.445        -0.000       \n",
            "   [0]  that                0.392        2.522        -3.358       -0.935       -8.337       -9.361       1.024        \n",
            "   [0]  movie               0.346        10.904       -5.266       -1.062       -8.377       -8.276       -0.101       \n",
            "   [0]  where               0.455        10.390       -6.730       -0.787       -8.279       -7.514       -0.766       \n",
            "   [0]  this                0.452        6.125        -3.161       -0.794       -8.480       -7.258       -1.222       \n",
            "   [0]  movie               0.386        8.779        -1.307       -0.951       -8.698       -7.546       -1.152       \n",
            "   [0]  s                   0.107        5.823        -2.354       -2.233       -8.768       -7.570       -1.198       \n",
            "   [0]  a                   0.074        7.236        -3.036       -2.600       -7.396       -9.963       2.567        \n",
            "   [0]  plot                0.085        8.060        -5.050       -2.464       -5.429       -10.594      5.000        \n",
            "   [0]  of                  0.035        4.021        -2.254       -3.355       -3.355       -9.552       5.000        \n",
            "   [1]  br                  0.026        0.000        0.000        0.000        0.000        -11.457      0.000        \n",
            "   [1]  br                  0.635        0.000        0.000        0.000        0.000        -13.425      0.000        \n",
            "   [1]  the                 0.692        0.000        0.000        0.000        0.000        -9.035       0.000        \n",
            "   [1]  special             0.695        0.000        0.000        0.000        0.000        -9.490       0.000        \n",
            "   [1]  effects             0.867        0.000        0.000        0.000        0.000        -7.711       0.000        \n",
            "   [1]  are                 0.955        0.000        0.000        0.000        0.000        -8.500       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  goes                0.414        0.000        0.000        0.000        -4.311       -4.349       0.000        \n",
            "   [1]  to                  0.786        0.000        0.000        0.000        -4.880       -4.525       -0.000       \n",
            "   [1]  the                 0.772        0.000        0.000        0.000        -5.523       -5.915       0.000        \n",
            "   [1]  well                0.125        0.000        0.000        0.000        -6.250       -8.532       0.000        \n",
            "   [0]  williams            0.464        2.785        -10.103      -0.767       -7.074       -8.286       1.212        \n",
            "   [0]  in                  0.418        7.610        -2.717       -0.872       -7.138       -9.265       2.127        \n",
            "   [0]  the                 0.316        5.253        -1.655       -1.152       -7.092       -7.917       0.825        \n",
            "   [0]  bechstein           0.284        8.397        -14.161      -1.258       -6.723       -8.932       2.209        \n",
            "   [0]  documentary         0.068        4.544        -6.886       -2.687       -6.185       -7.928       1.743        \n",
            "   [0]  out                 0.066        9.760        -5.582       -2.713       -3.958       -10.599      5.000        \n",
            "   [0]  of                  0.432        4.594        -2.145       -0.839       -1.409       -7.925       5.000        \n",
            "   [0]  tv                  0.650        7.462        -6.757       -0.431       -0.646       -7.439       5.000        \n",
            "   [0]  attending           0.784        10.933       -10.523      -0.244       -0.244       -7.047       5.000        \n",
            "   [1]  the                 0.781        0.000        0.000        0.000        0.000        -7.487       0.000        \n",
            "   [1]  original            0.853        0.000        0.000        0.000        0.000        -8.178       0.000        \n",
            "   [1]  little              0.788        0.000        0.000        0.000        0.000        -7.178       0.000        \n",
            "   [1]  mermaid             0.719        0.000        0.000        0.000        0.000        -7.002       0.000        \n",
            "   [1]  will                0.776        0.000        0.000        0.000        0.000        -8.658       0.000        \n",
            "   [1]  feel                0.759        0.000        0.000        0.000        0.000        -7.443       0.000        \n",
            "   [1]  blatantly           0.871        0.000        0.000        0.000        0.000        -6.705       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  sachs               0.066        0.000        0.000        0.000        -3.023       -3.948       0.000        \n",
            "   [1]  if                  0.543        0.000        0.000        0.000        -3.422       -10.250      0.000        \n",
            "   [1]  you                 0.799        0.000        0.000        0.000        -3.872       -12.333      0.000        \n",
            "   [1]  didn                0.656        0.000        0.000        0.000        -4.383       -5.228       0.000        \n",
            "   [1]  t                   0.601        0.000        0.000        0.000        -4.960       -11.387      0.000        \n",
            "   [1]  even                0.574        0.000        0.000        0.000        -5.614       -6.496       0.000        \n",
            "   [1]  chuckles            0.635        0.000        0.000        0.000        -6.354       -5.979       -0.000       \n",
            "   [1]  at                  0.683        0.000        0.000        0.000        -7.191       -6.129       -0.000       \n",
            "   [1]  that                0.613        0.000        0.000        0.000        -8.139       -8.034       -0.000       \n",
            "   [1]  name                0.509        0.000        0.000        0.000        -9.211       -7.291       -0.000       \n",
            "   [1]  the                 0.508        0.000        0.000        0.000        -10.425      -7.934       -0.000       \n",
            "   [0]  film                0.404        10.834       -3.033       -0.907       -11.799      -7.162       -4.636       \n",
            "   [0]  of                  0.310        12.202       -3.289       -1.172       -12.327      -9.114       -3.213       \n",
            "   [0]  the                 0.222        8.305        -0.624       -1.507       -12.624      -8.646       -3.979       \n",
            "   [0]  exception           0.207        8.556        -8.802       -1.577       -12.582      -8.109       -4.473       \n",
            "   [0]  bin                 0.051        4.967        -9.983       -2.983       -12.455      -9.071       -3.384       \n",
            "   [0]  wow                 0.048        8.063        -9.226       -3.046       -10.720      -10.222      -0.498       \n",
            "   [0]  a                   0.082        9.372        -2.722       -2.502       -8.685       -10.737      2.052        \n",
            "   [0]  excellent           0.028        9.440        -5.798       -3.565       -6.998       -8.642       1.644        \n",
            "   [0]  for                 0.021        10.993       -4.505       -3.886       -3.886       -10.648      5.000        \n",
            "Samples\n",
            "Sample 0 .  you like sci fi monsters that movie where this movie s a plot of br br the special effects are\n",
            "Sample 1 .  goes to the well williams in the bechstein documentary out of tv attending the original little mermaid will feel blatantly\n",
            "Sample 2 .  sachs if you didn t even chuckles at that name the film of the exception bin wow a excellent for\n",
            "\n",
            "\n",
            "targets[[565 348 1796 109 2 1343 564 1 35 2199 453 3 57 66 7 31 0 681 1864 1557][39088 5853 5 2 243 8 40 544 6560 2 4058 34 451 15 40 701 8 2 35397 1542][584 7829 2408 24603 1209 8747 3937 12430 2307 7281]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[379 565 348 1796 109 2 1343 564 1 35]...][[1 1 1 1 1 0 0 0 0 0]...][[379 565 348 1796 109 2 69848 69848 69848 69848]...][[565 348 1796 109 2 1343 564 1 35 2199]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[379 565 348 1796 109 2 1343 564 1 35]...][[1 1 1 1 1 0 0 0 0 0]...][[379 565 348 1796 109 2 69848 69848 69848 69848]...][[565 348 1796 109 2 1247 2373 2588 8 3714]...]\n",
            "targets[[71 366 44 33 674 10 17 45 308 155 220 31 0 53 457 15 0 4405 199 0][5 142 2 81 17 4 106 15 183 423 9 140 213 261 16 35 1401 4 106 7][19 494 4 28 19 1471 18 42 150 21]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[287 71 366 44 33 674 10 17 45 308]...][[1 1 1 1 1 1 1 1 1 0]...][[287 71 366 44 33 674 10 17 45 308]...][[71 366 44 33 674 10 17 45 308 155]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[287 71 366 44 33 674 10 17 45 308]...][[1 1 1 1 1 1 1 1 1 0]...][[287 71 366 44 33 674 10 17 45 308]...][[71 366 44 33 674 10 17 45 308 0]...]\n",
            "targets[[71 9 103 9 13 23 53 628 51 9 215 10 662 47 50 9 136 8384 264 0][2369 98 25 2 245 38806 4 169 14 5 100 2369 29 18 10 29 5 641 3996 4][9 213 196 10 13 28574 12 84 19 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3285 71 9 103 9 13 23 53 628 51]...][[1 1 0 0 0 0 0 0 0 0]...][[3285 71 9 69848 69848 69848 69848 69848 69848 69848]...][[71 9 103 9 13 23 53 628 51 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[3285 71 9 103 9 13 23 53 628 51]...][[1 1 0 0 0 0 0 0 0 0]...][[3285 71 9 69848 69848 69848 69848 69848 69848 69848]...][[71 9 242 81 200 9 1628 0 2799 18]...]\n",
            "targets[[242 2 19 1395 1 3896 1252 2570 28948 389 4 258 6166 4 122 0 84 5044 2683 3][208 8596 3033 50049 14631 46 20 38 45216 6389 1 10144 20 83 112 10 17 543 153 29002][3 30 9 89 21 180 387 134 30 131]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 2 19 1395 1 3896 1252 2570 28948]...][[1 1 1 1 1 0 0 0 0 0]...][[9 242 2 19 1395 1 69848 69848 69848 69848]...][[242 2 19 1395 1 3896 1252 2570 28948 389]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 2 19 1395 1 3896 1252 2570 28948]...][[1 1 1 1 1 0 0 0 0 0]...][[9 242 2 19 1395 1 69848 69848 69848 69848]...][[242 2 19 1395 1 9 1385 1136 58 0]...]\n",
            "targets[[653 130 5 8 11763 14107 0 46822 25 3062 0 12198 16468 1 67166 90 6 6 8 26260][2 2324 3 108 108 2119 703 104 9 196 9 207 579 0 250 0 1447 67 4 1494][13069 21 16447 3220 5 2 19 92 55 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 653 130 5 8 11763 14107 0 46822 25]...][[1 1 1 1 1 1 0 0 0 0]...][[0 653 130 5 8 11763 14107 69848 69848 69848]...][[653 130 5 8 11763 14107 0 46822 25 3062]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 653 130 5 8 11763 14107 0 46822 25]...][[1 1 1 1 1 1 0 0 0 0]...][[0 653 130 5 8 11763 14107 69848 69848 69848]...][[653 130 5 8 11763 14107 2109 4 1056 4]...]\n",
            "targets[[12 186 576 7414 13714 1 16633 25 1149 156 46 20 89 21 76 7 36 10 17 106][87 5 7 11 295 50 387 253 82 924 208 4528 38 2236 38652 41 17469 42970 118 0][604 1652 87 394 10 19 5 9 59 1203]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 186 576 7414 13714 1 16633 25 1149]...][[1 1 1 0 0 0 0 0 0 0]...][[7 12 186 576 69848 69848 69848 69848 69848 69848]...][[12 186 576 7414 13714 1 16633 25 1149 156]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 186 576 7414 13714 1 16633 25 1149]...][[1 1 1 0 0 0 0 0 0 0]...][[7 12 186 576 69848 69848 69848 69848 69848 69848]...][[12 186 576 0 63 1 165 23 23 775]...]\n",
            "targets[[5 2 3851 662 4 2 81 181 17 681 261 1 250 3 30 348 181 135 0 64][53 84 57 9 84 555 3 10 599 3101 436 128 8 60 640 13 51 7 13 7916][140 23 251 46 9 50 949 2 738 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 3851 662 4 2 81 181 17]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 2 3851 662 4 2 81 181 17]...][[5 2 3851 662 4 2 81 181 17 681]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 3851 662 4 2 81 181 17]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 2 3851 662 4 2 81 181 17]...][[5 2 3851 662 4 2 81 181 17 9]...]\n",
            "targets[[2972 3 0 9634 974 15 42 43 174 675 20 50 853 1491 4 93 0 88 737 1979][6362 6741 1493 629 5728 1 3559 33073 4048 33417 1899 15 62 373 7110 25175 5433 36 8802 4][8195 869 12138 0 755 3 0 836 6506 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[103 2972 3 0 9634 974 15 42 43 174]...][[1 1 1 1 1 1 1 0 0 0]...][[103 2972 3 0 9634 974 15 42 69848 69848]...][[2972 3 0 9634 974 15 42 43 174 675]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[103 2972 3 0 9634 974 15 42 43 174]...][[1 1 1 1 1 1 1 0 0 0]...][[103 2972 3 0 9634 974 15 42 69848 69848]...][[2972 3 0 9634 974 15 42 27 837 2]...]\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[1 1 1 1 1 1 1 1 0 0]...][[49 548 10 122 19754 5745 36 0 705 69848]...][[548 10 122 19754 5745 36 0 705 7094 1]...]\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[1 1 1 1 1 1 1 1 0 0]...][[49 548 10 122 19754 5745 36 0 705 69848]...][[548 10 122 19754 5745 36 0 705 298 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[1 1 1 1 1 1 1 1 0 0]...][[49 548 10 122 19754 5745 36 0 705 69848]...][[548 10 122 19754 5745 36 0 705 7 12]...]\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "global_step: 7911\n",
            " perplexity: 416.170\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            " percent of 3-grams captured: 0.373.\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            " percent of 2-grams captured: 0.652.\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            " percent of 4-grams captured: 0.131.\n",
            " geometric_avg: 0.317.\n",
            " arithmetic_avg: 0.385.\n",
            "global_step: 7911\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38980\n",
            " G train loss: -8.22331\n",
            "targets[[548 10 122 19754 5745 36 0 705 298 1 17 8 189 9 424 10 10 246 122 0][5 2 53674 19 4 106 2 6469 311 15 127 355 62 158 20264 5439 690 5 65 137][30 276 13364 11668 5 161 18 2 10754 8081]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[1 1 1 1 1 1 1 1 0 0]...][[49 548 10 122 19754 5745 36 0 705 69848]...][[548 10 122 19754 5745 36 0 705 298 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[49 548 10 122 19754 5745 36 0 705 298]...][[1 1 1 1 1 1 1 1 0 0]...][[49 548 10 122 19754 5745 36 0 705 69848]...][[548 10 122 19754 5745 36 0 705 3 10]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  god                 0.664        0.000        0.000        0.000        -5.135       -3.689       -0.000       \n",
            "   [1]  this                0.523        0.000        0.000        0.000        -5.812       -4.912       -0.000       \n",
            "   [1]  show                0.504        0.000        0.000        0.000        -6.577       -8.428       0.000        \n",
            "   [1]  deviates            0.548        0.000        0.000        0.000        -7.444       -8.369       0.000        \n",
            "   [1]  hugely              0.507        0.000        0.000        0.000        -8.425       -6.462       -0.000       \n",
            "   [1]  from                0.719        0.000        0.000        0.000        -9.535       -9.748       0.000        \n",
            "   [1]  the                 0.445        0.000        0.000        0.000        -10.792      -8.007       -0.000       \n",
            "   [1]  comic               0.169        0.000        0.000        0.000        -12.214      -7.654       -0.000       \n",
            "   [0]  of                  0.229        6.834        -2.177       -1.475       -13.823      -7.734       -5.000       \n",
            "   [0]  this                0.260        4.385        -3.235       -1.345       -13.976      -9.220       -4.757       \n",
            "   [0]  werewolf            0.286        1.227        -11.089      -1.251       -14.295      -9.774       -4.521       \n",
            "   [0]  is                  0.177        4.640        -2.869       -1.729       -14.763      -8.538       -5.000       \n",
            "   [0]  is                  0.078        8.007        -4.622       -2.552       -14.751      -9.678       -5.000       \n",
            "   [0]  so                  0.093        5.350        -4.461       -2.372       -13.808      -11.287      -2.520       \n",
            "   [0]  an                  0.018        7.858        -5.195       -4.007       -12.942      -12.585      -0.358       \n",
            "   [0]  previous            0.004        7.558        -7.194       -5.529       -10.113      -12.768      2.656        \n",
            "   [0]  horror              0.006        5.794        -4.808       -5.188       -5.188       -13.668      5.000        \n",
            "   [1]  tv                  0.006        0.000        0.000        0.000        0.000        -11.357      0.000        \n",
            "   [1]  show                0.022        0.000        0.000        0.000        0.000        -10.661      0.000        \n",
            "   [1]  the                 0.015        0.000        0.000        0.000        0.000        -11.680      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  is                  0.539        0.000        0.000        0.000        -23.492      -4.107       -0.000       \n",
            "   [0]  a                   0.544        1.236        -1.236       -0.608       -26.588      -9.855       -5.000       \n",
            "   [0]  worst               0.003        15.689       -3.399       -5.849       -29.403      -8.673       -5.000       \n",
            "   [0]  single              0.004        2.032        -8.271       -5.623       -26.657      -22.500      -4.157       \n",
            "   [0]  oh                  0.003        8.682        -11.188      -5.932       -23.806      -13.278      -5.000       \n",
            "   [0]  of                  0.002        8.134        -2.996       -6.057       -20.230      -10.006      -5.000       \n",
            "   [0]  music               0.004        2.467        -8.189       -5.421       -16.041      -10.014      -5.000       \n",
            "   [0]  beer                0.007        11.991       -12.108      -5.024       -12.019      -8.574       -3.445       \n",
            "   [0]  with                0.011        7.922        -4.009       -4.525       -7.917       -8.011       0.094        \n",
            "   [0]  a                   0.022        6.403        -2.093       -3.839       -3.839       -8.082       4.243        \n",
            "   [1]  your                0.008        0.000        0.000        0.000        0.000        -8.201       0.000        \n",
            "   [1]  friends             0.033        0.000        0.000        0.000        0.000        -8.048       0.000        \n",
            "   [1]  their               0.020        0.000        0.000        0.000        0.000        -8.516       0.000        \n",
            "   [1]  old                 0.008        0.000        0.000        0.000        0.000        -7.765       0.000        \n",
            "   [1]  stockholm           0.007        0.000        0.000        0.000        0.000        -8.365       0.000        \n",
            "   [1]  ghetto              0.005        0.000        0.000        0.000        0.000        -8.372       0.000        \n",
            "   [1]  talk                0.003        0.000        0.000        0.000        0.000        -7.179       0.000        \n",
            "   [1]  is                  0.008        0.000        0.000        0.000        0.000        -8.126       0.000        \n",
            "   [1]  really              0.030        0.000        0.000        0.000        0.000        -7.522       0.000        \n",
            "   [1]  something           0.026        0.000        0.000        0.000        0.000        -7.806       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  all                 0.507        0.000        0.000        0.000        -8.191       -4.137       -0.000       \n",
            "   [1]  american            0.611        0.000        0.000        0.000        -9.271       -4.696       -0.000       \n",
            "   [1]  soaps               0.672        0.000        0.000        0.000        -10.492      -6.883       -0.000       \n",
            "   [1]  dynasty             0.301        0.000        0.000        0.000        -11.875      -8.191       -0.000       \n",
            "   [0]  two                 0.437        3.009        -7.346       -0.827       -13.440      -9.476       -3.964       \n",
            "   [0]  from                0.331        9.362        -5.150       -1.107       -14.275      -9.193       -5.000       \n",
            "   [0]  films               0.298        6.386        -6.572       -1.210       -14.903      -7.434       -5.000       \n",
            "   [0]  listed              0.316        4.941        -10.083      -1.153       -15.497      -10.179      -5.000       \n",
            "   [0]  of                  0.081        12.904       -3.671       -2.519       -16.235      -9.379       -5.000       \n",
            "   [0]  hack                0.033        13.594       -11.717      -3.407       -15.523      -9.824       -5.000       \n",
            "   [0]  ordinary            0.012        3.899        -9.449       -4.396       -13.713      -11.831      -1.882       \n",
            "   [0]  allright            0.003        14.228       -14.008      -5.692       -10.545      -12.330      1.784        \n",
            "   [0]  s                   0.004        7.544        -3.968       -5.493       -5.493       -12.258      5.000        \n",
            "   [1]  inane               0.005        0.000        0.000        0.000        0.000        -12.088      0.000        \n",
            "   [1]  plots               0.011        0.000        0.000        0.000        0.000        -10.181      0.000        \n",
            "   [1]  and                 0.011        0.000        0.000        0.000        0.000        -9.489       0.000        \n",
            "   [1]  one                 0.010        0.000        0.000        0.000        0.000        -8.950       0.000        \n",
            "   [1]  dimensional         0.021        0.000        0.000        0.000        0.000        -8.898       0.000        \n",
            "   [1]  characters          0.053        0.000        0.000        0.000        0.000        -7.689       0.000        \n",
            "   [1]  many                0.048        0.000        0.000        0.000        0.000        -8.767       0.000        \n",
            "Samples\n",
            "Sample 0 .  god this show deviates hugely from the comic of this werewolf is is so an previous horror tv show the\n",
            "Sample 1 .  is a worst single oh of music beer with a your friends their old stockholm ghetto talk is really something\n",
            "Sample 2 .  all american soaps dynasty two from films listed of hack ordinary allright s inane plots and one dimensional characters many\n",
            "\n",
            "\n",
            "targets[[246 5 2 81 1234 1 690 7019 5 37 155 8 2 2726 20 50 667 0 762 636][140 2 340 3 184 98 1622 9 13 1298 4 169 0 2069 544 311 184 17 22 29][0 4144 4789 13 0 667 3 0 3248 36]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[772 246 5 2 81 1234 1 690 7019 5]...][[1 1 1 1 1 1 1 1 1 1]...][[772 246 5 2 81 1234 1 690 7019 5]...][[246 5 2 81 1234 1 690 7019 5 37]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[772 246 5 2 81 1234 1 690 7019 5]...][[1 1 1 1 1 1 1 1 1 1]...][[772 246 5 2 81 1234 1 690 7019 5]...][[246 5 2 81 1234 1 690 7019 5 37]...]\n",
            "targets[[968 212 18 89 21 1392 1452 4773 285 2 703 7485 3 1623 20 50 136 4087 4931 34][0 166 3 1210 3101 1692 2573 7576 12412 0 507 45 4 1775 48 53 7790 1513 11 10722][4267 6 6 303 377 5 119 127 217 114]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 968 212 18 89 21 1392 1452 4773 285]...][[1 1 1 1 1 1 1 1 1 0]...][[7 968 212 18 89 21 1392 1452 4773 285]...][[968 212 18 89 21 1392 1452 4773 285 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 968 212 18 89 21 1392 1452 4773 285]...][[1 1 1 1 1 1 1 1 1 0]...][[7 968 212 18 89 21 1392 1452 4773 285]...][[968 212 18 89 21 1392 1452 4773 285 2]...]\n",
            "targets[[9 1065 11 9 467 3523 4105 31 91 271 108 214 119 1 9 140 2 216 8 26][0 457 3 176 299 223 0 1054 3302 20189 0 6244 14088 11004 13370 1632 1 1073 4 4353][467 37 73 43 10 17 0 57 579 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2578 9 1065 11 9 467 3523 4105 31 91]...][[1 1 0 0 0 0 0 0 0 0]...][[2578 9 1065 69848 69848 69848 69848 69848 69848 69848]...][[9 1065 11 9 467 3523 4105 31 91 271]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2578 9 1065 11 9 467 3523 4105 31 91]...][[1 1 0 0 0 0 0 0 0 0]...][[2578 9 1065 69848 69848 69848 69848 69848 69848 69848]...][[9 1065 5 2 19 3 0 116 262 7]...]\n",
            "targets[[78 10 19 0 64 151 11 9 13 65 3693 43 13 11 7 236 28 348 7 12][6940 12 4739 9891 3349 12298 1613 13 371 2762 0 1613 83 64 28 2077 16 29 151 12272][196 7 13 35 554 1010 19 9 13 53]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[164 78 10 19 0 64 151 11 9 13]...][[1 1 1 1 1 1 1 0 0 0]...][[164 78 10 19 0 64 151 11 69848 69848]...][[78 10 19 0 64 151 11 9 13 65]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[164 78 10 19 0 64 151 11 9 13]...][[1 1 1 1 1 1 1 0 0 0]...][[164 78 10 19 0 64 151 11 69848 69848]...][[78 10 19 0 64 151 11 1 174 0]...]\n",
            "targets[[19 19245 13 2 84 1 2 227 16 8686 5123 7 13 40 84 276 92 19 31 2783][20 50 387 23680 1 18987 20 139 195 4 387 0 472 1 75 3 1210 1380 2961 3306][4957 3 73 467 1177 50 1667 4658 0 439]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 19 19245 13 2 84 1 2 227 16]...][[1 1 0 0 0 0 0 0 0 0]...][[0 19 19245 69848 69848 69848 69848 69848 69848 69848]...][[19 19245 13 2 84 1 2 227 16 8686]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 19 19245 13 2 84 1 2 227 16]...][[1 1 0 0 0 0 0 0 0 0]...][[0 19 19245 69848 69848 69848 69848 69848 69848 69848]...][[19 19245 747 11 5 68 27 4 132 2]...]\n",
            "targets[[17 13 1900 92 16 160 7673 246 0 321 514 10 17 13 634 4 2639 0 217 2968][1913 218 2 74 1126 249 267 44 22 2 2000 1 724 78 111 24 50 21 1013 94][2574 71 87 73 9 112 10 17 464 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 1900 92 16 160 7673 246 0]...][[1 1 1 1 1 1 0 0 0 0]...][[10 17 13 1900 92 16 160 69848 69848 69848]...][[17 13 1900 92 16 160 7673 246 0 321]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 1900 92 16 160 7673 246 0]...][[1 1 1 1 1 1 0 0 0 0]...][[10 17 13 1900 92 16 160 69848 69848 69848]...][[17 13 1900 92 16 160 0 716 74 7]...]\n",
            "targets[[84 57 9 215 10 17 9 1147 0 84 969 228 41 37 9 215 7 1382 227 311][207 38 4 198 10 163 399 16 2011 18414 1 13379 23 4 750 2 539 769 18 16][242 52 72 671 15 10 17 4 136 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 57 9 215 10 17 9 1147 0]...][[1 1 1 1 0 0 0 0 0 0]...][[0 84 57 9 215 69848 69848 69848 69848 69848]...][[84 57 9 215 10 17 9 1147 0 84]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 84 57 9 215 10 17 9 1147 0]...][[1 1 1 1 0 0 0 0 0 0]...][[0 84 57 9 215 69848 69848 69848 69848 69848]...][[84 57 9 215 47 3320 7 35 360 24324]...]\n",
            "targets[[125 3790 6 6 1156 1464 1469 1039 5947 5455 26979 22760 21959 1 2596 15626 513 33 1493 10401][17 13 43 14 1060 14 35 3257 223 66624 4517 3 6947 15903 9 382 9 159 21 512][20 254 2820 3 0 14037 2033 42 870 2057]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[24523 125 3790 6 6 1156 1464 1469 1039 5947]...][[1 1 1 0 0 0 0 0 0 0]...][[24523 125 3790 6 69848 69848 69848 69848 69848 69848]...][[125 3790 6 6 1156 1464 1469 1039 5947 5455]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[24523 125 3790 6 6 1156 1464 1469 1039 5947]...][[1 1 1 0 0 0 0 0 0 0]...][[24523 125 3790 6 69848 69848 69848 69848 69848 69848]...][[125 3790 6 61 80 146 36 896 436 70]...]\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[1 1 0 0 0 0 0 0 0 0]...][[401 29 3 69848 69848 69848 69848 69848 69848 69848]...][[29 3 1068 18 9 140 7 13 27 43]...]\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[1 1 0 0 0 0 0 0 0 0]...][[401 29 3 69848 69848 69848 69848 69848 69848 69848]...][[29 3 0 250 9 139 123 110 51 60]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[1 1 0 0 0 0 0 0 0 0]...][[401 29 3 69848 69848 69848 69848 69848 69848 69848]...][[29 3 405 10 13 180 671 11 5 2]...]\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "global_step: 7928\n",
            " perplexity: 416.174\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            " percent of 3-grams captured: 0.368.\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            " percent of 2-grams captured: 0.641.\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            " percent of 4-grams captured: 0.119.\n",
            " geometric_avg: 0.304.\n",
            " arithmetic_avg: 0.376.\n",
            "global_step: 7928\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38943\n",
            " G train loss: -8.45131\n",
            "targets[[29 3 0 250 9 139 123 110 51 60 3097 446 71 55 4 287 71 121 11 19242][13 2 130 8 10 17 1049 5 621 55 0 1437 5944 1 960 74 454 349 0 95][13 861 4 138 66 10 17 15 2 742]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[1 1 0 0 0 0 0 0 0 0]...][[401 29 3 69848 69848 69848 69848 69848 69848 69848]...][[29 3 0 250 9 139 123 110 51 60]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[401 29 3 0 250 9 139 123 110 51]...][[1 1 0 0 0 0 0 0 0 0]...][[401 29 3 69848 69848 69848 69848 69848 69848 69848]...][[29 3 10 17 1 0 129 911 18 3571]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  one                 0.829        0.000        0.000        0.000        -21.079      -4.250       -0.000       \n",
            "   [1]  of                  0.492        0.000        0.000        0.000        -23.857      -7.337       -0.000       \n",
            "   [0]  this                0.039        0.964        -1.920       -3.246       -27.000      -5.210       -5.000       \n",
            "   [0]  movie               0.011        7.666        -1.073       -4.511       -26.884      -15.389      -5.000       \n",
            "   [0]  and                 0.010        3.045        -3.489       -4.560       -25.321      -13.295      -5.000       \n",
            "   [0]  the                 0.005        10.300       -1.445       -5.402       -23.497      -9.854       -5.000       \n",
            "   [0]  end                 0.008        9.140        -6.037       -4.881       -20.479      -10.734      -5.000       \n",
            "   [0]  cheesy              0.006        9.785        -9.603       -5.157       -17.653      -9.029       -5.000       \n",
            "   [0]  but                 0.007        5.017        -3.601       -4.943       -14.143      -9.166       -4.977       \n",
            "   [0]  lion                0.004        4.978        -12.135      -5.483       -10.412      -9.390       -1.022       \n",
            "   [0]  blonde              0.004        10.402       -9.466       -5.577       -5.577       -9.375       3.797        \n",
            "   [1]  called              0.005        0.000        0.000        0.000        0.000        -9.530       0.000        \n",
            "   [1]  me                  0.011        0.000        0.000        0.000        0.000        -9.517       0.000        \n",
            "   [1]  up                  0.037        0.000        0.000        0.000        0.000        -9.421       0.000        \n",
            "   [1]  to                  0.192        0.000        0.000        0.000        0.000        -7.525       0.000        \n",
            "   [1]  let                 0.325        0.000        0.000        0.000        0.000        -8.391       0.000        \n",
            "   [1]  me                  0.772        0.000        0.000        0.000        0.000        -7.949       0.000        \n",
            "   [1]  know                0.920        0.000        0.000        0.000        0.000        -9.881       0.000        \n",
            "   [1]  that                0.966        0.000        0.000        0.000        0.000        -10.619      0.000        \n",
            "   [1]  megalodon           0.973        0.000        0.000        0.000        0.000        -10.146      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  was                 0.689        0.000        0.000        0.000        -4.905       -4.438       -0.000       \n",
            "   [1]  a                   0.623        0.000        0.000        0.000        -5.551       -7.800       0.000        \n",
            "   [1]  scene               0.578        0.000        0.000        0.000        -6.282       -8.253       0.000        \n",
            "   [1]  in                  0.565        0.000        0.000        0.000        -7.110       -14.882      0.000        \n",
            "   [1]  this                0.677        0.000        0.000        0.000        -8.047       -13.715      0.000        \n",
            "   [1]  movie               0.604        0.000        0.000        0.000        -9.108       -8.847       -0.000       \n",
            "   [1]  cold                0.709        0.000        0.000        0.000        -10.308      -11.772      0.000        \n",
            "   [1]  is                  0.444        0.000        0.000        0.000        -11.666      -10.016      -0.000       \n",
            "   [1]  running             0.560        0.000        0.000        0.000        -13.203      -11.085      -0.000       \n",
            "   [0]  paramount           0.307        5.906        -10.270      -1.180       -14.943      -9.044       -5.000       \n",
            "   [0]  overly              0.165        4.416        -10.725      -1.800       -15.577      -8.071       -5.000       \n",
            "   [0]  digart              0.051        9.091        -14.270      -2.974       -15.592      -11.468      -4.124       \n",
            "   [0]  and                 0.038        11.531       -3.039       -3.268       -14.281      -13.112      -1.169       \n",
            "   [0]  a                   0.023        5.417        -3.151       -3.784       -12.465      -10.996      -1.469       \n",
            "   [0]  rapping             0.039        8.988        -12.831      -3.247       -9.825       -9.934       0.109        \n",
            "   [0]  did                 0.083        8.272        -7.224       -2.492       -7.444       -8.630       1.186        \n",
            "   [0]  you                 0.141        9.183        -5.281       -1.961       -5.605       -9.548       3.944        \n",
            "   [0]  made                0.016        8.695        -5.095       -4.124       -4.124       -8.808       4.684        \n",
            "   [1]  the                 0.020        0.000        0.000        0.000        0.000        -11.465      0.000        \n",
            "   [1]  way                 0.057        0.000        0.000        0.000        0.000        -10.929      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  was                 0.844        0.000        0.000        0.000        -6.844       -4.254       -0.000       \n",
            "   [1]  forced              0.790        0.000        0.000        0.000        -7.745       -8.337       0.000        \n",
            "   [1]  to                  0.760        0.000        0.000        0.000        -8.766       -9.396       0.000        \n",
            "   [0]  both                0.316        5.068        -7.843       -1.152       -9.921       -8.748       -1.173       \n",
            "   [0]  called              0.144        7.380        -7.531       -1.939       -9.925       -9.517       -0.408       \n",
            "   [0]  history             0.405        3.941        -7.250       -0.904       -9.038       -9.858       0.819        \n",
            "   [0]  full                0.484        4.749        -8.291       -0.725       -9.206       -9.649       0.442        \n",
            "   [0]  masterpiece         0.096        5.807        -7.717       -2.340       -9.599       -5.533       -4.066       \n",
            "   [0]  and                 0.090        4.326        -2.777       -2.407       -8.216       -11.776      3.561        \n",
            "   [0]  when                0.121        9.797        -6.054       -2.110       -6.574       -11.173      4.599        \n",
            "   [0]  you                 0.099        7.306        -2.880       -2.312       -5.053       -8.260       3.208        \n",
            "   [0]  s                   0.045        12.582       -3.149       -3.102       -3.102       -6.563       3.460        \n",
            "   [1]  year                0.235        0.000        0.000        0.000        0.000        -11.971      0.000        \n",
            "   [1]  old                 0.536        0.000        0.000        0.000        0.000        -11.667      0.000        \n",
            "   [1]  and                 0.676        0.000        0.000        0.000        0.000        -9.703       0.000        \n",
            "   [1]  even                0.703        0.000        0.000        0.000        0.000        -8.915       0.000        \n",
            "   [1]  they                0.528        0.000        0.000        0.000        0.000        -8.711       0.000        \n",
            "   [1]  found               0.332        0.000        0.000        0.000        0.000        -7.704       0.000        \n",
            "   [1]  this                0.457        0.000        0.000        0.000        0.000        -9.583       0.000        \n",
            "   [1]  boring              0.424        0.000        0.000        0.000        0.000        -8.858       0.000        \n",
            "Samples\n",
            "Sample 0 .  one of this movie and the end cheesy but lion blonde called me up to let me know that megalodon\n",
            "Sample 1 .  was a scene in this movie cold is running paramount overly digart and a rapping did you made the way\n",
            "Sample 2 .  was forced to both called history full masterpiece and when you s year old and even they found this boring\n",
            "\n",
            "\n",
            "targets[[80 367 149 48 3 0 98 11 27 77 5786 250 123 1302 2784 36 3270 791 1259 3][261 16 46277 141 168 3088 10 5 2 2018 3 2 53 1836 239 4189 183 243 34 45][232 211 2163 0 64 293 9 58 254 44]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 80 367 149 48 3 0 98 11 27]...][[1 1 1 1 0 0 0 0 0 0]...][[9 80 367 149 48 69848 69848 69848 69848 69848]...][[80 367 149 48 3 0 98 11 27 77]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 80 367 149 48 3 0 98 11 27]...][[1 1 1 1 0 0 0 0 0 0]...][[9 80 367 149 48 69848 69848 69848 69848 69848]...][[80 367 149 48 22 5 4 28 1412 9]...]\n",
            "targets[[17 5 853 0 14474 12981 1 11905 662 123 92 6 6 239 7 5 0 1536 1 88][5 2 52 212 72 648 1436 17 85 7 5 2 994 1115 0 369 1220 25 303 1][0 921 5 0 63 3 105 75 0 24164]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 5 853 0 14474 12981 1 11905 662]...][[1 1 1 0 0 0 0 0 0 0]...][[10 17 5 853 69848 69848 69848 69848 69848 69848]...][[17 5 853 0 14474 12981 1 11905 662 123]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 5 853 0 14474 12981 1 11905 662]...][[1 1 1 0 0 0 0 0 0 0]...][[10 17 5 853 69848 69848 69848 69848 69848 69848]...][[17 5 853 913 2166 22 4793 818 1 0]...]\n",
            "targets[[17 400 71 15 0 16785 14109 4594 15659 12373 7 13 38 286 593 1 11990 2 130 36][196 11 0 101 68 65 3259 1 30 67 81 3052 0 848 8 60 660 13 5559 2163][2661 16899 8 26 209 14 1860 64172 15570 846]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 400 71 15 0 16785 14109 4594 15659]...][[1 1 1 0 0 0 0 0 0 0]...][[10 17 400 71 69848 69848 69848 69848 69848 69848]...][[17 400 71 15 0 16785 14109 4594 15659 12373]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 400 71 15 0 16785 14109 4594 15659]...][[1 1 1 0 0 0 0 0 0 0]...][[10 17 400 71 69848 69848 69848 69848 69848 69848]...][[17 400 71 167 30 741 9 117 0 544]...]\n",
            "targets[[548 597 586 0 75 34 45 110 10 2863 116 22953 444 10645 63 2028 3741 511 61 529][1339 4 5862 240 29 311 1 138 4 0 17 797 4 66 10 29 532 9 13 8][19 92 679 23045 4 991 8398 8 91 1110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[431 548 597 586 0 75 34 45 110 10]...][[1 1 1 1 1 1 1 0 0 0]...][[431 548 597 586 0 75 34 45 69848 69848]...][[548 597 586 0 75 34 45 110 10 2863]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[431 548 597 586 0 75 34 45 110 10]...][[1 1 1 1 1 1 1 0 0 0]...][[431 548 597 586 0 75 34 45 69848 69848]...][[548 597 586 0 75 34 45 353 8 29]...]\n",
            "targets[[64 293 9 1591 10 17 13 85 3 0 1009 261 234 22 0 1029 46 9 67 542][9 28246 27 195 4 712 4725 28581 4 0 1057 3354 18 884 4548 7 20 232 66 9][67 113 110 751 1787 304 2 74 216 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 64 293 9 1591 10 17 13 85 3]...][[1 1 1 1 1 0 0 0 0 0]...][[0 64 293 9 1591 10 69848 69848 69848 69848]...][[64 293 9 1591 10 17 13 85 3 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 64 293 9 1591 10 17 13 85 3]...][[1 1 1 1 1 0 0 0 0 0]...][[0 64 293 9 1591 10 69848 69848 69848 69848]...][[64 293 9 1591 10 98 6 9 196 318]...]\n",
            "targets[[52 9 667 10 19 0 52 9 5299 7 5 69 408 1010 2271 1 2677 247 2937 192][1475 9 5708 22 10 19 22 2269 132 9 13 24218 8558 60 9476 15131 5 12963 7780 4917][2 57 8 61 98 68 73 52 1342 87]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 52 9 667 10 19 0 52 9 5299]...][[1 1 1 1 1 1 1 1 1 1]...][[0 52 9 667 10 19 0 52 9 5299]...][[52 9 667 10 19 0 52 9 5299 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 52 9 667 10 19 0 52 9 5299]...][[1 1 1 1 1 1 1 1 1 1]...][[0 52 9 667 10 19 0 52 9 5299]...][[52 9 667 10 19 0 52 9 5299 7]...]\n",
            "targets[[166 31 2 2707 1045 1 174 1307 70 27 98 11 211 8 15 42 2 173 4416 131][6 1023 3993 43683 27173 1 82 2559 8647 28008 2731 55 47 32 121 43 0 3854 299 3854][55 39 14 29 3 0 437 250 92 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 166 31 2 2707 1045 1 174 1307 70]...][[1 0 0 0 0 0 0 0 0 0]...][[9 166 69848 69848 69848 69848 69848 69848 69848 69848]...][[166 31 2 2707 1045 1 174 1307 70 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 166 31 2 2707 1045 1 174 1307 70]...][[1 0 0 0 0 0 0 0 0 0]...][[9 166 69848 69848 69848 69848 69848 69848 69848 69848]...][[166 10 17 91 427 43 10 246 270 18]...]\n",
            "targets[[1935 25 799 1154 4 6372 34 96 481 11 1834 2852 521 1418 1 3033 2 791 48219 98][9 67 48 1943 16 10 19 603 233 9 367 0 116 3 1306 43880 3386 6970 29755 37][196 11 16 2 84 422 3 2 84 202]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1116 1935 25 799 1154 4 6372 34 96 481]...][[1 1 0 0 0 0 0 0 0 0]...][[1116 1935 25 69848 69848 69848 69848 69848 69848 69848]...][[1935 25 799 1154 4 6372 34 96 481 11]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1116 1935 25 799 1154 4 6372 34 96 481]...][[1 1 0 0 0 0 0 0 0 0]...][[1116 1935 25 69848 69848 69848 69848 69848 69848 69848]...][[1935 25 6206 3 943 433 147 16 3079 34]...]\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[1 1 1 1 1 1 1 1 1 1]...][[10 17 13 2 1498 432 3 1243 20 113]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[1 1 1 1 1 1 1 1 1 1]...][[10 17 13 2 1498 432 3 1243 20 113]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[1 1 1 1 1 1 1 1 1 1]...][[10 17 13 2 1498 432 3 1243 20 113]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "global_step: 7945\n",
            " perplexity: 416.842\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            " percent of 3-grams captured: 0.343.\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            " percent of 2-grams captured: 0.627.\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            " percent of 4-grams captured: 0.124.\n",
            " geometric_avg: 0.299.\n",
            " arithmetic_avg: 0.365.\n",
            "global_step: 7945\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38897\n",
            " G train loss: -8.44456\n",
            "targets[[17 13 2 1498 432 3 1243 20 113 693 47 13 164 22 0 101 68 839 408 1][78 10 17 20 121 11 10 5 17 45 1408 3990 18843 8 2 8860 3990 15 35 3355][215 7528 16 0 84 57 227 1606 85 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[1 1 1 1 1 1 1 1 1 1]...][[10 17 13 2 1498 432 3 1243 20 113]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 2 1498 432 3 1243 20 113]...][[1 1 1 1 1 1 1 1 1 1]...][[10 17 13 2 1498 432 3 1243 20 113]...][[17 13 2 1498 432 3 1243 20 113 693]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  movie               0.227        0.000        0.000        0.000        -1.551       -3.946       0.000        \n",
            "   [1]  was                 0.523        0.000        0.000        0.000        -1.756       -10.022      0.000        \n",
            "   [1]  a                   0.408        0.000        0.000        0.000        -1.987       -6.845       0.000        \n",
            "   [1]  confusing           0.425        0.000        0.000        0.000        -2.249       -7.403       0.000        \n",
            "   [1]  piece               0.473        0.000        0.000        0.000        -2.545       -8.341       0.000        \n",
            "   [1]  of                  0.529        0.000        0.000        0.000        -2.881       -10.218      0.000        \n",
            "   [1]  garbage             0.557        0.000        0.000        0.000        -3.260       -7.126       0.000        \n",
            "   [1]  you                 0.573        0.000        0.000        0.000        -3.690       -11.053      0.000        \n",
            "   [1]  never               0.452        0.000        0.000        0.000        -4.176       -7.505       0.000        \n",
            "   [1]  knew                0.815        0.000        0.000        0.000        -4.727       -8.825       0.000        \n",
            "   [1]  what                0.537        0.000        0.000        0.000        -5.350       -7.549       0.000        \n",
            "   [0]  the                 0.380        4.534        -1.382       -0.969       -6.055       -8.644       2.589        \n",
            "   [0]  title               0.631        9.555        -5.020       -0.460       -5.756       -8.378       2.622        \n",
            "   [0]  yet                 0.605        4.208        -7.481       -0.503       -5.993       -6.841       0.847        \n",
            "   [0]  not                 0.602        1.527        -4.692       -0.508       -6.214       -7.447       1.232        \n",
            "   [0]  the                 0.616        7.528        -1.872       -0.484       -6.459       -5.884       -0.574       \n",
            "   [0]  film                0.375        8.587        -3.205       -0.980       -6.762       -6.090       -0.672       \n",
            "   [0]  movie               0.081        10.479       -5.198       -2.510       -6.544       -8.406       1.862        \n",
            "   [0]  safe                0.072        8.152        -12.139      -2.634       -4.566       -9.938       5.000        \n",
            "   [0]  by                  0.112        2.204        -5.098       -2.187       -2.187       -8.291       5.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  into                0.588        0.000        0.000        0.000        -5.841       -4.099       -0.000       \n",
            "   [1]  this                0.597        0.000        0.000        0.000        -6.611       -10.294      0.000        \n",
            "   [1]  movie               0.636        0.000        0.000        0.000        -7.482       -9.235       0.000        \n",
            "   [1]  you                 0.612        0.000        0.000        0.000        -8.468       -8.886       0.000        \n",
            "   [1]  know                0.671        0.000        0.000        0.000        -9.584       -7.726       -0.000       \n",
            "   [1]  that                0.637        0.000        0.000        0.000        -10.847      -7.933       -0.000       \n",
            "   [1]  this                0.612        0.000        0.000        0.000        -12.276      -8.604       -0.000       \n",
            "   [0]  is                  0.364        2.127        -2.127       -1.010       -13.894      -10.121      -3.773       \n",
            "   [0]  average             0.267        6.014        -8.193       -1.321       -14.581      -9.413       -5.000       \n",
            "   [0]  known               0.302        7.550        -7.679       -1.196       -15.007      -11.901      -3.106       \n",
            "   [0]  year                0.137        10.535       -8.420       -1.986       -15.631      -9.079       -5.000       \n",
            "   [0]  other               0.080        12.776       -7.111       -2.520       -15.443      -11.166      -4.277       \n",
            "   [0]  the                 0.020        14.004       -2.113       -3.916       -14.626      -15.133      0.507        \n",
            "   [0]  causing             0.015        10.397       -12.995      -4.176       -12.121      -14.895      2.774        \n",
            "   [0]  is                  0.008        5.055        -2.987       -4.781       -8.992       -13.292      4.300        \n",
            "   [0]  it                  0.009        14.543       -4.109       -4.766       -4.766       -14.803      5.000        \n",
            "   [1]  lab                 0.010        0.000        0.000        0.000        0.000        -14.174      0.000        \n",
            "   [1]  with                0.008        0.000        0.000        0.000        0.000        -11.959      0.000        \n",
            "   [1]  an                  0.011        0.000        0.000        0.000        0.000        -12.963      0.000        \n",
            "   [1]  invisible           0.005        0.000        0.000        0.000        0.000        -12.975      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  saw                 0.405        0.000        0.000        0.000        -1.602       -4.241       0.000        \n",
            "   [1]  grease              0.345        0.000        0.000        0.000        -1.814       -15.018      0.000        \n",
            "   [1]  for                 0.638        0.000        0.000        0.000        -2.053       -7.095       0.000        \n",
            "   [1]  the                 0.519        0.000        0.000        0.000        -2.323       -6.071       0.000        \n",
            "   [1]  first               0.599        0.000        0.000        0.000        -2.629       -6.510       0.000        \n",
            "   [1]  time                0.499        0.000        0.000        0.000        -2.976       -5.658       0.000        \n",
            "   [1]  last                0.551        0.000        0.000        0.000        -3.368       -8.945       0.000        \n",
            "   [0]  film                0.596        8.814        -3.839       -0.517       -3.812       -8.583       4.771        \n",
            "   [0]  and                 0.641        5.459        -1.682       -0.444       -3.729       -8.347       4.618        \n",
            "   [0]  put                 0.510        3.431        -7.794       -0.673       -3.717       -8.267       4.549        \n",
            "   [0]  the                 0.204        5.644        -2.539       -1.587       -3.446       -6.783       3.337        \n",
            "   [0]  first               0.585        8.094        -2.628       -0.536       -2.104       -8.876       5.000        \n",
            "   [0]  version             0.887        4.810        -6.612       -0.120       -1.775       -7.256       5.000        \n",
            "   [0]  and                 0.778        4.857        -1.842       -0.251       -1.873       -8.989       5.000        \n",
            "   [0]  the                 0.501        6.681        -1.800       -0.691       -1.835       -7.781       5.000        \n",
            "   [0]  romantic            0.274        8.460        -8.236       -1.296       -1.296       -8.436       5.000        \n",
            "   [1]  mother              0.215        0.000        0.000        0.000        0.000        -9.052       0.000        \n",
            "   [1]  loved               0.490        0.000        0.000        0.000        0.000        -7.454       0.000        \n",
            "   [1]  so                  0.084        0.000        0.000        0.000        0.000        -7.691       0.000        \n",
            "   [1]  much                0.471        0.000        0.000        0.000        0.000        -9.825       0.000        \n",
            "Samples\n",
            "Sample 0 .  movie was a confusing piece of garbage you never knew what the title yet not the film movie safe by\n",
            "Sample 1 .  into this movie you know that this is average known year other the causing is it lab with an invisible\n",
            "Sample 2 .  saw grease for the first time last film and put the first version and the romantic mother loved so much\n",
            "\n",
            "\n",
            "targets[[2 115 222 1498 31 214 10 17 5 283 9 856 36 2 5307 5212 0 64 293 11][159 21 121 180 47 4 512 43 10 19 18 51 9 215 7 22 729 9 13 3382][17 5 2 12169 1421 6 6 6059 4925 650]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[152 2 115 222 1498 31 214 10 17 5]...][[1 1 1 1 1 1 1 1 1 1]...][[152 2 115 222 1498 31 214 10 17 5]...][[2 115 222 1498 31 214 10 17 5 283]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[152 2 115 222 1498 31 214 10 17 5]...][[1 1 1 1 1 1 1 1 1 1]...][[152 2 115 222 1498 31 214 10 17 5]...][[2 115 222 1498 31 214 10 17 5 283]...]\n",
            "targets[[493 1156 928 21393 6052 1 14340 13 2 126 17 94 9 856 8 189 9 13 53 1520][0 1210 3 31287 8 2 1244 3 15779 0 12688 15234 714 7500 789 2 8959 3 1 5245][7 12 0 19 41 42 60 4887 18 352]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2032 493 1156 928 21393 6052 1 14340 13 2]...][[1 1 0 0 0 0 0 0 0 0]...][[2032 493 1156 69848 69848 69848 69848 69848 69848 69848]...][[493 1156 928 21393 6052 1 14340 13 2 126]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2032 493 1156 928 21393 6052 1 14340 13 2]...][[1 1 0 0 0 0 0 0 0 0]...][[2032 493 1156 69848 69848 69848 69848 69848 69848 69848]...][[493 1156 751 511 1611 1917 4644 1890 24315 789]...]\n",
            "targets[[540 3 299 2818 45 1056 223 49 247 104 5793 6310 45 77 2270 1777 16 87 49 32][16 7 12 1271 3014 1 1149 500 7 12 2 81 346 797 122 120 10803 18 10 5][12571 285 0 172 3 780 35 1171 2786 4686]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 540 3 299 2818 45 1056 223 49 247]...][[1 1 1 1 1 1 1 1 1 1]...][[0 540 3 299 2818 45 1056 223 49 247]...][[540 3 299 2818 45 1056 223 49 247 104]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 540 3 299 2818 45 1056 223 49 247]...][[1 1 1 1 1 1 1 1 1 1]...][[0 540 3 299 2818 45 1056 223 49 247]...][[540 3 299 2818 45 1056 223 49 247 104]...]\n",
            "targets[[1154 1331 5 3770 29 3 0 720 250 98 123 92 15 0 1416 3 0 6744 717 31][3 544 311 2829 12 1048 1088 7535 12395 12 122 128 402 10 23 14 1474 15 0 19068][140 23 251 47 7 5 18 39 188 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1693 1154 1331 5 3770 29 3 0 720 250]...][[1 1 1 0 0 0 0 0 0 0]...][[1693 1154 1331 5 69848 69848 69848 69848 69848 69848]...][[1154 1331 5 3770 29 3 0 720 250 98]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1693 1154 1331 5 3770 29 3 0 720 250]...][[1 1 1 0 0 0 0 0 0 0]...][[1693 1154 1331 5 69848 69848 69848 69848 69848 69848]...][[1154 1331 5 769 12 5279 15 158 246 72]...]\n",
            "targets[[0 457 3 0 17 0 323 1394 1 0 135 3 0 1670 68 504 190 0 63 13][3220 13 1016 119 2 794 3 1408 154 1038 9396 33 2213 28852 1 0 2214 4513 31 2][5 29 3 0 250 184 104 9 27 123]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 3 0 17 0 323 1394 1]...][[1 1 1 1 1 1 1 1 0 0]...][[31 0 457 3 0 17 0 323 1394 69848]...][[0 457 3 0 17 0 323 1394 1 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[31 0 457 3 0 17 0 323 1394 1]...][[1 1 1 1 1 1 1 1 0 0]...][[31 0 457 3 0 17 0 323 1394 69848]...][[0 457 3 0 17 0 323 1394 1170 1]...]\n",
            "targets[[19 15 2 171 3 3049 8 3761 1204 6021 16767 5 322 14 35 12321 3 2 231 370][215 10 22 277 16 223 1 9 196 9 59 830 7 44 1 66 46 7 5 100][230 11 131 104 25 81 105 887 34 93]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 19 15 2 171 3 3049 8 3761 1204]...][[1 1 1 1 1 1 1 1 1 1]...][[397 19 15 2 171 3 3049 8 3761 1204]...][[19 15 2 171 3 3049 8 3761 1204 6021]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 19 15 2 171 3 3049 8 3761 1204]...][[1 1 1 1 1 1 1 1 1 1]...][[397 19 15 2 171 3 3049 8 3761 1204]...][[19 15 2 171 3 3049 8 3761 1204 6021]...]\n",
            "targets[[80 23 182 4 198 97 73 240 43 10 19 14 7 5 273 149 23 1237 0 717][2457 1 1069 1 275 122 5454 12554 17428 1580 278 10 1404 3 0 119 1281 15971 895 10][896 513 1 408 0 8092 921 5 1184 1678]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 80 23 182 4 198 97 73 240 43]...][[1 1 1 1 0 0 0 0 0 0]...][[9 80 23 182 4 69848 69848 69848 69848 69848]...][[80 23 182 4 198 97 73 240 43 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 80 23 182 4 198 97 73 240 43]...][[1 1 1 1 0 0 0 0 0 0]...][[9 80 23 182 4 69848 69848 69848 69848 69848]...][[80 23 182 4 262 10 818 2 658 959]...]\n",
            "targets[[206 5 2 4015 1 3502 959 368 15 323 848 1 760 152 9 83 987 7 5 23][26 8 4375 25 13217 1827 33 2 1107 3 4209 2 183 6307 5 5555 4 10811 26 5414][57698 158 12909 3 0 4754 2711 2686 4981 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 206 5 2 4015 1 3502 959 368 15]...][[1 1 1 1 1 0 0 0 0 0]...][[0 206 5 2 4015 1 69848 69848 69848 69848]...][[206 5 2 4015 1 3502 959 368 15 323]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 206 5 2 4015 1 3502 959 368 15]...][[1 1 1 1 1 0 0 0 0 0]...][[0 206 5 2 4015 1 69848 69848 69848 69848]...][[206 5 2 4015 1 807 123 10 201 4]...]\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[1 1 1 1 1 1 1 1 0 0]...][[1058 9 27 4 4938 0 543 3 0 69848]...][[9 27 4 4938 0 543 3 0 46 2228]...]\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[1 1 1 1 1 1 1 1 0 0]...][[1058 9 27 4 4938 0 543 3 0 69848]...][[9 27 4 4938 0 543 3 0 19 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[1 1 1 1 1 1 1 1 0 0]...][[1058 9 27 4 4938 0 543 3 0 69848]...][[9 27 4 4938 0 543 3 0 882 13380]...]\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "global_step: 7962\n",
            " perplexity: 417.209\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            " percent of 3-grams captured: 0.335.\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            " percent of 2-grams captured: 0.646.\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            " percent of 4-grams captured: 0.107.\n",
            " geometric_avg: 0.285.\n",
            " arithmetic_avg: 0.363.\n",
            "global_step: 7962\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38893\n",
            " G train loss: -8.39296\n",
            "targets[[9 27 4 4938 0 543 3 0 19 34 118 1997 4 76 2 765 1152 3 937 1120][10 122 389 22 143 8 0 1752 4128 7 13 2 1737 16 193 362 1 1532 3139 15][1222 3 3060 14505 8 4407 113 1439 1 94]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[1 1 1 1 1 1 1 1 0 0]...][[1058 9 27 4 4938 0 543 3 0 69848]...][[9 27 4 4938 0 543 3 0 19 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1058 9 27 4 4938 0 543 3 0 19]...][[1 1 1 1 1 1 1 1 0 0]...][[1058 9 27 4 4938 0 543 3 0 69848]...][[9 27 4 4938 0 543 3 0 1458 4053]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  i                   0.632        0.000        0.000        0.000        -4.369       -4.195       -0.000       \n",
            "   [1]  have                0.550        0.000        0.000        0.000        -4.944       -9.473       0.000        \n",
            "   [1]  to                  0.514        0.000        0.000        0.000        -5.596       -8.028       0.000        \n",
            "   [1]  defend              0.748        0.000        0.000        0.000        -6.333       -9.811       0.000        \n",
            "   [1]  the                 0.620        0.000        0.000        0.000        -7.168       -8.668       0.000        \n",
            "   [1]  writer              0.855        0.000        0.000        0.000        -8.113       -9.380       0.000        \n",
            "   [1]  of                  0.918        0.000        0.000        0.000        -9.182       -8.599       -0.000       \n",
            "   [1]  the                 0.451        0.000        0.000        0.000        -10.391      -6.979       -0.000       \n",
            "   [0]  confused            0.394        4.318        -9.169       -0.932       -11.761      -8.355       -3.406       \n",
            "   [0]  roman               0.520        5.935        -10.277      -0.655       -12.256      -7.342       -4.914       \n",
            "   [0]  was                 0.299        7.988        -5.630       -1.209       -13.129      -7.910       -5.000       \n",
            "   [0]  the                 0.326        10.943       -2.297       -1.121       -13.492      -8.819       -4.673       \n",
            "   [0]  fire                0.089        11.159       -8.695       -2.422       -14.001      -10.604      -3.397       \n",
            "   [0]  about               0.035        8.657        -5.269       -3.366       -13.105      -9.494       -3.611       \n",
            "   [0]  my                  0.068        2.538        -4.631       -2.691       -11.023      -10.979      -0.044       \n",
            "   [0]  good                0.011        7.664        -3.806       -4.551       -9.430       -6.867       -2.563       \n",
            "   [0]  good                0.004        8.455        -4.295       -5.523       -5.523       -10.156      4.633        \n",
            "   [1]  of                  0.001        0.000        0.000        0.000        0.000        -11.500      0.000        \n",
            "   [1]  emotional           0.001        0.000        0.000        0.000        0.000        -15.094      0.000        \n",
            "   [1]  situations          0.001        0.000        0.000        0.000        0.000        -12.661      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  this                0.584        0.000        0.000        0.000        -4.283       -3.940       -0.000       \n",
            "   [1]  show                0.425        0.000        0.000        0.000        -4.848       -6.408       0.000        \n",
            "   [0]  i                   0.494        5.773        -4.580       -0.706       -5.486       -6.961       1.475        \n",
            "   [0]  d                   0.494        11.044       -4.479       -0.704       -5.410       -8.096       2.686        \n",
            "   [0]  enjoyed             0.315        7.327        -4.931       -1.156       -5.326       -8.128       2.802        \n",
            "   [0]  it                  0.544        4.128        -2.567       -0.609       -4.720       -9.237       4.517        \n",
            "   [0]  there               0.435        3.471        -5.202       -0.831       -4.653       -6.654       2.001        \n",
            "   [0]  are                 0.874        11.550       -3.580       -0.135       -4.325       -7.294       2.969        \n",
            "   [0]  1950                0.416        12.585       -11.364      -0.878       -4.743       -7.502       2.759        \n",
            "   [0]  that                0.139        3.183        -3.284       -1.975       -4.374       -11.455      5.000        \n",
            "   [0]  i                   0.066        4.025        -1.663       -2.714       -2.714       -13.977      5.000        \n",
            "   [1]  a                   0.079        0.000        0.000        0.000        0.000        -13.266      0.000        \n",
            "   [1]  treat               0.283        0.000        0.000        0.000        0.000        -12.191      0.000        \n",
            "   [1]  for                 0.441        0.000        0.000        0.000        0.000        -10.704      0.000        \n",
            "   [1]  both                0.397        0.000        0.000        0.000        0.000        -10.194      0.000        \n",
            "   [1]  kids                0.463        0.000        0.000        0.000        0.000        -9.982       0.000        \n",
            "   [1]  and                 0.498        0.000        0.000        0.000        0.000        -9.405       0.000        \n",
            "   [1]  adults              0.765        0.000        0.000        0.000        0.000        -9.819       0.000        \n",
            "   [1]  alike               0.840        0.000        0.000        0.000        0.000        -8.863       0.000        \n",
            "   [1]  with                0.781        0.000        0.000        0.000        0.000        -8.175       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  appearance          0.420        0.000        0.000        0.000        -6.097       -4.202       -0.000       \n",
            "   [1]  of                  0.470        0.000        0.000        0.000        -6.901       -7.704       0.000        \n",
            "   [1]  michelle            0.694        0.000        0.000        0.000        -7.810       -6.948       -0.000       \n",
            "   [1]  yeoh                0.716        0.000        0.000        0.000        -8.839       -10.775      0.000        \n",
            "   [1]  in                  0.463        0.000        0.000        0.000        -10.004      -12.924      0.000        \n",
            "   [0]  legendary           0.208        11.957       -8.767       -1.569       -11.323      -12.019      0.697        \n",
            "   [0]  mare                0.199        10.288       -12.751      -1.616       -11.039      -12.963      1.924        \n",
            "   [0]  plays               0.098        9.704        -4.925       -2.325       -10.666      -12.438      1.773        \n",
            "   [0]  the                 0.123        6.283        -2.007       -2.092       -9.439       -13.549      4.110        \n",
            "   [0]  prince              0.105        10.089       -8.085       -2.255       -8.316       -13.891      5.000        \n",
            "   [0]  never               0.094        11.682       -10.289      -2.365       -6.859       -8.639       1.780        \n",
            "   [0]  said                0.138        11.959       -6.522       -1.983       -5.086       -11.377      5.000        \n",
            "   [0]  i                   0.151        10.291       -4.138       -1.890       -3.512       -9.756       5.000        \n",
            "   [0]  was                 0.159        13.244       -2.961       -1.836       -1.836       -8.327       5.000        \n",
            "   [1]  piqued              0.375        0.000        0.000        0.000        0.000        -9.947       0.000        \n",
            "   [1]  my                  0.485        0.000        0.000        0.000        0.000        -9.854       0.000        \n",
            "   [1]  interest            0.845        0.000        0.000        0.000        0.000        -8.397       0.000        \n",
            "   [1]  in                  0.968        0.000        0.000        0.000        0.000        -10.818      0.000        \n",
            "   [1]  the                 0.965        0.000        0.000        0.000        0.000        -11.748      0.000        \n",
            "   [1]  lady                0.963        0.000        0.000        0.000        0.000        -14.293      0.000        \n",
            "Samples\n",
            "Sample 0 .  i have to defend the writer of the confused roman was the fire about my good good of emotional situations\n",
            "Sample 1 .  this show i d enjoyed it there are 1950 that i a treat for both kids and adults alike with\n",
            "Sample 2 .  appearance of michelle yeoh in legendary mare plays the prince never said i was piqued my interest in the lady\n",
            "\n",
            "\n",
            "targets[[45 4 28 33 229 0 1504 250 17 9 27 110 8 0 227 844 154 51 9 215][1455 8 60 333 5 87 2373 4 720 228 167 0 129 3 799 174 422 0 863 22][9 50 1203 136 11 10 5 0 84 57]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 45 4 28 33 229 0 1504 250 17]...][[1 1 1 0 0 0 0 0 0 0]...][[10 45 4 28 69848 69848 69848 69848 69848 69848]...][[45 4 28 33 229 0 1504 250 17 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 45 4 28 33 229 0 1504 250 17]...][[1 1 1 0 0 0 0 0 0 0]...][[10 45 4 28 69848 69848 69848 69848 69848 69848]...][[45 4 28 92 11 325 2926 1 5047 13137]...]\n",
            "targets[[5 2 637 43 0 75 3 26524 958 8 775 47 5 677 637 39 25 2 173 135][47 2 1080 4110 15003 13 2 1178 15 10 19 24 67 0 3647 4 2249 2 19 15][14864 11059 5 2 49 19 15 480 1380 347]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 637 43 0 75 3 26524 958]...][[1 1 1 0 0 0 0 0 0 0]...][[10 5 2 637 69848 69848 69848 69848 69848 69848]...][[5 2 637 43 0 75 3 26524 958 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 637 43 0 75 3 26524 958]...][[1 1 1 0 0 0 0 0 0 0]...][[10 5 2 637 69848 69848 69848 69848 69848 69848]...][[5 2 637 245 78 2921 323 69 1 0]...]\n",
            "targets[[634 10 5 2 3879 832 827 17 18 36 0 9239 91 576 11 7 45 77 513 15][307 7 2361 349 15 30 0 305 926 7 13 2 1151 17 46 20 89 21 38 2789][70 30 27 9578 1375 11 7 83 113 25454]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 634 10 5 2 3879 832 827 17 18]...][[1 1 1 1 1 1 0 0 0 0]...][[591 634 10 5 2 3879 832 69848 69848 69848]...][[634 10 5 2 3879 832 827 17 18 36]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 634 10 5 2 3879 832 827 17 18]...][[1 1 1 1 1 1 0 0 0 0]...][[591 634 10 5 2 3879 832 69848 69848 69848]...][[634 10 5 2 3879 832 102 1 3058 23]...]\n",
            "targets[[3269 285 35 158 18 6345 1178 3084 1 3670 12418 1217 2 23 4 28 9045 5936 1376 32][19399 12 1616 27287 203 27 77 5578 51 24 389 15 0 321 3 10 19 2 74 984][19 5 35 2449 4 0 442 472 3 699]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1832 3269 285 35 158 18 6345 1178 3084 1]...][[1 1 1 0 0 0 0 0 0 0]...][[1832 3269 285 35 69848 69848 69848 69848 69848 69848]...][[3269 285 35 158 18 6345 1178 3084 1 3670]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1832 3269 285 35 158 18 6345 1178 3084 1]...][[1 1 1 0 0 0 0 0 0 0]...][[1832 3269 285 35 69848 69848 69848 69848 69848 69848]...][[3269 285 35 22302 905 1262 33 2858 12418 2964]...]\n",
            "targets[[26865 2591 5842 5 15174 3 189 1 1088 8 2 2540 637 393 14 2 183 243 8940 4835][626 13 1149 15167 22557 626 5 368 9 232 198 48 1095 4 10 17 7 12 2 73][27 4 136 11 3533 21106 1331 13 0 1164]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9946 26865 2591 5842 5 15174 3 189 1 1088]...][[1 1 1 0 0 0 0 0 0 0]...][[9946 26865 2591 5842 69848 69848 69848 69848 69848 69848]...][[26865 2591 5842 5 15174 3 189 1 1088 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9946 26865 2591 5842 5 15174 3 189 1 1088]...][[1 1 1 0 0 0 0 0 0 0]...][[9946 26865 2591 5842 69848 69848 69848 69848 69848 69848]...][[26865 2591 5842 1882 5 48336 6842 8 0 184]...]\n",
            "targets[[1236 16 536 1 1081 14437 678 1800 2369 346 378 678 41840 141 28 33951 6 6 9 215][103 10 17 141 93 200 57 338 19 1155 2 222 4217 9 59 138 22 43 10 220][196 10 17 118 2 185 205 49 301 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1281 1236 16 536 1 1081 14437 678 1800 2369]...][[1 1 1 0 0 0 0 0 0 0]...][[1281 1236 16 536 69848 69848 69848 69848 69848 69848]...][[1236 16 536 1 1081 14437 678 1800 2369 346]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1281 1236 16 536 1 1081 14437 678 1800 2369]...][[1 1 1 0 0 0 0 0 0 0]...][[1281 1236 16 536 69848 69848 69848 69848 69848 69848]...][[1236 16 536 60 544 2089 1 8831 33 0]...]\n",
            "targets[[47 27 20 226 20 27 599 35 30 160 360 7 5 948 233 2041 12 227 19 2828][30 0 826 1 1915 301 226 33 869 75 45 65 1699 10 17 8 235 7 2 1737][3 30 51 9 215 0 15235 1561 16 5455]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2041 47 27 20 226 20 27 599 35 30]...][[1 1 0 0 0 0 0 0 0 0]...][[2041 47 27 69848 69848 69848 69848 69848 69848 69848]...][[47 27 20 226 20 27 599 35 30 160]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2041 47 27 20 226 20 27 599 35 30]...][[1 1 0 0 0 0 0 0 0 0]...][[2041 47 27 69848 69848 69848 69848 69848 69848 69848]...][[47 27 2 53 172 8810 8 685 9909 796]...]\n",
            "targets[[2000 45 226 48 81 98 245 214 26 84 5 133 26 117 0 2120 6621 12205 33238 5][1019 747 4 1652 10 29 3 2 244 1749 2697 786 314 1515 1028 2934 87 583 7620 0][38 10 17 467 7 14 2 527 1 59]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2685 2000 45 226 48 81 98 245 214 26]...][[1 1 1 1 1 1 1 1 1 1]...][[2685 2000 45 226 48 81 98 245 214 26]...][[2000 45 226 48 81 98 245 214 26 84]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2685 2000 45 226 48 81 98 245 214 26]...][[1 1 1 1 1 1 1 1 1 1]...][[2685 2000 45 226 48 81 98 245 214 26]...][[2000 45 226 48 81 98 245 214 26 84]...]\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[1 1 1 1 1 1 1 1 1 0]...][[9 84 555 43 460 3694 51 9 215 0]...][[84 555 43 460 3694 51 9 215 0 17]...]\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[1 1 1 1 1 1 1 1 1 0]...][[9 84 555 43 460 3694 51 9 215 0]...][[84 555 43 460 3694 51 9 215 0 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[1 1 1 1 1 1 1 1 1 0]...][[9 84 555 43 460 3694 51 9 215 0]...][[84 555 43 460 3694 51 9 215 0 1611]...]\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "global_step: 7979\n",
            " perplexity: 417.436\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            " percent of 3-grams captured: 0.346.\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            " percent of 2-grams captured: 0.636.\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            " percent of 4-grams captured: 0.113.\n",
            " geometric_avg: 0.292.\n",
            " arithmetic_avg: 0.365.\n",
            "global_step: 7979\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38874\n",
            " G train loss: -8.42178\n",
            "targets[[84 555 43 460 3694 51 9 215 0 246 19313 167 94 9 159 21 58 121 7 4354][7 12 64 29 541 194 1278 4841 5 2 53 1413 102 745 3 22534 17989 455 534 14285][19 5 427 22 2 1749 3239 673 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[1 1 1 1 1 1 1 1 1 0]...][[9 84 555 43 460 3694 51 9 215 0]...][[84 555 43 460 3694 51 9 215 0 246]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 84 555 43 460 3694 51 9 215 0]...][[1 1 1 1 1 1 1 1 1 0]...][[9 84 555 43 460 3694 51 9 215 0]...][[84 555 43 460 3694 51 9 215 0 17]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  first               0.511        0.000        0.000        0.000        -5.444       -4.036       -0.000       \n",
            "   [1]  heard               0.479        0.000        0.000        0.000        -6.162       -8.404       0.000        \n",
            "   [1]  about               0.387        0.000        0.000        0.000        -6.974       -7.632       0.000        \n",
            "   [1]  white               0.316        0.000        0.000        0.000        -7.892       -6.563       -0.000       \n",
            "   [1]  noise               0.514        0.000        0.000        0.000        -8.933       -6.391       -0.000       \n",
            "   [1]  when                0.468        0.000        0.000        0.000        -10.110      -8.636       -0.000       \n",
            "   [1]  i                   0.789        0.000        0.000        0.000        -11.442      -6.935       -0.000       \n",
            "   [1]  saw                 0.705        0.000        0.000        0.000        -12.950      -8.359       -0.000       \n",
            "   [1]  the                 0.534        0.000        0.000        0.000        -14.656      -9.068       -0.000       \n",
            "   [0]  movie               0.518        6.011        -1.610       -0.657       -16.587      -10.072      -5.000       \n",
            "   [0]  to                  0.345        17.332       -1.721       -1.065       -18.030      -7.945       -5.000       \n",
            "   [0]  have                0.108        8.099        -2.850       -2.230       -19.201      -8.177       -5.000       \n",
            "   [0]  to                  0.076        8.557        -2.129       -2.577       -19.208      -12.791      -5.000       \n",
            "   [0]  agree               0.024        5.816        -6.762       -3.751       -18.822      -11.178      -5.000       \n",
            "   [0]  i                   0.006        8.906        -3.989       -5.068       -17.057      -11.680      -5.000       \n",
            "   [0]  was                 0.006        6.123        -1.579       -5.125       -13.570      -15.810      2.241        \n",
            "   [0]  a                   0.005        4.964        -1.738       -5.312       -9.558       -13.128      3.570        \n",
            "   [0]  very                0.008        7.350        -3.461       -4.805       -4.805       -11.548      5.000        \n",
            "   [1]  it                  0.003        0.000        0.000        0.000        0.000        -10.701      0.000        \n",
            "   [1]  existed             0.013        0.000        0.000        0.000        0.000        -12.155      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  it                  0.753        0.000        0.000        0.000        -11.477      -4.282       -0.000       \n",
            "   [1]  s                   0.287        0.000        0.000        0.000        -12.990      -6.758       -0.000       \n",
            "   [0]  not                 0.692        5.573        -3.743       -0.368       -14.701      -5.384       -5.000       \n",
            "   [0]  favorite            0.083        2.702        -7.317       -2.484       -16.222      -5.996       -5.000       \n",
            "   [0]  popularity          0.090        7.087        -10.421      -2.403       -15.548      -25.088      5.000        \n",
            "   [0]  harold              0.049        8.100        -9.972       -3.011       -14.878      -15.525      0.648        \n",
            "   [0]  ulrich              0.032        8.486        -13.100      -3.436       -13.430      -12.667      -0.763       \n",
            "   [0]  and                 0.036        11.682       -2.513       -3.333       -11.312      -11.966      0.654        \n",
            "   [0]  quite               0.045        5.103        -6.428       -3.100       -9.030       -8.851       -0.180       \n",
            "   [0]  some                0.036        2.284        -5.629       -3.326       -6.711       -7.641       0.929        \n",
            "   [0]  review              0.022        4.912        -8.035       -3.831       -3.831       -7.565       3.734        \n",
            "   [1]  likable             0.018        0.000        0.000        0.000        0.000        -9.139       0.000        \n",
            "   [1]  character           0.046        0.000        0.000        0.000        0.000        -7.552       0.000        \n",
            "   [1]  lots                0.070        0.000        0.000        0.000        0.000        -7.482       0.000        \n",
            "   [1]  of                  0.405        0.000        0.000        0.000        0.000        -8.533       0.000        \n",
            "   [1]  angular             0.542        0.000        0.000        0.000        0.000        -6.739       0.000        \n",
            "   [1]  goofiness           0.688        0.000        0.000        0.000        0.000        -9.496       0.000        \n",
            "   [1]  lead                0.687        0.000        0.000        0.000        0.000        -9.902       0.000        \n",
            "   [1]  actress             0.726        0.000        0.000        0.000        0.000        -9.253       0.000        \n",
            "   [1]  missy               0.198        0.000        0.000        0.000        0.000        -9.163       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  film                0.368        0.000        0.000        0.000        -2.159       -4.193       0.000        \n",
            "   [1]  is                  0.484        0.000        0.000        0.000        -2.444       -10.633      0.000        \n",
            "   [1]  based               0.578        0.000        0.000        0.000        -2.766       -6.668       0.000        \n",
            "   [1]  on                  0.570        0.000        0.000        0.000        -3.130       -4.868       0.000        \n",
            "   [1]  a                   0.582        0.000        0.000        0.000        -3.543       -11.565      0.000        \n",
            "   [1]  genuine             0.548        0.000        0.000        0.000        -4.010       -7.488       0.000        \n",
            "   [1]  1950s               0.535        0.000        0.000        0.000        -4.538       -7.814       0.000        \n",
            "   [1]  novel               0.558        0.000        0.000        0.000        -5.136       -9.052       0.000        \n",
            "   [1]  br                  0.658        0.000        0.000        0.000        -5.813       -8.404       0.000        \n",
            "   [1]  br                  0.935        0.000        0.000        0.000        -6.579       -9.760       0.000        \n",
            "   [0]  and                 0.289        11.000       -3.014       -1.242       -7.446       -6.547       -0.898       \n",
            "   [0]  who                 0.290        11.286       -5.931       -1.239       -7.022       -9.040       2.018        \n",
            "   [0]  add                 0.182        13.420       -7.670       -1.705       -6.545       -9.634       3.089        \n",
            "   [0]  no                  0.174        9.197        -5.361       -1.750       -5.478       -10.584      5.000        \n",
            "   [0]  each                0.175        4.250        -8.165       -1.741       -4.220       -9.314       5.000        \n",
            "   [0]  people              0.611        8.114        -5.381       -0.493       -2.806       -7.481       4.676        \n",
            "   [0]  episodes            0.368        6.604        -9.581       -0.999       -2.618       -8.937       5.000        \n",
            "   [0]  our                 0.263        8.126        -7.550       -1.334       -1.831       -9.950       5.000        \n",
            "   [0]  films               0.569        8.311        -5.469       -0.563       -0.563       -9.899       5.000        \n",
            "   [1]  novels              0.326        0.000        0.000        0.000        0.000        -9.510       0.000        \n",
            "Samples\n",
            "Sample 0 .  first heard about white noise when i saw the movie to have to agree i was a very it existed\n",
            "Sample 1 .  it s not favorite popularity harold ulrich and quite some review likable character lots of angular goofiness lead actress missy\n",
            "Sample 2 .  film is based on a genuine 1950s novel br br and who add no each people episodes our films novels\n",
            "\n",
            "\n",
            "targets[[19 5 37 74 11 7 45 4 28 110 4 28 2439 634 7 2103 35 980 612 493][681 115 2789 2479 0 2540 637 12170 31 2 57 51 338 13 29864 0 1522 3 7159 13577][1269 3 155 1409 5 4 11034 1 10881 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 37 74 11 7 45 4 28]...][[1 1 1 1 1 1 1 1 0 0]...][[10 19 5 37 74 11 7 45 4 69848]...][[19 5 37 74 11 7 45 4 28 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 37 74 11 7 45 4 28]...][[1 1 1 1 1 1 1 1 0 0]...][[10 19 5 37 74 11 7 45 4 69848]...][[19 5 37 74 11 7 45 4 4 367]...]\n",
            "targets[[169 10 19 1 47 9 1239 91 4187 432 1771 483 4 28 105 327 6459 104 9 329][2 173 683 4117 4 60 333 51 9 103 3 0 11894 683 38 7736 707 3276 72 114][354 19 36 17363 27995 5 554 1186 22 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 169 10 19 1 47 9 1239 91 4187]...][[1 1 1 1 1 1 0 0 0 0]...][[9 169 10 19 1 47 9 69848 69848 69848]...][[169 10 19 1 47 9 1239 91 4187 432]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 169 10 19 1 47 9 1239 91 4187]...][[1 1 1 1 1 1 0 0 0 0]...][[9 169 10 19 1 47 9 69848 69848 69848]...][[169 10 19 1 47 9 12 23 9 42]...]\n",
            "targets[[248 3273 18 5970 192 17 11 267 187 0 176 1 143 175 4 5979 91 2423 834 58][5 2 539 832 827 17 11 5 53 647 8 87 331 1 342 193 667 0 170 19][9895 31 26 7750 44 4748 8 0 1752 1916]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 248 3273 18 5970 192 17 11 267 187]...][[1 1 1 1 1 1 1 0 0 0]...][[2 248 3273 18 5970 192 17 11 69848 69848]...][[248 3273 18 5970 192 17 11 267 187 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 248 3273 18 5970 192 17 11 267 187]...][[1 1 1 1 1 1 1 0 0 0]...][[2 248 3273 18 5970 192 17 11 69848 69848]...][[248 3273 18 5970 192 17 11 12 51 4]...]\n",
            "targets[[64 307 10 17 85 3 9120 6832 1 18292 5428 3 4659 2024 9120 6832 1207 3593 10 17][60 1187 12114 4 4337 16107 203 27 77 498 4 0 10569 57 9 139 110 7 9 140][3 0 20248 3 2 49 1860 19 5 11]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 64 307 10 17 85 3 9120 6832 1]...][[1 1 1 1 1 1 0 0 0 0]...][[9 64 307 10 17 85 3 69848 69848 69848]...][[64 307 10 17 85 3 9120 6832 1 18292]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 64 307 10 17 85 3 9120 6832 1]...][[1 1 1 1 1 1 0 0 0 0]...][[9 64 307 10 17 85 3 69848 69848 69848]...][[64 307 10 17 85 3 10 19 1 88]...]\n",
            "targets[[1 0 1370 15456 5 2 535 1330 848 725 427 22 2 63 33 28411 15797 1183 1 0][128 7 429 5 0 181 17 208 181 8 2 145 360 341 919 89 21 663 0 607][0 1791 3 26 312 0 4139 846 577 23947]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[601 1 0 1370 15456 5 2 535 1330 848]...][[1 0 0 0 0 0 0 0 0 0]...][[601 1 69848 69848 69848 69848 69848 69848 69848 69848]...][[1 0 1370 15456 5 2 535 1330 848 725]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[601 1 0 1370 15456 5 2 535 1330 848]...][[1 0 0 0 0 0 0 0 0 0]...][[601 1 69848 69848 69848 69848 69848 69848 69848 69848]...][[1 2052 13 2 487 945 775 4340 5421 118]...]\n",
            "targets[[27 110 0 1561 16 10 17 440 214 119 1 9 27 4 136 11 4022 1756 280 38][509 10 17 53 73 6 6 10 5 0 64 8563 1873 9465 17947 7719 9 139 110 9][17 5 669 37281 3 472 84 3 30 3803]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 27 110 0 1561 16 10 17 440 214]...][[1 1 1 1 1 1 1 1 1 1]...][[9 27 110 0 1561 16 10 17 440 214]...][[27 110 0 1561 16 10 17 440 214 119]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 27 110 0 1561 16 10 17 440 214]...][[1 1 1 1 1 1 1 1 1 1]...][[9 27 110 0 1561 16 10 17 440 214]...][[27 110 0 1561 16 10 17 440 214 119]...]\n",
            "targets[[5 0 666 250 19 11 9 27 123 110 8 60 114 42 4 14087 9 80 23 6261][153 780 35886 34 5 542 16 437 161 269 10 737 4361 680 1159 2 679 19165 169 14][17 210 21 273 73 3 60 57 7 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 666 250 19 11 9 27 123]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 0 666 250 19 11 9 27 69848]...][[5 0 666 250 19 11 9 27 123 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 666 250 19 11 9 27 123]...][[1 1 1 1 1 1 1 1 0 0]...][[10 5 0 666 250 19 11 9 27 69848]...][[5 0 666 250 19 11 9 27 168 15]...]\n",
            "targets[[627 353 0 829 3 0 6313 128 22 898 167 9 106 2 17 9 27 211 4 4847][5 2 65 647 19 1 11 5 23 2 74 151 7 5 2 2182 3 2 5087 825][23 28 16211 9 232 366 15 0 360 753]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 627 353 0 829 3 0 6313 128 22]...][[1 1 1 1 1 0 0 0 0 0]...][[9 627 353 0 829 3 69848 69848 69848 69848]...][[627 353 0 829 3 0 6313 128 22 898]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 627 353 0 829 3 0 6313 128 22]...][[1 1 1 1 1 0 0 0 0 0]...][[9 627 353 0 829 3 69848 69848 69848 69848]...][[627 353 0 829 3 5342 14 0 17 11]...]\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[1 1 1 1 1 1 1 1 0 0]...][[7 188 180 31129 4 1401 2 12137 153 69848]...][[188 180 31129 4 1401 2 12137 153 1464 29910]...]\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[1 1 1 1 1 1 1 1 0 0]...][[7 188 180 31129 4 1401 2 12137 153 69848]...][[188 180 31129 4 1401 2 12137 153 12 84]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[1 1 1 1 1 1 1 1 0 0]...][[7 188 180 31129 4 1401 2 12137 153 69848]...][[188 180 31129 4 1401 2 12137 153 1 8]...]\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "global_step: 7996\n",
            " perplexity: 417.213\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            " percent of 3-grams captured: 0.329.\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            " percent of 2-grams captured: 0.646.\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            " percent of 4-grams captured: 0.109.\n",
            " geometric_avg: 0.285.\n",
            " arithmetic_avg: 0.361.\n",
            "global_step: 7996\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38908\n",
            " G train loss: -8.52602\n",
            "targets[[188 180 31129 4 1401 2 12137 153 12 84 806 1576 5663 257 51 20 27 23 239 92][4095 1388 12 2515 941 384 15 2314 3567 3522 14 29 3 0 52 3337 3 0 1689 2550][9 555 47 12 0 757 3 1105 1526 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[1 1 1 1 1 1 1 1 0 0]...][[7 188 180 31129 4 1401 2 12137 153 69848]...][[188 180 31129 4 1401 2 12137 153 12 84]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 188 180 31129 4 1401 2 12137 153 12]...][[1 1 1 1 1 1 1 1 0 0]...][[7 188 180 31129 4 1401 2 12137 153 69848]...][[188 180 31129 4 1401 2 12137 153 15 2824]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  seems               0.737        0.000        0.000        0.000        -3.260       -4.164       0.000        \n",
            "   [1]  quite               0.590        0.000        0.000        0.000        -3.690       -9.367       0.000        \n",
            "   [1]  churlish            0.546        0.000        0.000        0.000        -4.176       -12.436      0.000        \n",
            "   [1]  to                  0.562        0.000        0.000        0.000        -4.726       -10.710      0.000        \n",
            "   [1]  excuse              0.375        0.000        0.000        0.000        -5.349       -10.804      0.000        \n",
            "   [1]  a                   0.680        0.000        0.000        0.000        -6.054       -9.651       0.000        \n",
            "   [1]  novice              0.688        0.000        0.000        0.000        -6.851       -8.632       0.000        \n",
            "   [1]  director            0.652        0.000        0.000        0.000        -7.754       -8.304       0.000        \n",
            "   [0]  with                0.581        5.150        -4.759       -0.544       -8.776       -8.938       0.162        \n",
            "   [0]  significant         0.506        6.340        -9.528       -0.682       -9.317       -9.173       -0.144       \n",
            "   [0]  successful          0.381        7.458        -8.224       -0.966       -9.773       -7.434       -2.339       \n",
            "   [0]  takes               0.291        8.250        -7.750       -1.234       -9.967       -7.776       -2.191       \n",
            "   [0]  was                 0.080        11.231       -5.331       -2.529       -9.884       -6.955       -2.929       \n",
            "   [0]  there               0.066        7.715        -6.331       -2.717       -8.323       -12.924      4.601        \n",
            "   [0]  s                   0.110        5.979        -2.173       -2.208       -6.345       -11.937      5.000        \n",
            "   [0]  yet                 0.106        7.889        -7.285       -2.243       -4.682       -9.753       5.000        \n",
            "   [0]  for                 0.063        6.529        -4.309       -2.761       -2.761       -9.256       5.000        \n",
            "   [1]  not                 0.062        0.000        0.000        0.000        0.000        -10.271      0.000        \n",
            "   [1]  yet                 0.059        0.000        0.000        0.000        0.000        -9.460       0.000        \n",
            "   [1]  made                0.033        0.000        0.000        0.000        0.000        -9.162       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  alfred              0.495        0.000        0.000        0.000        -5.928       -4.189       -0.000       \n",
            "   [1]  green               0.501        0.000        0.000        0.000        -6.709       -8.128       0.000        \n",
            "   [1]  s                   0.528        0.000        0.000        0.000        -7.594       -7.978       0.000        \n",
            "   [1]  melodrama           0.405        0.000        0.000        0.000        -8.594       -10.541      0.000        \n",
            "   [1]  baby                0.670        0.000        0.000        0.000        -9.727       -8.492       -0.000       \n",
            "   [1]  face                0.477        0.000        0.000        0.000        -11.009      -7.480       -0.000       \n",
            "   [1]  with                0.452        0.000        0.000        0.000        -12.459      -7.286       -0.000       \n",
            "   [0]  the                 0.392        8.891        -1.118       -0.938       -14.101      -7.380       -5.000       \n",
            "   [0]  mother              0.179        10.856       -6.112       -1.719       -14.898      -6.653       -5.000       \n",
            "   [0]  in                  0.172        9.302        -3.000       -1.762       -14.916      -7.891       -5.000       \n",
            "   [0]  a                   0.174        6.861        -2.048       -1.746       -14.887      -8.452       -5.000       \n",
            "   [0]  word                0.069        6.080        -7.541       -2.680       -14.873      -7.469       -5.000       \n",
            "   [0]  actresses           0.024        3.035        -8.826       -3.719       -13.799      -8.643       -5.000       \n",
            "   [0]  is                  0.022        3.231        -3.363       -3.805       -11.409      -9.086       -2.323       \n",
            "   [0]  she                 0.018        6.027        -7.071       -4.012       -8.606       -8.370       -0.235       \n",
            "   [0]  the                 0.006        10.673       -2.386       -5.199       -5.199       -8.138       2.939        \n",
            "   [1]  of                  0.004        0.000        0.000        0.000        0.000        -11.504      0.000        \n",
            "   [1]  the                 0.006        0.000        0.000        0.000        0.000        -10.770      0.000        \n",
            "   [1]  pre                 0.007        0.000        0.000        0.000        0.000        -9.308       0.000        \n",
            "   [1]  code                0.009        0.000        0.000        0.000        0.000        -9.371       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  i                   0.414        0.000        0.000        0.000        -7.392       -4.239       -0.000       \n",
            "   [1]  heard               0.389        0.000        0.000        0.000        -8.366       -6.165       -0.000       \n",
            "   [1]  what                0.513        0.000        0.000        0.000        -9.468       -9.436       -0.000       \n",
            "   [1]  s                   0.428        0.000        0.000        0.000        -10.716      -6.680       -0.000       \n",
            "   [1]  the                 0.324        0.000        0.000        0.000        -12.128      -8.597       -0.000       \n",
            "   [0]  catch               0.294        8.248        -9.285       -1.223       -13.726      -8.848       -4.879       \n",
            "   [0]  to                  0.080        4.724        -2.820       -2.529       -14.151      -7.510       -5.000       \n",
            "   [0]  go                  0.123        8.823        -4.465       -2.092       -13.154      -13.383      0.230        \n",
            "   [0]  for                 0.087        12.266       -4.724       -2.442       -12.519      -8.134       -4.385       \n",
            "   [0]  the                 0.089        3.698        -1.778       -2.425       -11.406      -8.881       -2.525       \n",
            "   [0]  at                  0.062        7.474        -9.045       -2.785       -10.165      -7.992       -2.173       \n",
            "   [0]  direct              0.072        6.112        -8.367       -2.631       -8.352       -8.019       -0.333       \n",
            "   [0]  that                0.036        4.690        -3.173       -3.314       -6.475       -7.043       0.568        \n",
            "   [0]  forth               0.028        7.240        -11.583      -3.577       -3.577       -7.713       4.136        \n",
            "   [1]  attempts            0.022        0.000        0.000        0.000        0.000        -8.444       0.000        \n",
            "   [1]  like                0.015        0.000        0.000        0.000        0.000        -6.263       0.000        \n",
            "   [1]  in                  0.012        0.000        0.000        0.000        0.000        -7.490       0.000        \n",
            "   [1]  out                 0.010        0.000        0.000        0.000        0.000        -7.983       0.000        \n",
            "   [1]  jeffrey             0.006        0.000        0.000        0.000        0.000        -9.357       0.000        \n",
            "   [1]  also                0.005        0.000        0.000        0.000        0.000        -8.021       0.000        \n",
            "Samples\n",
            "Sample 0 .  seems quite churlish to excuse a novice director with significant successful takes was there s yet for not yet made\n",
            "Sample 1 .  alfred green s melodrama baby face with the mother in a word actresses is she the of the pre code\n",
            "Sample 2 .  i heard what s the catch to go for the at direct that forth attempts like in out jeffrey also\n",
            "\n",
            "\n",
            "targets[[36029 12 8356 2502 36 2 6801 834 61 113 1564 73 3 35 1421 16 915 2739 4696 8][122 5 122 607 99 29 422 9 307 7 22 1631 282 99 11 1289 12 122 61 5][17 13 4321 14 194 14 20 148 261 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[584 36029 12 8356 2502 36 2 6801 834 61]...][[1 1 0 0 0 0 0 0 0 0]...][[584 36029 12 69848 69848 69848 69848 69848 69848 69848]...][[36029 12 8356 2502 36 2 6801 834 61 113]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[584 36029 12 8356 2502 36 2 6801 834 61]...][[1 1 0 0 0 0 0 0 0 0]...][[584 36029 12 69848 69848 69848 69848 69848 69848 69848]...][[36029 12 2 1151 3 1607 36 503 98 6]...]\n",
            "targets[[50 21 262 10 17 1339 4 76 142 2 2364 303 678 3 1108 7 5 1184 1678 1][0 1002 3 1541 1292 1882 9014 30486 22 2 3456 3 1151 216 104 30 3 61 68 74][16 729 14 2 15685 755 43 0 7548 4674]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 50 21 262 10 17 1339 4 76 142]...][[1 1 1 1 1 0 0 0 0 0]...][[9 50 21 262 10 17 69848 69848 69848 69848]...][[50 21 262 10 17 1339 4 76 142 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 50 21 262 10 17 1339 4 76 142]...][[1 1 1 1 1 0 0 0 0 0]...][[9 50 21 262 10 17 69848 69848 69848 69848]...][[50 21 262 10 17 8 0 618 1963 0]...]\n",
            "targets[[23 74 18 79 23 37 81 4550 19 2970 1654 5 2 1059 645 36 1061 2295 11649 34][10 17 93 71 230 145 184 51 9 1715 11 9 1499 16 7 1 1066 52 72 308][0 1029 3 0 277 7 550 520 3406 6078]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 23 74 18 79 23 37 81 4550 19]...][[1 0 0 0 0 0 0 0 0 0]...][[2 23 69848 69848 69848 69848 69848 69848 69848 69848]...][[23 74 18 79 23 37 81 4550 19 2970]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 23 74 18 79 23 37 81 4550 19]...][[1 0 0 0 0 0 0 0 0 0]...][[2 23 69848 69848 69848 69848 69848 69848 69848 69848]...][[23 1646 25 356 14 30 1512 8 0 320]...]\n",
            "targets[[1 71 5 2 436 43 1902 55 8 3249 5816 2838 248 38 7872 7 38 10555 41 52][96 27 77 2 81 17 153 141 27 287 9161 10354 42 486 51 54 5 1531 4 54][44 3 720 399 6 6 7 12 245 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9953 1 71 5 2 436 43 1902 55 8]...][[1 1 1 1 1 1 1 1 0 0]...][[9953 1 71 5 2 436 43 1902 55 69848]...][[1 71 5 2 436 43 1902 55 8 3249]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9953 1 71 5 2 436 43 1902 55 8]...][[1 1 1 1 1 1 1 1 0 0]...][[9953 1 71 5 2 436 43 1902 55 69848]...][[1 71 5 2 436 43 1902 55 621 8]...]\n",
            "targets[[335 3133 15 0 5372 738 9 627 198 75 0 4132 3 0 813 18 10 17 5 180][95 5766 5 397 5 30 6859 190 161 5 1067 8 131 798 43 7 107 5249 64 694][384 5 2 37508 2515 1156 2 53 183 2314]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 335 3133 15 0 5372 738 9 627 198]...][[1 1 1 1 1 1 1 1 1 1]...][[9 335 3133 15 0 5372 738 9 627 198]...][[335 3133 15 0 5372 738 9 627 198 75]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 335 3133 15 0 5372 738 9 627 198]...][[1 1 1 1 1 1 1 1 1 1]...][[9 335 3133 15 0 5372 738 9 627 198]...][[335 3133 15 0 5372 738 9 627 198 75]...]\n",
            "targets[[140 213 261 16 49 492 707 771 7 28 1177 98 41 246 202 16 0 183 41 0][984 3 0 955 5010 17 3 0 858 304 1764 1032 3406 14 0 5787 3 26 102 36][12403 146 2799 4707 9 67 3 4073 17949 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 140 213 261 16 49 492 707 771 7]...][[1 1 1 1 1 1 1 1 1 0]...][[9 140 213 261 16 49 492 707 771 7]...][[140 213 261 16 49 492 707 771 7 28]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 140 213 261 16 49 492 707 771 7]...][[1 1 1 1 1 1 1 1 1 0]...][[9 140 213 261 16 49 492 707 771 7]...][[140 213 261 16 49 492 707 771 7 96]...]\n",
            "targets[[9 207 38 4 136 43 2236 2004 12 0 1313 1611 5 11 275 3302 331 1 2 243][227 10 1594 3 1594 12 83 28 22 277 15 0 1971 3 0 1287 1869 1568 14072 223][5 35 2483 17 326 22 378 23 35 12178]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[30 9 207 38 4 136 43 2236 2004 12]...][[1 1 1 1 1 1 1 1 1 1]...][[30 9 207 38 4 136 43 2236 2004 12]...][[9 207 38 4 136 43 2236 2004 12 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[30 9 207 38 4 136 43 2236 2004 12]...][[1 1 1 1 1 1 1 1 1 1]...][[30 9 207 38 4 136 43 2236 2004 12]...][[9 207 38 4 136 43 2236 2004 12 0]...]\n",
            "targets[[20 27 23 4660 7 239 0 19 1104 27 2 1770 530 1116 1057 62 4781 13 4 3383][306 4 28 8 0 5150 128 9 50 21 387 134 10 6 6 17 210 21 381 0][139 4652 4 66 10 17 16 2 194 57]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 27 23 4660 7 239 0 19 1104]...][[1 1 1 1 1 1 1 1 1 0]...][[46 20 27 23 4660 7 239 0 19 1104]...][[20 27 23 4660 7 239 0 19 1104 27]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 27 23 4660 7 239 0 19 1104]...][[1 1 1 1 1 1 1 1 1 0]...][[46 20 27 23 4660 7 239 0 19 1104]...][[20 27 23 4660 7 239 0 19 1104 8]...]\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[1 1 1 1 1 1 1 0 0 0]...][[9 215 2215 56 1731 2346 8 10 69848 69848]...][[215 2215 56 1731 2346 8 10 5 2299 11]...]\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[1 1 1 1 1 1 1 0 0 0]...][[9 215 2215 56 1731 2346 8 10 69848 69848]...][[215 2215 56 1731 2346 8 10 17 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[1 1 1 1 1 1 1 0 0 0]...][[9 215 2215 56 1731 2346 8 10 69848 69848]...][[215 2215 56 1731 2346 8 10 2 711 202]...]\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "global_step: 8013\n",
            " perplexity: 417.405\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            " percent of 3-grams captured: 0.345.\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            " percent of 2-grams captured: 0.647.\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            " percent of 4-grams captured: 0.115.\n",
            " geometric_avg: 0.295.\n",
            " arithmetic_avg: 0.369.\n",
            "global_step: 8013\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38870\n",
            " G train loss: -8.50353\n",
            "targets[[215 2215 56 1731 2346 8 10 17 0 64 151 9 118 66 13 5319 3195 12 5909 2028][145 13 30 326 8 29 191 7 92 0 16767 298 3 5508 147 8 60 660 100 166][108 82 104 61 25 1211 352 33 28440 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[1 1 1 1 1 1 1 0 0 0]...][[9 215 2215 56 1731 2346 8 10 69848 69848]...][[215 2215 56 1731 2346 8 10 17 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 215 2215 56 1731 2346 8 10 17 0]...][[1 1 1 1 1 1 1 0 0 0]...][[9 215 2215 56 1731 2346 8 10 69848 69848]...][[215 2215 56 1731 2346 8 10 17 34 139]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  saw                 0.507        0.000        0.000        0.000        -3.438       -4.217       0.000        \n",
            "   [1]  virtually           0.522        0.000        0.000        0.000        -3.891       -12.950      0.000        \n",
            "   [1]  no                  0.585        0.000        0.000        0.000        -4.404       -10.635      0.000        \n",
            "   [1]  redeeming           0.423        0.000        0.000        0.000        -4.984       -9.465       0.000        \n",
            "   [1]  qualities           0.640        0.000        0.000        0.000        -5.641       -8.513       0.000        \n",
            "   [1]  in                  0.572        0.000        0.000        0.000        -6.384       -9.074       0.000        \n",
            "   [1]  this                0.654        0.000        0.000        0.000        -7.225       -8.841       0.000        \n",
            "   [0]  movie               0.594        1.115        -1.115       -0.521       -8.177       -10.457      2.280        \n",
            "   [0]  who                 0.290        4.066        -5.859       -1.238       -8.665       -8.692       0.027        \n",
            "   [0]  ve                  0.095        5.614        -4.585       -2.356       -8.405       -9.762       1.357        \n",
            "   [0]  been                0.211        12.532       -2.297       -1.558       -6.847       -10.701      3.854        \n",
            "   [0]  high                0.304        4.489        -7.251       -1.189       -5.986       -9.272       3.286        \n",
            "   [0]  parts               0.144        9.874        -7.048       -1.937       -5.428       -7.547       2.119        \n",
            "   [0]  for                 0.183        8.883        -3.656       -1.700       -3.951       -10.856      5.000        \n",
            "   [0]  this                0.224        9.232        -2.416       -1.496       -2.549       -8.584       5.000        \n",
            "   [0]  film                0.304        13.866       -1.052       -1.192       -1.192       -8.662       5.000        \n",
            "   [1]  tarantino           0.338        0.000        0.000        0.000        0.000        -8.532       0.000        \n",
            "   [1]  s                   0.758        0.000        0.000        0.000        0.000        -8.340       0.000        \n",
            "   [1]  seeming             0.583        0.000        0.000        0.000        0.000        -9.623       0.000        \n",
            "   [1]  insane              0.602        0.000        0.000        0.000        0.000        -12.481      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  real                0.510        0.000        0.000        0.000        -6.637       -4.172       -0.000       \n",
            "   [1]  was                 0.542        0.000        0.000        0.000        -7.512       -4.844       -0.000       \n",
            "   [1]  all                 0.400        0.000        0.000        0.000        -8.501       -9.612       0.000        \n",
            "   [1]  shot                0.690        0.000        0.000        0.000        -9.622       -9.588       -0.000       \n",
            "   [1]  in                  0.488        0.000        0.000        0.000        -10.890      -12.002      0.000        \n",
            "   [1]  one                 0.345        0.000        0.000        0.000        -12.325      -10.360      -0.000       \n",
            "   [0]  and                 0.310        8.976        -2.638       -1.171       -13.949      -8.847       -5.000       \n",
            "   [0]  there               0.352        3.434        -5.492       -1.043       -14.462      -11.073      -3.389       \n",
            "   [0]  should              0.267        5.587        -4.775       -1.319       -15.187      -8.384       -5.000       \n",
            "   [0]  bought              0.014        7.114        -5.922       -4.249       -15.696      -10.671      -5.000       \n",
            "   [0]  it                  0.018        17.432       -2.399       -4.019       -12.956      -12.915      -0.041       \n",
            "   [0]  would               0.016        10.459       -4.575       -4.111       -10.114      -9.910       -0.204       \n",
            "   [0]  give                0.052        11.800       -5.606       -2.963       -6.794       -10.572      3.778        \n",
            "   [0]  a                   0.089        14.079       -2.853       -2.415       -4.336       -8.761       4.424        \n",
            "   [0]  drug                0.114        7.128        -9.517       -2.175       -2.175       -8.288       5.000        \n",
            "   [1]  in                  0.045        0.000        0.000        0.000        0.000        -7.640       0.000        \n",
            "   [1]  my                  0.134        0.000        0.000        0.000        0.000        -8.546       0.000        \n",
            "   [1]  opinion             0.561        0.000        0.000        0.000        0.000        -6.283       0.000        \n",
            "   [1]  any                 0.674        0.000        0.000        0.000        0.000        -12.282      0.000        \n",
            "   [1]  work                0.777        0.000        0.000        0.000        0.000        -7.534       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  many                0.530        0.000        0.000        0.000        -5.105       -4.169       -0.000       \n",
            "   [1]  other               0.648        0.000        0.000        0.000        -5.778       -10.575      0.000        \n",
            "   [1]  films               0.605        0.000        0.000        0.000        -6.539       -6.060       -0.000       \n",
            "   [1]  which               0.620        0.000        0.000        0.000        -7.401       -9.206       0.000        \n",
            "   [1]  are                 0.363        0.000        0.000        0.000        -8.376       -9.081       0.000        \n",
            "   [1]  disturbing          0.568        0.000        0.000        0.000        -9.480       -8.311       -0.000       \n",
            "   [1]  either              0.723        0.000        0.000        0.000        -10.730      -9.993       -0.000       \n",
            "   [1]  by                  0.487        0.000        0.000        0.000        -12.144      -9.932       -0.000       \n",
            "   [0]  me                  0.841        16.681       -6.151       -0.173       -13.744      -10.051      -3.693       \n",
            "   [0]  clive               0.754        4.795        -11.424      -0.283       -15.359      -8.856       -5.000       \n",
            "   [0]  dialogue            0.916        7.043        -7.690       -0.087       -17.063      -9.813       -5.000       \n",
            "   [0]  night               0.488        10.380       -6.983       -0.717       -19.213      -9.500       -5.000       \n",
            "   [0]  br                  0.647        16.994       -4.069       -0.436       -20.933      -10.852      -5.000       \n",
            "   [0]  and                 0.003        8.259        -2.085       -5.847       -23.199      -17.918      -5.000       \n",
            "   [0]  extraordinary       0.001        12.675       -10.581      -6.961       -19.639      -22.358      2.719        \n",
            "   [0]  pryor               0.001        8.957        -9.440       -7.581       -14.348      -15.093      0.745        \n",
            "   [0]  film                0.000        4.989        -5.189       -7.659       -7.659       -16.996      5.000        \n",
            "   [1]  their               0.000        0.000        0.000        0.000        0.000        -11.009      0.000        \n",
            "   [1]  sheer               0.001        0.000        0.000        0.000        0.000        -10.182      0.000        \n",
            "   [1]  violence            0.001        0.000        0.000        0.000        0.000        -10.054      0.000        \n",
            "Samples\n",
            "Sample 0 .  saw virtually no redeeming qualities in this movie who ve been high parts for this film tarantino s seeming insane\n",
            "Sample 1 .  real was all shot in one and there should bought it would give a drug in my opinion any work\n",
            "Sample 2 .  many other films which are disturbing either by me clive dialogue night br and extraordinary pryor film their sheer violence\n",
            "\n",
            "\n",
            "targets[[15383 12 1969 5 0 63 3 2 125 12 15568 78 4887 256 16181 7899 685 5 8403 33][229 126 94 20 59 512 766 436 1159 2 160 728 3550 543 5492 1543 7020 34 12 301][89 21 121 47 0 859 10805 215 8 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 15383 12 1969 5 0 63 3 2 125]...][[1 1 0 0 0 0 0 0 0 0]...][[35 15383 12 69848 69848 69848 69848 69848 69848 69848]...][[15383 12 1969 5 0 63 3 2 125 12]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[35 15383 12 1969 5 0 63 3 2 125]...][[1 1 0 0 0 0 0 0 0 0]...][[35 15383 12 69848 69848 69848 69848 69848 69848 69848]...][[15383 12 601 2907 29424 22 98 4 417 2187]...]\n",
            "targets[[13 2 394 453 3 281 1 57 39 13 64 29 1413 102 3412 12 939 9182 295 332][2008 577 2100 35540 45 77 259 4 1178 2 2136 11 59 129 30 3561 1 43312 18 784][233 318 40 8 163 179 9 722 43 20]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 13 2 394 453 3 281 1 57 39]...][[1 1 1 1 1 1 1 1 1 1]...][[10 13 2 394 453 3 281 1 57 39]...][[13 2 394 453 3 281 1 57 39 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 13 2 394 453 3 281 1 57 39]...][[1 1 1 1 1 1 1 1 1 1]...][[10 13 2 394 453 3 281 1 57 39]...][[13 2 394 453 3 281 1 57 39 13]...]\n",
            "targets[[0 4308 1116 1057 16 10 610 637 9 203 987 4 256 56591 18746 0 19 61 3085 258][29 670 4480 9 198 7 29 314 16 0 4837 343 135 1 769 1785 342 873 843 7][5 29 3 0 250 104 9 139 110 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[464 0 4308 1116 1057 16 10 610 637 9]...][[1 1 1 1 1 1 1 1 0 0]...][[464 0 4308 1116 1057 16 10 610 637 69848]...][[0 4308 1116 1057 16 10 610 637 9 203]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[464 0 4308 1116 1057 16 10 610 637 9]...][[1 1 1 1 1 1 1 1 0 0]...][[464 0 4308 1116 1057 16 10 610 637 69848]...][[0 4308 1116 1057 16 10 610 637 191 18]...]\n",
            "targets[[64 151 447 72 2 348 17 5 2 2119 348 17 2382 5 42 11 6 6 7 188][17 5 2 8297 502 3 0 2116 1447 70 27 37 108 81 98 9 50 21 387 87][1948 246 5 1938 9442 16 9505 3524 1 1907]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 64 151 447 72 2 348 17 5 2]...][[1 0 0 0 0 0 0 0 0 0]...][[0 64 69848 69848 69848 69848 69848 69848 69848 69848]...][[64 151 447 72 2 348 17 5 2 2119]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 64 151 447 72 2 348 17 5 2]...][[1 0 0 0 0 0 0 0 0 0]...][[0 64 69848 69848 69848 69848 69848 69848 69848 69848]...][[64 55 22 0 145 250 3 0 84 13]...]\n",
            "targets[[2 903 11 10 3578 1594 13 400 4 178 696 4 1766 51446 9 139 113 196 0 678][5 65 29 3 0 126 4030 98 9 139 110 8 2 132 6 6 193 0 2642 1][685 761 18305 2433 668 154 8 1061 16 26]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[91 2 903 11 10 3578 1594 13 400 4]...][[1 1 1 1 1 1 1 1 0 0]...][[91 2 903 11 10 3578 1594 13 400 69848]...][[2 903 11 10 3578 1594 13 400 4 178]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[91 2 903 11 10 3578 1594 13 400 4]...][[1 1 1 1 1 1 1 1 0 0]...][[91 2 903 11 10 3578 1594 13 400 69848]...][[2 903 11 10 3578 1594 13 400 30 8105]...]\n",
            "targets[[477 2 680 61 6804 22 0 410 3 2 184 17 6 6 716 163 263 19478 76 1423][0 665 3 5252 2 21483 11958 2735 33 1644 26505 5 2308 20142 22 246 12 84 16839 2480][180 2 1343 1 8890 2515 270 8 5213 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[63 477 2 680 61 6804 22 0 410 3]...][[1 1 1 1 1 1 1 1 0 0]...][[63 477 2 680 61 6804 22 0 410 69848]...][[477 2 680 61 6804 22 0 410 3 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[63 477 2 680 61 6804 22 0 410 3]...][[1 1 1 1 1 1 1 1 0 0]...][[63 477 2 680 61 6804 22 0 410 69848]...][[477 2 680 61 6804 22 0 410 0 17]...]\n",
            "targets[[108 388 9 67 53 360 1422 3 10 17 9 42 103 0 834 3 2 460 125 116][738 1745 1022 6 6 10 462 539 19 45 77 73 3496 43 233 91 768 8 5470 1][17 5 43 2 183 234 34 5 0 1378]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[38 108 388 9 67 53 360 1422 3 10]...][[1 1 1 1 1 1 1 1 1 1]...][[38 108 388 9 67 53 360 1422 3 10]...][[108 388 9 67 53 360 1422 3 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[38 108 388 9 67 53 360 1422 3 10]...][[1 1 1 1 1 1 1 1 1 1]...][[38 108 388 9 67 53 360 1422 3 10]...][[108 388 9 67 53 360 1422 3 10 17]...]\n",
            "targets[[734 17 15 0 629 15176 12 648 450 46 20 424 29948 20 232 112 10 17 504 1290][1018 10 487 22 1901 29 311 1 420 21 262 0 2011 8391 3 7 58 46 0 5488][0 19 672 0 84 459 228 465 38 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 734 17 15 0 629 15176 12 648 450]...][[1 1 1 1 1 1 1 1 1 1]...][[2 734 17 15 0 629 15176 12 648 450]...][[734 17 15 0 629 15176 12 648 450 46]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 734 17 15 0 629 15176 12 648 450]...][[1 1 1 1 1 1 1 1 1 1]...][[2 734 17 15 0 629 15176 12 648 450]...][[734 17 15 0 629 15176 12 648 450 46]...]\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[1 1 1 1 1 1 1 1 1 1]...][[499 44 839 441 3 38 2 1808 823 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[1 1 1 1 1 1 1 1 1 1]...][[499 44 839 441 3 38 2 1808 823 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[1 1 1 1 1 1 1 1 1 1]...][[499 44 839 441 3 38 2 1808 823 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "global_step: 8030\n",
            " perplexity: 417.796\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            " percent of 3-grams captured: 0.326.\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            " percent of 2-grams captured: 0.631.\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            " percent of 4-grams captured: 0.112.\n",
            " geometric_avg: 0.284.\n",
            " arithmetic_avg: 0.356.\n",
            "global_step: 8030\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38845\n",
            " G train loss: -8.65979\n",
            "targets[[44 839 441 3 38 2 1808 823 246 17 43 2 1666 1988 3705 22 16 43 1706 228][12 23 0 117 883 17 7 12 401 23 0 117 960 17 7 150 21 27 0 117][19 162 56 11555 43 107 238 546 2 755]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[1 1 1 1 1 1 1 1 1 1]...][[499 44 839 441 3 38 2 1808 823 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[499 44 839 441 3 38 2 1808 823 246]...][[1 1 1 1 1 1 1 1 1 1]...][[499 44 839 441 3 38 2 1808 823 246]...][[44 839 441 3 38 2 1808 823 246 17]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  out                 0.058        0.000        0.000        0.000        -5.346       -4.333       -0.000       \n",
            "   [1]  poorly              0.166        0.000        0.000        0.000        -6.050       -8.982       0.000        \n",
            "   [1]  sort                0.335        0.000        0.000        0.000        -6.847       -10.734      0.000        \n",
            "   [1]  of                  0.363        0.000        0.000        0.000        -7.750       -9.742       0.000        \n",
            "   [1]  like                0.325        0.000        0.000        0.000        -8.771       -6.057       -0.000       \n",
            "   [1]  a                   0.313        0.000        0.000        0.000        -9.927       -7.127       -0.000       \n",
            "   [1]  below               0.383        0.000        0.000        0.000        -11.235      -8.082       -0.000       \n",
            "   [1]  average             0.407        0.000        0.000        0.000        -12.715      -8.014       -0.000       \n",
            "   [1]  tv                  0.310        0.000        0.000        0.000        -14.391      -9.038       -0.000       \n",
            "   [1]  movie               0.872        0.000        0.000        0.000        -16.287      -9.468       -0.000       \n",
            "   [0]  to                  0.301        5.330        -4.648       -1.199       -18.434      -9.335       -5.000       \n",
            "   [0]  picked              0.069        4.669        -7.661       -2.678       -19.505      -8.260       -5.000       \n",
            "   [0]  sure                0.014        12.320       -7.609       -4.261       -19.045      -11.165      -5.000       \n",
            "   [0]  a                   0.013        12.976       -2.993       -4.314       -16.732      -15.047      -1.686       \n",
            "   [0]  history             0.014        11.807       -6.977       -4.277       -14.054      -11.979      -2.075       \n",
            "   [0]  endings             0.022        4.152        -11.247      -3.796       -11.065      -10.605      -0.460       \n",
            "   [0]  the                 0.032        3.917        -4.193       -3.440       -8.227       -10.056      1.829        \n",
            "   [0]  story               0.073        9.817        -4.047       -2.623       -5.418       -9.490       4.072        \n",
            "   [0]  runs                0.042        10.756       -9.630       -3.163       -3.163       -8.999       5.000        \n",
            "   [1]  minutes             0.007        0.000        0.000        0.000        0.000        -9.315       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  s                   0.278        0.000        0.000        0.000        -1.386       -4.400       0.000        \n",
            "   [1]  not                 0.691        0.000        0.000        0.000        -1.569       -14.392      0.000        \n",
            "   [1]  the                 0.745        0.000        0.000        0.000        -1.776       -11.847      0.000        \n",
            "   [1]  best                0.631        0.000        0.000        0.000        -2.010       -15.219      0.000        \n",
            "   [0]  many                0.575        9.200        -5.991       -0.553       -2.274       -12.117      5.000        \n",
            "   [0]  thing               0.791        2.283        -5.565       -0.235       -1.948       -11.364      5.000        \n",
            "   [0]  i                   0.918        3.152        -1.073       -0.086       -1.939       -12.822      5.000        \n",
            "   [0]  end                 0.830        4.196        -7.593       -0.186       -2.098       -13.132      5.000        \n",
            "   [0]  i                   0.733        7.988        -2.196       -0.310       -2.164       -11.686      5.000        \n",
            "   [0]  have                0.810        8.170        -2.808       -0.211       -2.098       -11.283      5.000        \n",
            "   [0]  13                  0.630        4.030        -8.712       -0.462       -2.136       -10.493      5.000        \n",
            "   [0]  the                 0.418        8.983        -2.447       -0.873       -1.894       -9.988       5.000        \n",
            "   [0]  going               0.315        9.418        -8.190       -1.155       -1.155       -10.263      5.000        \n",
            "   [1]  movie               0.258        0.000        0.000        0.000        0.000        -8.008       0.000        \n",
            "   [1]  it                  0.107        0.000        0.000        0.000        0.000        -10.334      0.000        \n",
            "   [1]  doesn               0.199        0.000        0.000        0.000        0.000        -11.493      0.000        \n",
            "   [1]  t                   0.350        0.000        0.000        0.000        0.000        -9.568       0.000        \n",
            "   [1]  have                0.604        0.000        0.000        0.000        0.000        -8.024       0.000        \n",
            "   [1]  the                 0.482        0.000        0.000        0.000        0.000        -7.754       0.000        \n",
            "   [1]  best                0.478        0.000        0.000        0.000        0.000        -10.866      0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  film                0.649        0.000        0.000        0.000        -0.778       -4.201       0.000        \n",
            "   [1]  makes               0.470        0.000        0.000        0.000        -0.880       -9.593       0.000        \n",
            "   [1]  no                  0.469        0.000        0.000        0.000        -0.996       -11.543      0.000        \n",
            "   [1]  pretense            0.441        0.000        0.000        0.000        -1.128       -6.136       0.000        \n",
            "   [1]  about               0.315        0.000        0.000        0.000        -1.276       -8.049       0.000        \n",
            "   [1]  being               0.688        0.000        0.000        0.000        -1.444       -10.124      0.000        \n",
            "   [1]  anything            0.683        0.000        0.000        0.000        -1.635       -11.209      0.000        \n",
            "   [1]  except              0.627        0.000        0.000        0.000        -1.850       -10.915      0.000        \n",
            "   [0]  by                  0.580        4.393        -4.976       -0.545       -2.094       -10.549      5.000        \n",
            "   [0]  his                 0.657        10.049       -5.563       -0.421       -1.754       -10.153      5.000        \n",
            "   [0]  kind                0.783        7.304        -6.864       -0.245       -1.509       -9.937       5.000        \n",
            "   [0]  punk                0.793        4.901        -12.341      -0.232       -1.430       -13.472      5.000        \n",
            "   [0]  this                0.668        5.999        -6.295       -0.403       -1.355       -15.015      5.000        \n",
            "   [0]  movie               0.716        11.291       -2.279       -0.335       -1.078       -12.232      5.000        \n",
            "   [0]  is                  0.823        4.894        -1.257       -0.195       -0.841       -12.473      5.000        \n",
            "   [0]  shown               0.784        7.304        -7.372       -0.244       -0.731       -11.336      5.000        \n",
            "   [0]  and                 0.576        8.145        -2.292       -0.552       -0.552       -10.380      5.000        \n",
            "   [1]  it                  0.530        0.000        0.000        0.000        0.000        -10.978      0.000        \n",
            "   [1]  in                  0.532        0.000        0.000        0.000        0.000        -9.728       0.000        \n",
            "   [1]  the                 0.574        0.000        0.000        0.000        0.000        -9.130       0.000        \n",
            "Samples\n",
            "Sample 0 .  out poorly sort of like a below average tv movie to picked sure a history endings the story runs minutes\n",
            "Sample 1 .  s not the best many thing i end i have 13 the going movie it doesn t have the best\n",
            "Sample 2 .  film makes no pretense about being anything except by his kind punk this movie is shown and it in the\n",
            "\n",
            "\n",
            "targets[[243 12 373 162 2 845 15 0 1727 4 586 0 518 36 1636 844 154 309 0 1727][937 1 734 17 145 112 63 23 2 3435 2914 755 6 6 5 43 385 474 75 0][1779 149 10 17 1 13 53 4232 9 139]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 243 12 373 162 2 845 15 0 1727]...][[1 1 1 1 1 1 1 1 1 0]...][[2 243 12 373 162 2 845 15 0 1727]...][[243 12 373 162 2 845 15 0 1727 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 243 12 373 162 2 845 15 0 1727]...][[1 1 1 1 1 1 1 1 1 0]...][[2 243 12 373 162 2 845 15 0 1727]...][[243 12 373 162 2 845 15 0 1727 8]...]\n",
            "targets[[5057 577 2386 6828 26 1299 4 0 1727 1 1497 0 13987 3 947 12958 25258 31 0 457][118 23 27 0 3372 3 107 482 4 667 3172 99 884 8 0 1864 18 256 307 7][5 1242 4 512 11 2 2138 3 6940 104]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[577 5057 577 2386 6828 26 1299 4 0 1727]...][[1 1 1 1 1 1 1 0 0 0]...][[577 5057 577 2386 6828 26 1299 4 69848 69848]...][[5057 577 2386 6828 26 1299 4 0 1727 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[577 5057 577 2386 6828 26 1299 4 0 1727]...][[1 1 1 1 1 1 1 0 0 0]...][[577 5057 577 2386 6828 26 1299 4 69848 69848]...][[5057 577 2386 6828 26 1299 4 105 643 1]...]\n",
            "targets[[0 670 392 2607 88 3 0 442 17 6 6 14 7 551 60 939 1291 0 277 768][8 411 20 159 21 854 36 0 84 29250 3246 104 11 0 3246 13 65 74 33332 267][42 215 6111 1 9 27 4 136 11 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[13114 0 670 392 2607 88 3 0 442 17]...][[1 1 0 0 0 0 0 0 0 0]...][[13114 0 670 69848 69848 69848 69848 69848 69848 69848]...][[0 670 392 2607 88 3 0 442 17 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[13114 0 670 392 2607 88 3 0 442 17]...][[1 1 0 0 0 0 0 0 0 0]...][[13114 0 670 69848 69848 69848 69848 69848 69848 69848]...][[0 670 3 614 1639 153 1041 8 18 8863]...]\n",
            "targets[[10 13 42 14 9 67 6994 53 379 9 13 861 4 106 7 8 26840 2 173 2196][17 65 9 382 65 1762 91 195 109 1463 37 200 1 969 2427 2507 50 1142 144 90][719 6 6 9 42 307 10 175 1 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 10 13 42 14 9 67 6994 53 379]...][[1 1 1 1 1 1 0 0 0 0]...][[10 10 13 42 14 9 67 69848 69848 69848]...][[10 13 42 14 9 67 6994 53 379 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 10 13 42 14 9 67 6994 53 379]...][[1 1 1 1 1 1 0 0 0 0]...][[10 10 13 42 14 9 67 69848 69848 69848]...][[10 13 42 14 9 67 93 2 1565 4]...]\n",
            "targets[[37 14 2 340 3 0 3101 443 168 9 802 2392 11849 1 9 27 4 136 11 9][5 2 2845 1 13668 817 1 7 3658 69 97 7 672 120 187 2829 14 2 1548 20804][8 160 728 2654 223 163 250 17 3 2654]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[815 37 14 2 340 3 0 3101 443 168]...][[1 1 1 0 0 0 0 0 0 0]...][[815 37 14 2 69848 69848 69848 69848 69848 69848]...][[37 14 2 340 3 0 3101 443 168 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[815 37 14 2 340 3 0 3101 443 168]...][[1 1 1 0 0 0 0 0 0 0]...][[815 37 14 2 69848 69848 69848 69848 69848 69848]...][[37 14 2 37 74 57 8 52 85 15]...]\n",
            "targets[[5 137 51 7 269 4 19 1 1054 294 62 19 472 32 27 198 178 440 3 0][69 92 1614 18 241 23 16 0 823 276 374 13646 3729 17 1352 9 59 112 4 66][24743 168 31 10 9 76 28478 940 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[39 5 137 51 7 269 4 19 1 1054]...][[1 1 1 1 1 1 1 1 1 0]...][[39 5 137 51 7 269 4 19 1 1054]...][[5 137 51 7 269 4 19 1 1054 294]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[39 5 137 51 7 269 4 19 1 1054]...][[1 1 1 1 1 1 1 1 1 0]...][[39 5 137 51 7 269 4 19 1 1054]...][[5 137 51 7 269 4 19 1 1054 3]...]\n",
            "targets[[856 4 66 2 49 184 17 51 9 1291 0 578 330 234 18 9 13 671 0 3741][19 45 2 81 809 30 0 95 144 88 3 0 2722 25 23 69 542 18 1810 2][6 6 1357 129 3 0 176 5 2 15239]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 856 4 66 2 49 184 17 51 9]...][[1 1 1 0 0 0 0 0 0 0]...][[9 856 4 66 69848 69848 69848 69848 69848 69848]...][[856 4 66 2 49 184 17 51 9 1291]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 856 4 66 2 49 184 17 51 9]...][[1 1 1 0 0 0 0 0 0 0]...][[9 856 4 66 69848 69848 69848 69848 69848 69848]...][[856 4 66 26 1185 34 386 21 32 196]...]\n",
            "targets[[509 10 17 0 19 69 2501 20129 1489 8 114 30 3 0 454 68 263 239 19905 29][19 13 3813 8 0 1598 1050 15 74 116 74 503 1 2 839 7958 109 410 142 14][5 2 81 360 341 487 45 35 177 745]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 509 10 17 0 19 69 2501 20129 1489]...][[1 1 0 0 0 0 0 0 0 0]...][[9 509 10 69848 69848 69848 69848 69848 69848 69848]...][[509 10 17 0 19 69 2501 20129 1489 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 509 10 17 0 19 69 2501 20129 1489]...][[1 1 0 0 0 0 0 0 0 0]...][[9 509 10 69848 69848 69848 69848 69848 69848 69848]...][[509 10 17 2 74 3 2 19 32 38]...]\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[1 1 0 0 0 0 0 0 0 0]...][[25081 5 29 69848 69848 69848 69848 69848 69848 69848]...][[5 29 3 679 2841 357 8 2 49 227]...]\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[1 1 0 0 0 0 0 0 0 0]...][[25081 5 29 69848 69848 69848 69848 69848 69848 69848]...][[5 29 151 9 50 136 43 10 17 1317]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[1 1 0 0 0 0 0 0 0 0]...][[25081 5 29 69848 69848 69848 69848 69848 69848 69848]...][[5 29 3 0 145 15819 315 483 3 104]...]\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "global_step: 8047\n",
            " perplexity: 417.178\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            " percent of 3-grams captured: 0.332.\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            " percent of 2-grams captured: 0.645.\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            " percent of 4-grams captured: 0.114.\n",
            " geometric_avg: 0.290.\n",
            " arithmetic_avg: 0.363.\n",
            "global_step: 8047\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38817\n",
            " G train loss: -8.56064\n",
            "targets[[5 29 151 9 50 136 43 10 17 1317 9 140 29 3 146 75 34 1285 4111 37][39 12 238 22 246 11 96 93 814 847 168 38 972 1864 2668 3719 2004 5 7 23756][288 21 251 47 4 512 51 9 418 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[1 1 0 0 0 0 0 0 0 0]...][[25081 5 29 69848 69848 69848 69848 69848 69848 69848]...][[5 29 151 9 50 136 43 10 17 1317]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[25081 5 29 151 9 50 136 43 10 17]...][[1 1 0 0 0 0 0 0 0 0]...][[25081 5 29 69848 69848 69848 69848 69848 69848 69848]...][[5 29 2342 1147 22 0 115 219 8 0]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  is                  0.478        0.000        0.000        0.000        -16.075      -4.190       -0.000       \n",
            "   [1]  one                 0.583        0.000        0.000        0.000        -18.193      -8.284       -0.000       \n",
            "   [0]  display             0.313        6.826        -9.860       -1.161       -20.591      -16.731      -3.860       \n",
            "   [0]  missed              0.028        4.024        -10.413      -3.581       -21.990      -13.849      -5.000       \n",
            "   [0]  on                  0.049        7.560        -3.661       -3.017       -20.834      -21.879      1.045        \n",
            "   [0]  the                 0.047        9.331        -1.145       -3.053       -20.165      -16.721      -3.444       \n",
            "   [0]  little              0.026        9.600        -5.191       -3.632       -19.367      -13.990      -5.000       \n",
            "   [0]  least               0.005        6.487        -7.200       -5.260       -17.809      -12.751      -5.000       \n",
            "   [0]  in                  0.006        4.440        -4.048       -5.099       -14.202      -13.979      -0.223       \n",
            "   [0]  the                 0.007        10.571       -1.447       -5.016       -10.304      -12.488      2.184        \n",
            "   [0]  murphy              0.003        8.455        -10.897      -5.984       -5.984       -11.096      5.000        \n",
            "   [1]  m                   0.002        0.000        0.000        0.000        0.000        -12.904      0.000        \n",
            "   [1]  one                 0.002        0.000        0.000        0.000        0.000        -11.569      0.000        \n",
            "   [1]  of                  0.004        0.000        0.000        0.000        0.000        -11.350      0.000        \n",
            "   [1]  those               0.047        0.000        0.000        0.000        0.000        -11.002      0.000        \n",
            "   [1]  people              0.223        0.000        0.000        0.000        0.000        -8.853       0.000        \n",
            "   [1]  who                 0.599        0.000        0.000        0.000        0.000        -9.150       0.000        \n",
            "   [1]  loves               0.787        0.000        0.000        0.000        0.000        -9.391       0.000        \n",
            "   [1]  cats                0.734        0.000        0.000        0.000        0.000        -8.504       0.000        \n",
            "   [1]  so                  0.505        0.000        0.000        0.000        0.000        -10.016      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  there               0.342        0.000        0.000        0.000        -12.479      -4.114       -0.000       \n",
            "   [1]  s                   0.730        0.000        0.000        0.000        -14.123      -8.387       -0.000       \n",
            "   [1]  anything            0.690        0.000        0.000        0.000        -15.985      -5.378       -0.000       \n",
            "   [1]  on                  0.205        0.000        0.000        0.000        -18.091      -7.733       -0.000       \n",
            "   [0]  this                0.487        6.548        -1.727       -0.719       -20.475      -6.804       -5.000       \n",
            "   [0]  old                 0.345        7.604        -8.071       -1.064       -22.359      -7.845       -5.000       \n",
            "   [0]  lupone              0.280        8.036        -15.009      -1.273       -24.102      -6.920       -5.000       \n",
            "   [0]  with                0.252        8.690        -5.438       -1.380       -25.837      -8.160       -5.000       \n",
            "   [0]  br                  0.169        8.867        -5.760       -1.777       -27.680      -7.742       -5.000       \n",
            "   [0]  they                0.000        10.800       -4.388       -8.418       -29.316      -12.230      -5.000       \n",
            "   [0]  wasn                0.000        6.461        -6.078       -8.536       -23.652      -29.412      5.000        \n",
            "   [0]  t                   0.000        8.157        -0.024       -8.516       -17.108      -30.333      5.000        \n",
            "   [0]  make                0.000        10.219       -3.756       -9.724       -9.724       -17.315      5.000        \n",
            "   [1]  theatre             0.000        0.000        0.000        0.000        0.000        -17.071      0.000        \n",
            "   [1]  san                 0.000        0.000        0.000        0.000        0.000        -16.185      0.000        \n",
            "   [1]  francisco           0.000        0.000        0.000        0.000        0.000        -15.823      0.000        \n",
            "   [1]  international       0.001        0.000        0.000        0.000        0.000        -9.573       0.000        \n",
            "   [1]  is                  0.000        0.000        0.000        0.000        0.000        -10.723      0.000        \n",
            "   [1]  it                  0.000        0.000        0.000        0.000        0.000        -9.819       0.000        \n",
            "   [1]  pernell             0.000        0.000        0.000        0.000        0.000        -8.248       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  wasn                0.528        0.000        0.000        0.000        -3.510       -4.181       0.000        \n",
            "   [1]  t                   0.566        0.000        0.000        0.000        -3.973       -12.885      0.000        \n",
            "   [1]  sure                0.635        0.000        0.000        0.000        -4.497       -7.908       0.000        \n",
            "   [0]  a                   0.540        4.674        -2.618       -0.616       -5.089       -6.959       1.870        \n",
            "   [0]  fan                 0.618        8.872        -3.625       -0.481       -5.063       -5.677       0.614        \n",
            "   [0]  in                  0.321        10.012       -3.198       -1.136       -5.186       -5.740       0.554        \n",
            "   [0]  my                  0.596        5.865        -3.630       -0.517       -4.583       -7.592       3.009        \n",
            "   [0]  both                0.419        7.219        -8.743       -0.870       -4.602       -5.998       1.396        \n",
            "   [0]  details             0.287        9.396        -8.679       -1.248       -4.224       -7.557       3.332        \n",
            "   [0]  and                 0.277        3.777        -2.855       -1.283       -3.368       -8.714       5.000        \n",
            "   [0]  gore                0.309        5.861        -9.234       -1.175       -2.359       -7.923       5.000        \n",
            "   [0]  out                 0.262        4.038        -5.678       -1.340       -1.340       -8.045       5.000        \n",
            "   [1]  film                0.048        0.000        0.000        0.000        0.000        -8.069       0.000        \n",
            "   [1]  i                   0.023        0.000        0.000        0.000        0.000        -14.189      0.000        \n",
            "   [1]  liked               0.028        0.000        0.000        0.000        0.000        -12.623      0.000        \n",
            "   [1]  the                 0.057        0.000        0.000        0.000        0.000        -12.268      0.000        \n",
            "   [1]  graphic             0.068        0.000        0.000        0.000        0.000        -10.636      0.000        \n",
            "   [1]  novel               0.187        0.000        0.000        0.000        0.000        -10.017      0.000        \n",
            "   [1]  and                 0.232        0.000        0.000        0.000        0.000        -9.670       0.000        \n",
            "   [1]  was                 0.230        0.000        0.000        0.000        0.000        -9.544       0.000        \n",
            "Samples\n",
            "Sample 0 .  is one display missed on the little least in the murphy m one of those people who loves cats so\n",
            "Sample 1 .  there s anything on this old lupone with br they wasn t make theatre san francisco international is it pernell\n",
            "Sample 2 .  wasn t sure a fan in my both details and gore out film i liked the graphic novel and was\n",
            "\n",
            "\n",
            "targets[[11381 33 48 14 0 117 699 19 3 0 1128 200 1708 1 699 443 31 91 117 0][2127 223 42 389 22 3685 37 9 242 3999 503 10 14 9 106 7 0 64 864 9][4 211 5 35 5177 19 349 15 11357 11388]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[107 11381 33 48 14 0 117 699 19 3]...][[1 1 1 1 1 1 0 0 0 0]...][[107 11381 33 48 14 0 117 69848 69848 69848]...][[11381 33 48 14 0 117 699 19 3 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[107 11381 33 48 14 0 117 699 19 3]...][[1 1 1 1 1 1 0 0 0 0]...][[107 11381 33 48 14 0 117 69848 69848 69848]...][[11381 33 48 14 0 117 10215 980 0 938]...]\n",
            "targets[[21505 19 472 5 4 103 11 10 88 1614 766 680 45 77 475 3278 9 569 21 136][159 21 27 73 109 1 13 2572 634 20 1143 2 171 3 57 149 75 2856 79 7][27 56 321 14 4 61 310 153 714 32677]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[87 21505 19 472 5 4 103 11 10 88]...][[1 1 1 1 1 1 1 1 1 0]...][[87 21505 19 472 5 4 103 11 10 88]...][[21505 19 472 5 4 103 11 10 88 1614]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[87 21505 19 472 5 4 103 11 10 88]...][[1 1 1 1 1 1 1 1 1 0]...][[87 21505 19 472 5 4 103 11 10 88]...][[21505 19 472 5 4 103 11 10 88 212]...]\n",
            "targets[[20 112 0 123 19186 988 3 1241 1264 1412 7 12 273 318 3486 42 16 0 955 1144][5554 42 195 6211 1 499 318 2 1137 125 20584 622 373 3905 5 40 9688 10 5 23][307 7 22 277 9 50 21 837 10 2566]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 112 0 123 19186 988 3 1241 1264]...][[1 1 1 1 0 0 0 0 0 0]...][[46 20 112 0 123 69848 69848 69848 69848 69848]...][[20 112 0 123 19186 988 3 1241 1264 1412]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 112 0 123 19186 988 3 1241 1264]...][[1 1 1 1 0 0 0 0 0 0]...][[46 20 112 0 123 69848 69848 69848 69848 69848]...][[20 112 0 123 186 298 16 37 9 84]...]\n",
            "targets[[6385 1564 2 237 11 5 193 901 16 0 534 1 12097 16 0 102 54 285 1083 1897][5 0 777 755 3 5625 12 2401 549 2570 3234 1 26 3396 15 0 17854 54465 38 9116][10 17 5 437 394 0 964 559 2 29539]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2917 6385 1564 2 237 11 5 193 901 16]...][[1 1 1 1 1 0 0 0 0 0]...][[2917 6385 1564 2 237 11 69848 69848 69848 69848]...][[6385 1564 2 237 11 5 193 901 16 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2917 6385 1564 2 237 11 5 193 901 16]...][[1 1 1 1 1 0 0 0 0 0]...][[2917 6385 1564 2 237 11 69848 69848 69848 69848]...][[6385 1564 2 237 11 3150 17 1767 308 0]...]\n",
            "targets[[17 13 649 326 8 0 25211 1084 393 15 0 1500 36 0 1230 10098 391 0 172 3][17 702 0 63 43 35 234 20600 16659 62 2260 55 8 64536 8 0 3907 12 40 324][13 694 154 158 0 57 10 1613 559 265]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 649 326 8 0 25211 1084 393]...][[1 1 1 1 1 1 1 1 1 1]...][[10 17 13 649 326 8 0 25211 1084 393]...][[17 13 649 326 8 0 25211 1084 393 15]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 649 326 8 0 25211 1084 393]...][[1 1 1 1 1 1 1 1 1 1]...][[10 17 13 649 326 8 0 25211 1084 393]...][[17 13 649 326 8 0 25211 1084 393 15]...]\n",
            "targets[[5 2 630 7719 43 0 145 980 323 5432 3564 1178 2711 31369 2392 511 16661 15773 2 428][105 179 11 25 88 3107 43 10 19 25 91 26551 1853 1 0 992 3 91 5583 1394][1190 5 35 576 184 340 1 10 5 92]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 630 7719 43 0 145 980 323]...][[1 1 1 0 0 0 0 0 0 0]...][[10 5 2 630 69848 69848 69848 69848 69848 69848]...][[5 2 630 7719 43 0 145 980 323 5432]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 630 7719 43 0 145 980 323]...][[1 1 1 0 0 0 0 0 0 0]...][[10 5 2 630 69848 69848 69848 69848 69848 69848]...][[5 2 630 279 2604 8 13726 4310 5 117]...]\n",
            "targets[[139 241 307 272 2645 1140 104 1 10 29 426 1455 44 14 29 3 0 117 5656 3325][109 954 5 2 4260 5190 134 80 70 27 4 27 258 485 5923 26248 8 643 4 230][0 1782 3 1490 0 2630 19889 13046 2896 26775]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 139 241 307 272 2645 1140 104 1 10]...][[1 1 1 1 1 1 1 1 1 0]...][[9 139 241 307 272 2645 1140 104 1 10]...][[139 241 307 272 2645 1140 104 1 10 29]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 139 241 307 272 2645 1140 104 1 10]...][[1 1 1 1 1 1 1 1 1 0]...][[9 139 241 307 272 2645 1140 104 1 10]...][[139 241 307 272 2645 1140 104 1 10 8289]...]\n",
            "targets[[531 8 0 390 3 548 1 30 11 5 4065 93 71 68804 10 17 47 1748 25 20][12 97 74 4616 786 17763 159 21 5984 52 4 0 1471 6040 85 22 0 2058 24 13][779 261 16 100 266 3 5893 9364 8 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 531 8 0 390 3 548 1 30 11]...][[1 1 1 1 1 1 0 0 0 0]...][[60 531 8 0 390 3 548 69848 69848 69848]...][[531 8 0 390 3 548 1 30 11 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[60 531 8 0 390 3 548 1 30 11]...][[1 1 1 1 1 1 0 0 0 0]...][[60 531 8 0 390 3 548 69848 69848 69848]...][[531 8 0 390 3 548 91 106 0 81]...]\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 0 0 0 0 0 0 0 0 0]...][[115 2838 69848 69848 69848 69848 69848 69848 69848 69848]...][[2838 1 5778 20 5 421 4700 14 315 214]...]\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 0 0 0 0 0 0 0 0 0]...][[115 2838 69848 69848 69848 69848 69848 69848 69848 69848]...][[2838 9 50 6208 136 5 241 60 160 1628]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 0 0 0 0 0 0 0 0 0]...][[115 2838 69848 69848 69848 69848 69848 69848 69848 69848]...][[2838 5 4 387 0 117 731 9 93 23]...]\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "global_step: 8064\n",
            " perplexity: 417.353\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            " percent of 3-grams captured: 0.315.\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            " percent of 2-grams captured: 0.627.\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            " percent of 4-grams captured: 0.101.\n",
            " geometric_avg: 0.271.\n",
            " arithmetic_avg: 0.348.\n",
            "global_step: 8064\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38759\n",
            " G train loss: -8.43054\n",
            "targets[[2838 9 50 6208 136 5 241 60 160 1628 122 7 12 37 1616 1 607 1 58 0][84 9 13 2 115 11329 43 633 57 44 3 60 114 4 66 1426 9 382 9 242][139 77 259 4 1434 185 10 19 42 33]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 0 0 0 0 0 0 0 0 0]...][[115 2838 69848 69848 69848 69848 69848 69848 69848 69848]...][[2838 9 50 6208 136 5 241 60 160 1628]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[115 2838 9 50 6208 136 5 241 60 160]...][[1 0 0 0 0 0 0 0 0 0]...][[115 2838 69848 69848 69848 69848 69848 69848 69848 69848]...][[2838 1 0 2412 11 9 13 1316 63 36]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  britain             0.448        0.000        0.000        0.000        -8.234       -4.140       -0.000       \n",
            "   [0]  and                 0.442        3.388        -2.585       -0.815       -9.319       -7.639       -1.681       \n",
            "   [0]  the                 0.312        7.026        -1.935       -1.166       -9.625       -7.025       -2.599       \n",
            "   [0]  turkey              0.158        11.221       -8.134       -1.845       -9.573       -8.966       -0.607       \n",
            "   [0]  that                0.128        10.564       -3.706       -2.053       -8.747       -11.405      2.658        \n",
            "   [0]  i                   0.164        2.629        -3.242       -1.805       -7.576       -12.472      4.896        \n",
            "   [0]  was                 0.112        7.548        -4.343       -2.188       -6.531       -12.358      5.000        \n",
            "   [0]  worthy              0.264        7.008        -8.958       -1.332       -4.915       -11.885      5.000        \n",
            "   [0]  story               0.096        8.247        -7.196       -2.339       -4.056       -11.707      5.000        \n",
            "   [0]  from                0.143        10.898       -4.324       -1.942       -1.942       -11.798      5.000        \n",
            "   [1]  show                0.093        0.000        0.000        0.000        0.000        -11.587      0.000        \n",
            "   [1]  it                  0.076        0.000        0.000        0.000        0.000        -10.837      0.000        \n",
            "   [1]  s                   0.098        0.000        0.000        0.000        0.000        -10.655      0.000        \n",
            "   [1]  so                  0.161        0.000        0.000        0.000        0.000        -11.114      0.000        \n",
            "   [1]  creative            0.095        0.000        0.000        0.000        0.000        -10.488      0.000        \n",
            "   [1]  and                 0.133        0.000        0.000        0.000        0.000        -11.089      0.000        \n",
            "   [1]  hilarious           0.285        0.000        0.000        0.000        0.000        -9.756       0.000        \n",
            "   [1]  and                 0.360        0.000        0.000        0.000        0.000        -9.448       0.000        \n",
            "   [1]  even                0.553        0.000        0.000        0.000        0.000        -8.533       0.000        \n",
            "   [1]  the                 0.443        0.000        0.000        0.000        0.000        -7.652       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  first               0.278        0.000        0.000        0.000        -10.498      -4.266       -0.000       \n",
            "   [1]  i                   0.768        0.000        0.000        0.000        -11.882      -7.109       -0.000       \n",
            "   [1]  was                 0.732        0.000        0.000        0.000        -13.447      -8.187       -0.000       \n",
            "   [1]  a                   0.600        0.000        0.000        0.000        -15.219      -7.459       -0.000       \n",
            "   [0]  part                0.060        5.482        -5.899       -2.816       -17.225      -6.940       -5.000       \n",
            "   [0]  of                  0.190        12.182       -2.225       -1.663       -16.308      -10.109      -5.000       \n",
            "   [0]  film                0.233        5.494        -4.932       -1.459       -16.575      -7.189       -5.000       \n",
            "   [0]  you                 0.170        9.753        -4.614       -1.772       -17.108      -7.573       -5.000       \n",
            "   [0]  have                0.141        8.459        -3.004       -1.959       -17.357      -6.676       -5.000       \n",
            "   [0]  do                  0.012        7.029        -5.599       -4.383       -17.427      -8.063       -5.000       \n",
            "   [0]  the                 0.010        7.874        -2.753       -4.601       -14.763      -12.248      -2.515       \n",
            "   [0]  examples            0.007        7.769        -9.904       -4.969       -11.501      -9.951       -1.551       \n",
            "   [0]  film                0.001        7.663        -5.436       -7.393       -7.393       -11.063      3.670        \n",
            "   [1]  to                  0.001        0.000        0.000        0.000        0.000        -15.809      0.000        \n",
            "   [1]  see                 0.001        0.000        0.000        0.000        0.000        -14.660      0.000        \n",
            "   [1]  seven               0.001        0.000        0.000        0.000        0.000        -10.141      0.000        \n",
            "   [1]  i                   0.001        0.000        0.000        0.000        0.000        -10.009      0.000        \n",
            "   [1]  mean                0.001        0.000        0.000        0.000        0.000        -10.953      0.000        \n",
            "   [1]  i                   0.001        0.000        0.000        0.000        0.000        -9.893       0.000        \n",
            "   [1]  am                  0.001        0.000        0.000        0.000        0.000        -9.868       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  ve                  0.659        0.000        0.000        0.000        -14.881      -4.209       -0.000       \n",
            "   [1]  been                0.876        0.000        0.000        0.000        -16.842      -5.092       -0.000       \n",
            "   [1]  trying              0.707        0.000        0.000        0.000        -19.061      -7.718       -0.000       \n",
            "   [0]  1                   0.153        1.649        -8.662       -1.878       -21.573      -3.470       -5.000       \n",
            "   [0]  the                 0.046        9.012        -3.578       -3.081       -22.291      -7.543       -5.000       \n",
            "   [0]  woman               0.020        11.227       -7.022       -3.904       -21.742      -11.731      -5.000       \n",
            "   [0]  version             0.026        5.727        -6.414       -3.647       -20.188      -10.682      -5.000       \n",
            "   [0]  and                 0.005        4.845        -3.141       -5.208       -18.721      -8.654       -5.000       \n",
            "   [0]  at                  0.005        5.774        -5.731       -5.299       -15.293      -12.829      -2.464       \n",
            "   [0]  where               0.011        6.113        -6.714       -4.497       -11.312      -10.617      -0.695       \n",
            "   [0]  watch               0.019        14.277       -7.032       -3.951       -7.713       -8.983       1.270        \n",
            "   [0]  is                  0.014        6.033        -5.935       -4.257       -4.257       -7.288       3.031        \n",
            "   [1]  phrases             0.021        0.000        0.000        0.000        0.000        -9.946       0.000        \n",
            "   [1]  about               0.069        0.000        0.000        0.000        0.000        -9.161       0.000        \n",
            "   [1]  teenagers           0.059        0.000        0.000        0.000        0.000        -8.623       0.000        \n",
            "   [1]  seduce              0.117        0.000        0.000        0.000        0.000        -9.376       0.000        \n",
            "   [1]  and                 0.107        0.000        0.000        0.000        0.000        -7.934       0.000        \n",
            "   [1]  kill                0.185        0.000        0.000        0.000        0.000        -7.967       0.000        \n",
            "   [1]  man                 0.144        0.000        0.000        0.000        0.000        -6.303       0.000        \n",
            "   [1]  in                  0.137        0.000        0.000        0.000        0.000        -7.951       0.000        \n",
            "Samples\n",
            "Sample 0 .  britain and the turkey that i was worthy story from show it s so creative and hilarious and even the\n",
            "Sample 1 .  first i was a part of film you have do the examples film to see seven i mean i am\n",
            "Sample 2 .  ve been trying 1 the woman version and at where watch is phrases about teenagers seduce and kill man in\n",
            "\n",
            "\n",
            "targets[[242 335 8962 4 66 11 0 823 678 16 10 17 5 463 223 163 16 47 7240 71][215 10 19 31 10705 12 2004 637 19 1322 1 13 10041 4 892 193 0 964 1 18399][20 957 4 19711 4 1901 729 1 20 50]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 335 8962 4 66 11 0 823 678]...][[1 1 1 1 1 0 0 0 0 0]...][[9 242 335 8962 4 66 69848 69848 69848 69848]...][[242 335 8962 4 66 11 0 823 678 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 242 335 8962 4 66 11 0 823 678]...][[1 1 1 1 1 0 0 0 0 0]...][[9 242 335 8962 4 66 69848 69848 69848 69848]...][[242 335 8962 4 66 253 3 2 457 4]...]\n",
            "targets[[2290 10 19 1 1239 7 2 81 368 15 81 2324 156 8 0 794 11 10 19 13][124 23 365 108 683 4 122 20 47 2066 5 42 106 10 17 89 21 1647 16 342][19 13 642 128 15 0 412 2054 1028 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[113 2290 10 19 1 1239 7 2 81 368]...][[1 1 1 1 1 1 0 0 0 0]...][[113 2290 10 19 1 1239 7 69848 69848 69848]...][[2290 10 19 1 1239 7 2 81 368 15]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[113 2290 10 19 1 1239 7 2 81 368]...][[1 1 1 1 1 1 0 0 0 0]...][[113 2290 10 19 1 1239 7 69848 69848 69848]...][[2290 10 19 1 1239 7 188 4 53 200]...]\n",
            "targets[[9562 151 43 10 3140 5 11 221 30 0 5920 575 0 873 980 1031 1722 3688 306 4][109 1022 6 6 9 5915 1681 4554 9 864 134 24 3348 0 209 3 2 557 1141 8][672 4 106 10 17 18 529 55 85 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 9562 151 43 10 3140 5 11 221 30]...][[1 1 0 0 0 0 0 0 0 0]...][[0 9562 151 69848 69848 69848 69848 69848 69848 69848]...][[9562 151 43 10 3140 5 11 221 30 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 9562 151 43 10 3140 5 11 221 30]...][[1 1 0 0 0 0 0 0 0 0]...][[0 9562 151 69848 69848 69848 69848 69848 69848 69848]...][[9562 151 14 184 256 370 904 8 6057 132]...]\n",
            "targets[[13 1427 4 28 2 613 17 61 389 44 31 0 170 57 14 0 200 341 984 3][9 50 21 262 75 25 1245 330 192 4 165 38 10 432 3 821 10797 9 215 7][12 194 13210 56 65 811 55 4 0 6198]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 13 1427 4 28 2 613 17 61 389]...][[1 1 0 0 0 0 0 0 0 0]...][[10 13 1427 69848 69848 69848 69848 69848 69848 69848]...][[13 1427 4 28 2 613 17 61 389 44]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 13 1427 4 28 2 613 17 61 389]...][[1 1 0 0 0 0 0 0 0 0]...][[10 13 1427 69848 69848 69848 69848 69848 69848 69848]...][[13 1427 1 197 64 13 0 1350 1333 681]...]\n",
            "targets[[17 13 53 49 7 13 155 1263 594 1 212 7 288 21 14 49 14 639 308 18][1742 155 1258 1 2167 2226 5 213 1349 6217 20 15 40 2457 1 1774 7 12 576 11][12 53 53 155 20 121 42 38 2 201]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 53 49 7 13 155 1263 594]...][[1 1 1 1 1 1 1 0 0 0]...][[10 17 13 53 49 7 13 155 69848 69848]...][[17 13 53 49 7 13 155 1263 594 1]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 13 53 49 7 13 155 1263 594]...][[1 1 1 1 1 1 1 0 0 0]...][[10 17 13 53 49 7 13 155 69848 69848]...][[17 13 53 49 7 13 155 10 19 75]...]\n",
            "targets[[987 23 107 11 4444 3 2596 14 2 183 493 7 12 194 1 0 63 5 2 115][215 10 17 22 1901 7 13 65 155 36 0 3398 557 2424 4 0 3398 200 74 454][1274 183 125 5 427 22 2 1133 2598 304]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 987 23 107 11 4444 3 2596 14 2]...][[1 1 1 1 1 1 1 1 1 0]...][[9 987 23 107 11 4444 3 2596 14 2]...][[987 23 107 11 4444 3 2596 14 2 183]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 987 23 107 11 4444 3 2596 14 2]...][[1 1 1 1 1 1 1 1 1 0]...][[9 987 23 107 11 4444 3 2596 14 2]...][[987 23 107 11 4444 3 2596 14 2 385]...]\n",
            "targets[[23178 45 92 31 219 105 81 104 970 62552 66578 41917 1 22421 44044 47423 18 10 57 24][13 30103 31 0 378 1045 67 634 38690 0 277 1647 185 4 223 11930 1167 9 121 1][9 13 261 144 0 1568 31 338 378 261]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23776 23178 45 92 31 219 105 81 104 970]...][[1 1 1 1 1 1 0 0 0 0]...][[23776 23178 45 92 31 219 105 69848 69848 69848]...][[23178 45 92 31 219 105 81 104 970 62552]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23776 23178 45 92 31 219 105 81 104 970]...][[1 1 1 1 1 1 0 0 0 0]...][[23776 23178 45 92 31 219 105 69848 69848 69848]...][[23178 45 92 31 219 105 338 23422 2 3955]...]\n",
            "targets[[83 367 10 1330 22753 1165 2 171 52 46 20 27 110 41 25 2 340 3 0 314][5 23 2 737 5817 17 882 5 7 2 737 3115 19 9 382 7 12 3115 18 23][0 687 176 3 1509 10 1 3409 1363 11]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20 83 367 10 1330 22753 1165 2 171 52]...][[1 0 0 0 0 0 0 0 0 0]...][[20 83 69848 69848 69848 69848 69848 69848 69848 69848]...][[83 367 10 1330 22753 1165 2 171 52 46]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20 83 367 10 1330 22753 1165 2 171 52]...][[1 0 0 0 0 0 0 0 0 0]...][[20 83 69848 69848 69848 69848 69848 69848 69848 69848]...][[83 133 77 48 5069 15 155 4800 8467 36]...]\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[1 1 1 1 1 1 1 1 1 0]...][[1818 9 140 23 8014 4 949 829 18 10]...][[9 140 23 8014 4 949 829 18 10 5]...]\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[1 1 1 1 1 1 1 1 1 0]...][[1818 9 140 23 8014 4 949 829 18 10]...][[9 140 23 8014 4 949 829 18 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[1 1 1 1 1 1 1 1 1 0]...][[1818 9 140 23 8014 4 949 829 18 10]...][[9 140 23 8014 4 949 829 18 10 5]...]\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "global_step: 8081\n",
            " perplexity: 417.262\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            " percent of 3-grams captured: 0.329.\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            " percent of 2-grams captured: 0.630.\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            " percent of 4-grams captured: 0.107.\n",
            " geometric_avg: 0.281.\n",
            " arithmetic_avg: 0.355.\n",
            "global_step: 8081\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38738\n",
            " G train loss: -8.49714\n",
            "targets[[9 140 23 8014 4 949 829 18 10 17 13 37 7692 1343 9 230 9 203 9 12344][22 0 206 0 379 803 10 6841 5 37 335 4567 29 45 4 589 47 0 3799 13][2190 1199 2190 225 308 444 463 1394 17238 116]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[1 1 1 1 1 1 1 1 1 0]...][[1818 9 140 23 8014 4 949 829 18 10]...][[9 140 23 8014 4 949 829 18 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1818 9 140 23 8014 4 949 829 18 10]...][[1 1 1 1 1 1 1 1 1 0]...][[1818 9 140 23 8014 4 949 829 18 10]...][[9 140 23 8014 4 949 829 18 10 637]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  i                   0.474        0.000        0.000        0.000        -1.356       -4.246       0.000        \n",
            "   [1]  m                   0.643        0.000        0.000        0.000        -1.534       -7.420       0.000        \n",
            "   [1]  not                 0.586        0.000        0.000        0.000        -1.737       -7.004       0.000        \n",
            "   [1]  motivated           0.548        0.000        0.000        0.000        -1.965       -7.701       0.000        \n",
            "   [1]  to                  0.508        0.000        0.000        0.000        -2.224       -7.116       0.000        \n",
            "   [1]  write               0.495        0.000        0.000        0.000        -2.518       -3.569       0.000        \n",
            "   [1]  reviews             0.637        0.000        0.000        0.000        -2.849       -7.268       0.000        \n",
            "   [1]  but                 0.705        0.000        0.000        0.000        -3.225       -9.661       0.000        \n",
            "   [1]  this                0.508        0.000        0.000        0.000        -3.650       -8.217       0.000        \n",
            "   [0]  documentary         0.514        1.717        -5.910       -0.665       -4.131       -9.092       4.961        \n",
            "   [0]  for                 0.471        3.045        -3.799       -0.754       -3.922       -10.931      5.000        \n",
            "   [0]  how                 0.597        5.222        -5.848       -0.516       -3.586       -9.644       5.000        \n",
            "   [0]  is                  0.734        11.578       -4.705       -0.310       -3.474       -6.805       3.331        \n",
            "   [0]  suck                0.746        8.654        -9.590       -0.292       -3.582       -9.281       5.000        \n",
            "   [0]  them                0.470        3.571        -6.834       -0.754       -3.723       -9.728       5.000        \n",
            "   [0]  to                  0.679        8.869        -3.761       -0.387       -3.359       -13.048      5.000        \n",
            "   [0]  often               0.379        5.327        -7.660       -0.970       -3.364       -8.891       5.000        \n",
            "   [0]  made                0.067        8.063        -5.311       -2.709       -2.709       -13.498      5.000        \n",
            "   [1]  i                   0.031        0.000        0.000        0.000        0.000        -17.374      0.000        \n",
            "   [1]  cringed             0.070        0.000        0.000        0.000        0.000        -12.315      0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  on                  0.434        0.000        0.000        0.000        -4.914       -4.066       -0.000       \n",
            "   [1]  the                 0.439        0.000        0.000        0.000        -5.562       -7.244       0.000        \n",
            "   [1]  original            0.652        0.000        0.000        0.000        -6.295       -4.781       -0.000       \n",
            "   [1]  the                 0.744        0.000        0.000        0.000        -7.124       -5.520       -0.000       \n",
            "   [1]  awful               0.185        0.000        0.000        0.000        -8.063       -6.067       -0.000       \n",
            "   [0]  london              0.205        8.325        -8.701       -1.583       -9.126       -7.898       -1.227       \n",
            "   [0]  to                  0.231        4.856        -5.501       -1.464       -8.536       -9.193       0.657        \n",
            "   [0]  be                  0.541        11.510       -2.635       -0.614       -8.004       -7.264       -0.740       \n",
            "   [0]  hour                0.323        8.254        -8.057       -1.130       -8.365       -7.095       -1.270       \n",
            "   [0]  about               0.172        5.915        -3.924       -1.763       -8.188       -6.565       -1.622       \n",
            "   [0]  while               0.144        8.799        -8.032       -1.938       -7.271       -6.628       -0.643       \n",
            "   [0]  and                 0.127        11.910       -3.593       -2.064       -6.036       -6.107       0.072        \n",
            "   [0]  this                0.073        5.052        -3.085       -2.624       -4.495       -6.490       1.996        \n",
            "   [0]  is                  0.120        5.212        -1.963       -2.118       -2.118       -8.373       5.000        \n",
            "   [1]  to                  0.070        0.000        0.000        0.000        0.000        -6.683       0.000        \n",
            "   [1]  wonder              0.155        0.000        0.000        0.000        0.000        -8.073       0.000        \n",
            "   [1]  what                0.495        0.000        0.000        0.000        0.000        -7.020       0.000        \n",
            "   [1]  the                 0.409        0.000        0.000        0.000        0.000        -6.719       0.000        \n",
            "   [1]  intent              0.336        0.000        0.000        0.000        0.000        -7.328       0.000        \n",
            "   [1]  was                 0.180        0.000        0.000        0.000        0.000        -6.718       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  0                   0.636        0.000        0.000        0.000        -3.233       -4.395       0.000        \n",
            "   [1]  shooting            0.601        0.000        0.000        0.000        -3.659       -7.895       0.000        \n",
            "   [1]  0                   0.624        0.000        0.000        0.000        -4.141       -6.849       0.000        \n",
            "   [1]  script              0.612        0.000        0.000        0.000        -4.687       -7.679       0.000        \n",
            "   [1]  1                   0.520        0.000        0.000        0.000        -5.304       -9.871       0.000        \n",
            "   [1]  direction           0.666        0.000        0.000        0.000        -6.003       -7.676       0.000        \n",
            "   [1]  5                   0.257        0.000        0.000        0.000        -6.795       -10.485      0.000        \n",
            "   [1]  photography         0.424        0.000        0.000        0.000        -7.690       -12.436      0.000        \n",
            "   [0]  who                 0.478        15.806       -3.952       -0.739       -8.703       -11.367      2.663        \n",
            "   [0]  become              0.292        9.929        -6.536       -1.232       -9.014       -10.387      1.372        \n",
            "   [0]  happy               0.212        5.575        -7.791       -1.553       -8.807       -9.171       0.364        \n",
            "   [0]  richard             0.183        8.249        -8.583       -1.701       -8.211       -8.915       0.704        \n",
            "   [0]  blake               0.132        6.381        -9.464       -2.021       -7.368       -8.222       0.854        \n",
            "   [0]  allen               0.876        5.885        -7.478       -0.132       -6.051       -9.444       3.393        \n",
            "   [0]  of                  0.138        5.729        -3.212       -1.981       -6.699       -8.407       1.708        \n",
            "   [0]  engaging            0.052        6.472        -8.921       -2.948       -5.340       -11.302      5.000        \n",
            "   [0]  saved               0.067        7.899        -10.540      -2.707       -2.707       -12.128      5.000        \n",
            "   [1]  have                0.064        0.000        0.000        0.000        0.000        -10.728      0.000        \n",
            "   [1]  been                0.172        0.000        0.000        0.000        0.000        -9.669       0.000        \n",
            "   [1]  entirely            0.382        0.000        0.000        0.000        0.000        -8.755       0.000        \n",
            "Samples\n",
            "Sample 0 .  i m not motivated to write reviews but this documentary for how is suck them to often made i cringed\n",
            "Sample 1 .  on the original the awful london to be hour about while and this is to wonder what the intent was\n",
            "Sample 2 .  0 shooting 0 script 1 direction 5 photography who become happy richard blake allen of engaging saved have been entirely\n",
            "\n",
            "\n",
            "targets[[722 884 829 11 136 137 38 89 21 453 127 57 10 19 4250 22 1746 7 124 4][30 34 27 110 0 17 1 353 0 298 94 9 242 767 4 146 34 159 21 353][17850 220 8 0 412 5 2267 2716 35 7252]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 722 884 829 11 136 137 38 89 21]...][[1 1 1 0 0 0 0 0 0 0]...][[9 722 884 829 69848 69848 69848 69848 69848 69848]...][[722 884 829 11 136 137 38 89 21 453]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 722 884 829 11 136 137 38 89 21]...][[1 1 1 0 0 0 0 0 0 0]...][[9 722 884 829 69848 69848 69848 69848 69848 69848]...][[722 884 829 36 0 19 9 420 13433 3569]...]\n",
            "targets[[46 7 1189 21 427 22 2 298 10 17 59 27 77 497 1 91 447 85 7 5][246 3586 1861 10 17 2 735 47 5 2 735 4 71 5 87 5 7 614 11 2][746 114 50 28 2 88 259 15816 58 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[58 46 7 1189 21 427 22 2 298 10]...][[1 1 1 1 1 1 0 0 0 0]...][[58 46 7 1189 21 427 22 69848 69848 69848]...][[46 7 1189 21 427 22 2 298 10 17]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[58 46 7 1189 21 427 22 2 298 10]...][[1 1 1 1 1 1 0 0 0 0]...][[58 46 7 1189 21 427 22 69848 69848 69848]...][[46 7 1189 21 427 22 1659 4 60 84]...]\n",
            "targets[[8 2 16918 5 29 3 0 117 5927 4962 104 16 317 996 29 995 88 3 62 104][29 3 0 81 284 1781 12 5085 183 468 5057 418 2254 11257 31 0 57 3 91 2583][1665 477 5 147 2 4591 878 29 11 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[400 8 2 16918 5 29 3 0 117 5927]...][[1 1 1 1 1 1 0 0 0 0]...][[400 8 2 16918 5 29 3 69848 69848 69848]...][[8 2 16918 5 29 3 0 117 5927 4962]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[400 8 2 16918 5 29 3 0 117 5927]...][[1 1 1 1 1 1 0 0 0 0]...][[400 8 2 16918 5 29 3 69848 69848 69848]...][[8 2 16918 5 29 3 2 117 714 82]...]\n",
            "targets[[12 1247 51 9 242 10 44 3 8817 15 2 19 1610 3 0 1851 45 2 53 5723][140 35 6345 821 1352 61 5 29 293 9 67 4 66 10 17 149 101 1 3052 9684][64 215 10 17 282 969 154 602 51 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 1247 51 9 242 10 44 3 8817]...][[1 1 1 1 1 1 1 1 0 0]...][[7 12 1247 51 9 242 10 44 3 69848]...][[12 1247 51 9 242 10 44 3 8817 15]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 1247 51 9 242 10 44 3 8817]...][[1 1 1 1 1 1 1 1 0 0]...][[7 12 1247 51 9 242 10 44 3 69848]...][[12 1247 51 9 242 10 44 3 10 202]...]\n",
            "targets[[662 5 13446 3 959 1720 6 6 84 0 28144 25 2 903 56 5171 848 1 64 0][2871 418 137 38 29 0 1675 54 9749 55 4 136 9 230 38 9 182 4 28 1616][3 0 368 104 3 0 544 3037 723 21]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 662 5 13446 3 959 1720 6 6 84]...][[1 1 1 1 1 1 1 1 1 0]...][[10 662 5 13446 3 959 1720 6 6 84]...][[662 5 13446 3 959 1720 6 6 84 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 662 5 13446 3 959 1720 6 6 84]...][[1 1 1 1 1 1 1 1 1 0]...][[10 662 5 13446 3 959 1720 6 6 84]...][[662 5 13446 3 959 1720 6 6 84 6405]...]\n",
            "targets[[32 83 27 2 2380 265 4 9571 10 609 767 23 2 735 14 4443 7 5 1770 12991][17 11464 12 1068 5 376 97 498 4 346 16 71 10 17 11067 71 4 80 47 54][6 454 10 17 1762 9 1024 60 308 541]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[94 32 83 27 2 2380 265 4 9571 10]...][[1 1 1 1 1 1 1 1 1 1]...][[94 32 83 27 2 2380 265 4 9571 10]...][[32 83 27 2 2380 265 4 9571 10 609]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[94 32 83 27 2 2380 265 4 9571 10]...][[1 1 1 1 1 1 1 1 1 1]...][[94 32 83 27 2 2380 265 4 9571 10]...][[32 83 27 2 2380 265 4 9571 10 609]...]\n",
            "targets[[1666 3129 7657 3 2 1040 64873 4958 575 0 13697 12 518 267 185 8 4026 2242 8 0][956 55 3220 6 6 513 33 10656 4387 6 6 1156 6845 6565 1976 10233 5060 5838 4713 3926][15717 12 325 19 408 33 5022 9052 3728 778]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 1666 3129 7657 3 2 1040 64873 4958 575]...][[1 1 0 0 0 0 0 0 0 0]...][[2 1666 3129 69848 69848 69848 69848 69848 69848 69848]...][[1666 3129 7657 3 2 1040 64873 4958 575 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[2 1666 3129 7657 3 2 1040 64873 4958 575]...][[1 1 0 0 0 0 0 0 0 0]...][[2 1666 3129 69848 69848 69848 69848 69848 69848 69848]...][[1666 3129 19 3880 16 328 15 572 1 2]...]\n",
            "targets[[20 38 74 360 341 3265 155 104 2637 56 52 10 5 0 17 16 20 6 6 7][202 3 1472 1483 8343 33280 31 40 812 12 7547 328 45 663 13669 180 21513 2 1579 615][9 242 1632 4 4801 2 19 11 12 77]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 74 360 341 3265 155 104 2637]...][[1 0 0 0 0 0 0 0 0 0]...][[46 20 69848 69848 69848 69848 69848 69848 69848 69848]...][[20 38 74 360 341 3265 155 104 2637 56]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[46 20 38 74 360 341 3265 155 104 2637]...][[1 0 0 0 0 0 0 0 0 0]...][[46 20 69848 69848 69848 69848 69848 69848 69848 69848]...][[20 136 10 10 17 5 48 561 1 9]...]\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[1 1 1 1 1 1 1 1 1 1]...][[23256 958 13 142 2 1133 1670 725 11 1426]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[1 1 1 1 1 1 1 1 1 1]...][[23256 958 13 142 2 1133 1670 725 11 1426]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[1 1 1 1 1 1 1 1 1 1]...][[23256 958 13 142 2 1133 1670 725 11 1426]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "global_step: 8098\n",
            " perplexity: 416.705\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            " percent of 3-grams captured: 0.335.\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            " percent of 2-grams captured: 0.653.\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            " percent of 4-grams captured: 0.119.\n",
            " geometric_avg: 0.296.\n",
            " arithmetic_avg: 0.369.\n",
            "global_step: 8098\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38721\n",
            " G train loss: -8.61321\n",
            "targets[[958 13 142 2 1133 1670 725 11 1426 154 309 7 13 654 78 157 1156 2181 16 16123][1 57 175 7 188 11 0 1619 156 3 338 25 1608 71 15 62 1966 14 909 3154][5 1872 393 463 29 3 0 117 104 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[1 1 1 1 1 1 1 1 1 1]...][[23256 958 13 142 2 1133 1670 725 11 1426]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[23256 958 13 142 2 1133 1670 725 11 1426]...][[1 1 1 1 1 1 1 1 1 1]...][[23256 958 13 142 2 1133 1670 725 11 1426]...][[958 13 142 2 1133 1670 725 11 1426 154]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  island              0.850        0.000        0.000        0.000        -0.402       -4.022       0.000        \n",
            "   [1]  was                 0.364        0.000        0.000        0.000        -0.455       -6.731       0.000        \n",
            "   [1]  such                0.502        0.000        0.000        0.000        -0.515       -8.570       0.000        \n",
            "   [1]  a                   0.508        0.000        0.000        0.000        -0.583       -11.459      0.000        \n",
            "   [1]  successful          0.452        0.000        0.000        0.000        -0.659       -7.250       0.000        \n",
            "   [1]  fox                 0.487        0.000        0.000        0.000        -0.746       -7.014       0.000        \n",
            "   [1]  musical             0.541        0.000        0.000        0.000        -0.845       -9.780       0.000        \n",
            "   [1]  that                0.528        0.000        0.000        0.000        -0.956       -8.578       0.000        \n",
            "   [1]  seven               0.590        0.000        0.000        0.000        -1.082       -8.269       0.000        \n",
            "   [1]  years               0.852        0.000        0.000        0.000        -1.224       -7.959       0.000        \n",
            "   [1]  later               0.927        0.000        0.000        0.000        -1.386       -6.987       0.000        \n",
            "   [0]  a                   0.639        3.861        -2.989       -0.448       -1.568       -9.096       5.000        \n",
            "   [0]  girl                0.754        7.557        -6.711       -0.282       -1.268       -5.706       4.438        \n",
            "   [0]  angie               0.494        8.305        -11.289      -0.706       -1.115       -4.650       3.534        \n",
            "   [0]  attempt             0.754        6.205        -8.057       -0.282       -0.463       -7.161       5.000        \n",
            "   [0]  across              0.954        7.727        -8.539       -0.047       -0.205       -5.260       5.000        \n",
            "   [0]  the                 0.980        7.973        -1.783       -0.021       -0.179       -7.902       5.000        \n",
            "   [0]  first               0.984        9.285        -3.981       -0.016       -0.180       -6.582       5.000        \n",
            "   [0]  an                  0.967        5.446        -5.290       -0.034       -0.185       -4.230       4.044        \n",
            "   [0]  mutant              0.842        14.640       -9.380       -0.172       -0.172       -5.860       5.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  and                 0.548        0.000        0.000        0.000        -1.445       -4.072       0.000        \n",
            "   [1]  time                0.583        0.000        0.000        0.000        -1.636       -6.831       0.000        \n",
            "   [1]  again               0.651        0.000        0.000        0.000        -1.851       -7.978       0.000        \n",
            "   [1]  it                  0.648        0.000        0.000        0.000        -2.095       -7.571       0.000        \n",
            "   [1]  seems               0.640        0.000        0.000        0.000        -2.371       -7.375       0.000        \n",
            "   [1]  that                0.661        0.000        0.000        0.000        -2.684       -6.723       0.000        \n",
            "   [1]  the                 0.479        0.000        0.000        0.000        -3.038       -6.366       0.000        \n",
            "   [0]  newspapers          0.564        8.785        -12.271      -0.573       -3.438       -8.879       5.000        \n",
            "   [0]  just                0.634        7.294        -6.828       -0.455       -3.243       -9.236       5.000        \n",
            "   [0]  well                0.542        7.697        -5.472       -0.613       -3.155       -7.571       4.416        \n",
            "   [0]  with                0.595        8.190        -4.456       -0.519       -2.877       -8.390       5.000        \n",
            "   [0]  there               0.685        7.855        -5.918       -0.378       -2.669       -8.803       5.000        \n",
            "   [0]  was                 0.523        10.772       -2.722       -0.648       -2.593       -8.550       5.000        \n",
            "   [0]  start               0.567        6.011        -7.011       -0.567       -2.202       -8.475       5.000        \n",
            "   [0]  but                 0.566        3.539        -3.038       -0.569       -1.850       -7.866       5.000        \n",
            "   [0]  them                0.235        6.788        -7.203       -1.449       -1.449       -8.307       5.000        \n",
            "   [1]  talents             0.298        0.000        0.000        0.000        0.000        -12.562      0.000        \n",
            "   [1]  as                  0.218        0.000        0.000        0.000        0.000        -10.480      0.000        \n",
            "   [1]  dramatic            0.229        0.000        0.000        0.000        0.000        -9.774       0.000        \n",
            "   [1]  performers          0.237        0.000        0.000        0.000        0.000        -9.150       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  is                  0.705        0.000        0.000        0.000        -5.542       -3.743       -0.000       \n",
            "   [1]  survive             0.607        0.000        0.000        0.000        -6.272       -10.099      0.000        \n",
            "   [1]  style               0.556        0.000        0.000        0.000        -7.099       -13.913      0.000        \n",
            "   [1]  5                   0.501        0.000        0.000        0.000        -8.034       -10.123      0.000        \n",
            "   [1]  one                 0.493        0.000        0.000        0.000        -9.093       -9.835       0.000        \n",
            "   [1]  of                  0.466        0.000        0.000        0.000        -10.291      -7.808       -0.000       \n",
            "   [1]  the                 0.595        0.000        0.000        0.000        -11.647      -8.136       -0.000       \n",
            "   [1]  best                0.429        0.000        0.000        0.000        -13.182      -6.172       -0.000       \n",
            "   [1]  films               0.787        0.000        0.000        0.000        -14.919      -6.442       -0.000       \n",
            "   [0]  with                0.372        2.496        -3.863       -0.989       -16.885      -6.187       -5.000       \n",
            "   [0]  so                  0.264        7.839        -5.155       -1.333       -17.990      -8.009       -5.000       \n",
            "   [0]  movie               0.020        6.812        -4.040       -3.933       -18.853      -9.569       -5.000       \n",
            "   [0]  to                  0.017        8.467        -2.824       -4.077       -16.886      -17.988      1.103        \n",
            "   [0]  makers              0.040        6.015        -10.395      -3.219       -14.497      -15.881      1.384        \n",
            "   [0]  the                 0.038        6.622        -2.334       -3.264       -12.763      -12.003      -0.761       \n",
            "   [0]  day                 0.022        4.159        -5.936       -3.836       -10.751      -12.083      1.333        \n",
            "   [0]  so                  0.024        5.131        -5.714       -3.728       -7.826       -11.690      3.864        \n",
            "   [0]  no                  0.010        4.761        -5.605       -4.638       -4.638       -12.216      5.000        \n",
            "   [1]  is                  0.015        0.000        0.000        0.000        0.000        -13.699      0.000        \n",
            "   [1]  about               0.029        0.000        0.000        0.000        0.000        -10.192      0.000        \n",
            "Samples\n",
            "Sample 0 .  island was such a successful fox musical that seven years later a girl angie attempt across the first an mutant\n",
            "Sample 1 .  and time again it seems that the newspapers just well with there was start but them talents as dramatic performers\n",
            "Sample 2 .  is survive style 5 one of the best films with so movie to makers the day so no is about\n",
            "\n",
            "\n",
            "targets[[5 0 1536 17 9 139 123 110 9 140 1234 5138 1 9 211 8 42 14 0 21][7 12 275 454 8 62 56641 46982 19031 4 2 2787 2891 8 47897 41 2 234 674 47][82 423 3 60 1842 68 9027 33 959 98]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 1536 17 9 139 123 110 9]...][[1 1 1 1 1 1 1 1 1 1]...][[10 5 0 1536 17 9 139 123 110 9]...][[5 0 1536 17 9 139 123 110 9 140]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 0 1536 17 9 139 123 110 9]...][[1 1 1 1 1 1 1 1 1 1]...][[10 5 0 1536 17 9 139 123 110 9]...][[5 0 1536 17 9 139 123 110 9 140]...]\n",
            "targets[[17 5 2 453 3 57 0 225 45 7189 0 135 25 23 2050 0 305 290 25 3453][2 186 49 17 18 7 932 2 160 271 0 271 13 2225 1 448 37 466 118 23][31322 9878 17761 1 2 609 3503 3 362 11]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 5 2 453 3 57 0 225 45]...][[1 1 1 1 1 0 0 0 0 0]...][[10 17 5 2 453 3 69848 69848 69848 69848]...][[17 5 2 453 3 57 0 225 45 7189]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 17 5 2 453 3 57 0 225 45]...][[1 1 1 1 1 0 0 0 0 0]...][[10 17 5 2 453 3 69848 69848 69848 69848]...][[17 5 2 453 3 281 3 2 675 3]...]\n",
            "targets[[62 10855 5195 21385 1 3247 4962 68 37 404 7248 99 16 894 3389 33 15853 439 1139 8197][49506 12 6414 1745 946 762 22 343 1 0 484 1702 11710 8592 14 4104 200 112 0 1025][19 13 92 8 796 483 1 7 274 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[8 62 10855 5195 21385 1 3247 4962 68 37]...][[1 1 1 1 1 1 1 0 0 0]...][[8 62 10855 5195 21385 1 3247 4962 69848 69848]...][[62 10855 5195 21385 1 3247 4962 68 37 404]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[8 62 10855 5195 21385 1 3247 4962 68 37]...][[1 1 1 1 1 1 1 0 0 0]...][[8 62 10855 5195 21385 1 3247 4962 69848 69848]...][[62 10855 5195 21385 1 3247 4962 1 57845 2208]...]\n",
            "targets[[4 106 10 17 5 2 821 1 9 89 21 382 11 8 2 337 95 9 13 3624][202 5 0 2017 3804 3 699 201 1 360 341 832 827 3782 11086 2 752 713 9283 1729][67 0 1004 4 166 4839 7 15 35 279]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[245 4 106 10 17 5 2 821 1 9]...][[1 1 1 1 1 1 1 1 1 0]...][[245 4 106 10 17 5 2 821 1 9]...][[4 106 10 17 5 2 821 1 9 89]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[245 4 106 10 17 5 2 821 1 9]...][[1 1 1 1 1 1 1 1 1 0]...][[245 4 106 10 17 5 2 821 1 9]...][[4 106 10 17 5 2 821 1 9 712]...]\n",
            "targets[[5 2 81 17 47 162 10 17 37 81 5 0 98 197 4669 285 4 7 12 3034][212 19 36 1806 153 786 1047 17417 5 2 1179 1282 11 5 247 1 181 2702 14 7][50 21 833 1697 3656 44 9 106 86 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 81 17 47 162 10 17 37]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 2 81 17 47 162 10 69848 69848]...][[5 2 81 17 47 162 10 17 37 81]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 81 17 47 162 10 17 37]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 2 81 17 47 162 10 69848 69848]...][[5 2 81 17 47 162 10 19 18 13]...]\n",
            "targets[[307 10 17 23 37 73 16 9915 12492 18 16 16885 19327 0 200 1615 1 454 1 4366][1756 1 1922 4529 5304 52 397 1580 36 2783 3661 10 57 436 1 201 2993 27 77 1296][59 27 1715 11 0 0 1497 68 30 8]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 307 10 17 23 37 73 16 9915 12492]...][[1 1 1 1 1 1 1 1 0 0]...][[9 307 10 17 23 37 73 16 9915 69848]...][[307 10 17 23 37 73 16 9915 12492 18]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 307 10 17 23 37 73 16 9915 12492]...][[1 1 1 1 1 1 1 1 0 0]...][[9 307 10 17 23 37 73 16 9915 69848]...][[307 10 17 23 37 73 16 9915 7516 3157]...]\n",
            "targets[[4 987 10 339 35542 2590 22698 587 50 486 546 0 3260 34 13 60 18498 6050 67 49][307 223 3144 4302 459 44 3 163 10181 1809 3808 8156 16569 34002 212 239 565 777 17 7456][9 2337 10 19 13 5941 8 5284 9 793]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[27 4 987 10 339 35542 2590 22698 587 50]...][[1 0 0 0 0 0 0 0 0 0]...][[27 4 69848 69848 69848 69848 69848 69848 69848 69848]...][[4 987 10 339 35542 2590 22698 587 50 486]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[27 4 987 10 339 35542 2590 22698 587 50]...][[1 0 0 0 0 0 0 0 0 0]...][[27 4 69848 69848 69848 69848 69848 69848 69848 69848]...][[4 288 21 77 0 1234 22 3541 961 3]...]\n",
            "targets[[12453 3 98 124 2 403 138 4 66 131 483 11 560 90 1545 47 551 4 62 2373][17 5 0 84 3 0 1408 3202 9509 3982 98 1 5 29 3 0 117 31 0 170][838 19 2775 1592 1939 150 21 27 238 22]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 12453 3 98 124 2 403 138 4 66]...][[1 1 1 1 1 1 1 0 0 0]...][[47 12453 3 98 124 2 403 138 69848 69848]...][[12453 3 98 124 2 403 138 4 66 131]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[47 12453 3 98 124 2 403 138 4 66]...][[1 1 1 1 1 1 1 0 0 0]...][[47 12453 3 98 124 2 403 138 69848 69848]...][[12453 3 98 124 2 403 138 78 1210 3]...]\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[1 1 1 1 1 0 0 0 0 0]...][[14 2 543 9 169 104 69848 69848 69848 69848]...][[2 543 9 169 104 44 44 44 5962 8]...]\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[1 1 1 1 1 0 0 0 0 0]...][[14 2 543 9 169 104 69848 69848 69848 69848]...][[2 543 9 169 104 10 74 235 7 78]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[1 1 1 1 1 0 0 0 0 0]...][[14 2 543 9 169 104 69848 69848 69848 69848]...][[2 543 9 169 104 11 9 13 886 11]...]\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "global_step: 8115\n",
            " perplexity: 416.740\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            " percent of 3-grams captured: 0.345.\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            " percent of 2-grams captured: 0.639.\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            " percent of 4-grams captured: 0.109.\n",
            " geometric_avg: 0.289.\n",
            " arithmetic_avg: 0.364.\n",
            "global_step: 8115\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38653\n",
            " G train loss: -8.65862\n",
            "targets[[2 543 9 169 104 10 74 235 7 78 369 2 605 4127 8 0 384 690 43 3214][3 0 88 322 98 123 1056 8 4800 1 426 0 117 29 92 294 0 6983 3 0][412 550 7 30 2110 15786 210 21 0 64]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[1 1 1 1 1 0 0 0 0 0]...][[14 2 543 9 169 104 69848 69848 69848 69848]...][[2 543 9 169 104 10 74 235 7 78]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[14 2 543 9 169 104 10 74 235 7]...][[1 1 1 1 1 0 0 0 0 0]...][[14 2 543 9 169 104 69848 69848 69848 69848]...][[2 543 9 169 104 10 210 21 58 0]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  a                   0.464        0.000        0.000        0.000        -2.252       -4.170       0.000        \n",
            "   [1]  writer              0.355        0.000        0.000        0.000        -2.548       -5.591       0.000        \n",
            "   [1]  i                   0.663        0.000        0.000        0.000        -2.884       -7.279       0.000        \n",
            "   [1]  find                0.660        0.000        0.000        0.000        -3.264       -8.052       0.000        \n",
            "   [1]  films               0.276        0.000        0.000        0.000        -3.694       -7.554       0.000        \n",
            "   [0]  this                0.213        3.124        -3.124       -1.545       -4.181       -10.063      5.000        \n",
            "   [0]  isn                 0.557        5.725        -7.064       -0.584       -2.984       -11.529      5.000        \n",
            "   [0]  t                   0.808        9.992        -1.058       -0.213       -2.716       -8.092       5.000        \n",
            "   [0]  even                0.811        4.899        -4.408       -0.209       -2.832       -6.835       4.003        \n",
            "   [0]  the                 0.705        7.932        -2.398       -0.350       -2.968       -7.623       4.654        \n",
            "   [0]  critique            0.640        6.653        -9.283       -0.447       -2.964       -8.417       5.000        \n",
            "   [0]  for                 0.458        5.173        -3.248       -0.780       -2.849       -9.312       5.000        \n",
            "   [0]  a                   0.449        9.676        -2.055       -0.800       -2.341       -8.961       5.000        \n",
            "   [0]  original            0.175        10.374       -5.022       -1.744       -1.744       -8.410       5.000        \n",
            "   [1]  in                  0.155        0.000        0.000        0.000        0.000        -9.522       0.000        \n",
            "   [1]  the                 0.187        0.000        0.000        0.000        0.000        -9.931       0.000        \n",
            "   [1]  face                0.268        0.000        0.000        0.000        0.000        -8.768       0.000        \n",
            "   [1]  talk                0.294        0.000        0.000        0.000        0.000        -8.203       0.000        \n",
            "   [1]  about               0.458        0.000        0.000        0.000        0.000        -8.065       0.000        \n",
            "   [1]  insulting           0.175        0.000        0.000        0.000        0.000        -8.745       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  of                  0.501        0.000        0.000        0.000        -4.446       -4.196       -0.000       \n",
            "   [1]  the                 0.569        0.000        0.000        0.000        -5.032       -8.996       0.000        \n",
            "   [1]  most                0.592        0.000        0.000        0.000        -5.695       -6.626       0.000        \n",
            "   [1]  excellent           0.605        0.000        0.000        0.000        -6.446       -8.051       0.000        \n",
            "   [1]  movies              0.496        0.000        0.000        0.000        -7.295       -7.401       0.000        \n",
            "   [1]  ever                0.605        0.000        0.000        0.000        -8.257       -8.535       0.000        \n",
            "   [1]  produced            0.732        0.000        0.000        0.000        -9.345       -7.635       -0.000       \n",
            "   [1]  in                  0.670        0.000        0.000        0.000        -10.576      -11.684      0.000        \n",
            "   [0]  this                0.533        11.965       -3.058       -0.629       -11.970      -10.037      -1.933       \n",
            "   [0]  is                  0.256        5.710        -3.266       -1.363       -12.836      -11.139      -1.697       \n",
            "   [0]  an                  0.285        8.420        -4.058       -1.256       -12.985      -11.831      -1.154       \n",
            "   [0]  wonderful           0.084        4.290        -5.484       -2.477       -13.275      -9.992       -3.284       \n",
            "   [0]  good                0.071        6.054        -4.565       -2.643       -12.221      -14.544      2.323        \n",
            "   [0]  i                   0.040        4.575        -4.482       -3.223       -10.840      -10.662      -0.177       \n",
            "   [0]  thought             0.045        6.810        -3.049       -3.102       -8.621       -12.426      3.806        \n",
            "   [0]  would               0.035        8.024        -7.087       -3.359       -6.246       -7.634       1.388        \n",
            "   [0]  not                 0.038        3.732        -4.791       -3.267       -3.267       -8.021       4.754        \n",
            "   [1]  decline             0.008        0.000        0.000        0.000        0.000        -9.034       0.000        \n",
            "   [1]  of                  0.017        0.000        0.000        0.000        0.000        -11.942      0.000        \n",
            "   [1]  the                 0.030        0.000        0.000        0.000        0.000        -8.331       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  title               0.646        0.000        0.000        0.000        -3.598       -3.944       0.000        \n",
            "   [1]  says                0.591        0.000        0.000        0.000        -4.072       -6.671       0.000        \n",
            "   [1]  it                  0.550        0.000        0.000        0.000        -4.609       -7.139       0.000        \n",
            "   [1]  all                 0.486        0.000        0.000        0.000        -5.216       -5.635       0.000        \n",
            "   [1]  danny               0.442        0.000        0.000        0.000        -5.903       -6.100       0.000        \n",
            "   [1]  trejo               0.611        0.000        0.000        0.000        -6.681       -6.968       0.000        \n",
            "   [1]  isn                 0.783        0.000        0.000        0.000        -7.562       -7.739       0.000        \n",
            "   [1]  t                   0.602        0.000        0.000        0.000        -8.558       -8.493       -0.000       \n",
            "   [0]  like                0.456        3.087        -4.248       -0.785       -9.686       -7.293       -2.393       \n",
            "   [0]  off                 0.275        6.191        -7.447       -1.291       -10.073      -9.635       -0.438       \n",
            "   [0]  and                 0.237        12.003       -2.781       -1.441       -9.939       -9.881       -0.059       \n",
            "   [0]  some                0.276        9.186        -5.783       -1.286       -9.618       -10.600      0.982        \n",
            "   [0]  an                  0.103        13.826       -5.188       -2.268       -9.430       -8.268       -1.162       \n",
            "   [0]  blatantly           0.081        8.837        -10.207      -2.514       -8.105       -11.429      3.324        \n",
            "   [0]  horror              0.186        6.718        -5.254       -1.683       -6.328       -11.318      4.990        \n",
            "   [0]  modern              0.078        6.225        -7.846       -2.547       -5.257       -8.809       3.552        \n",
            "   [0]  and                 0.047        13.151       -3.810       -3.067       -3.067       -9.889       5.000        \n",
            "   [1]  the                 0.028        0.000        0.000        0.000        0.000        -10.104      0.000        \n",
            "   [1]  plot                0.028        0.000        0.000        0.000        0.000        -10.795      0.000        \n",
            "   [1]  is                  0.058        0.000        0.000        0.000        0.000        -9.696       0.000        \n",
            "Samples\n",
            "Sample 0 .  a writer i find films this isn t even the critique for a original in the face talk about insulting\n",
            "Sample 1 .  of the most excellent movies ever produced in this is an wonderful good i thought would not decline of the\n",
            "Sample 2 .  title says it all danny trejo isn t like off and some an blatantly horror modern and the plot is\n",
            "\n",
            "\n",
            "targets[[5 2 53 155 1 610 17 43 105 524 7148 1 5234 42 5243 0 145 176 259 4][27 79 77 261 16 0 17 4319 16 154 1415 20 37 73 16 0 3968 4 0 2147][84 3 0 3955 19257 104 13750 5 88 730]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 53 155 1 610 17 43 105]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 2 53 155 1 610 17 69848 69848]...][[5 2 53 155 1 610 17 43 105 524]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 2 53 155 1 610 17 43 105]...][[1 1 1 1 1 1 1 0 0 0]...][[10 5 2 53 155 1 610 17 69848 69848]...][[5 2 53 155 1 610 17 9 118 24]...]\n",
            "targets[[6592 201 5 29 3 4668 1 3222 12 84 98 16 10569 1128 1670 37 7 210 21 799][215 10 19 1 196 7 13 475 594 429 2 12117 487 208 2 742 3 10482 342 10][215 10 432 22 711 1 9 380 20 47]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 6592 201 5 29 3 4668 1 3222 12]...][[1 1 1 1 1 0 0 0 0 0]...][[10 6592 201 5 29 3 69848 69848 69848 69848]...][[6592 201 5 29 3 4668 1 3222 12 84]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 6592 201 5 29 3 4668 1 3222 12]...][[1 1 1 1 1 0 0 0 0 0]...][[10 6592 201 5 29 3 69848 69848 69848 69848]...][[6592 201 5 29 3 0 29 13 149 9]...]\n",
            "targets[[491 4 28 2883 1354 9 182 4 28 2883 1354 6 6 10475 26453 6 6 9 813 11][0 393 3 5182 1275 12563 12 14438 2454 29328 5 2 681 115 19 1471 1 29 11 9285][98 27 2260 55 2 171 1 25 1510 52]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1310 491 4 28 2883 1354 9 182 4 28]...][[1 1 1 1 1 1 1 1 1 1]...][[1310 491 4 28 2883 1354 9 182 4 28]...][[491 4 28 2883 1354 9 182 4 28 2883]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[1310 491 4 28 2883 1354 9 182 4 28]...][[1 1 1 1 1 1 1 1 1 1]...][[1310 491 4 28 2883 1354 9 182 4 28]...][[491 4 28 2883 1354 9 182 4 28 2883]...]\n",
            "targets[[65 112 0 1626 4678 9 139 307 7 51 9 13 2 493 1 147 14 2 183 1174][7 18 133 27 4395 119 0 1437 3439 0 17 13 1393 69 15 0 1068 3 156 3129][97 73 15457 1081 5 0 64 2043 3 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 112 0 1626 4678 9 139 307 7]...][[1 1 1 1 1 1 1 1 1 0]...][[9 65 112 0 1626 4678 9 139 307 7]...][[65 112 0 1626 4678 9 139 307 7 51]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 65 112 0 1626 4678 9 139 307 7]...][[1 1 1 1 1 1 1 1 1 0]...][[9 65 112 0 1626 4678 9 139 307 7]...][[65 112 0 1626 4678 9 139 307 7 672]...]\n",
            "targets[[19 5 2 297 63 43 2 183 2435 125 1318 15 2 1247 1245 21970 11 406 26 2][423 106 0 122 2842 11 91 22 91 2 81 2327 16 1137 423 190 32 365 4 535][104 3 0 3631 5001 8 10 411 25 504]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 2 297 63 43 2 183 2435]...][[1 1 1 1 1 1 1 1 1 1]...][[10 19 5 2 297 63 43 2 183 2435]...][[19 5 2 297 63 43 2 183 2435 125]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 2 297 63 43 2 183 2435]...][[1 1 1 1 1 1 1 1 1 1]...][[10 19 5 2 297 63 43 2 183 2435]...][[19 5 2 297 63 43 2 183 2435 125]...]\n",
            "targets[[19 389 1180 14 2 49 181 19 61 9 89 21 65 103 7 5 9 254 0 63][22 0 858 304 33 584 772 17657 0 12800 2242 5 2 102 2018 8621 187 0 321 3][14749 5857 9250 1807 13 1318 4 55734 8 0]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 389 1180 14 2 49 181 19 61]...][[1 1 1 1 1 1 1 1 1 1]...][[10 19 389 1180 14 2 49 181 19 61]...][[19 389 1180 14 2 49 181 19 61 9]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 389 1180 14 2 49 181 19 61]...][[1 1 1 1 1 1 1 1 1 1]...][[10 19 389 1180 14 2 49 181 19 61]...][[19 389 1180 14 2 49 181 19 61 9]...]\n",
            "targets[[3 2866 28 2972 3 0 9634 18 15 1728 341 2 385 177 1 35 3920 225 6 6][4543 11 9 50 138 22 10 678 2341 5 29 6 6 3465 4 136 8600 10344 3220 83][71 366 44 33 674 11 9 367 2 49]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[103 3 2866 28 2972 3 0 9634 18 15]...][[1 1 1 1 1 1 1 1 1 0]...][[103 3 2866 28 2972 3 0 9634 18 15]...][[3 2866 28 2972 3 0 9634 18 15 1728]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[103 3 2866 28 2972 3 0 9634 18 15]...][[1 1 1 1 1 1 1 1 1 0]...][[103 3 2866 28 2972 3 0 9634 18 15]...][[3 2866 28 2972 3 0 9634 18 15 0]...]\n",
            "targets[[1022 1404 360 341 81 19 537 600 1 343 47 332 96 20 999 16 0 4290 883 5][467 10 17 30 3 146 74 829 20 139 42 353 25 335 356 7 5 37 1058 1][3754 5 29 3 46 23 0 1536 122 22]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[5139 1022 1404 360 341 81 19 537 600 1]...][[1 1 1 0 0 0 0 0 0 0]...][[5139 1022 1404 360 69848 69848 69848 69848 69848 69848]...][[1022 1404 360 341 81 19 537 600 1 343]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[5139 1022 1404 360 341 81 19 537 600 1]...][[1 1 1 0 0 0 0 0 0 0]...][[5139 1022 1404 360 69848 69848 69848 69848 69848 69848]...][[1022 1404 360 85 1 618 21 97 336 48]...]\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 1 1 1 1 1 1 0 0 0]...][[397 177 1024 22 3851 225 720 41 69848 69848]...][[177 1024 22 3851 225 720 41 4784 212 220]...]\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 1 1 1 1 1 1 0 0 0]...][[397 177 1024 22 3851 225 720 41 69848 69848]...][[177 1024 22 3851 225 720 41 37 1532 9125]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 1 1 1 1 1 1 0 0 0]...][[397 177 1024 22 3851 225 720 41 69848 69848]...][[177 1024 22 3851 225 720 41 78 67257 41]...]\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "global_step: 8132\n",
            " perplexity: 416.803\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            " percent of 3-grams captured: 0.346.\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            " percent of 2-grams captured: 0.635.\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            " percent of 4-grams captured: 0.114.\n",
            " geometric_avg: 0.293.\n",
            " arithmetic_avg: 0.365.\n",
            "global_step: 8132\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38623\n",
            " G train loss: -8.85536\n",
            "targets[[177 1024 22 3851 225 720 41 37 1532 9125 31 0 1606 1244 32 6417 14 37912 96 10][10 738 5 1216 1517 9 182 4 93 2 1153 220 84 157 3615 128 3125 11 12881 4089][1556 43 2 385 474 985 243 4708 3744 34]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 1 1 1 1 1 1 0 0 0]...][[397 177 1024 22 3851 225 720 41 69848 69848]...][[177 1024 22 3851 225 720 41 37 1532 9125]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[397 177 1024 22 3851 225 720 41 37 1532]...][[1 1 1 1 1 1 1 0 0 0]...][[397 177 1024 22 3851 225 720 41 69848 69848]...][[177 1024 22 3851 225 720 41 29458 3539 31]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  cast                0.625        0.000        0.000        0.000        -5.117       -4.422       -0.000       \n",
            "   [1]  wasted              0.639        0.000        0.000        0.000        -5.791       -8.268       0.000        \n",
            "   [1]  on                  0.671        0.000        0.000        0.000        -6.554       -8.486       0.000        \n",
            "   [1]  worthless           0.526        0.000        0.000        0.000        -7.418       -7.965       0.000        \n",
            "   [1]  script              0.641        0.000        0.000        0.000        -8.396       -12.739      0.000        \n",
            "   [1]  ten                 0.433        0.000        0.000        0.000        -9.502       -11.428      0.000        \n",
            "   [1]  or                  0.480        0.000        0.000        0.000        -10.754      -11.255      0.000        \n",
            "   [0]  equalizer           0.537        5.944        -12.724      -0.622       -12.171      -9.155       -3.016       \n",
            "   [0]  mild                0.425        9.177        -9.960       -0.856       -13.071      -8.979       -4.092       \n",
            "   [0]  at                  0.198        9.573        -5.944       -1.621       -13.825      -9.616       -4.209       \n",
            "   [0]  having              0.145        6.018        -7.556       -1.933       -13.813      -8.954       -4.859       \n",
            "   [0]  am                  0.051        6.054        -5.474       -2.984       -13.445      -10.022      -3.423       \n",
            "   [0]  who                 0.028        9.443        -6.943       -3.568       -11.839      -10.814      -1.025       \n",
            "   [0]  sit                 0.019        10.279       -6.126       -3.973       -9.361       -10.914      1.554        \n",
            "   [0]  all                 0.039        5.059        -5.596       -3.257       -6.098       -11.097      4.999        \n",
            "   [0]  the                 0.040        14.313       -1.911       -3.215       -3.215       -7.531       4.316        \n",
            "   [1]  as                  0.012        0.000        0.000        0.000        0.000        -8.921       0.000        \n",
            "   [1]  juveniles           0.020        0.000        0.000        0.000        0.000        -10.933      0.000        \n",
            "   [1]  could               0.020        0.000        0.000        0.000        0.000        -9.936       0.000        \n",
            "   [1]  this                0.026        0.000        0.000        0.000        0.000        -9.643       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  this                0.710        0.000        0.000        0.000        -10.656      -4.156       -0.000       \n",
            "   [1]  review              0.446        0.000        0.000        0.000        -12.060      -7.068       -0.000       \n",
            "   [0]  dennis              0.563        1.312        -10.650      -0.574       -13.650      -6.893       -5.000       \n",
            "   [0]  fawlty              0.371        8.592        -14.366      -0.992       -14.798      -6.594       -5.000       \n",
            "   [0]  shot                0.049        9.827        -8.002       -3.013       -15.626      -7.222       -5.000       \n",
            "   [0]  of                  0.048        3.873        -2.884       -3.037       -14.275      -9.517       -4.758       \n",
            "   [0]  friends             0.033        10.397       -7.353       -3.407       -12.719      -7.603       -5.000       \n",
            "   [0]  hollywood           0.056        4.076        -7.451       -2.889       -10.539      -7.215       -3.324       \n",
            "   [0]  friend              0.066        8.073        -9.115       -2.723       -8.658       -6.106       -2.552       \n",
            "   [0]  acting              0.058        4.075        -7.531       -2.843       -6.717       -7.136       0.418        \n",
            "   [0]  s                   0.012        10.334       -3.755       -4.385       -4.385       -6.104       1.719        \n",
            "   [1]  point               0.020        0.000        0.000        0.000        0.000        -7.071       0.000        \n",
            "   [1]  first               0.025        0.000        0.000        0.000        0.000        -5.140       0.000        \n",
            "   [1]  another             0.014        0.000        0.000        0.000        0.000        -4.621       0.000        \n",
            "   [1]  poster              0.017        0.000        0.000        0.000        0.000        -5.035       0.000        \n",
            "   [1]  here                0.020        0.000        0.000        0.000        0.000        -4.767       0.000        \n",
            "   [1]  noted               0.027        0.000        0.000        0.000        0.000        -4.888       0.000        \n",
            "   [1]  that                0.024        0.000        0.000        0.000        0.000        -5.423       0.000        \n",
            "   [1]  moonlight           0.105        0.000        0.000        0.000        0.000        -4.810       0.000        \n",
            "   [1]  mile                0.117        0.000        0.000        0.000        0.000        -5.117       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  opera               0.424        0.000        0.000        0.000        -1.979       -4.055       0.000        \n",
            "   [1]  about               0.604        0.000        0.000        0.000        -2.240       -10.560      0.000        \n",
            "   [1]  a                   0.567        0.000        0.000        0.000        -2.535       -7.604       0.000        \n",
            "   [1]  small               0.477        0.000        0.000        0.000        -2.869       -6.171       0.000        \n",
            "   [1]  town                0.470        0.000        0.000        0.000        -3.247       -5.324       0.000        \n",
            "   [1]  married             0.473        0.000        0.000        0.000        -3.675       -6.865       0.000        \n",
            "   [1]  woman               0.488        0.000        0.000        0.000        -4.159       -6.130       0.000        \n",
            "   [1]  kay                 0.488        0.000        0.000        0.000        -4.707       -7.673       0.000        \n",
            "   [1]  francis             0.623        0.000        0.000        0.000        -5.328       -11.682      0.000        \n",
            "   [1]  who                 0.387        0.000        0.000        0.000        -6.030       -9.759       0.000        \n",
            "   [0]  few                 0.509        7.886        -9.173       -0.675       -6.824       -11.389      4.564        \n",
            "   [0]  flash               0.706        5.803        -10.175      -0.348       -6.959       -10.361      3.402        \n",
            "   [0]  the                 0.493        3.580        -3.580       -0.708       -7.483       -6.669       -0.813       \n",
            "   [0]  beginning           0.417        6.802        -6.795       -0.875       -7.668       -7.397       -0.271       \n",
            "   [0]  robe                0.254        14.041       -11.345      -1.372       -7.689       -7.327       -0.361       \n",
            "   [0]  art                 0.452        11.383       -8.861       -0.795       -7.149       -10.416      3.268        \n",
            "   [0]  in                  0.185        4.603        -3.781       -1.686       -7.191       -8.407       1.216        \n",
            "   [0]  actress             0.044        10.352       -8.783       -3.124       -6.230       -9.137       2.907        \n",
            "   [0]  everyone            0.030        8.950        -8.676       -3.515       -3.515       -10.018      5.000        \n",
            "   [1]  in                  0.013        0.000        0.000        0.000        0.000        -10.675      0.000        \n",
            "Samples\n",
            "Sample 0 .  cast wasted on worthless script ten or equalizer mild at having am who sit all the as juveniles could this\n",
            "Sample 1 .  this review dennis fawlty shot of friends hollywood friend acting s point first another poster here noted that moonlight mile\n",
            "Sample 2 .  opera about a small town married woman kay francis who few flash the beginning robe art in actress everyone in\n",
            "\n",
            "\n",
            "targets[[9 121 88 75 103 959 50 21 93 2 49 662 61 5 1216 297 56 223 959 18][1591 10 17 85 9 13 14454 144 0 184 17 2539 16 146 98 11 56 29 12 555][19 5 172 3 0 6356 8133 184 1568 645]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 9 121 88 75 103 959 50 21 93]...][[1 0 0 0 0 0 0 0 0 0]...][[591 9 69848 69848 69848 69848 69848 69848 69848 69848]...][[9 121 88 75 103 959 50 21 93 2]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[591 9 121 88 75 103 959 50 21 93]...][[1 0 0 0 0 0 0 0 0 0]...][[591 9 69848 69848 69848 69848 69848 69848 69848 69848]...][[9 2525 65 106 2 246 17 37 850 130]...]\n",
            "targets[[1406 666 8858 5866 0 247 8 2 10110 328 9573 4550 6 6 0 666 1164 430 15 10][3541 3079 5 2 4324 1 4750 3246 436 427 22 0 297 63 3 4238 34 118 0 1483][19 5 2 2004 1568 3 87 70 14 1804]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[436 1406 666 8858 5866 0 247 8 2 10110]...][[1 1 1 0 0 0 0 0 0 0]...][[436 1406 666 8858 69848 69848 69848 69848 69848 69848]...][[1406 666 8858 5866 0 247 8 2 10110 328]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[436 1406 666 8858 5866 0 247 8 2 10110]...][[1 1 1 0 0 0 0 0 0 0]...][[436 1406 666 8858 69848 69848 69848 69848 69848 69848]...][[1406 666 8858 119 22177 24 382 3 43007 21634]...]\n",
            "targets[[2833 5 0 9724 3 2 63 6774 720 154 881 15 7971 12 1188 2639 9 723 21 110][1609 274 178 128 134 54 5 29 3 3500 12 88 4687 1 467 156 40 1110 3 2][23 110 10 7768 19 8 2 53 194 57]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6283 2833 5 0 9724 3 2 63 6774 720]...][[1 1 1 1 0 0 0 0 0 0]...][[6283 2833 5 0 9724 69848 69848 69848 69848 69848]...][[2833 5 0 9724 3 2 63 6774 720 154]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[6283 2833 5 0 9724 3 2 63 6774 720]...][[1 1 1 1 0 0 0 0 0 0]...][[6283 2833 5 0 9724 69848 69848 69848 69848 69848]...][[2833 5 0 9724 444 4 3361 4 78 48]...]\n",
            "targets[[1066 0 57 4 106 10 835 61 5 226 8 336 1355 1 6462 29 3 0 872 276][3489 1 751 5023 25 2 2151 3 51893 34 1134 4 560 160 728 16 2 126 114 44][254 161 160 19818 8 10 19 18 11 5]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[34 1066 0 57 4 106 10 835 61 5]...][[1 1 1 1 1 1 1 1 1 1]...][[34 1066 0 57 4 106 10 835 61 5]...][[1066 0 57 4 106 10 835 61 5 226]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[34 1066 0 57 4 106 10 835 61 5]...][[1 1 1 1 1 1 1 1 1 1]...][[34 1066 0 57 4 106 10 835 61 5]...][[1066 0 57 4 106 10 835 61 5 226]...]\n",
            "targets[[19 5 186 49 16 1487 1 436 9 139 77 4 2896 37213 1 112 0 5135 7 12][1309 3 503 10 19 45 239 4 5301 28202 6037 8 0 898 1202 7 724 354 3 0][136 10 17 5 16584 5 73 97 81 35]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 186 49 16 1487 1 436 9]...][[1 1 1 1 1 0 0 0 0 0]...][[10 19 5 186 49 16 69848 69848 69848 69848]...][[19 5 186 49 16 1487 1 436 9 139]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 19 5 186 49 16 1487 1 436 9]...][[1 1 1 1 1 0 0 0 0 0]...][[10 19 5 186 49 16 69848 69848 69848 69848]...][[19 5 186 49 16 0 897 834 926 9]...]\n",
            "targets[[5 64 641 1604 16 439 3 74 17 707 7 5 52 2611 16 1500 3 2654 12 1560][5787 5 29 65 2372 663 6808 9 1046 11 7 12 12642 8 0 1468 1 0 116 5][0 84 172 3 10 19 9 15840 256 1147]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 64 641 1604 16 439 3 74 17]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 64 641 1604 16 439 3 74 17]...][[5 64 641 1604 16 439 3 74 17 707]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 64 641 1604 16 439 3 74 17]...][[1 1 1 1 1 1 1 1 1 0]...][[10 5 64 641 1604 16 439 3 74 17]...][[5 64 641 1604 16 439 3 74 17 16]...]\n",
            "targets[[3 0 117 98 3 0 291 1 0 1504 2707 8 11224 546 16 0 129 10 19 5][6 10 5 29 3 60 519 98 0 63 5 69 585 0 101 166 53 69 8 0][5101 11 27 16997 55 37 229 25 43 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 117 98 3 0 291 1 0]...][[1 1 0 0 0 0 0 0 0 0]...][[29 3 0 69848 69848 69848 69848 69848 69848 69848]...][[3 0 117 98 3 0 291 1 0 1504]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 117 98 3 0 291 1 0]...][[1 1 0 0 0 0 0 0 0 0]...][[29 3 0 69848 69848 69848 69848 69848 69848 69848]...][[3 0 177 45 259 27 8 1901 216 1]...]\n",
            "targets[[12 77 2 132 233 318 10 0 84 57 37 9 307 7 175 15 0 325 17 8][96 387 134 48 75 569 21 169 10 155 46 20 159 21 437 3919 15 0 1204 11][219 7 12 23 370 3 536 41 5994 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 77 2 132 233 318 10 0 84]...][[1 1 1 1 1 1 1 1 1 1]...][[7 12 77 2 132 233 318 10 0 84]...][[12 77 2 132 233 318 10 0 84 57]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[7 12 77 2 132 233 318 10 0 84]...][[1 1 1 1 1 1 1 1 1 1]...][[7 12 77 2 132 233 318 10 0 84]...][[12 77 2 132 233 318 10 0 84 57]...]\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[1 1 0 0 0 0 0 0 0 0]...][[307 0 176 69848 69848 69848 69848 69848 69848 69848]...][[0 176 71 1075 10 617 687 63 578 1480]...]\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[1 1 0 0 0 0 0 0 0 0]...][[307 0 176 69848 69848 69848 69848 69848 69848 69848]...][[0 176 8859 31 0 6181 19 1322 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[1 1 0 0 0 0 0 0 0 0]...][[307 0 176 69848 69848 69848 69848 69848 69848 69848]...][[0 176 112 1035 12 27874 13867 20902 2 160]...]\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "global_step: 8149\n",
            " perplexity: 417.049\n",
            " gen_learning_rate: 0.000010\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            " percent of 3-grams captured: 0.337.\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            " percent of 2-grams captured: 0.649.\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            " percent of 4-grams captured: 0.112.\n",
            " geometric_avg: 0.290.\n",
            " arithmetic_avg: 0.366.\n",
            "global_step: 8149\n",
            " is_present_rate: 0.500\n",
            " D train loss: 0.38588\n",
            " G train loss: -8.77867\n",
            "targets[[0 176 8859 31 0 6181 19 1322 6 6 20 25 1435 78 10 462 17 1 604 479][74 46 20 353 0 1177 80 661 2 2200 1 89 21 278 661 144 0 7261 3 1353][19 1020 4041 33 7585 3 91 655 1 16]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[1 1 0 0 0 0 0 0 0 0]...][[307 0 176 69848 69848 69848 69848 69848 69848 69848]...][[0 176 8859 31 0 6181 19 1322 6 6]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[307 0 176 8859 31 0 6181 19 1322 6]...][[1 1 0 0 0 0 0 0 0 0]...][[307 0 176 69848 69848 69848 69848 69848 69848 69848]...][[0 176 5 2 303 172 5 35 3312 61]...]\n",
            " Sample: 0\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  the                 0.622        0.000        0.000        0.000        -4.571       -4.115       -0.000       \n",
            "   [1]  world               0.574        0.000        0.000        0.000        -5.173       -9.746       0.000        \n",
            "   [0]  is                  0.328        11.597       -1.661       -1.115       -5.855       -6.565       0.710        \n",
            "   [0]  a                   0.422        7.305        -0.813       -0.863       -5.364       -7.119       1.755        \n",
            "   [0]  high                0.347        4.757        -5.707       -1.057       -5.095       -5.513       0.418        \n",
            "   [0]  part                0.411        9.024        -5.695       -0.890       -4.570       -7.026       2.456        \n",
            "   [0]  is                  0.436        3.357        -4.332       -0.830       -4.165       -7.996       3.831        \n",
            "   [0]  an                  0.487        11.111       -4.000       -0.718       -3.774       -6.625       2.850        \n",
            "   [0]  patient             0.277        11.426       -10.247      -1.284       -3.458       -6.833       3.375        \n",
            "   [0]  which               0.240        6.760        -6.030       -1.428       -2.461       -12.267      5.000        \n",
            "   [0]  may                 0.311        5.956        -5.929       -1.169       -1.169       -8.033       5.000        \n",
            "   [1]  are                 0.058        0.000        0.000        0.000        0.000        -7.626       0.000        \n",
            "   [1]  drawn               0.020        0.000        0.000        0.000        0.000        -12.124      0.000        \n",
            "   [1]  into                0.347        0.000        0.000        0.000        0.000        -12.731      0.000        \n",
            "   [1]  this                0.522        0.000        0.000        0.000        0.000        -8.420       0.000        \n",
            "   [1]  dark                0.627        0.000        0.000        0.000        0.000        -7.591       0.000        \n",
            "   [1]  movie               0.816        0.000        0.000        0.000        0.000        -6.684       0.000        \n",
            "   [1]  and                 0.843        0.000        0.000        0.000        0.000        -6.330       0.000        \n",
            "   [1]  cannot              0.878        0.000        0.000        0.000        0.000        -5.603       0.000        \n",
            "   [1]  turn                0.947        0.000        0.000        0.000        0.000        -6.403       0.000        \n",
            " Sample: 1\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  bad                 0.597        0.000        0.000        0.000        -4.019       -3.851       -0.000       \n",
            "   [1]  if                  0.821        0.000        0.000        0.000        -4.548       -8.267       0.000        \n",
            "   [1]  you                 0.712        0.000        0.000        0.000        -5.148       -9.238       0.000        \n",
            "   [0]  can                 0.742        5.479        -3.790       -0.299       -5.826       -4.605       -1.221       \n",
            "   [0]  worked              0.184        5.076        -6.334       -1.691       -6.256       -5.964       -0.292       \n",
            "   [0]  to                  0.194        10.126       -2.665       -1.638       -5.167       -9.217       4.050        \n",
            "   [0]  be                  0.309        5.694        -2.747       -1.173       -3.994       -8.267       4.273        \n",
            "   [0]  inferior            0.571        9.214        -10.709      -0.560       -3.192       -6.402       3.209        \n",
            "   [0]  dark                0.576        3.933        -8.944       -0.552       -2.979       -6.335       3.355        \n",
            "   [0]  funny               0.499        10.029       -7.296       -0.696       -2.747       -7.922       5.000        \n",
            "   [0]  along               0.375        3.048        -7.466       -0.980       -2.322       -7.773       5.000        \n",
            "   [0]  defined             0.219        7.390        -10.644      -1.519       -1.519       -6.765       5.000        \n",
            "   [1]  t                   0.013        0.000        0.000        0.000        0.000        -8.003       0.000        \n",
            "   [1]  put                 0.008        0.000        0.000        0.000        0.000        -15.131      0.000        \n",
            "   [1]  yourself            0.009        0.000        0.000        0.000        0.000        -9.333       0.000        \n",
            "   [1]  through             0.008        0.000        0.000        0.000        0.000        -7.390       0.000        \n",
            "   [1]  the                 0.014        0.000        0.000        0.000        0.000        -7.037       0.000        \n",
            "   [1]  agony               0.043        0.000        0.000        0.000        0.000        -6.337       0.000        \n",
            "   [1]  of                  0.094        0.000        0.000        0.000        0.000        -6.235       0.000        \n",
            "   [1]  sitting             0.083        0.000        0.000        0.000        0.000        -7.699       0.000        \n",
            " Sample: 2\n",
            "   [p]  Word                p(real)      log-perp     log(p(a))    r            R=V*(s)      b=V(s)       A(a,s)       \n",
            "   [1]  film                0.435        0.000        0.000        0.000        -9.369       -4.240       -0.000       \n",
            "   [1]  deserves            0.627        0.000        0.000        0.000        -10.604      -12.479      0.000        \n",
            "   [1]  recognition         0.511        0.000        0.000        0.000        -12.001      -8.593       -0.000       \n",
            "   [1]  by                  0.800        0.000        0.000        0.000        -13.582      -8.493       -0.000       \n",
            "   [0]  bad                 0.379        10.892       -5.809       -0.970       -15.372      -6.509       -5.000       \n",
            "   [0]  so                  0.311        3.427        -5.709       -1.167       -16.300      -5.037       -5.000       \n",
            "   [0]  bette               0.181        5.941        -10.634      -1.712       -17.126      -5.068       -5.000       \n",
            "   [0]  concert             0.022        8.158        -8.893       -3.809       -17.446      -6.634       -5.000       \n",
            "   [0]  she                 0.035        2.080        -6.642       -3.344       -15.433      -13.632      -1.802       \n",
            "   [0]  not                 0.023        5.930        -5.082       -3.771       -13.683      -8.298       -5.000       \n",
            "   [0]  to                  0.049        3.314        -2.910       -3.021       -11.218      -8.998       -2.220       \n",
            "   [0]  happy               0.009        6.857        -7.783       -4.705       -9.278       -5.455       -3.823       \n",
            "   [0]  true                0.006        9.551        -8.504       -5.176       -5.176       -8.350       3.174        \n",
            "   [1]  almost              0.004        0.000        0.000        0.000        0.000        -10.513      0.000        \n",
            "   [1]  brilliant           0.004        0.000        0.000        0.000        0.000        -11.081      0.000        \n",
            "   [1]  job                 0.009        0.000        0.000        0.000        0.000        -10.200      0.000        \n",
            "   [1]  done                0.006        0.000        0.000        0.000        0.000        -9.181       0.000        \n",
            "   [1]  by                  0.029        0.000        0.000        0.000        0.000        -9.344       0.000        \n",
            "   [1]  the                 0.027        0.000        0.000        0.000        0.000        -7.994       0.000        \n",
            "   [1]  leading             0.056        0.000        0.000        0.000        0.000        -9.047       0.000        \n",
            "Samples\n",
            "Sample 0 .  the world is a high part is an patient which may are drawn into this dark movie and cannot turn\n",
            "Sample 1 .  bad if you can worked to be inferior dark funny along defined t put yourself through the agony of sitting\n",
            "Sample 2 .  film deserves recognition by bad so bette concert she not to happy true almost brilliant job done by the leading\n",
            "\n",
            "\n",
            "targets[[89 21 121 47 17 131 82 10805 215 18 7 682 288 21 0 170 29 9 118 10][559 0 281 1 2191 970 1787 14420 7650 4662 1166 23349 1 2920 11588 278 2422 2 782 4277][1 21248 2359 178 15 2 53 10714 2926 3]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 89 21 121 47 17 131 82 10805 215]...][[1 1 0 0 0 0 0 0 0 0]...][[9 89 21 69848 69848 69848 69848 69848 69848 69848]...][[89 21 121 47 17 131 82 10805 215 18]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[9 89 21 121 47 17 131 82 10805 215]...][[1 1 0 0 0 0 0 0 0 0]...][[9 89 21 69848 69848 69848 69848 69848 69848 69848]...][[89 21 65 111 2 91 340 11 9 59]...]\n",
            "targets[[5 29 3 0 30 57 7433 98 9 139 123 110 7 204 28 180 28208 18 0 5160][196 10 17 389 596 53 69 1078 11 7 96 139 710 6574 8 0 2903 7161 9 96][59 139 4325 5078 7971 2298 2 12046 44768 4]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 29 3 0 30 57 7433 98 9]...][[1 0 0 0 0 0 0 0 0 0]...][[10 5 69848 69848 69848 69848 69848 69848 69848 69848]...][[5 29 3 0 30 57 7433 98 9 139]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 29 3 0 30 57 7433 98 9]...][[1 0 0 0 0 0 0 0 0 0]...][[10 5 69848 69848 69848 69848 69848 69848 69848 69848]...][[5 23 49 10 229 92 144 11 18 397]...]\n",
            "targets[[1082 15 0 105 897 4937 104 186 73 121 47 32 50 512 2 385 522 3 75 2377][20 182 4 66 2 17 11 1990 7425 55 29 4602 640 15 100 82 4602 640 0 28471][12 35 212 17 4 28 92 43 2 243]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[146 1082 15 0 105 897 4937 104 186 73]...][[1 1 1 1 1 0 0 0 0 0]...][[146 1082 15 0 105 897 69848 69848 69848 69848]...][[1082 15 0 105 897 4937 104 186 73 121]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[146 1082 15 0 105 897 4937 104 186 73]...][[1 1 1 1 1 0 0 0 0 0]...][[146 1082 15 0 105 897 69848 69848 69848 69848]...][[1082 15 0 105 897 1924 951 332 34 138]...]\n",
            "targets[[3 0 250 98 9 139 123 110 116 13 394 193 16 0 362 1 0 1532 88 4][3 320 5 23 65 2 49 17 33 100 1194 18 7 5 2 2229 29 837 46 1242][1430 1022 6 6 39 25 3388 14582 8 47]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 250 98 9 139 123 110 116]...][[1 1 1 1 1 1 1 0 0 0]...][[29 3 0 250 98 9 139 123 69848 69848]...][[3 0 250 98 9 139 123 110 116 13]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[29 3 0 250 98 9 139 123 110 116]...][[1 1 1 1 1 1 1 0 0 0]...][[29 3 0 250 98 9 139 123 69848 69848]...][[3 0 250 98 9 139 123 143 11 16]...]\n",
            "targets[[321 3 235 2 19 43 0 3179 1 3609 3 998 0 708 968 38 49 321 16 2][2541 543 153 23057 2569 124 0 14684 15 26 811 55 4 3340 1116 599 7537 1156 2638 2142][0 154 75 27 77 1073 4 66 0 414]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 321 3 235 2 19 43 0 3179 1]...][[1 1 1 1 1 1 1 1 1 0]...][[0 321 3 235 2 19 43 0 3179 1]...][[321 3 235 2 19 43 0 3179 1 3609]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[0 321 3 235 2 19 43 0 3179 1]...][[1 1 1 1 1 1 1 1 1 0]...][[0 321 3 235 2 19 43 0 3179 1]...][[321 3 235 2 19 43 0 3179 1 8657]...]\n",
            "targets[[5 53 799 2 414 19 0 990 59 28 2734 33 10946 18 113 585 37 19964 10 5][9 84 307 10 17 71 2 3097 1 35 1780 34 13 258 567 68 2 441 3 3797][2628 1059 642 22 3857 13 65 74 3 30]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 53 799 2 414 19 0 990 59]...][[1 1 1 0 0 0 0 0 0 0]...][[10 5 53 799 69848 69848 69848 69848 69848 69848]...][[5 53 799 2 414 19 0 990 59 28]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[10 5 53 799 2 414 19 0 990 59]...][[1 1 1 0 0 0 0 0 0 0]...][[10 5 53 799 69848 69848 69848 69848 69848 69848]...][[5 53 799 201 9 123 4 103 16 10]...]\n",
            "targets[[0 543 153 3 0 2986 1868 1086 2266 27613 34 12138 2 755 4129 33 2 15814 680 31608][139 67 0 1164 1062 678 10 17 6 6 84 3 30 0 101 2501 8 10 17 25][215 10 17 119 223 154 602 1 7 133]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[36 0 543 153 3 0 2986 1868 1086 2266]...][[1 1 1 1 1 1 1 1 1 0]...][[36 0 543 153 3 0 2986 1868 1086 2266]...][[0 543 153 3 0 2986 1868 1086 2266 27613]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[36 0 543 153 3 0 2986 1868 1086 2266]...][[1 1 1 1 1 1 1 1 1 0]...][[36 0 543 153 3 0 2986 1868 1086 2266]...][[0 543 153 3 0 2986 1868 1086 2266 1956]...]\n",
            "targets[[109 1 105 1906 225 92 101 168 38 3391 593 5626 3465 4 136 10 92 7 871 4][17 29 3 0 117 9 139 123 110 2180 43 7 124 7 20301 3459 8 2 45054 41028][5 29 3 0 250 104 9 139 123 110]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[838 109 1 105 1906 225 92 101 168 38]...][[1 1 1 1 1 1 0 0 0 0]...][[838 109 1 105 1906 225 92 69848 69848 69848]...][[109 1 105 1906 225 92 101 168 38 3391]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[838 109 1 105 1906 225 92 101 168 38]...][[1 1 1 1 1 1 0 0 0 0]...][[838 109 1 105 1906 225 92 69848 69848 69848]...][[109 1 105 1906 225 92 0 9914 430 0]...]\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20820 144 0 4278 544 31 311 9 389 596]...][[1 1 0 0 0 0 0 0 0 0]...][[20820 144 0 69848 69848 69848 69848 69848 69848 69848]...][[144 0 340 3 30 6 9 196 10 17]...]\n",
            "targets[[144 0 4278 544 31 311 9 389 596 10 17 1 2700 9 207 830 7 44 9 1147][1 52863 45 213 77 60 519 298 9 27 353 2 171 3 1177 1 587 3 90 67][368 1079 221 3481 1 1507 241 85 3 7]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20820 144 0 4278 544 31 311 9 389 596]...][[1 1 0 0 0 0 0 0 0 0]...][[20820 144 0 69848 69848 69848 69848 69848 69848 69848]...][[144 0 4278 544 31 311 9 389 596 10]...]\n",
            "inputs, targets_present, masked_inputs, sequence[[20820 144 0 4278 544 31 311 9 389 596]...][[1 1 0 0 0 0 0 0 0 0]...][[20820 144 0 69848 69848 69848 69848 69848 69848 69848]...][[144 0 5505 15921 7772 12 0 19 47 5]...]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ee23ffc12b85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'cd /content/yesweGAN/maskgan_colab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'python train_mask_gan.py  --data_dir=\\'dataset/imdb\\'  --data_set=\\'imdb\\'  --batch_size=128  --sequence_length=20  --base_directory=\\'/content/yesweGAN/maskgan_colab/maskGAN\\'  --maskgan_ckpt=\\'/content/yesweGAN/maskgan_colab/maskGAN/train/model.ckpt-6006\\'  --hparams=\"gen_rnn_size=650,dis_rnn_size=650,gen_num_layers=2,dis_num_layers=2,gen_learning_rate=0.00001,gen_learning_rate_decay=0.999999,gen_full_learning_rate_steps=1e9,gen_vd_keep_prob=0.33971,rl_discount_rate=0.8835659,dis_learning_rate=0.001,baseline_decay=0.99,dis_train_iterations=8,dis_pretrain_learning_rate=0.00005,critic_learning_rate=0.0009,dis_vd_keep_prob=0.71940\"  --mode=\\'TRAIN\\'  --mask_strategy=contiguous  --max_steps=10000  --generator_optimizer=adam  --perplexity_threshold=1000000  --generator_model=\\'seq2seq_vd\\'  --discriminator_model=\\'seq2seq_vd\\'  --summaries_every=250  --print_every=250  --max_num_to_print=3  --gen_training_strategy=\\'reinforce\\'  --seq2seq_share_embedding=true  --baseline_method=critic  --attention_option=luong'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_shell.pyc\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_system_commands.pyc\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_system_commands.pyc\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_system_commands.pyc\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_message.pyc\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/_message.pyc\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFBa7_iW_mzS",
        "colab_type": "code",
        "outputId": "2ecebd83-235d-4a45-e631-e9284a94566e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# make copy of gan training checkpoints\n",
        "%cd /content\n",
        "!cp -r '/content/yesweGAN/maskgan_colab/maskGAN/train' '/content/drive/My Drive/imdb gan checkpoint - stochastic contiguous'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8hYuMZmmkcm",
        "colab_type": "text"
      },
      "source": [
        "## Generate samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw-SWqvTmpsi",
        "colab_type": "code",
        "outputId": "8b6e912d-248d-4bf9-92dc-05e5a2c89950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/yesweGAN/maskgan_colab\n",
        "!python generate_samples.py \\\n",
        "--data_dir='/content/yesweGAN/maskgan_colab/dataset/imdb' \\\n",
        "--data_set='imdb' \\\n",
        "--batch_size=1 \\\n",
        "--sequence_length=20 \\\n",
        "--base_directory='/content/yesweGAN/maskgan_colab/maskGAN/train' \\\n",
        "--hparams=\"gen_rnn_size=650,dis_rnn_size=650,gen_num_layers=2,gen_vd_keep_prob=0.33971\" \\\n",
        "--generator_model='seq2seq_vd' \\\n",
        "--discriminator_model='seq2seq_vd' \\\n",
        "--is_present_rate=0.5 \\\n",
        "--maskgan_ckpt='/content/yesweGAN/maskgan_colab/maskGAN/train/model.ckpt-6006' \\\n",
        "--seq2seq_share_embedding=true \\\n",
        "--mask_strategy=contiguous \\\n",
        "--dis_share_embedding=true \\\n",
        "--attention_option=luong \\\n",
        "--output_path='/content/yesweGAN/maskgan_colab' \\\n",
        "--baseline_method=critic \\\n",
        "--output_masked_logs=True \\\n",
        "--number_epochs=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yesweGAN/maskgan_colab\n",
            "Vocab size: 69848\n",
            "\n",
            "Optimizing Generator vars:\n",
            "<tf.Variable 'gen/decoder/rnn/embedding:0' shape=(69848, 650) dtype=float32_ref>\n",
            "<tf.Variable 'gen/encoder/rnn/missing_embedding:0' shape=(1, 650) dtype=float32_ref>\n",
            "<tf.Variable 'gen/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1300, 2600) dtype=float32_ref>\n",
            "<tf.Variable 'gen/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(2600,) dtype=float32_ref>\n",
            "<tf.Variable 'gen/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(1300, 2600) dtype=float32_ref>\n",
            "<tf.Variable 'gen/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(2600,) dtype=float32_ref>\n",
            "<tf.Variable 'gen/decoder/attention_keys/weights:0' shape=(650, 650) dtype=float32_ref>\n",
            "<tf.Variable 'gen/decoder/rnn/softmax_b:0' shape=(69848,) dtype=float32_ref>\n",
            "<tf.Variable 'gen/decoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1300, 2600) dtype=float32_ref>\n",
            "<tf.Variable 'gen/decoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(2600,) dtype=float32_ref>\n",
            "<tf.Variable 'gen/decoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(1300, 2600) dtype=float32_ref>\n",
            "<tf.Variable 'gen/decoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(2600,) dtype=float32_ref>\n",
            "<tf.Variable 'gen/decoder/rnn/attention_construct/weights:0' shape=(1300, 650) dtype=float32_ref>\n",
            "\n",
            "Optimizing Discriminator vars:\n",
            "<tf.Variable 'dis/encoder/rnn/missing_embedding:0' shape=(1, 650) dtype=float32_ref>\n",
            "<tf.Variable 'dis/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1300, 2600) dtype=float32_ref>\n",
            "<tf.Variable 'dis/encoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(2600,) dtype=float32_ref>\n",
            "<tf.Variable 'dis/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(1300, 2600) dtype=float32_ref>\n",
            "<tf.Variable 'dis/encoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(2600,) dtype=float32_ref>\n",
            "<tf.Variable 'dis/decoder/attention_keys/weights:0' shape=(650, 650) dtype=float32_ref>\n",
            "<tf.Variable 'dis/decoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(1300, 2600) dtype=float32_ref>\n",
            "<tf.Variable 'dis/decoder/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(2600,) dtype=float32_ref>\n",
            "<tf.Variable 'dis/decoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(1300, 2600) dtype=float32_ref>\n",
            "<tf.Variable 'dis/decoder/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(2600,) dtype=float32_ref>\n",
            "<tf.Variable 'dis/decoder/rnn/attention_construct/weights:0' shape=(1300, 650) dtype=float32_ref>\n",
            "<tf.Variable 'dis/decoder/rnn/weights:0' shape=(650, 1) dtype=float32_ref>\n",
            "<tf.Variable 'dis/decoder/rnn/biases:0' shape=(1,) dtype=float32_ref>\n",
            "\n",
            "Optimizing Critic vars:\n",
            "<tf.Variable 'critic/rnn/weights:0' shape=(650, 1) dtype=float32_ref>\n",
            "<tf.Variable 'critic/rnn/biases:0' shape=(1,) dtype=float32_ref>\n",
            "WARNING:tensorflow:From generate_samples.py:201: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2020-03-24 22:36:52.203107: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
            "2020-03-24 22:36:52.377304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-24 22:36:52.377829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.62GiB\n",
            "2020-03-24 22:36:52.377866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1312] Adding visible gpu devices: 0\n",
            "2020-03-24 22:36:52.754795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:993] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14152 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Epoch number: 0\n",
            "targets[[17 13 37 379 11 9 307 55 4 2911 144 1073 16 7 4 366 16 0 109 101]]\n",
            "targets[[12 727 4 66 11 51052 7026 5 2 1133 1032 153 1 23 2 2825 16 4282 3 338]]\n",
            "targets[[17 5 591 13633 698 87 4 1501 2 680 264 26 117 166 13 5673 120 1042 5133 5]]\n",
            "targets[[5 401 2 374 74 1355 17 1574 1932 399 8 47 5 408 38 2 3578 24 5 3738]]\n",
            "targets[[0 368 66981 63 3 112 4995 1786 1 1641 9 402 6343 10 63 8 303 377 165 9]]\n",
            "targets[[2142 5 29 3 0 52 2189 2187 11 3086 45 123 67 4 845 15 1 0 109 5]]\n",
            "targets[[7 5 213 2 222 871 8 869 2895 4 76 4 66 2558 98 15 646 2283 1 152]]\n",
            "targets[[91 57 10 13 2 871 3127 4 5604 8 19 1 152 7 13 2 13311 878 9 242]]\n",
            "targets[[288 21 180 251 46 10 13 42 164 4 28 157 29 3 146 3096 15598 1989 11295 11]]\n",
            "targets[[3057 9 42 1454 149 1 9 133 27 74 1355 8 60 1637 97 73 2848 97 73 1817]]\n",
            "targets[[1813 9934 12 5633 3 13569 15943 78 2177 15 115 17681 1 73 21002 7 162 71 103 143]]\n",
            "targets[[6816 13 22 3 0 1536 2187 9 27 123 110 8 0 486 890 24 12 65 17581 88]]\n",
            "targets[[8 0 462 5 6059 4925 12 1992 8 0 4822 4 338 99 328 3 0 330 12 2826]]\n",
            "targets[[4 572 5 2 385 18 212 19 1156 2314 3567 714 7296 1 1925 13302 33 6886 3567 13]]\n",
            "targets[[96 27 77 2 2952 63 427 22 0 2291 5375 3 1161 75 18 7 288 21 6 6]]\n",
            "targets[[994 1115 15 35 1186 177 3 158 57066 1832 3269 792 5574 7024 1644 9130 65352 1654 58228 1]]\n",
            "targets[[3445 5431 41 4168 3 0 14 7 12 542 128 8 0 2304 13 2 186 348 184 17]]\n",
            "targets[[22 514 6 6 1235 9384 308 6626 308 6 6 500 2756 14736 6 6 35 19165 739 3369]]\n",
            "targets[[57 14003 22915 210 21 11412 2903 18 5 11013 26 3510 355 16946 1 8869 193 8 2331 3]]\n",
            "targets[[232 113 387 47 15 0 7075 3109 3 82 2134 3 3402 2282 3 2828 2720 19 1104 1]]\n",
            "targets[[140 23 1085 251 9 2755 0 109 3 15359 869 8316 1432 85 9 420 21 387 0 405]]\n",
            "targets[[4806 11627 10239 2121 5321 2110 11749 1681 15601 28666 27264 601 13936 0 64 390 11 13803 13 22]]\n",
            "targets[[9 13 99 107 1865 2313 4 66 10 19 123 233 9 84 1018 1968 3 7 9 319]]\n",
            "targets[[9 470 4 940 22 13 0 189 11 0 3507 3 10 19 465 4 80 437 56 4442]]\n",
            "targets[[1312 656 12 872 3196 5 91 1874 1221 34965 2365 14523 3865 1247 417 2346 36 157 917 24]]\n",
            "targets[[203 987 11 9 67 60 5242 43 10 17 167 9 13 164 4 106 7 0 289 293]]\n",
            "targets[[12 2 453 3 1966 16 30 0 275 986 279 1396 571 416 9 121 7 5 2 832]]\n",
            "targets[[2630 4012 703 396 7404 52410 41394 22 3099 8 0 1606 974 1 724 8 112 15 11139 0]]\n",
            "targets[[5 2 81 630 184 17 11 2652 0 3370 3 0 1752 4 544 1820 3166 15 87 452]]\n",
            "targets[[47 59 20 80 15 287 71 198 20 2 1068 20 50 352 2 9448 7 1 19541 7]]\n",
            "targets[[5 437 56 293 4 453 127 57 15 10 19 0 206 300 7 30 1 133 1765 55]]\n",
            "targets[[0 6647 1549 34391 3065 38248 1 6017 10660 0 1377 15345 2573 29188 709 21 127 1194 488 3]]\n",
            "targets[[215 15319 4120 1 7 13 1393 33 0 9614 34 585 178 43 0 17 1 4769 178 2]]\n",
            "targets[[49071 6997 1181 1426 75 8 2 1693 8 31097 8 0 1289 12 79 24 9488 11 24 67]]\n",
            "targets[[109 5 0 101 25 595 2035 56 1979 5693 1730 0 1450 25 23 69 1379 1 0 271]]\n",
            "targets[[441 3 2 662 4 316 5928 1217 1305 1756 12 102 5 5146 4 1529 14 1217 5 229]]\n",
            "targets[[0 1791 3 26 312 3831 6953 577 23947 584 786 4246 302 26 3228 4189 796 291 158 518]]\n",
            "targets[[481 9 139 110 447 104 18 11 204 28 38299 9 140 37 6243 33 87 1194 131 74]]\n",
            "targets[[10813 5 0 117 17 43 0 2752 4360 1087 7 274 7 12 4606 1 87 0 351 2752]]\n",
            "targets[[9 672 149 10 17 9 13 1458 47 0 574 5 10 428 4 28 2 201 2 436]]\n",
            "targets[[15 2 341 3 2873 1476 8 5431 712 1885 786 5188 1 577 10946 2276 8 1832 3269 1]]\n",
            "targets[[5183 1224 17 13 0 227 542 806 513 33 1116 1692 4811 16388 235 1182 359 3 24907 2796]]\n",
            "targets[[20 148 235 2 680 43 8279 9 262 20 141 80 283 20 50 4 345 0 310 5221]]\n",
            "targets[[5 29 3 0 117 104 9 27 123 110 9 395 7 4 255 113 167 27 9 123]]\n",
            "targets[[64 1059 389 596 10 5795 446 0 8949 493 51 2 1023 377 4357 718 2938 4 48 3]]\n",
            "targets[[5 29 3 146 98 20 66 282 1 402 16 2 194 57 9 215 7 143 8 0]]\n",
            "targets[[12663 203 3454 15 4601 31 0 1718 3 10 13649 336 19 14 840 203 174 666 2123 571]]\n",
            "targets[[5 0 63 3 2850 11735 11106 40 407 114 14 2 224 3550 4075 40 2061 1 969 291]]\n",
            "targets[[14938 3727 283 43 0 1299 3 338 1 0 21278 608 3 1629 930 8 37 108 98 131]]\n",
            "targets[[71 366 33 674 11 9 13 1027 37 73 52 6 6 0 84 172 13 52 38 1979]]\n",
            "targets[[2 385 474 5 5427 33 2 493 461 2 831 557 1768 267 99 86 33 4191 4 28]]\n",
            "targets[[1518 285 0 415 3 2 1948 2469 1028 27357 8 2339 31 1682 748 13729 24 5 2 9841]]\n",
            "targets[[0 544 4286 12 251 118 2249 2 217 910 3 601 1420 9995 10264 12755 549 3 8993 5]]\n",
            "targets[[13 73 126 72 856 0 834 465 229 4632 4 278 7 2887 18 0 17 912 22 2]]\n",
            "targets[[5 2 19 15 35 212 264 148 29030 5025 834 143 4 283 36 3033 4 11930 10 92]]\n",
            "targets[[215 10 17 31 0 6113 19 1322 1 7 835 71 4 1695 23 64 294 0 2683 18]]\n",
            "targets[[5 56 95 16 71 4 5580 3141 87 394 10 17 5 18 9 83 350 2656 0 6068]]\n",
            "targets[[91 212 834 9360 5 180 2212 15 2 10367 225 1 19100 946 7 96 27 77 12178 296]]\n",
            "targets[[1342 125 1255 19325 45 2 29 311 749 15 26 1368 12 312 8497 16619 54 3605 2 243]]\n",
            "targets[[594 1273 2531 73 126 8 10 17 11 9 856 24 118 2 2769 301 116 14 2 10289]]\n",
            "targets[[162 0 221 105 588 23 2 938 1805 18 9 89 21 103 805 11 0 249 0 708]]\n",
            "targets[[92 16 246 17 1403 33 297 697 10 17 5 12831 22 2732 180 404 7 12 631 4]]\n",
            "targets[[3821 48 3 60 519 98 27 211 36 10 57 1 88 3 90 1201 4 169 35 310]]\n",
            "targets[[5 180 2 263 17 18 2 1737 4 28 251 7 1430 283 11 162 98 744 221 11]]\n",
            "targets[[10190 5140 5 2 19 11 13 92 16 941 16960 543 153 284 14561 13 1318 8 7473 1]]\n",
            "targets[[65 89 21 121 47 9 856 164 78 10 17 99 30 7 12 513 33 22847 13253 0]]\n",
            "targets[[13 0 88 3920 1470 3 2 63 9 27 110 8 180 48 57 7 124 536 4 0]]\n",
            "targets[[45 4 28 29 3 0 88 8383 155 1 69 896 832 827 201 202 123 92 15 2]]\n",
            "targets[[9453 12 2876 16 107 482 4 1451 184 1 201 5 437 20246 8 0 477 5962 12 35]]\n",
            "targets[[509 0 954 3 0 63 344 0 224 1 23 219 0 116 40530 5 53 49 166 33]]\n",
            "targets[[4 198 10 487 308 464 7 107 1495 8 1315 3 0 2859 3 1575 29631 1 0 5020]]\n",
            "targets[[1124 0 365 4 3617 9030 16 131 244 3 184 98 18 32 141 31 219 3617 48 2380]]\n",
            "targets[[17 5 497 758 7 0 716 1762 1 0 64 1731 492 59 27 77 318 11341 3579 2467]]\n",
            "targets[[307 10 859 2555 1264 354 33 8624 17012 22 0 2099 19 1904 3 2930 20307 14 7188 36]]\n",
            "targets[[38 5250 5512 1 470 157 29 3 40 104 37 51 9 215 16206 16 463 1138 31 19733]]\n",
            "targets[[242 37 5440 11 10 244 3 360 1208 19 59 58 28 8 5174 4 818 8 0 84]]\n",
            "targets[[3754 7150 11 12 401 1 769 4281 412 89 21 20 103 31 219 11 12 47 9 196]]\n",
            "targets[[9 555 3 10 17 7 13 53 2409 38 14455 1793 41 441 3 18 574 56 0 17]]\n",
            "targets[[1591 10 19 532 7 13 0 1084 4782 5415 7 13 2 2197 2529 984 3 0 1084 37]]\n",
            "targets[[321 3 8 0 390 3 0 75 5 49 2 2482 150 21 182 26 64 518 4 129]]\n",
            "targets[[112 47 9 27 307 37 229 0 84 541 3 7 13 1986 23 212 16 71 18 14]]\n",
            "targets[[5 37 980 74 336 156 20 50 380 32 148 259 65 245 4 3803 2 7408 18 70]]\n",
            "targets[[595 3446 17 50 345 636 127 485 208 787 238 8301 7 406 20 2 754 11 5 2478]]\n",
            "targets[[156 32 68 4854 327 4854 6 6 10 5 2 323 17 11018 3225 297 1 23 436 165]]\n",
            "targets[[17 13 23 37 73 7279 128 8 8451 58 152 7 195 49 156 81 225 1 248 49]]\n",
            "targets[[38 192 1156 1976 8230 1 388 2003 15 2546 1205 25 98 43 47 108 342 230 43 12798]]\n",
            "targets[[718 2 57 9 23876 2439 11 2 19 96 28 0 250 327 33 91 197 6081 3720 154]]\n",
            "targets[[27 77 261 931 4 318 0 19 339 3 11131 12 298 2285 39524 1047 786 38374 7 13]]\n",
            "targets[[12 23 0 88 69 92 1224 98 3 30 57 18 16 47 7 5 7 12 186 1121]]\n",
            "targets[[196 10 17 13 247 4 106 132 31 0 170 57 2340 983 3 5546 3637 16 362 2087]]\n",
            "targets[[614 675 3 2558 5 25740 6525 8 2 336 1433 30 0 1170 1820 98 15 5590 757 68]]\n",
            "targets[[17 272 65 74 18 7 5 6972 3 247 0 74 116 1 336 444 7132 0 19 12]]\n",
            "targets[[5 2 248 10807 735 15 35 4049 572 1 35 1262 1154 4266 15863 0 4695 4 0 572]]\n",
            "targets[[29 666 49 3408 23 29 666 155 344 473 0 19 0 442 177 406 2372 347 9 121]]\n",
            "targets[[1472 522 3 183 1532 34 25 48 2182 3 11995 355 302 57 44 36 62 3281 11413 7553]]\n",
            "targets[[28 585 9 140 23 97 11561 15 9035 396 82 72 884 55 128 1 39 1 318 87]]\n",
            "targets[[5 0 64 339 3 1303 6802 11 9 139 110 239 9 242 884 0 298 147 1 0]]\n",
            "targets[[215 2 186 336 1005 3 10 18 0 1371 344 5 11 7 1449 0 2826 9228 1 450]]\n",
            "targets[[678 10 17 195 128 317 2190 44 3 163 5 229 97 385 7 12 2 607 19 215]]\n",
            "targets[[302 2 194 57 16 0 19 4 76 164 23 31 30 3074 1094 41 631 9 13 53]]\n",
            "targets[[1588 4882 2181 61 1109 245 22 0 6672 3 18050 5 349 0 170 410 14 26 5353 599]]\n",
            "targets[[98 306 4 28 92 167 70 25 1632 16 90 14 9 307 10 19 92 8 5470 8]]\n",
            "targets[[1475 236 136 11 46 29 68 4 1143 2 2361 311 149 2 17 20 203 28 65 1072]]\n",
            "targets[[22 0 823 354 63 33 184 543 1917 691 43 37 446 18211 2291 1 6135 1161 38 2282]]\n",
            "targets[[17 13 8023 1 67 2 81 63 344 7735 13 81 8 7 39 13 48 81 1425 0]]\n",
            "targets[[13 2 371 504 19 3857 42 252 10 349 15 668 388 16 6111 12 249 132 16330 47]]\n",
            "targets[[288 21 180 14 74 14 3033 2 791 4823 18 221 46 7 13 428 4 28 2 316]]\n",
            "targets[[14938 5 270 8 160 728 111 2 29336 3 0 3561 61 5 1067 8 0 84 8380 4818]]\n",
            "targets[[1999 10840 680 11 83 3383 88 75 12 8574 0 6358 125 5 251 4 7293 255 15 2]]\n",
            "targets[[65 467 10 17 9 409 498 4 0 270 7 13 763 31 0 17 13 92 8 26992]]\n",
            "targets[[3904 109 56 102 954 9 418 78 10 17 15 303 1422 36 0 298 7 96 27 77]]\n",
            "targets[[232 182 4 66 2 4065 2150 46 20 148 2 5209 2893 340 18 7 59 28 6526 4]]\n",
            "targets[[424 10 202 51 7 84 3319 22 246 18 14 2 307 7 29 1307 99 0 82 9]]\n",
            "targets[[1566 396 17942 1 2 1566 234 14479 25 400 8 0 2059 18 852 169 62 95 4 35]]\n",
            "targets[[3 0 250 98 9 139 123 110 56 321 47 4 949 43 7 4 2288 8 0 4906]]\n",
            "targets[[282 175 2 277 889 31 0 2255 1045 2588 71 78 2 1024 311 34 96 5714 2 17]]\n",
            "targets[[1609 5 2 539 543 1 534 18 9 254 10 1262 348 7 13 5002 14 2 316 201]]\n",
            "targets[[1022 6 6 39 25 108 212 2008 436 202 642 22 1901 246 18 173 25 11640 128 11300]]\n",
            "targets[[121 0 63 186 362 624 8 0 1473 51 12848 137 499 2235 90 55 6 6 69 10]]\n",
            "targets[[17 5 29 3 0 250 3 0 56760 0 64 279 15 2 2837 3 638 5 11945 44250]]\n",
            "targets[[3 20 34 27 353 60 7928 6230 83 121 11 9 27 478 5786 16 1 4240 22 10]]\n",
            "targets[[709 21 108 13855 0 4082 547 180 38 11 3 6839 1736 1318 15 7676 18799 8 3631 15734]]\n",
            "targets[[1594 36 2573 7576 12412 53 1293 17 8 1315 3 1080 1 877 58 245 4 10383 47 5]]\n",
            "targets[[1349 37 49 9 27 113 110 2 125 28 52 155 72 1574 1932 8 10 749 55 201]]\n",
            "targets[[5849 758 149 10 17 46 20 25 7372 2418 20 236 182 4 3492 1791 46 20 25 2]]\n",
            "targets[[5 33 229 29 3 0 88 1185 104 9 139 110 1 9 140 1082 15 0 515 3]]\n",
            "targets[[17 67 37 73 1004 18 113 180 254 91 10813 4947 8307 102 13 29 54 285 69 18]]\n",
            "targets[[103 9 1046 11 2 171 3 0 798 128 203 28 1163 58 46 0 17 5 23 2802]]\n",
            "targets[[23354 1922 8689 58348 120 26 5755 1110 3 2685 50134 0 21901 5936 1376 36 1363 17941 1 406]]\n",
            "targets[[2 8597 37 11 20 89 21 27 4 353 0 372 3 60 609 46 20 89 21 182]]\n",
            "targets[[20968 41 190 20 3923 26 390 5 2 15310 85 26 122 3577 8871 3637 4 342 22 29]]\n",
            "targets[[221 11291 291 158 19 83 704 193 2 3292 1 2 1778 7 5 0 63 3 5258 55]]\n",
            "targets[[17 6 6 9 424 7 17 85 3 0 879 111 0 26484 25 571 1305 1 9878 3321]]\n",
            "targets[[630 261 1474 36 0 311 3 0 2717 162 26 981 14 2 9532 68862 151 8 0 4538]]\n",
            "targets[[723 21 110 26 17 233 0 407 3821 51 9 1591 7 9 402 8991 2414 10578 2703 1879]]\n",
            "targets[[423 12 994 11 406 1287 21580 314 6380 18 115 4 80 4505 362 6738 62 1496 6002 491]]\n",
            "targets[[13 29 3 60 84 959 35707 2430 0 53 84 107 0 1670 1 0 9089 223 9 723]]\n",
            "targets[[67 2 171 3 689 15 10 19 18 0 289 692 68 11 7 5 2270 348 1 1483]]\n",
            "targets[[928 1470 3 0 368 3392 7175 3 1795 276 705 298 202 5 186 73 1507 490 1 7]]\n",
            "targets[[2 171 3 17 4603 188 4 27 110 10 19 1 529 7 649 1153 829 9 874 4]]\n",
            "targets[[1947 2884 499 8 5870 22 2 462 1049 12850 311 14 1572 1795 35205 28803 9983 0 1386 3]]\n",
            "targets[[7220 5 2 1568 3 275 354 184 547 248 72 5210 0 170 738 275 214 30 275 4077]]\n",
            "targets[[50 64 25352 545 4 940 22 104 9 38 10 5 157 158 1628 2559 5 29 3 6921]]\n",
            "targets[[2572 101 1 2 336 659 4 0 428 637 393 92 10 0 250 359 3 60 17 2255]]\n",
            "targets[[2 684 8233 7 5 504 1 426 1121 4 66 30 0 699 4862 8 142 2 5077 95]]\n",
            "targets[[20 148 2 21 4136 3948 30607 340 9 395 20 830 10 44 7 274 2 9201 489 3]]\n",
            "targets[[323 1506 663 35905 45 1408 1500 32 1134 4 304 2 2528 9128 22 1575 35905 1 40 2535]]\n",
            "targets[[17 5 49 158 3041 658 247 9 83 9880 987 11 10 210 21 29 3 0 2616 41]]\n",
            "targets[[329 4 106 274 38 25502 145 18213 1 58 11 2372 4361 122 251 587 3 90 329 0]]\n",
            "targets[[35 379 17 15 2 1157 63 344 10 45 4 28 29 3 0 250 503 1 946 2730]]\n",
            "targets[[210 21 47 24 329 4 28 1 14 2 3464 1352 10 9391 71 4 136 37 24 203]]\n",
            "targets[[1018 17411 400 31 0 160 728 19 1 378 1322 1 9 481 9 67 48 303 1943 16]]\n",
            "targets[[236 23 28 0 117 3 0 1541 1012 104 18 0 8806 5 60 519 29 10 5 0]]\n",
            "targets[[5 60 8839 738 3 2 1183 2529 17 8 202 13107 643 294 131 18675 483 7 12 79]]\n",
            "targets[[5 0 117 19 9 27 110 8 154 7 319 71 553 15991 1 9 27 4 136 8]]\n",
            "targets[[19 188 4 27 912 2 115 3923 22 71 6 6 99 9 307 7 16 0 84 57]]\n",
            "targets[[431 51 83 10 5453 421 1367 22 378 41 277 31 219 287 3685 35170 7 37 9 50]]\n",
            "targets[[1982 21 555 53 49 179 37 9 159 21 138 78 7 15 303 1422 1 133 7 1339]]\n",
            "targets[[9 103 1574 14750 5 208 813 0 117 749 55 705 4253 3 1187 154 9 27 27 30]]\n",
            "targets[[5 56 864 14 4 34 5 8 3822 3 0 2763 3 24274 8 10 19 679 2329 1609]]\n",
            "targets[[1109 2 1086 12673 160 728 303 377 234 36 2 266 3 12822 78 0 176 3 2483 4256]]\n",
            "targets[[242 1 13 53 2445 33 0 17 7 13 60 30 57 519 17 3 5267 107 2567 8]]\n",
            "targets[[3 0 15956 499 44 15 2 194 181 717 11 5 1186 208 107 1990 1094 94 218 65]]\n",
            "targets[[5627 1 11706 17927 25 105 9051 34 27 2 668 249 4758 560 8 338 908 698 283 43]]\n",
            "targets[[2718 16 10 422 13 414 60 518 94 796 41 163 13 2229 43 0 2647 151 54 13]]\n",
            "targets[[20 722 1431 4035 94 10 17 83 28 127 4065 12745 0 29 20 1017 303 1 18845 10690]]\n",
            "targets[[50 213 28 6167 8 2 6489 3339 17 3 318 179 11 20 139 113 110 167 9 42]]\n",
            "targets[[221 50 21 262 2 17 38 10 13 58 92 221 94 9 402 82 9148 74 98 142]]\n",
            "targets[[67 8919 303 1422 16 10 17 9 242 1806 1 233 12733 8522 45 6156 421 8 0 227]]\n",
            "targets[[9 59 38 4 136 10 5 29 3 0 117 98 9 27 123 110 1 8 107 0]]\n",
            "targets[[12 245 4 262 10 13 44 119 2 2040 602 18 7 13 157 8 2 194 344 501]]\n",
            "targets[[5 35 2449 4 601 1420 32 350 4 1005 2 11168 17 33 787 74 156 74 2595 47]]\n",
            "targets[[118 959 65 93 10 15 87 65830 10 17 5 7 12 37 374 9 382 31 0 129]]\n",
            "targets[[1347 3 13254 23333 6 6 10 13 8 0 143 3 60 378 11545 1 9 723 21 307]]\n",
            "targets[[550 11 2911 144 0 17 33 0 129 3 0 17 9 2439 7 97 6 6 15182 41487]]\n",
            "targets[[316 216 1705 1 1480 3083 1167 308 163 538 1088 6 6 37 70 148 1393 15 2 49494]]\n",
            "targets[[67 307 10 22 4670 1912 294 0 544 4237 7 12 35 1938 7890 1 5716 570 4 6841]]\n",
            "targets[[465 35 1055 2182 3 31007 1 9 15 2 644 15 2 667 533 7 912 82 214 7]]\n",
            "targets[[17 45 77 839 2034 1 934 6795 0 298 33 5234 1274 13 408 8 25640 525 99 9183]]\n",
            "targets[[5496 5 2 641 658 201 43 2 742 3 4309 27641 4 8862 120 253 388 5496 7 12]]\n",
            "targets[[71 97 10 1312 305 5 29 11 9 402 53 10541 8 5353 9 17636 55 0 223 19803]]\n",
            "targets[[9 140 36 0 22297 7642 1 9 215 11 17 446 1047 3930 29771 508 22444 1 60 660]]\n",
            "targets[[27 65 509 149 10 247 572 735 15 6596 183 1 1885 46687 23 303 436 41 807 18]]\n",
            "targets[[2 201 11 195 12077 8 829 1 33 17 5849 9 169 10 17 4 28 980 155 0]]\n",
            "targets[[9695 12 8796 3318 668 5638 15470 15720 34 191 2 1165 185 0 10568 3233 3 0 44203 0]]\n",
            "targets[[17 5 92 55 3 1472 135 15 1472 101 53 115 41156 5 92 199 0 135 41 101]]\n",
            "targets[[10 5 65 1009 257 0 8573 91 754 5 1340 1 23 2982 97 4026 0 452 1325 5]]\n",
            "targets[[50 366 15 0 1679 116 18 10 19 5 2 1521 256 2260 55 8 6153 9 50 380]]\n",
            "targets[[242 2 2484 2230 340 18 23 2 3499 340 9 27 56 573 8 1665 98 1050 15 119]]\n",
            "targets[[117 172 43 10 17 5 11 70 50 147 30 359 0 17 12 412 14 2 1010 12748]]\n",
            "targets[[15785 5 47 389 4 60 333 99 149 2596 1442 12 1242 1318 2187 15 7641 16239 2168 1]]\n",
            "targets[[12 213 26702 4 106 104 645 56 52 72 2 291 976 15906 35 5667 878 15 108 990]]\n",
            "targets[[5 0 117 17 9 139 123 110 1787 16377 751 2691 105 34 182 4 1872 8 0 2494]]\n",
            "targets[[325 3 153 1911 21316 12 2622 3 414 471 3090 0 388 107 10560 5267 1 42 167 2804]]\n",
            "targets[[1306 24102 24 2254 971 0 217 17 292 349 15 1457 1190 32 1986 712 0 41867 4 0]]\n",
            "targets[[6 39 5 161 65 4 395 18345 20 96 66 0 271 556 36 0 457 13071 15 0]]\n",
            "targets[[60 47 4 136 7 5 42 157 184 17 23 85 7 13 428 4 28 631 18 85]]\n",
            "targets[[17 5 161 18 2 1770 25147 9074 368 39852 1 160 567 35354 2068 55 15 869 1254 4]]\n",
            "targets[[1022 39 12 56 95 16 71 4 3963 10 17 208 3604 109 753 85 0 95 0 225]]\n",
            "targets[[5 22 0 2671 30 3236 378 36 4408 84 14710 13183 0 1966 3 84 57 964 6 6]]\n",
            "targets[[63 344 3 10 19 5 221 335 684 21274 0 153 543 3 10 19 559 990 5052 36]]\n",
            "targets[[76 0 553 11 146 571 8 235 4541 1312 159 21 278 73 196 78 0 17 0 101]]\n",
            "targets[[0 1161 5 256 247 15 1625 0 3417 8 0 158 1274 86 55 357 2 234 1161 269]]\n",
            "targets[[703 540 1116 153 1452 12894 12 84 12879 78 0 184 477 1861 392 2 105 172 2515 1]]\n",
            "targets[[9021 9149 432 8685 269 120 208 107 675 41 64095 14 5 37 1105 15 5876 9021 9149 19]]\n",
            "targets[[21 251 47 4 512 36 10 17 1078 91 504 1568 3 399 1 964 18 8 0 129]]\n",
            "targets[[2 95 7 59 27 77 126 46 10 19 13 1990 92 85 94 1276 59 957 659 4]]\n",
            "targets[[139 555 30 0 869 368 798 18 9 59 651 7 2 3988 368 667 3 0 158 1274]]\n",
            "targets[[17 5 397 47 12503 7 36 82 1138 12 832 827 5 0 189 11 0 1036 45 56]]\n",
            "targets[[2146 627 162 104 11 5365 7791 278 292 0 356 95 32 25 212 4 168 31 1 103]]\n",
            "targets[[1514 37 245 149 10 17 9 799 516 545 7 5 37 3470 74 1 37 335 4900 3]]\n",
            "targets[[10 360 341 1138 12 832 827 17 2 183 243 6675 22009 11725 64 4 169 800 107 35]]\n",
            "targets[[215 10 17 2 1476 154 463 154 4 28 2475 602 16 0 84 0 57 8 0 615]]\n",
            "targets[[16808 1065 1 513 10 168 31 687 249 6304 4553 1 0 6589 199 4682 26 84 3728 778]]\n",
            "targets[[0 57 9 2337 107 180 13962 1 5393 33 10 17 9 5146 4 7 14 0 88 617]]\n",
            "targets[[121 29 3 0 1396 8 10 19 18 9 89 21 103 9 140 4883 85 9 139 585]]\n",
            "targets[[17 13 49 2800 18 134 870 1800 154 4 93 157 29 99 1073 16 43 463 154 16]]\n",
            "targets[[0 298 5 241 29 3 60 88 1628 1177 9 27 353 7 3388 214 1 27 509 7]]\n",
            "targets[[7 12 23 781 15 0 1968 11 12 16 251 10 17 926 2 243 15 29 636 3]]\n",
            "targets[[1535 5 2 191 22 0 1047 30862 1720 3 2491 1 764 0 105 2895 27 108 263 302]]\n",
            "targets[[113 1018 25818 51 7 13 1900 22 9 159 21 106 73 729 1 0 321 3 2 3578]]\n",
            "targets[[12 12941 747 7431 192 15 2 105 782 4466 3 10337 18503 1 7601 15473 119 0 26625 12975]]\n",
            "targets[[5 2 1860 13393 270 8 10984 199 24672 1 2514 7 12 0 1638 63 3 6581 4238 0]]\n",
            "targets[[153 5 633 144 178 2 1001 228 1347 144 0 531 3 2 1800 291 158 234 8 9173]]\n",
            "targets[[204 27 77 427 22 1308 697 1 70 121 11 0 1155 3 10 246 14362 436 559 7743]]\n",
            "targets[[0 9638 25 297 8 189 1 0 217 177 13 8234 15 4472 14 2 914 3 8588 10528]]\n",
            "targets[[5151 3712 790 5348 5528 5444 898 2253 390 9 103 285 2 1503 3980 8 0 8552 6 6]]\n",
            "targets[[36 10898 2057 2804 13 2 245 486 4 811 39 25 173 184 439 34 59 3133 11 7]]\n",
            "targets[[2124 3146 11 12 0 670 11 269 4 333 87 80 98 38 10 76 92 13 39 56]]\n",
            "targets[[215 10 17 16 0 84 57 43 1706 733 154 602 1 174 57 11 9 27 0 1421]]\n",
            "targets[[10 19 32484 18693 21447 494 4 359 2 3862 1405 2459 11 150 21 16109 31 30 4 0]]\n",
            "targets[[637 33 12493 2477 5 437 504 9 215 7 3896 22 2698 368 17 1234 9 103 9 83]]\n",
            "targets[[9 409 8 0 0 1581 11 510 3 10 122 13 763 1 9 27 110 87 0 1257]]\n",
            "targets[[218 65 74 0 64 315 95 1731 492 5 0 290 36 0 3109 3 3608 329 294 0]]\n",
            "targets[[65 288 21 73 3 2 63 8 10 19 7 3979 427 392 120 0 697 8 0 84]]\n",
            "targets[[116 13 49 0 29979 3 11 57 13 591 6 6 18 1213 17 1104 4267 6 6 99]]\n",
            "targets[[637 3 17082 10 407 3991 1128 14355 3 490 12 3854 13 901 106 10 1 380 71 46]]\n",
            "targets[[10 19 386 0 7989 1465 5 23 1608 30 991 703 443 5 4856 1 330 8 3122 15]]\n",
            "targets[[1052 526 5043 547 15 2 2293 757 0 430 128 5 11 11397 5 23 42 2 757 3]]\n",
            "targets[[68 213 259 4 76 71 516 6021 8305 282 1065 3 0 125 8 0 460 1941 12 18843]]\n",
            "targets[[396 5 2 370 1576 1509 1264 276 1470 3 0 12806 1076 928 5687 705 298 1 729 202]]\n",
            "targets[[9 242 241 29 3 0 84 75 8 0 217 176 4 66 10 17 6 6 30 9]]\n",
            "targets[[17 5 2 2388 502 3 31230 81 4715 8 2 19 20 139 195 665 6213 1 20268 399]]\n",
            "targets[[2 243 24 45 42 1825 4620 22 0 958 3 18821 1012 12 2857 5 22298 18 14 24]]\n",
            "targets[[9 110 2 738 3 10 17 7 13 213 0 170 10 5 74 37 9 13 1632 4]]\n",
            "targets[[5 2 1990 838 1 53 544 570 4 2131 8 22 0 2986 1868 1086 105 2866 28 19]]\n",
            "targets[[0 1155 3 6391 67 137 4 136 8 10 19 91 757 13 1207 7573 44 33 0 4870]]\n",
            "targets[[223 6 6 12172 0 5953 320 3 40 1506 1 425 25149 24618 29297 12294 30199 15105 29054 1070]]\n",
            "targets[[132 0 19 5 35 2475 1005 120 3 0 5962 19 12214 15 944 4142 7802 27194 1 284]]\n",
            "targets[[176 5 221 1611 490 18 5 35 212 1 744 17 15 2 303 7663 177 1 2 69]]\n",
            "targets[[17 235 5 31 91 117 8 0 227 694 163 154 2 160 1842 3 1271 1031 543 964]]\n",
            "targets[[1046 15 0 798 43 0 608 3 803 8 10 17 2649 0 1973 8 0 114 3 16310]]\n",
            "targets[[139 110 10 17 8 0 206 5487 339 15 1268 14 6279 14 540 328 2177 178 3302 4762]]\n",
            "targets[[13 0 84 3556 17 546 14306 11147 98 1 140 11 9 215 36 0 457 4 0 129]]\n",
            "targets[[53 647 17 840 0 653 717 3 20155 12 1013 36 0 4101 15 2 605 11478 1649 64]]\n",
            "targets[[84 57 9 215 10 19 9 196 1357 9 27 4 197 11 0 951 3 0 63 3]]\n",
            "targets[[5337 12 361 5 2 81 354 39 12 5 64 223 75 8 0 19 1868 12 162 7]]\n",
            "targets[[27 307 10 19 440 214 1 6667 33 2 6589 3 2 173 154 199 4712 1 2 74]]\n",
            "targets[[17 65 2144 36 0 557 3581 4 0 2812 129 7 13 65 74 9 50 21 262 9]]\n",
            "targets[[84 215 10 17 51 9 13 43 163 154 158 60 1462 1291 7 31 258 711 49353 85]]\n",
            "targets[[277 270 3 10 202 5 322 0 500 5 81 1 0 434 492 5 414 58 18435 0]]\n",
            "targets[[1932 5 1679 8 26 1110 3 0 276 1 8 2 936 4 0 673 5 0 549 3]]\n",
            "targets[[75 366 532 11 0 2214 1523 5 0 64 640 15 0 964 11 50 93 0 81 181]]\n",
            "targets[[17 5 2 972 3 2514 12 1256 7 45 283 20 182 8 35 1001 12 19 5258 55]]\n",
            "targets[[121 56 29 2052 18 9 80 10 19 5 5177 16 29 293 7 5 0 12853 3 105]]\n",
            "targets[[5 0 244 3 17 61 274 0 32579 3 703 443 51 7 269 4 235 3090 0 153]]\n",
            "targets[[140 2 200 340 3 2042 1333 132 26 104 404 27 137 356 15 90 20 50 213 1572]]\n",
            "targets[[1217 5 0 224 153 3 2 1092 1248 2524 11 45 11834 1248 12 364 200 151 2 13023]]\n",
            "targets[[13 42 20820 144 4278 51 9 215 35 3193 16 8031 513 33 1457 1190 147 10 389 14]]\n",
            "targets[[13 671 8 10 19 14 0 19 118 23 409 55 4 91 6207 2 81 834 13 11824]]\n",
            "targets[[823 3148 2489 3973 26263 7431 24877 15 10198 12775 33 1917 36607 7639 120 952 5950 7454 183 1532]]\n",
            "targets[[13 2 519 1312 305 11 9 656 11 32 59 768 22 1912 41 277 233 60 11654 35971]]\n",
            "targets[[13 1431 963 10 5 0 3460 16 0 343 130 11 3574 309 8 0 130 6 6 9]]\n",
            "targets[[111 4 875 1690 10 55 31 200 745 16 64 223 3758 11 12 275 3708 9 232 113]]\n",
            "targets[[38 4200 30048 257 1640 1934 18 13305 5 10 17 2 3503 3 13345 41151 565 1940 13247 4]]\n",
            "targets[[113 555 3 0 125 8 0 2032 357 318 7 227 2269 22 10 38068 1234 168 60 1355]]\n",
            "targets[[1901 246 45 47 12 446 0 1685 1234 61 5 2 1284 14 1284 50 879 533 533 104]]\n",
            "targets[[30 696 1158 16 468 11363 12 12547 14 2 3254 10 17 9462 180 7245 11 24 5 23]]\n",
            "targets[[942 10 738 83 76 71 13797 33 0 2821 19 1502 32370 10 2147 18 9 83 4938 10]]\n",
            "targets[[133 38 10 19 7 45 48 27230 119 116 33 5123 14 2 17099 22 0 27582 18 0]]\n",
            "targets[[0 716 5 14 5608 14 96 28 2641 12773 2266 15938 218 1018 8 0 1077 3 2 19558]]\n",
            "targets[[9 395 318 0 5356 1331 20 2330 9 80 7 12 37 3756 74 20 148 251 4 367]]\n",
            "targets[[196 10 17 13 437 539 591 37 39 25 2 1260 173 1362 11 50 28 2940 718 18]]\n",
            "targets[[2506 262 48 75 165 38 10 239 133 651 506 1734 439 58 164 14 229 14 4 136]]\n",
            "targets[[21 76 71 356 22902 13 4516 1 5 401 0 117 20436 458 4 28 427 22 0 11168]]\n",
            "targets[[9 38 0 156 8 10 17 9 254 7 4 28 348 9 17454 2 173 214 18 32]]\n",
            "targets[[5 605 49687 66542 19 1100 50 11726 449 16 55055 45263 89 21 66 2169 1655 30 42 865]]\n",
            "targets[[67 0 1792 3 318 10 19 31 2 1322 1 1957 9 604 870 16 0 17 4 28]]\n",
            "targets[[17 5 327 497 137 3252 6149 4 6288 3212 785 71 149 7 357 0 129 464 0 189]]\n",
            "targets[[80 23 182 4 76 78 97 73 1519 43 10 17 14 7 124 23 1810 11 73 57]]\n",
            "targets[[467 10 17 0 1425 13 3419 0 109 67 48 337 1290 1 505 1 0 101 68 69]]\n",
            "targets[[25 131 75 532 0 503 16 10 122 5 475 838 9 65 38 2629 2581 13491 1 9]]\n",
            "targets[[1404 1250 1404 1250 1404 6 6 9 27 9851 10 78 317 9307 74 74 116 33 0 3309]]\n",
            "targets[[329 4 106 10 17 14 2 527 1 1999 51 9 13 8 60 2087 18 9 307 7]]\n",
            "targets[[84 215 10 17 22 3685 14 2 493 9 420 21 402 0 390 3 10452 17 41 34]]\n",
            "targets[[5 43 2 183 373 622 8595 1 625 1451 292 8 2 647 63 3 2 114 781 356]]\n",
            "targets[[742 3 19 1155 25 2735 4 2 2727 958 4 1176 48 441 3 112 63 17 1022 1404]]\n",
            "targets[[9 27 77 2567 22 0 2598 369 3 5403 23699 1 42 0 82 249 9 1779 0 605]]\n",
            "targets[[5 13 60 84 806 19 111 9 1011 2155 14 10857 12 568 6 6 7 13 0 872]]\n",
            "targets[[9 215 10 19 9 353 35 2553 15 9551 11764 111 24 300 11 24 1411 26 537 1]]\n",
            "targets[[604 65 1652 87 74 6165 1229 5 20 27 4 66 7 4 262 7 18 9 89 21]]\n",
            "targets[[0 2291 4050 11 0 2032 5 2 3061 3 0 708 12 2353 687 791 4816 1 7836 3014]]\n",
            "targets[[65 89 21 121 134 1574 1932 5322 22 4 80 10 17 0 225 13 394 1 24 159]]\n",
            "targets[[67 110 4458 12 0 1215 1141 167 816 10 56 23 0 1587 584 7593 1807 339 18 0]]\n",
            "targets[[0 15389 10 19 494 37 245 4 1482 120 2 3790 1278 201 2686 152 7 1015 0 17]]\n",
            "targets[[9 121 34805 202 13 113 303 540 7 13 113 65 1010 546 272 172 1108 7 13 1244]]\n",
            "targets[[1 1746 5 35 1264 19 270 8 2 994 176 0 19 5 43 2 1782 11 5 2481]]\n",
            "targets[[886 29 3 60 203 66 12 6 6 2 3804 3 1619 2718 49 116 1 503 292 15]]\n",
            "targets[[9459 5 2 323 1031 534 18 58 54 96 23 586 10 1000 6699 17 282 175 10880 1884]]\n",
            "targets[[662 4 165 2 984 3 959 12 5764 409 181 984 3 8448 31952 14699 1727 5133 498 5]]\n",
            "targets[[17 11 475 4655 71 240 51 9 84 215 7 805 9 139 1147 44 22 238 38 7]]\n",
            "targets[[7094 2570 10493 2383 14822 2155 15754 4708 40516 6716 42512 1 2 700 2427 2810 316 2166 748 1459]]\n",
            "targets[[5396 31 2 4985 14318 12 3439 1625 18327 218 26 933 22 2 4306 316 7208 16 40 237]]\n",
            "targets[[33 11 9 382 0 147 221 3388 74 246 274 15 964 34 103 5451 0 361 31 283]]\n",
            "targets[[133 747 37 1366 7 559 178 799 315 35 541 4 1134 11 0 17 13 853 1427 14]]\n",
            "targets[[5 2 74 17 11 14903 4 28 35 5108 19 2665 4 3482 764 43 0 4009 3 1967]]\n",
            "targets[[112 201 61 11072 112 6236 1 4995 689 49 347 33 455 156 1 2 49 4848 128 16]]\n",
            "targets[[22 2697 499 44 53 74 7 113 11950 7 42 218 447 1 447 357 0 129 1 10]]\n",
            "targets[[1659 3 4527 45 29 151 11 45 77 1796 233 0 206 314 2520 2 6053 3 825 2957]]\n",
            "targets[[213 467 26 12312 237 14 0 1252 8 0 1248 7340 1 107 1082 15 26 13848 9 307]]\n",
            "targets[[10 17 13 437 539 9 65 89 21 121 134 295 550 7 45 2 565 1069 9 196]]\n",
            "targets[[418 4 0 443 4 66 10 29 18 9 319 99 221 35 541 9 1951 60 2188 99]]\n",
            "targets[[9 569 21 230 11181 4 738 137 9 64 215 2 315 541 3 18 9 232 93 35]]\n",
            "targets[[3 0 2140 5 2 19 11 9 139 67 8 60 6746 16 180 2 132 18 42 113]]\n",
            "targets[[9 529 7 2 308 163 18 8 2 49 95 46 20 121 47 9 382 69 10 5]]\n",
            "targets[[16 146 261 16 2 1703 4802 13297 7 5034 108 6822 15 4802 12 117 9 772 59893 1]]\n",
            "targets[[63 5 1348 1 8551 50060 3569 14300 6706 2 755 11 302 0 507 78 2 1313 32670 33]]\n",
            "targets[[21497 10 17 99 884 798 128 1 3088 1530 136 11 152 19242 45 2 594 321 7810 2421]]\n",
            "targets[[1271 1258 471 17 534 45 157 222 172 14 665 8868 314 1548 8583 12 939 8 10 889]]\n",
            "targets[[3 74 98 83 27 2 1794 249 15 10 29 1304 342 3 14982 5 2 14846 1737 16]]\n",
            "targets[[24538 4470 10 17059 18744 3 0 472 3 0 1274 8 764 1056 33 3176 2966 0 19 5]]\n",
            "targets[[173 7204 761 36883 1 19857 29510 80 47 32 50 15 0 11682 37929 3 3532 11 32 25]]\n",
            "targets[[173 75 1808 34 1180 10 4732 365 4 28 330 10 4823 3 2 17 5 0 244 3]]\n",
            "targets[[653 717 3 10 19 43903 14 64 2 5211 19 50 8 189 20 25 37 3799 22 0]]\n",
            "targets[[4 875 87 43 15 0 24044 4214 6 6 1621 331 6093 11923 702 0 63 3 11923 12]]\n",
            "targets[[108 3750 80 20 365 7 465 38 2365 195 37 108 4583 18 24 118 23 191 100 9]]\n",
            "targets[[1818 569 21 1392 503 2 738 16 2 92 16 246 17 18 9 195 1423 149 132 31]]\n",
            "targets[[3 0 117 98 37 229 3 3752 1 11 9 27 123 110 5 14403 9 467 7 37]]\n",
            "targets[[242 2 669 19216 8434 340 1 83 138 4 100 19 4 66 40 61 5 47 559 71]]\n",
            "targets[[9 467 10 17 7 5 43 1117 114 8 2 385 1782 43 9254 1 3974 112 1 9665]]\n",
            "targets[[9423 114 14 35 8247 1 231 125 45 579 2 479 16 0 250 51 26 312 45 4512]]\n",
            "targets[[173 510 111 10 17 5 805 2887 155 25 475 33 0 189 11 7 5 9778 2091 46]]\n",
            "targets[[12 245 4 76 0 370 918 3 87 901 10 304 5 132 1353 8 29 12 578 644]]\n",
            "targets[[139 110 10 17 175 1059 1 7 5 53 1876 18 9 50 402 1729 7 51 9 215]]\n",
            "targets[[89 21 121 87 10 17 195 92 7 5 23 58 2 63 9 785 1073 16 7 4]]\n",
            "targets[[139 110 60 3097 8629 2 3167 214 1 7 213 124 0 2666 7 9479 71 4 56 129]]\n",
            "targets[[436 637 13 1933 14 2 277 1553 22 31418 0 227 249 3961 246 9 672 149 7 15]]\n",
            "targets[[6048 68 1349 22 10 122 771 20 4208 15 90 41 23 85 3 0 1749 1849 62 3171]]\n",
            "targets[[84 555 43 10 36 60 49 425 34 585 71 4 818 7 37 9 118 1357 47 2]]\n",
            "targets[[467 484 3 548 7 13 2 368 1 51 9 84 555 10 13 556 44 9 13 21624]]\n",
            "targets[[67 0 1792 3 318 10 19 31 0 26427 958 2004 19 1322 1 13 53 1520 14648 39733]]\n",
            "targets[[2854 10 5 2 703 19 3749 15 0 4870 22 183 524 15 73 920 331 134 5 7]]\n",
            "targets[[1690 55 1901 7 12 14 2372 14 9 402 15 0 170 471 98 20 59 512 18 15]]\n",
            "targets[[10 5 29 3 0 117 3563 9 139 110 22 0 540 1 1048 3 235 98 10 29]]\n",
            "targets[[27 4 589 47 17 48 3 131 82 1996 307 6 6 10 63 8 10 17 13 394]]\n",
            "targets[[425 1 9 418 144 2 8198 48 6972 3 154 602 3 20961 0 184 104 8 0 378]]\n",
            "targets[[96 136 10 17 13 2 13053 4 0 3476 18 91 126 72 11 20 96 136 10 17]]\n",
            "targets[[281 33718 42702 6 6 1235 9384 308 6626 308 6 6 500 2756 13423 3462 6 6 8488 9171]]\n",
            "targets[[215 10 17 14 2 493 1 67 2 598 4 66 7 1059 99 52 154 72 9 182]]\n",
            "targets[[19 162 56 266 31 30 9 529 7 2 223 85 0 156 118 23 1713 8 62 510]]\n",
            "targets[[1469 45 2 173 13151 8 26 873 8673 590 4426 1 320 4 41002 25 2424 775 90 18]]\n",
            "targets[[13 0 795 8441 17 1 0 227 29 1305 14406 13 187 4 191 172 8 0 235 3]]\n",
            "targets[[36978 34444 207 242 2682 24141 635 91 1438 8 0 115 179 0 63 43 242 2682 6024 14203]]\n",
            "targets[[75 663 338 12 220 3 1080 46 2 549 50 22800 3699 6874 4 0 333 3 2 493]]\n",
            "targets[[0 2316 302 265 8 0 4417 176 111 631 98 409 1 2 739 3 183 1035 270 44]]\n",
            "targets[[531 5 0 2006 3 6756 51 47 562 4 105 115 75 5 273 52 72 2 2000 3]]\n",
            "targets[[5 2 155 19 7 45 30 0 648 959 13912 224 81 2046 3 101 63 1359 20726 15]]\n",
            "targets[[10 17 84 389 44 0 829 68 1216 11454 18 0 878 517 13 1262 2033 47 96 28]]\n",
            "targets[[5 0 441 3 369 11 406 6290 3897 2 74 390 7 150 21 121 47 7 5 259]]\n",
            "targets[[990 1 49 4050 3 6150 25 31 0 1960 3 10 17 622 716 5 0 11645 8742 18]]\n",
            "targets[[1327 87 8 26 309 98 3080 4498 449 968 38 14000 18597 6 6 203 27 77 2360 44]]\n",
            "targets[[262 0 626 412 20 25 2960 5 5343 895 130 408 33 4095 5341 36 0 7321 17 3]]\n",
            "targets[[65 509 10 17 51 9 1900 215 7 22 832 827 12 1855 1307 22 2217 6532 9 13]]\n",
            "targets[[262 10 19 13 92 1846 91 3507 1237 11 7 59 28 326 185 33 952 2134 3 75]]\n",
            "targets[[9 103 23 9 196 10 122 13 186 1587 49 1 7 67 52 72 275 762 0 851]]\n",
            "targets[[456 2045 17 2 1793 9556 3 2381 1254 36 0 276 7306 25 4228 8 10 19191 11823 2181]]\n",
            "targets[[51911 12 723 3 10042 5 29 3 105 1987 4 2 1312 63 2 4015 2888 1116 368 1625]]\n",
            "targets[[402 1729 10 122 51 9 13 2 527 9 196 0 3914 13 0 7433 151 9 139 110]]\n",
            "targets[[110 35 5044 2683 3 10 9 103 439 3 832 827 181 83 3739 7 39 5 983 4]]\n",
            "targets[[9986 12 1508 9395 5 35 1638 1115 63 270 8 0 2192 567 3 24151 7 5 0 63]]\n",
            "targets[[17 45 275 179 618 356 15 7 6 6 308 0 743 5 4134 6058 1427 16 362 8]]\n",
            "targets[[2 1048 2357 17 4 166 69 7 45 4 28 352 371 206 41 2 53 49 8894 10]]\n",
            "targets[[2661 5 29 3 60 519 184 399 1 9 213 307 30 26 104 10 880 29 9 80]]\n",
            "targets[[373 559 71 4 66 10 19 51 9 13 720 0 291 167 54 1103 7 1168 60 442]]\n",
            "targets[[1803 34 45 110 0 703 206 15 5359 751 1 6840 9433 10 5 0 250 984 3 2]]\n",
            "targets[[45 4 28 29 3 60 30 57 7625 464 91 40726 1 336 2159 57117 3 2703 18638 91]]\n",
            "targets[[39 255 332 44 39 34 1198 11 30 0 356 101 1041 55 8 0 356 3605 6 6]]\n",
            "targets[[325 1 3549 4712 13941 12 836 4564 144 1547 2746 55 52 1148 72 58 0 1996 128 27]]\n",
            "targets[[2975 662 11 65 1455 22 91 197 10 662 162 115 2 857 4 0 84 29 402 0]]\n",
            "targets[[1921 1331 3005 55 111 0 84 1921 319 120 4918 14771 5 330 1 6968 45819 5 715 2450]]\n",
            "targets[[2676 16 10 17 5 23 64 91 116 1 946 18 0 3555 25 35 6518 4345 3 4339]]\n",
            "targets[[2907 12 498 3369 3 0 795 244 5912 5 2 2161 658 469 6815 63 91 1638 4621 92]]\n",
            "targets[[5 2 1338 1 1571 3429 3 0 2401 1630 1743 22530 8606 1 11208 1145 790 6 6 132]]\n",
            "targets[[856 137 81 51 70 418 4 66 10 1931 7 5 634 2 2598 304 278 22 19 0]]\n",
            "targets[[42 27 4 136 11 10 17 13 497 264 39 13 308 49 3116 36 0 17 9 2945]]\n",
            "targets[[2142 1739 26 590 14 2 153 15 148 8780 2 368 184 201 11 45 2 669 1116 2526]]\n",
            "targets[[1896 1401 16 729 5 0 666 88 548 379 432 3 1223 123 4 599 2671 729 0 328]]\n",
            "targets[[13169 5 35 212 115 680 270 167 176 299 223 1 9 6022 10 51 28832 7980 7 29]]\n",
            "targets[[84 3065 8013 17 9 139 123 110 13 2133 0 5394 251 2 337 17 18 7 401 1455]]\n",
            "targets[[73 14 9 112 11631 10764 9 42 420 21 367 10 17 85 48 3 0 1711 581 3139]]\n",
            "targets[[2 759 125 1 2 184 17 340 9 13 65 261 931 4 318 10 18 7 12 65]]\n",
            "targets[[1008 2074 5 0 17 11 92 0 81 2365 2226 2 314 2 81 17 97 6 6 8]]\n",
            "targets[[7 96 27 6 6 60 894 660 3 6442 1193 10 17 38 388 330 2972 16 29 9306]]\n",
            "targets[[22379 12 47 12 30542 3341 5 2 539 1084 15 29 679 2999 0 834 128 5 11 2739]]\n",
            "targets[[34 467 0 105 368 2977 33 2273 65673 83 28 671 8 10 19 30 0 1279 1 868]]\n",
            "targets[[2 360 341 17 7 12 95 721 823 8 172 4 2 69 408 2716 2604 225 11 45]]\n",
            "targets[[3 0 75 34 738 1412 128 5028 11642 71 15 62 605 608 3 19 1862 6 6 51]]\n",
            "targets[[1287 1869 17 20 121 39 25 131 156 1 1396 34 282 32 950 22 260 32 1997 4]]\n",
            "targets[[19 302 47 96 27 77 2 49 321 2 19149 2634 291 158 1868 1 335 5866 7 6603]]\n",
            "targets[[159 21 121 47 4 512 51 9 418 4 66 10 17 14 0 829 11 9 139 353]]\n",
            "targets[[0 125 1 26 989 5 2 2812 1058 16736 11 162 20 1124 0 397 168 31 35 6877]]\n",
            "targets[[2080 2312 122 8 60 660 5 35 1504 5015 368 9 723 21 110 174 422 18 9 133]]\n",
            "targets[[894 553 5 11 20 604 4116 10 17 36 91 991 1308 25190 38 37 108 276 1996 2446]]\n",
            "targets[[0 872 360 341 184 19 3 30 57 9 84 215 10 17 51 9 13 187 2784 154]]\n",
            "targets[[180 2248 18 799 413 2864 6219 978 5 127 117 227 4497 16 2 1636 978 41 348 1606]]\n",
            "targets[[139 353 2723 798 4029 0 102 954 0 725 580 1 52 49 996 4 496 57 15 10]]\n",
            "targets[[556 119 4 0 2010 346 8 3870 2348 4 28 579 8 14 2 1610 3 0 231 183]]\n",
            "targets[[202 218 223 399 4295 85 7 1411 48 3 5834 3731 328 22 19 1 376 286 83 353]]\n",
            "targets[[20 723 21 110 975 10738 20 723 21 2 4718 38 93 127 197 184 17 8 29 249]]\n",
            "targets[[25408 12 35635 56 59291 5 2 49 181 19 18 8808 97 108 1450 1 990 36 126 98]]\n",
            "targets[[17 5 221 38 2 1952 3 0 184 477 8 2 266 8 0 170 95 14 0 206]]\n",
            "targets[[9 196 10 236 28 5295 18 7 13 58 447 72 9 4325 533 9 38 4 106 2]]\n",
            "targets[[1692 25473 185 12 0 316 8509 5 2 4201 19 185 4 708 15 56 14235 8 5117 2]]\n",
            "targets[[2148 26 58548 175 147 8 2 807 184 19 427 22 1917 691 12 298 4060 0 170 95]]\n",
            "targets[[49 216 1947 0 452 14547 63 270 8 4739 1128 4800 204 27 77 35 570 4 13161 1255]]\n",
            "targets[[17486 12 13727 5 29 3 146 735 104 8 0 3092 3 10767 11 59 28 53 727 4]]\n",
            "targets[[27 110 10 22 3566 440 214 1 30 9 50 136 5 25321 190 2549 92 7 203 27]]\n",
            "targets[[52 96 20 999 16 72 2 2233 3084 105 1549 342 2 13124 3 35 2444 125 2 5498]]\n",
            "targets[[9 353 0 2690 22 898 9 13 53 2229 9 196 7 59 28 35 212 17 8 0]]\n",
            "targets[[5 2 17 11 5 43 107 4784 7881 1 3851 7 8 56 95 5 35 2995 4 255]]\n",
            "targets[[5 29 3 0 250 98 11 9 27 123 110 70 121 87 4226 25 1 9 604 66]]\n",
            "targets[[74 42 74 9 50 402 0 1561 16 10 17 2 69 3147 15 30 0 1 7834 652]]\n",
            "targets[[19 1430 0 29 11253 11 30 1098 98 141 27 1 11 5 297 1487 8596 112 2244 2587]]\n",
            "targets[[5639 302 240 1108 5093 3 127 114 10 17 302 240 1001 5093 3 7 9 604 262 9]]\n",
            "targets[[17 285 38 2 1118 782 246 122 20 121 0 244 3 246 9 140 664 43 609 528]]\n",
            "targets[[3 2170 1274 3 574 223 9969 463 399 1078 0 3630 177 571 8 10 17 1364 1441 9682]]\n",
            "targets[[183 1602 5 259 4 1664 22 26 330 324 12 166 22 10154 21774 26 7693 373 45 2441]]\n",
            "targets[[19 5 379 0 877 5 74 0 5 225 1562 1 58 0 343 135 25 3851 0 3805]]\n",
            "targets[[38 88 3693 11 7 59 20033 4073 69 7 159 21 9 13 1520 15 959 8 47 7]]\n",
            "targets[[242 2 679 184 19 4500 18 10 13 29 3 0 250 104 9 27 123 110 737 3]]\n",
            "targets[[63080 14 7 5 19605 21659 5 29 3 0 219 206 219 212 1 219 1687 104 9 27]]\n",
            "targets[[48 82 798 122 10 17 236 2357 20 51 20 148 2 115 493 1 11 5 241 30]]\n",
            "targets[[0 173 34 592 4 28 439 3 792 8209 10 5 426 29 4 2831 1646 2 81 115]]\n",
            "targets[[13568 124 2 2769 301 15 10 471 1471 1156 13022 11332 17793 1277 1 1813 3527 1 24 124]]\n",
            "targets[[402 1902 55 15 1681 0 4009 246 148 1106 9 467 0 316 460 865 2253 18 10 6895]]\n",
            "targets[[5 29 3 0 1536 19 377 3236 9 27 123 110 8 60 114 1 9 26291 23 0]]\n",
            "targets[[5 29 3 0 117 684 646 202 9 27 110 7 11334 212 666 1 1363 762 3 766]]\n",
            "targets[[7 13 645 95 143 8 7426 8 1049 537 133 1386 0 15270 33 61 30 297 766 104]]\n",
            "targets[[307 303 3455 14 172 3 0 163 17 277 270 446 342 34 1992 3411 56 813 46 11]]\n",
            "targets[[53 911 1 774 1179 17 15 0 3639 4 28 2752 1 687 642 8 0 826 393 1]]\n",
            "targets[[65 112 10 122 7 12 38 884 2 298 1 253 4061 866 20 1716 52 7 218 20]]\n",
            "targets[[470 4 38 10 65 18 1464 1469 102 5 42 97 5952 1 335 119 0 351 533 10]]\n",
            "targets[[10973 45 4 28 29 3 0 88 4532 4437 1 2799 201 12 123 92 6 6 132 0]]\n",
            "targets[[9 215 0 13 556 22 246 9 148 353 0 798 3 0 1502 1 805 96 23 262]]\n",
            "targets[[20 723 21 110 10 487 7 5 205 55 39 15 183 2884 14 0 1536 3 30 57]]\n",
            "targets[[3256 12243 5 2 4832 73 38 0 670 14969 61 50 28 2 1793 151 8 2 53 9997]]\n",
            "targets[[11485 5 0 63 3 15260 15480 175 859 1316 2117 6964 2 1023 10274 1077 1602 11 747 4]]\n",
            "targets[[20 92 0 1414 3 318 0 17 167 884 0 298 597 89 21 198 55 22 0 202]]\n",
            "targets[[17 59 139 77 2 5801 2761 48 3 0 3468 2906 1685 1500 51 84 645 18 7 13]]\n",
            "targets[[5 3053 8 5150 3667 33 2 1257 5084 22 0 1733 15 56 531 31 30 37 9 1385]]\n",
            "targets[[215 10 17 22 0 832 827 1234 1 7 11260 9 307 15 105 355 1 30 275 3]]\n",
            "targets[[12809 550 7 30 10 5 29 65 74 17 61 5 610 85 9 1818 38 15459 1 9]]\n",
            "targets[[533 367 65 2372 98 146 11 1999 914 51 75 58 1031 75 76 292 15 49 2962 4]]\n",
            "targets[[147 128 5 2 17 111 1310 188 4 1046 22 0 170 6855 7 5 2 53 1247 4392]]\n",
            "targets[[307 10 17 4120 15 2 425 9 27 4 5751 11 9 59 27 113 92 7 144 0]]\n",
            "targets[[806 1455 4469 0 1586 3044 1 687 214 14 775 2610 12 117 46 7 1449 0 41319 1]]\n",
            "targets[[112 19 1471 1 10 13 160 4 71 2715 37 9 401 509 7 6 6 190 7 5]]\n",
            "targets[[1075 0 368 2087 8 0 1473 530 3 5810 18 0 1890 25 40090 1 25 23 53 631]]\n",
            "targets[[96 5221 2867 3 3168 1 315 3168 578 775 178 9 204 58 262 7 47 13 1346 4]]\n",
            "targets[[467 0 84 17 10 662 5 2 997 1 23 31 30 2458 8 2 363 3 1265 0]]\n",
            "targets[[202 3 7434 88 3 90 11973 729 3 0 2654 12 18 79 15 48 9983 31 0 1253]]\n",
            "targets[[116 8 10 17 13 37 74 257 15 0 461 51 24 389 16376 31 90 31 0 129]]\n",
            "targets[[4 28 0 1536 1 15566 8449 1084 39 5 0 117 687 15896 22 0 773 2813 2455 63]]\n",
            "targets[[5 2 171 3 2843 649 1517 22 10 1904 43 10 19 61 9 50 21 387 9 27]]\n",
            "targets[[108 3 178 656 11 70 96 1402 240 1044 1 2757 26707 1 28 850 88 3 178 9]]\n",
            "targets[[5879 0 335 379 527 12 122 36 0 6895 133 2050 4 10881 183 423 15 7 12 605]]\n",
            "targets[[244 3 166 2097 8 26 234 2069 5 56 5785 72 4750 7 141 28 2 9869 2 9273]]\n",
            "targets[[242 2 3917 59304 4 0 21427 166 3 19 9085 28830 16693 622 7120 4445 2927 3 928 114]]\n",
            "targets[[457 3 0 19 581 2409 1 0 655 13 53 69 226 18 7 30 195 2 222 2636]]\n",
            "targets[[5 3979 427 22 697 11 3697 294 1221 3290 12 2697 3 3500 111 99 5845 4 2 619]]\n",
            "targets[[3 30 10 17 13 92 16 729 109 1555 7 45 2 681 17 3 0 1307 230 0]]\n",
            "targets[[1307 9 389 596 2 5238 3 1071 5655 3 440 4927 2651 9 1339 4 4192 459 3 90]]\n",
            "targets[[75 7831 2978 8964 14 0 117 5023 3489 17 9 89 21 103 37 2978 8964 5 2121 3489]]\n",
            "targets[[889 13 23 2 49 17 9 196 0 289 102 1221 13 2 1758 6702 42 645 36 1061]]\n",
            "targets[[409 181 339 3 3760 484 5 29 200 910 3 2 17 14 30 2673 3 1890 1214 253]]\n",
            "targets[[434 5 1225 740 14 14103 14 791 14525 61 83 1090 1979 4148 208 0 955 3566 2094 18]]\n",
            "targets[[68 105 104 3 10 477 0 1897 2 314 5 1318 6 6 0 5553 1575 140 505 8]]\n",
            "targets[[9 67 56 17291 321 22 47 4 512 36 10 17 10 251 14 574 288 21 47 9]]\n",
            "targets[[118 9 3188 10 637 11 12 65 610 14 3563 25 775 60 519 104 190 10 29 13]]\n",
            "targets[[4074 3 100 807 2150 41 436 3 100 244 10 3610 184 19 5 335 3941 0 1595 5]]\n",
            "targets[[14 11424 14 1302 2784 36 3270 791 41 2951 3 0 817 0 1033 154 5 426 3449 8]]\n",
            "targets[[9771 24495 5 802 8 14 35 3955 1236 1655 33 1171 1352 20429 57400 3930 43294 8139 4 3260]]\n",
            "targets[[5 649 2 63 43 0 1902 620 199 1911 13552 2365 1769 1 28349 2250 3175 4053 54 302]]\n",
            "targets[[7 614 4 198 2 17 56 399 9 1385 23 190 108 399 898 3865 10 42 103 1719]]\n",
            "targets[[16203 24 45 77 60 519 16 2 194 57 9 13 1073 16 194 16 15823 4 768 1]]\n",
            "targets[[5 2 17 725 47 5 2 17 725 843 0 63 7 5 3199 31 117 1159 2 24]]\n",
            "targets[[3 30 10 19 13 23 645 4 7495 9545 839 32 136 9 136 32 2700 0 63 3]]\n",
            "targets[[215 61317 4120 9 1216 89 21 198 73 3117 4 47 388 204 136 43 2 19 167 9]]\n",
            "targets[[211 22 10 5 2 81 17 9 89 21 121 47 75 382 51 32 136 0 116 13]]\n",
            "targets[[3 0 117 1979 184 104 123 92 46 20 424 0 115 234 34 451 185 0 2847 5267]]\n",
            "targets[[60 548 87 1185 13 10 17 70 215 10 31 29 3 0 12081 8 160 728 1 9]]\n",
            "targets[[1495 3804 3 930 249 1386 1 0 10822 3 0 1938 9929 1324 22 91 9052 5585 119 1118]]\n",
            "targets[[96 53 69 28 0 250 432 3 725 797 123 9703 22 19 3353 1491 0 6505 34 11133]]\n",
            "targets[[63 344 59 27 77 49 46 0 156 257 0 455 3434 5634 159 21 119 486 37 73]]\n",
            "targets[[5 23 43 6955 882 5 7 43 256 192 19 11064 41 12022 4 833 44 3115 1450 1]]\n",
            "targets[[67 0 81 8727 3372 4 169 10 22 711 246 31 317 8 0 2015 10 1307 1 47]]\n",
            "targets[[191 22 0 15833 757 1 270 294 0 1312 905 99 0 897 2908 2509 4333 4 1312 45]]\n",
            "targets[[255 5595 10 19 41 13 7 64 0 277 768 11 67 669 3008 325 7189 199 135 7]]\n",
            "targets[[5 0 88 2892 1 1407 680 9 139 123 110 431 111 4 366 6 6 109 47 115]]\n",
            "targets[[21236 1688 11 24 45 0 13538 3 2 49 153 58 46 24 50 21 180 76 3748 3]]\n",
            "targets[[448 11 0 17 13 2310 53 1383 56 109 785 4652 16 137 4 551 1 161 118 2310]]\n",
            "targets[[2 2271 561 51 20 1382 387 11 20 80 23 4205 4 0 5524 3 12315 1729 38802 1729]]\n",
            "targets[[5 23 174 19 12 301 4 22800 20 15795 9 83 191 35 3332 2102 119 2 2935 2402]]\n",
            "targets[[10 288 21 0 250 17 9 139 123 110 18 9 67 555 745 3 49 179 43 7]]\n",
            "targets[[17 13 1796 2 81 225 1 0 1135 3 1853 0 405 13 5318 1498 1 259 65 245]]\n",
            "targets[[402 107 6121 3 17 537 51 9 13 1137 1 3621 381 334 37 357 381 6243 192 14]]\n",
            "targets[[618 7 162 56 266 7 12 42 2 742 3 1472 161 1334 292 8 14 4515 14 95]]\n",
            "targets[[1161 6065 13 35 16315 984 3 0 2004 703 599 7015 995 0 84 19 316 1161 45 283]]\n",
            "targets[[5 2 19 11 83 383 20 1545 42 47 7 12 30 43 16 146 34 25 78 142]]\n",
            "targets[[10 55 31 338 378 16 668 576 996 12111 17124 5725 1 0 213 1311 6471 2504 18 4065]]\n",
            "targets[[13 4778 31 2450 1 426 118 23 27 0 689 9902 5492 67 8 0 17 18 9 133]]\n",
            "targets[[944 13 2088 2 2757 14828 36 61 2 323 10028 20988 3 15099 16280 10240 3502 142 7987 48897]]\n",
            "targets[[2514 12 68 0 2040 51 108 19 2626 874 4 359 62 160 2129 36 5130 7902 4 2692]]\n",
            "targets[[1932 0 872 549 3 176 299 1331 13 213 2 618 2139 279 1 24 67 2 81 260]]\n",
            "targets[[8 0 485 5 397 7 2130 9462 0 4547 3 1925 2 7236 572 34 16501 320 326 8]]\n",
            "targets[[84 3595 228 3 2507 3358 25 1085 3362 1 1232 1678 0 101 25 841 1 212 0 22912]]\n",
            "targets[[17 5 248 1611 64 6626 1991 22 898 31 0 561 1 7 141 783 1611 6 6 0]]\n",
            "targets[[8 60 660 872 112 63 123 585 9 467 7 14 2 527 1 9 112 7 147 2]]\n",
            "targets[[46 29 159 21 942 11 4598 13 8 336 3488 31 0 57 3 1468 1 2108 240 167]]\n",
            "targets[[92 16 246 17 13 37 49 11 1783 154 99 256 307 7 9 133 50 21 76 7]]\n",
            "targets[[124 1135 2 173 212 753 18 7 1015 4 122 2058 3 30 0 10415 6537 642 34 25]]\n",
            "targets[[307 10 22 246 2 363 3 1816 3 602 1 94 1059 99 0 3316 13 119 9 307]]\n",
            "targets[[9 307 2 246 122 11 2963 7 13 408 33 503 904 33 140 311 12623 14 2 14976]]\n",
            "targets[[50 21 76 119 87 81 10 19 5 3 268 7 5 2 222 2063 1 119 0 1350]]\n",
            "targets[[5 2 63 3 0 10218 6506 2159 27059 0 883 11 386 0 1274 4 6731 2398 1768 41]]\n",
            "targets[[42 89 21 387 134 10 17 5 381 1445 55 8 128 13122 7 5 2941 7 210 21]]\n",
            "targets[[0 63 2 34991 10987 3906 2 114 3 1072 4 320 183 2329 1 40 527 582 1 22446]]\n",
            "targets[[64 151 9 96 169 43 10 17 11 9 424 13 0 237 3 790 12123 24 2882 0]]\n",
            "targets[[35 158 21199 16 0 69170 3 4376 2 1485 17 4 2 928 2757 5795 9 140 2122 3223]]\n",
            "targets[[5 157 3 0 2386 5510 11427 1783 2183 11 709 21 642 22 2128 729 1557 1 0 64]]\n",
            "targets[[1148 8453 51 149 2 19 5340 131 223 3722 84 47 162 255 103 131 223 50 28 18891]]\n",
            "targets[[5101 9 139 555 3 10 19 65 211 185 4 29 151 7 210 21 4833 416 0 177]]\n",
            "targets[[25 2 171 3 2119 75 44 39 34 83 3764 11 10 5 14334 15 48 244 3 323]]\n",
            "targets[[3 30 9 59 38 4 136 11 9 27 56 689 15 565 274 1 10 17 124 23]]\n",
            "targets[[17 13 609 15 2 5660 970 0 653 130 1197 2186 18 11 2186 13 1760 3584 99 0]]\n",
            "targets[[15535 302 2 1729 431 7530 31 26 701 4116 802 22 33 0 4025 5306 3314 3 26 324]]\n",
            "targets[[6957 13 241 0 227 117 122 4 922 8 0 1118 12 91 610 11 91 119 91 13]]\n",
            "targets[[10 17 126 72 0 895 3358 17 15 22969 416 1 56 416 85 39 13 126 116 1]]\n",
            "targets[[50 9 136 9 140 2 17 1352 458 1837 1 458 5352 37 3 268 9 140 164 4]]\n",
            "targets[[177 4106 1 5152 21290 8 127 104 1441 8909 12 314 1001 43 4181 17402 3 916 13633 13]]\n",
            "targets[[9 232 987 0 1032 8 0 19 5 65 647 172 3 10 5 696 4 0 109 18]]\n",
            "targets[[254 7 552 212 11 0 19 165 1339 4 3178 0 6589 199 60 197 276 1087 1 11]]\n",
            "targets[[288 21 2 74 19 23 33 100 801 7 13 53 69 2967 1329 763 1 1339 4 22621]]\n",
            "targets[[467 10 17 7 702 43 2 396 1559 78 2 125 1 2 1347 4 2 46310 15 26]]\n",
            "targets[[12079 1 5382 1939 304 2 53 12947 363 34 634 112 253 82 51 32 8121 22 0 82]]\n",
            "targets[[9345 191 3774 5 263 8 2 171 3 741 4 174 82 8441 17 92 37 229 16 29]]\n",
            "targets[[19 13 2 229 1535 36 0 298 33 761 9581 34 1065 43 1697 41579 3653 884 2 270]]\n",
            "targets[[202 13 2 593 721 0 372 3 0 246 1141 202 3 0 249 18 805 159 21 169]]\n",
            "targets[[316 1 460 15598 655 1 983 3 7 3353 10 1480 297 114 2619 3 2 3239 572 8]]\n",
            "targets[[0 17 5 52 1856 15 235 838 1044 1585 22 2 145 1613 18 14531 27 0 3989 4]]\n",
            "targets[[9 196 9 207 110 48 74 2651 50 21 351 10 29 152 574 9 103 9 207 248]]\n",
            "targets[[2924 1022 9 242 36 34124 2149 12135 111 10 559 265 60 231 58 693 520 9 409 2]]\n",
            "targets[[5 634 0 749 18 15 74 116 1 2 839 196 44 109 2 2931 522 45 1379 2]]\n",
            "targets[[27 581 78 0 769 3 10 958 1 47 9 215 13 323 16198 29 3 0 289 101]]\n",
            "targets[[3 0 1517 2843 10 17 45 1918 188 4 6376 22 0 12095 1317 9 89 21 103 11]]\n",
            "targets[[88 16347 914 8 3897 12 246 17 63 846 22224 0 176 836 4933 3410 3 0 63 150]]\n",
            "targets[[42 110 10 22 32807 7 12 1424 8 60 333 7 12 576 11 132 0 4535 25 2391]]\n",
            "targets[[107 2 977 862 340 3 184 98 7 12 77 2 132 233 9 139 110 29 11 65]]\n",
            "targets[[202 67 2 171 3 1004 1 9 1830 144 317 762 3 7 0 9616 335 2371 7 14]]\n",
            "targets[[140 2 200 340 3 184 1 9 196 9 59 722 10 19 14 88 4957 36 1409 2446]]\n",
            "targets[[4403 5 2 6915 34 5 4496 16 2 572 1 45 4 350 1 731 313 60 3627 300]]\n",
            "targets[[10 5 42 1407 1243 65 23 273 60 57 503 10 3545 9 140 0 530 11 923 1517]]\n",
            "targets[[59 23 651 10 2 3074 807 17 233 39 25 48 1265 11 93 20 449 51 272 20]]\n",
            "targets[[268 46 20 25 884 60 738 20 27 110 10 19 478 20030 25235 5 29 3 60 88]]\n",
            "targets[[1203 9 159 21 512 97 73 36 10 17 0 5924 16 7 159 21 58 122 0 13190]]\n",
            "targets[[0 399 3 10 17 25 542 16 2 171 3 201 10 5 2 53 613 1 6193 19]]\n",
            "targets[[0 405 13 42 74 14 69 14 911 9 67 4 1028 545 4 106 0 442 151 0]]\n",
            "targets[[29 130 0 49 454 30 479 78 51 2989 8 2 644 36 0 74 454 0 1997 4]]\n",
            "targets[[47 2 462 9570 755 0 109 5 37 2456 63 5294 37 2565 116 37 6671 1 0 135]]\n",
            "targets[[67 303 1943 16 10 19 9 196 0 834 212 9 1423 144 7 58 152 9 254 0]]\n",
            "targets[[36 0 81 17 11357 10 5 43 0 6085 1051 832 827 17 132 31 214 0 19 5]]\n",
            "targets[[3218 5 2 3934 115 471 680 11 45 77 16722 1059 513 33 4616 786 17763 7 12 2]]\n",
            "targets[[53 4851 137 261 8562 3208 177 14 2 3008 137 1092 11417 5 42 0 84 3 108 1854]]\n",
            "targets[[1591 10 37 446 19 42 490 36 2707 85 39 12 2 3116 22 7 4254 11 7 12]]\n",
            "targets[[84 2645 228 3 10 17 25 2 11964 3 725 1580 1003 4 6948 20 78 0 1405 1]]\n",
            "targets[[175 9 27 4 940 22 10 397 1094 1 841 755 3 868 1 4002 0 224 8 397]]\n",
            "targets[[293 9 27 110 8448 19475 13 91 6850 16 206 626 1 2397 1672 16 0 4076 9 203]]\n",
            "targets[[17 12 834 5 3659 2 243 218 2862 51 13275 33 2 2985 8 2 1503 6 6 18]]\n",
            "targets[[112 0 9755 202 18 0 17 159 21 211 498 7 13 226 934 4 108 1300 510 68]]\n",
            "targets[[236 27 77 1678 46 7 1982 21 77 16 0 153 12 4689 8 1394 406 20 2 6383]]\n",
            "targets[[5293 5204 1 20 103 7324 17811 1093 601 1420 8 10 17 5204 285 433 530 1 45 745]]\n",
            "targets[[1636 338 45 1056 34451 2033 1 5121 2415 3 0 63 2547 692 1 10 17 1430 2 222]]\n",
            "targets[[174 74 2748 1720 1 3398 39618 3308 4 5807 30 9207 3 2169 265 8 1486 670 23698 351]]\n",
            "targets[[1026 10425 2908 9 512 75 30 119 0 640 68 664 43 10 3111 969 228 0 364 249]]\n",
            "targets[[10 5 241 0 250 17 9 27 123 110 61 5 606 134 7 785 60 659 9 84]]\n",
            "targets[[10113 26 81 3365 16 0 8652 1 0 176 3 0 3485 84 15064 2 1700 564 51 0]]\n",
            "targets[[35157 23 2 2293 28 145 1475 58 8 60 303 377 8 36301 8 0 53 407 1916 70]]\n",
            "targets[[65 509 0 1659 7 13 14 504 14 9 3530 7 59 28 46 23 126 1882 18872 13]]\n",
            "targets[[13 37 4189 33 0 145 906 31 0 457 3 0 19 11 9 448 1213 4 60 2791]]\n",
            "targets[[424 0 298 9 65 118 9 196 7 13 2 81 994 63 15 3866 413 1 1293 101]]\n",
            "targets[[9 1444 8 137 41 5 11 74 6556 556 36 39554 308 223 548 13 514 283 47 45]]\n",
            "targets[[30 146 75 11 118 23 38 3687 223 10 795 3969 162 0 325 168 14 49 14 0]]\n",
            "targets[[1889 4 353 0 298 10 17 5 427 22 9 140 256 1732 1440 43 0 763 914 9]]\n",
            "targets[[2952 16 683 5 0 29 293 16 318 10 53 1562 10828 725 0 626 5 4988 108 214]]\n",
            "targets[[27 110 108 11633 10531 1521 98 1 10 29 5 49 10 5 2 145 297 1521 17 11]]\n",
            "targets[[167 2042 1333 1739 26 3015 891 669 2662 8982 15 4386 2379 1 2 3953 835 891 52 613]]\n",
            "targets[[29 220 13165 2476 8644 702 2959 23027 1932 11 134 54 1384 4542 44 16 35 1115 54 300]]\n",
            "targets[[5921 300 39 12 56 447 3084 72 2 74 17 2274 127 281 1 127 57 1 11 12]]\n",
            "targets[[26 390 5 0 543 1 153 141 28 3023 240 8 1943 1243 38 10 5 113 92 175]]\n",
            "targets[[19 5 2 9817 1 734 20894 585 144 0 531 35 6726 291 158 396 578 8 2 3870]]\n",
            "targets[[5 56 1235 3 10 17 11 9 13 23 335 2984 4 5415 6 6 969 228 2471 4]]\n",
            "targets[[690 1771 0 8336 5 165 1986 736 690 1771 85 70 121 0 803 3 47 551 164 8]]\n",
            "targets[[0 734 7324 1 15440 16917 8223 45 82 200 1784 4 26 904 38 15886 16550 15620 65907 1]]\n",
            "targets[[29 13 74 18 9 139 110 447 1314 6 6 9 64 1291 10 29 85 1925 7702 13]]\n",
            "targets[[24 13 1137 1787 26066 67 2 989 3 1510 2 2889 6445 42 38 26 373 18 2509 11]]\n",
            "targets[[10 17 123 26349 379 0 84 29 13 437 81 1 9 50 21 262 32 2597 15 10]]\n",
            "targets[[856 2 171 51 9 307 0 17 3114 7 118 33 56 801 409 55 4 60 1422 9]]\n",
            "targets[[215 10 17 16 0 84 57 51 9 13 2 183 2166 1 9 165 424 7 9 1203]]\n",
            "targets[[1667 940 22 104 18 9 139 353 0 82 798 1 9 604 262 11 39 25 75 22351]]\n",
            "targets[[7 302 2 370 315 541 4 76 5321 44 3 2593 1 4 366 398 0 301 47 2]]\n",
            "targets[[63 3 178 5 2 397 17 8 91 197 1340 95 9 386 21 138 78 15762 43 0]]\n",
            "targets[[67 35 1421 4 93 29 3 0 117 734 1641 3248 98 123 85 32 67 0 156 0]]\n",
            "targets[[27 110 2 171 3 74 98 9 140 613 60 355 1 9 93 7 2 220 4 106]]\n",
            "targets[[80 9 58 366 15 10 17 6 6 10 5 241 0 37106 19 9 139 123 110 8]]\n",
            "targets[[1910 3 318 0 1701 11 8504 1547 68 462 692 0 2799 3625 1 10453 378 2628 11 70]]\n",
            "targets[[50 21 262 286 59 165 182 4 278 10 19 44 16 0 1008 4 667 116 13 5362]]\n",
            "targets[[198 10 17 720 9 420 21 76 144 7 167 1453 2487 6 6 0 82 798 1067 0]]\n",
            "targets[[45 195 4 28 29 3 0 88 504 104 123 92 23 64 16 0 6325 655 0 1717]]\n",
            "targets[[184 98 25 212 983 3 3717 983 3 9329 1 983 3 450 4 138 349 15 7 0]]\n",
            "targets[[10 22 1901 143 8 0 407 1118 12 1 467 7 113 215 7 175 357 7 1197 55]]\n",
            "targets[[16 29 3 0 250 98 3 30 57 2 54 893 967 34 280 38 7 3972 36 0]]\n",
            "targets[[13 261 931 4 191 2 956 36 60 348 13863 8 1672 472 4 106 10 17 2 544]]\n",
            "targets[[5 208 2 2828 3 2 813 0 1504 250 17 2041 3069 45 123 92 1 11 550 2]]\n",
            "targets[[27 555 43 10 673 2 194 57 602 108 3 60 355 27 395 71 4 353 7 9]]\n",
            "targets[[3 0 114 3 284 15864 284 1596 2 125 2002 36 1598 34442 8 4739 1128 1844 24 5]]\n",
            "targets[[5458 0 125 34 13 426 0 88 2240 4179 1 5784 1619 1692 3 26 57 1907 45 2]]\n",
            "targets[[35 504 2510 3 15826 6 6 2 736 565 777 1299 4977 333 7031 17 4 61 27869 127]]\n",
            "targets[[160 728 51 0 3293 1 2630 1086 3439 3 2 1672 4958 2153 22956 2934 2332 974 3712 2569]]\n",
            "targets[[20 148 2 340 3 0 298 60 425 20588 41 0 206 8165 17 3 0 170 390 20]]\n",
            "targets[[84 179 84 6 6 6531 3134 494 8516 86 24 65 124 18 469 0 125 1505 21 67]]\n",
            "targets[[141 27 77 126 73 126 2 1023 2431 2347 6807 9746 0 572 3 2 17680 5196 1 0]]\n",
            "targets[[133 3233 5 8485 6949 4 48 3 0 5085 8 61 9914 45 77 571 14 2 153 863]]\n",
            "targets[[286 34 45 77 1292 30 40 114 1 5 147 2 961 1506 1 2 543 16 2 961]]\n",
            "targets[[195 10 19 36 2 1948 6771 1 13 53 2229 43 7 7 67 2 700 694 8 898]]\n",
            "targets[[7572 2908 8 0 8739 38185 1455 44 775 0 668 327 85 3 0 1539 8 1277 36 0]]\n",
            "targets[[19314 5 23 64 29 3 0 250 104 9 27 123 110 7 5 241 0 250 17 3]]\n",
            "targets[[418 4 66 46679 49515 15 53 303 1943 11941 23393 92 29 3 0 117 1071 104 3 0]]\n",
            "targets[[312 3326 71 4 10 17 1 9 1986 196 9 236 367 7 37 9 159 21 521 7]]\n",
            "targets[[9 84 215 0 1029 3 10 378 9 67 0 11425 6648 11 7 236 129 55 107 29]]\n",
            "targets[[0 422 3896 22 246 1 65 509 7 91 42 2 81 202 210 21 7 1 7 13]]\n",
            "targets[[273 149 257 15 0 337 936 3 2 4398 15 5207 20 25 1027 2 200 776 185 63]]\n",
            "targets[[1122 63 321 16 1047 7633 5 953 1 3943 71 2 1483 8343 181 3574 1 94 2 125]]\n",
            "targets[[2 17 494 4 76 88 3 91 611 36 2 109 936 20 139 2700 44 69 167 2911]]\n",
            "targets[[10678 62930 1 46638 10360 32372 25 5452 8 2 1077 292 15 629 714 18 0 84 692 4007]]\n",
            "targets[[25 48 98 11 350 37 245 4 599 2 765 2345 11 32 663 33 2 4089 10 17]]\n",
            "targets[[362 2591 647 1964 5 65 838 17 208 2729 41 6800 0 177 5 3816 1 53 8063 0]]\n",
            "targets[[67 2 598 4 66 2 2683 3 0 17 8 15470 7 13 2 53 901 432 264 7]]\n",
            "targets[[17 92 71 230 145 767 16 29 3 0 158 2085 11 5 259 4 76 2 1309 58]]\n",
            "targets[[232 365 4 366 31 0 129 3 10 19 56 1250 89 21 3019 42 71 674 3543 11419]]\n",
            "targets[[219 2721 4095 1669 693 407 22 11 1256 1189 21 26 15471 1 11 3090 1 4644 68 111]]\n",
            "targets[[1890 21033 8785 12703 58105 3340 2 17 43 12703 41 2432 928 1890 3 12839 7 5 20424 542]]\n",
            "targets[[3403 243 461 2746 6648 22 2 69 1202 2356 1 0 34279 3050 4 704 0 803 4 615]]\n",
            "targets[[822 6 6 147 167 2 7380 3 443 13573 12647 22 62 54546 12 1797 71 4 3820 73]]\n",
            "targets[[70 27 2 183 125 34 45 1059 211 4 2 1782 1 5 35 1768 39 18 5 17751]]\n",
            "targets[[40019 12 3249 7578 673 465 1154 4 7972 16 0 260 18 0 4423 17 5 1050 15 1828]]\n",
            "targets[[5 2 2478 6320 19 1471 11 50 28 11068 15 0 117 276 13970 36 0 5287 7 5]]\n",
            "targets[[215 10 17 51 9 13 43 694 154 158 1 9 424 7 18 7 288 21 357 9]]\n",
            "targets[[141 28 250 2926 3 2 20476 673 9 165 448 1072 4 865 144 0 17 37 108 109]]\n",
            "targets[[128 7 429 5 0 181 17 208 181 8 2 145 360 341 919 89 21 663 0 607]]\n",
            "targets[[684 266 19 15 2 53 849 109 1 35 158 1255 5283 61 116 13 42 3362 0 19]]\n",
            "targets[[19 9 84 215 8 5051 31 0 1150 8 9 13 53 183 18 0 1388 644 63 65]]\n",
            "targets[[24333 5 117 8 98 22 1328 1 128 24 5 143 4 26 10664 22 53760 14 0 63]]\n",
            "targets[[1591 10 19 43 2 3423 602 51 9 67 161 332 4 80 22 2 2069 311 30 9]]\n",
            "targets[[7654 5 2 434 3 0 611 3 3630 1790 22 11 61 5 1089 2082 4 2045 0 7359]]\n",
            "targets[[0 574 13 5035 6031 11740 514 0 135 11 12 30 9 182 4 121 85 11 5 0]]\n",
            "targets[[89 21 121 134 32 93 142 2 200 845 43 10 19 0 3884 151 9 38 43 10]]\n",
            "targets[[1190 5 31 26 117 24 113 252 2 209 38 10 29 167 1 24 426 124 7 53]]\n",
            "targets[[242 2 81 340 3 153 5309 19249 622 1186 11812 1745 539 184 14 69 14 81 4927 2651]]\n",
            "targets[[6964 31 26 117 14 2 10163 10274 3766 8 2083 4605 1 520 5232 12 972 0 11485 5]]\n",
            "targets[[5 127 737 23665 17 2 742 3 10987 101 44 22 48 658 1693 26 8132 1345 45 0]]\n",
            "targets[[12 576 11 0 289 293 16 10 19 12 2204 5 35 570 4 11913 0 1279 3 0]]\n",
            "targets[[140 2 200 200 340 3 28462 4522 1 9 103 10 5 0 117 19 24 12 92 4]]\n",
            "targets[[17 5 241 29 3 0 88 348 1314 9 123 215 7 45 195 161 4 380 546 16]]\n",
            "targets[[48 2875 3447 3933 12 0 8532 3 548 8110 2651 18 38 3933 12 24980 3 0 1794 445]]\n",
            "targets[[62 859 1724 479 227 291 0 8304 887 25 143 15 0 160 19 10 57 201 766 2711]]\n",
            "targets[[10 28 853 0 250 17 123 278 4 3928 591 576 119 0 351 101 8833 396 2293 12]]\n",
            "targets[[3 30 1100 203 66 10 17 31 219 223 214 4 1382 387 47 0 574 5 1365 39]]\n",
            "targets[[10 13 645 9 196 10 13 29 3 0 88 13245 104 123 92 190 1160 4 1166 9253]]\n",
            "targets[[1 30 2122 549 6735 274 26 16919 3 439 26 297 3647 15 10 26 197 806 8 174]]\n",
            "targets[[0 112 3 30 179 7931 87 22 708 118 10 17 76 700 399 52 38 5069 700 399]]\n",
            "targets[[5621 9617 8 35 16071 1962 95 267 143 8 57 4 0 249 42 167 0 4793 10204 1259]]\n",
            "targets[[89 21 456 46 20 207 38 60 940 41 56 18 9 103 11 20 34 949 11 0]]\n",
            "targets[[63 3 2 18778 471 3144 1659 5627 5 326 185 119 6959 3232 0 711 33514 3675 86 9217]]\n",
            "targets[[6022 10 17 36 11756 12 795 9891 19 15011 1322 51 0 878 13 201 9 13 53 7496]]\n",
            "targets[[1171 2786 2121 3933 15 2 323 312 1 2 49 301 1129 26 665 17513 5427 51 26 158]]\n",
            "targets[[2908 747 15 157 1851 43 4 191 265 29 3 0 8637 5 2 669 3861 802 33 48660]]\n",
            "targets[[8 2170 5 35 1638 1115 8 19 8 0 2511 176 7 26289 0 507 78 108 385 3427]]\n",
            "targets[[3944 5 2 9308 14222 3803 9594 8 20691 1547 34 635 800 5871 33 2213 12 88 1076 746]]\n",
            "targets[[65 112 0 1258 181 1 832 827 104 3 0 4754 1 91 85 3 0 534 12 11]]\n",
            "targets[[20 182 4 121 0 145 63 3 0 11265 9 1478 20 1226 55 2 1005 3 43519 12]]\n",
            "targets[[0 7307 27 39953 134 5 0 361 13385 90 51 32 25 22 62 197 134 124 7 776]]\n",
            "targets[[8469 2576 10572 1001 12 1351 47 52 80 70 182 349 15 76 3158 10 5 29 3 0]]\n",
            "targets[[793 23 4 2376 238 18 9 17868 0 1250 4267 42 8 411 6 6 0 9711 13 2564]]\n",
            "targets[[98 25 4308 15 2 611 4 7549 1828 8 2 507 61 11656 90 55 8 0 153 12]]\n",
            "targets[[9 215 0 17 434 9 196 7 13 137 38 1036 41 272 38 7697 1332 18 9 254]]\n",
            "targets[[25 48 104 38 2647 6245 0 17 41 840 3432 11 25 5028 10966 33 1502 1 20339 3139]]\n",
            "targets[[548 60 548 134 11506 14307 71 131 68 0 227 683 3 2426 22 0 1484 1 5 0]]\n",
            "targets[[0 5613 3 12 140 471 207 9 772 342 381 3238 6282 1 94 627 4923 8 952 741]]\n",
            "targets[[2 8597 46 20 139 110 733 823 2019 807 98 167 20 139 110 10 29 33 0 129]]\n",
            "targets[[81 17 637 951 3 0 407 483 3 0 2386 887 20507 2626 103 3 29619 24795 14 20]]\n",
            "targets[[139 110 2 1131 3274 3 0 18036 5565 104 33 10 220 1 9 139 67 10 29 7871]]\n",
            "targets[[281 5 2 112 63 624 8 91 11546 16 11308 8 0 4602 276 919 3 9171 31 0]]\n",
            "targets[[1382 387 11 75 34 353 0 298 89 21 1124 10 17 9 262 7 12 297 16 1118]]\n",
            "targets[[3379 25 1902 55 1 25 398 180 69 16 90 13654 1530 23 843 0 4279 1278 156 1396]]\n",
            "targets[[254 10 17 4 28 2 81 321 11 159 21 1634 7 188 32 254 2 95 4 1738]]\n",
            "targets[[25 56 1022 8 10 738 39 12 161 4 2376 6 6 56 109 161 88 4909 274 31]]\n",
            "targets[[21073 1 26 312 11093 68 1777 16 180 2 173 1116 1935 3 4921 8 0 3037 1 1916]]\n",
            "targets[[1059 418 4 66 1588 24502 12 23993 31 0 53162 1322 2004 786 443 786 8 3815 1 9]]\n",
            "targets[[9 985 35 5371 2482 204 23 27 77 14 81 14 4326 1607 41 1802 12 176 18 9]]\n",
            "targets[[1591 10 17 3896 1 99 1706 228 60 312 1739 9593 12751 4851 228 8 1 9 13 391]]\n",
            "targets[[1667 949 2 1517 738 16 10 2147 18 10 57 448 55527 4 311 15125 5 208 813 29]]\n",
            "targets[[1022 6 6 287 12 28 1146 1 2 4260 825 43 10 19 3677 70 6 6 33 490]]\n",
            "targets[[5 0 441 3 19 11 406 184 104 2 74 390 23 14 2 914 3 2063 536 41]]\n",
            "targets[[0 897 17 1409 10 29 5 79 427 120 0 1330 434 19 1 4582 3612 125 8994 15]]\n",
            "targets[[17 13 4752 55 2 662 4 284 3467 12 2530 10 159 21 712 55 205 9 140 23]]\n",
            "targets[[1029 3 0 889 162 10 17 168 65 49 89 21 28 4374 5507 3284 389 44 8 4704]]\n",
            "targets[[140 23 251 9 387 111 30 131 17953 1227 6366 75 25 664 43 128 376 7 12 42]]\n",
            "targets[[29 5361 2 19 22 2168 624 5211 12 12640 59 1477 28 335 120 0 2341 2 34521 4162]]\n",
            "targets[[98 25 329 4 4768 417 2185 12329 8500 162 7 924 14 20 236 121 24 5 2 737]]\n",
            "targets[[43 127 120 1176 98 16 679 156 38 131 105 9003 1518 5 955 8 10 755 3 2511]]\n",
            "targets[[139 195 4 136 9 288 21 97 1520 15 10 4 28 1146 9 112 0 206 35650 1]]\n",
            "targets[[46 9 67 6013 11 1948 3874 8 1008 1265 0 646 412 16 38931 5 0 390 3 35]]\n",
            "targets[[21 7 28 81 46 23 157 1278 17 165 278 35 129 4 30 3 131 374 1099 9]]\n",
            "targets[[972 3 2004 443 11 30 7098 7358 14 7 2107 15 417 1399 61 121 56 7358 2758 34]]\n",
            "targets[[1022 349 15 11279 1388 1 0 1294 3 0 5216 98 0 8960 125 3727 2276 4595 8 480]]\n",
            "targets[[19 5 953 20 386 21 123 66 238 38 7 0 848 3051 5 16958 0 101 25 206]]\n",
            "targets[[247 115 4798 78 0 176 3 30197 5 42 14 49 41 126 72 108 104 9 139 110]]\n",
            "targets[[5 33 229 0 117 6651 3 544 6 6 0 688 1742 1293 109 1 1094 655 93 579]]\n",
            "targets[[139 509 174 679 1241 1264 8299 1 12291 19 11 9 139 110 233 69 3150 63 190 0]]\n",
            "targets[[12 77 2 171 3 5223 43 771 10 17 5 49 41 74 9 424 7 31 84 18]]\n",
            "targets[[27 42 110 2845 4046 7563 8 2 363 3 26 98 64 2 222 21918 9 195 899 8]]\n",
            "targets[[242 2 340 3 4212 2661 18 9 79 942 11 24 404 1601 8 911 104 190 73 3]]\n",
            "targets[[793 149 10 6488 3 0 443 51 9 13 733 154 158 9 27 113 77 0 170 233]]\n",
            "targets[[318 0 2229 411 3 4412 3573 9 3580 87 9 59 4370 4 0 63 3 2 125 34]]\n",
            "targets[[11 2 17 38 10 45 77 1056 8 3790 46 7 67 77 36 0 4754 9 569 21]]\n",
            "targets[[5 35 570 33 193 2089 5182 6336 17030 1 1035 31 35 11895 4336 3 0 5216 18 10]]\n",
            "targets[[2 453 3 57 1 281 60 10317 1 9 215 10 17 99 318 0 5924 1 532 7]]\n",
            "targets[[5 356 15 338 32 12307 55 2215 3837 181 1412 1 7993 145 5437 38 2656 0 6068 10]]\n",
            "targets[[45 77 300 167 18 9 389 4 0 170 1169 37 7 203 28 300 175 46 20 139]]\n",
            "targets[[956 8 223 683 59 28 2199 1896 7 13 23 155 8 189 7 67 43 308 13419 273]]\n",
            "targets[[11230 3 0 3202 6094 1497 8 5789 427 22 0 11510 298 5 21936 763 33 2811 1 4340]]\n",
            "targets[[149 10 17 9 13 1203 671 23 85 3 0 156 63 41 946 9 13 671 33 10]]\n",
            "targets[[3 0 762 22 905 308 25 379 39 5 56 1898 4 4585 3079 41 3270 4521 14 32]]\n",
            "targets[[1462 5 35 1504 1594 3 2 17 2698 12 116 5 371 38257 14 5 0 217 5902 264]]\n",
            "targets[[43772 5050 2210 20 353 10 1 76 143 4 71 7 12 127 158 4670 7138 3791 1709 1286]]\n",
            "targets[[36 322 354 63 0 1178 3 0 12895 4 496 2 3458 5 35 11952 3 1098 443 36]]\n",
            "targets[[72 2 484 3 548 47 2 17 6143 125 2579 2579 2579 2579 2579 2579 2579 2579 47 9]]\n",
            "targets[[47 45 4 28 29 3 0 88 445 2644 2272 2136 98 3 30 57 584 5342 1206 8203]]\n",
            "targets[[196 11 7 13 2 65 49 19 1 67 647 2282 18 47 118 100 1117 817 17 403]]\n",
            "targets[[362 106 16496 1590 4 1590 37 9 139 7 110 2 173 214 7 12 65 180 1799 295]]\n",
            "targets[[13 53 21368 15 10 835 283 13 394 36 0 366 0 201 13 54218 0 181 3900 0]]\n",
            "targets[[738 204 2924 1022 26 234 2069 499 44 583 15 1799 6296 15810 33 2883 1354 14 2685 2966]]\n",
            "targets[[27 110 10 122 275 214 0 84 57 13 85 9 13 20820 144 4278 1 9 196 7]]\n",
            "targets[[5 35 1149 17 9 112 7 2 171 1 7 12 29 3 60 519 104 7 12 29]]\n",
            "targets[[5 29 3 440 98 11 1477 1403 0 2514 1305 32143 577 13918 513 1521 17 2686 3880 18]]\n",
            "targets[[12 29 0 42062 88 247 1071 299 98 9 139 211 596 7 926 2 351 2490 177 1]]\n",
            "targets[[2966 2554 19 274 178 0 5651 3 0 958 3 3774 8 30 62 11109 70 121 2 171]]\n",
            "targets[[1195 5 2 1247 411 3 2 1880 1960 487 11 5 212 23 64 85 3 0 343 135]]\n",
            "targets[[17 5 634 2 181 17 31 91 2075 7 53279 1449 1132 1 63 18 18673 11 15 91]]\n",
            "targets[[481 9 50 66 0 220 10 216 13 259 4 93 18 84 134 118 7 27 4 28]]\n",
            "targets[[242 2229 3 47 6506 16377 13 787 8 0 17 1 79 0 5526 3 0 3735 11 24]]\n",
            "targets[[10 17 672 44 155 18 927 17476 9 196 7 59 28 52 1174 5543 450 427 22 0]]\n",
            "targets[[728 9 112 20 42 38 91 5325 1547 13069 21 16447 5 2 13189 3 952 547 11 5447]]\n",
            "targets[[0 359 3 1903 929 637 3 22766 9042 5990 33 0 3336 75 5 48 3 0 88 1097]]\n",
            "targets[[19 5 92 55 3 1747 1 1358 3 19 11 32 254 22 0 2235 644 1814 11 159]]\n",
            "targets[[606 0 662 20 139 77 2308 127 2678 4 66 10 5 0 811 55 4 666 2647 4542]]\n",
            "targets[[9 288 21 1900 899 4 66 9 13 2441 33 60 355 1 0 829 33467 7 14 2]]\n",
            "targets[[424 10 19 2 171 0 63 427 22 145 697 5 1578 1 323 6129 6350 7288 29 3]]\n",
            "targets[[2 2710 11522 228 10 6241 4351 3 1051 607 8898 133 188 2 222 194 132 20 148 149]]\n",
            "targets[[2 414 17 295 784 4 66 10 29 6 6 1911 4103 1 2393 14265 25 193 2801 2232]]\n",
            "targets[[497 17 13 22 31 38317 10 501 291 9 196 9 13 164 4 1176 545 42 149 7]]\n",
            "targets[[12 591 4 449 31 131 441 3 595 374 1256 174 147 1 94 58 46 7 45 2992]]\n",
            "targets[[1600 4 5782 0 7830 3 60 3117 16 10 19 14 9 307 7 131 25 0 1428 3]]\n",
            "targets[[1286 9094 686 4926 4470 4 129 30 1515 15 142 638 1 15665 9 96 4097 24 13 2]]\n",
            "targets[[3 30 65 2573 9353 127 945 12836 568 866 20 624 8 127 323 88 1336 1499 8 2131]]\n",
            "targets[[17 13 0 250 9 139 123 110 9 419 32 89 21 383 7 8 0 378 5174 85]]\n",
            "targets[[9 138 4 66 0 17 9 13 1072 1 27 56 6443 3 10 17 31 30 0 1561]]\n",
            "targets[[3355 4450 499 14 2 183 1457 8609 2117 5 1018 33 26 6974 373 5331 4713 149 2 234]]\n",
            "targets[[13 1819 192 4 28 482 4 4804 10 19 22 7371 1108 8 23507 15 60 312 132 9]]\n",
            "targets[[20 25 23 2 234 445 0 567 3 720 160 728 782 83 28 2 415 18685 4665 453]]\n",
            "targets[[26685 12 84 806 5 35 5961 3 49 179 4 211 132 1796 47 88 1633 104 608 4130]]\n",
            "targets[[67 856 4 28 1520 33 0 5883 9379 33 0 63 3830 33 0 2420 18 56 0 109]]\n",
            "targets[[17 13 2 337 842 0 177 118 2 81 301 1 11063 9317 1197 54 50 28 2 53]]\n",
            "targets[[307 0 10214 339 3 10 19 1 6013 43 969 228 78 7 11 9 13 113 381 60]]\n",
            "targets[[5 157 49 848 995 47 6696 793 4 80 61 13 350 1 93 2 2707 44 3 2]]\n",
            "targets[[5 29 3 0 88 8489 1 1182 2643 1358 3 2363 123 5490 14 2 184 17 6 6]]\n",
            "targets[[678 2361 311 2069 311 2069 2015 2841 311 7918 2015 6 6 1681 2289 9742 2502 5683 22 0]]\n",
            "targets[[2 669 9264 921 340 16 108 154 9 874 4 830 44 17358 12 160 17 548 45 2]]\n",
            "targets[[13 0 84 57 577 2146 326 409 181 906 7 210 21 65 2 1405 19 38 0 3784]]\n",
            "targets[[5642 1 3331 790 25 8174 33 3672 8991 132 44 6960 29 249 1 579 143 4 2 10167]]\n",
            "targets[[20 148 2 340 3 0 544 16029 11390 94 10 17 5 401 164 4 11986 20 172 201]]\n",
            "targets[[84 628 5185 17 13 165 1678 7 785 127 573 977 18599 14 16 10 432 3 1223 7]]\n",
            "targets[[17 13 208 2 813 53 736 39 27 77 2 2998 82 98 92 15 634 2 730 13234]]\n",
            "targets[[6322 35 10205 12 19107 40388 2413 9280 3025 5 8 2331 3 1453 78 0 356 933 14119 26]]\n",
            "targets[[65 722 10 122 9 67 307 29 422 1 9 693 10 122 5 65 394 0 63 410]]\n",
            "targets[[307 7 51 7 13 84 12376 8 5247 1 307 31 30 175 1059 96 865 1 106 7]]\n",
            "targets[[2 666 243 119 1582 9 254 10 19 554 3214 1 15447 4 666 342 119 1582 23 4]]\n",
            "targets[[183 276 6788 4263 17543 2638 9552 2608 8 7945 261 16 26 425 1012 11254 5285 3789 282 8]]\n",
            "targets[[19 5 2 16411 3 4036 847 247 36 366 4 1454 0 9559 24187 17144 3 544 1916 4036]]\n",
            "targets[[25 322 202 23 42 848 202 3161 12504 710 3783 0 22948 3 202 142 14 0 3911 3161]]\n",
            "targets[[3 5951 501 13 2 938 2102 8 880 3287 9870 1688 24 5 2 1562 279 31 117 6]]\n",
            "targets[[84 3 0 173 274 2992 1644 31 26 88 11729 221 4 0 220 3 54312 26 64 122]]\n",
            "targets[[9 856 2 248 838 1940 2451 1110 3 2 2712 1192 216 1 35 1377 838 2451 1110 3]]\n",
            "targets[[13 1435 4 10 17 2229 4 66 87 32 27 3364 35151 20279 12 1758 673 9 196 11]]\n",
            "targets[[685 0 8124 11639 187 2 14781 5111 34 45 2 8258 22 40 5519 1 2 7407 19122 3938]]\n",
            "targets[[139 113 77 2 340 3 1588 4882 264 9 139 113 77 2 45428 352 10 17 654 100]]\n",
            "targets[[4 0 1214 10 5 29 3 0 733 250 104 11 9 139 123 110 6 6 23 11]]\n",
            "targets[[28 180 1221 15 20 9 140 23 65 78 184 98 31 30 152 9 288 21 1390 31]]\n",
            "targets[[19 5 38 35 8264 3 0 10943 7 45 142 1501 3974 1 2857 20 50 23 853 262]]\n",
            "targets[[307 2150 31 46218 4120 1 92 7 144 0 217 487 9 67 110 7 167 154 602 18]]\n",
            "targets[[13 2 706 245 340 3 2507 1873 1 2507 1873 3680 9 467 10615 1 26 355 0 3474]]\n",
            "targets[[5517 3219 3234 21149 5 221 4182 16 114 696 4 26 6017 1964 18 14 26 1376 635 2]]\n",
            "targets[[1203 5 0 250 122 9 27 123 110 22 246 123 1 9 106 2 171 3 246 7]]\n",
            "targets[[215 10 115 7036 10074 16 0 84 57 53 1059 22 29 3 146 2885 277 12 11 306]]\n",
            "targets[[17 83 138 185 185 8 472 14 29 3 0 7625 205 349 489 3 4167 3329 6756 1]]\n",
            "targets[[347 8 10 17 68 822 0 405 13 81 1306 18809 2152 2 822 237 14 527 5466 8]]\n",
            "targets[[13 180 853 0 250 19 9 139 123 110 0 109 159 21 93 2 217 171 3 266]]\n",
            "targets[[5 2 497 17 5386 0 189 11 7 12 370 3 3601 47627 1 12171 7 12 327 2]]\n",
            "targets[[125 10907 2 183 243 33 43550 3872 2580 8 40 1542 1 33 1057 40 15 1703 3872 8]]\n",
            "targets[[5 2 68681 158 3041 1115 8029 9 387 11 33 490 12 991 1645 0 2094 3 0 3030]]\n",
            "targets[[0 580 128 9 66 11 10 17 5 23 509 33 30 1 5 2 9758 69 424 17]]\n",
            "targets[[5 29 3 60 30 57 519 21 2165 202 0 64 430 9 27 5 11 7 5 56]]\n",
            "targets[[3 4926 5 270 22 66010 8630 111 2 522 3 668 331 25 919 7083 120 8 2 711]]\n",
            "targets[[928 18717 4036 104 27 113 65 226 2 217 171 16 71 18 3 0 3274 11 9 139]]\n",
            "targets[[71 875 33 674 9 89 21 38 184 98 9 89 21 367 3394 8 60 2073 9 89]]\n",
            "targets[[3 0 250 104 9 139 123 110 11 14903 4 28 43 2557 41 5957 56 870 7 12]]\n",
            "targets[[9 13 64 1408 60 373 1 324 1448 60 920 582 4 6 6 191 71 4 106 0]]\n",
            "targets[[255 34 204 23 121 47 2 29 279 17 13 38 10 5 0 117 502 10 109 5]]\n",
            "targets[[3367 2144 8 0 17 0 17 13 165 186 155 18 30 3367 3496 43 0 217 17 13]]\n",
            "targets[[12 2 3408 8 10 17 11 12 1262 374 7 562 740 0 129 51 7 12 2065 12562]]\n",
            "targets[[717 3 9165 31 0 366 5 1243 0 216 3357 0 2054 1170 59 776 205 143 23 4]]\n",
            "targets[[3955 4183 16 1225 6555 7 15 687 1278 1735 1935 142 14 0 5633 1418 1225 190 5 973]]\n",
            "targets[[5 2 17 11 1109 2 171 3 0 6038 3 2 975 17 0 289 1539 107 11 296]]\n",
            "targets[[2 2033 19 10 13 1221 16554 399 14 1305 2 216 34 635 313 14740 26 26 19922 114]]\n",
            "targets[[9 203 136 51 9 215 0 1561 9 13 2313 4271 1360 633 22 74 1801 2530 1651 33]]\n",
            "targets[[12 56 9185 0 84 13887 19 13 2 2128 2138 7 13 35 1470 3 2 1076 5687 1]]\n",
            "targets[[5 2 6384 16 0 666 88 1383 17 564 3 60 2732 594 412 322 153 9 215 4]]\n",
            "targets[[65 509 0 19 9 738 317 41 459 104 3136 1307 1 327 2676 60 19259 22 0 95]]\n",
            "targets[[3 0 81 179 43 0 2664 256 421 2 2540 3955 19 5584 1234 5 7 715 75 0]]\n",
            "targets[[213 9 27 4 870 2 291 41 105 167 381 78 149 2 729 202 2 122 784 4]]\n",
            "targets[[303 377 12211 117 355 2913 1 20649 1134 4 191 2 1282 4 6634 1978 32 25 39 32]]\n",
            "targets[[106 745 3 631 98 41 31 219 32 350 4 28 1 10 45 4 28 0 250 46]]\n",
            "targets[[9 67 42 110 0 1659 3 10 122 9 59 27 1281 7 2 163 9 13 1240 3382]]\n",
            "targets[[9 4847 22 0 8289 37716 4 198 71 35 321 3 87 49 2 17 5 9 27 4]]\n",
            "targets[[17 5 12704 33 2262 1 53 4814 536 7 12 79 13689 33 2 1000 109 1 74 116]]\n",
            "targets[[8178 2691 10 1086 15439 21 27 77 5941 190 15 0 4313 3502 992 1 638 11 5 663]]\n",
            "targets[[8524 5 29 3 60 519 102 156 37 9 470 1275 331 36 574 4 3210 8 189 9]]\n",
            "targets[[84 20196 17 13 4025 17212 10 190 5 23 64 2044 18 9388 6136 5 408 44 3 0]]\n",
            "targets[[17 285 52 38 137 1669 59 27 513 8 0 6560 7 79 27 0 6437 3 107 645]]\n",
            "targets[[0 10039 623 2829 6 6 111 29 623 157 747 6 6 10 5 2 26687 19 1471 1]]\n",
            "targets[[42 1779 149 10 835 1593 9 307 0 29000 277 437 1149 434 492 1 13 7107 4 66]]\n",
            "targets[[353 1305 4519 24 12 245 6388 1471 15 0 88 1598 23202 1 24581 9 139 123 7042 39]]\n",
            "targets[[335 387 10 17 45 2 360 678 128 18 133 9 198 7 2 163 44 3 163 134]]\n",
            "targets[[5 2 1509 1264 19 427 718 2 703 16430 1264 202 0 202 2191 3448 22 1084 2480 18]]\n",
            "targets[[140 23 2 543 41 35 3965 9 140 42 2 1395 11 45 110 10 17 173 228 602]]\n",
            "targets[[6786 484 0 2401 12611 3 3922 2317 1 4843 786 9747 5 8136 282 175 445 444 3 520]]\n",
            "targets[[2575 26 17 8 1051 573 3 47 2 17 59 168 38 22 2 341 3 163 6942 1]]\n",
            "targets[[0 154 9 27 110 284 6205 2096 1 961 8 30 2672 3 2783 3661 1 8 10 434]]\n",
            "targets[[13 73 126 72 9 67 7231 8 48 741 7 67 2 126 63 72 211 3 0 82]]\n",
            "targets[[637 5 43 87 460 75 25 452 1 1777 16 30 316 689 174 670 3053 8 10 19]]\n",
            "targets[[42 1059 307 10 22 0 6113 1234 0 321 16 0 19 13 4 704 108 1035 17196 8]]\n",
            "targets[[17 13 23 1093 41 155 42 2 647 1924 22 0 214 7 236 27 77 196 2901 16]]\n",
            "targets[[42 110 2 6137 2239 2628 2 363 3 1816 602 1 147 256 110 0 160 277 9 50]]\n",
            "targets[[122 269 55 15 212 1908 14 688 14 0 1899 1234 7 5 5002 14 625 18 8 11768]]\n",
            "targets[[5 29 3 0 88 871 98 9 27 15932 4 76 144 9 140 23 259 4 28 1799]]\n",
            "targets[[6 427 22 0 6647 1487 304 3 0 170 412 12800 2242 5 0 755 11 116 81 2992]]\n",
            "targets[[35 2538 17 0 116 13 6435 3264 1 612 1 0 935 224 13 3920 10 17 40758 36]]\n",
            "targets[[12 227 626 5 2 737 5537 9976 19 9 242 2613 11 0 19 5 8084 14 2 201]]\n",
            "targets[[3 0 81 3830 17 3 0 3988 10 2 145 436 15 91 876 36 142 2 19846 0]]\n",
            "targets[[5 401 29 3 0 88 212 274 4 106 39 25 745 3 3599 274 44 39 18 10]]\n",
            "targets[[67 0 1421 3 318 10 19 31 0 1351 19 1322 1 14 9 2164 55 8 0 3392]]\n",
            "targets[[42 654 3106 1 9 139 67 2 2533 227 105 154 1 9 139 77 244 3 4012 566]]\n",
            "targets[[0 115 13298 454 506 10 5 2 17 15 2 53 2409 366 11 623 55 1225 247 27007]]\n",
            "targets[[12 5 1891 2 378 458 15 0 1254 36 40 1496 132 4442 40 324 12 2509 328 11]]\n",
            "targets[[2 945 11591 5 516 8 2 1666 1988 26 12766 2861 812 5847 3450 27390 3367 150 21 262]]\n",
            "targets[[2 4083 896 19 43 35 5279 814 1832 7795 34 2 522 3 276 2773 4038 34 24 329]]\n",
            "targets[[140 65 22 0 8062 43 10 17 152 0 580 5 397 1 25146 7 5 404 7123 33]]\n",
            "targets[[13 155 5434 9038 15 3598 3 7191 18 469 79 29 3 146 354 1400 274 8 0 4128]]\n",
            "targets[[1591 10 19 85 3 5019 25251 34 118 142 2 81 301 8 17046 83 847 9 242 79]]\n",
            "targets[[2117 14 2041 1170 515 14 2 5074 396 16 2603 246 1554 11 12 2214 13133 6252 24 5]]\n",
            "targets[[2815 966 7622 124 23 121 87 4 488 3843 6676 274 10 5 3843 6676 2348 0 145 122]]\n",
            "targets[[8292 10 17 120 0 4229 31 2707 14 9 140 2 340 3 27902 12 6963 102 0 82]]\n",
            "targets[[247 9 418 15 694 355 4 2 5862 4804 816 3 10 19 70 389 4 66 263 29]]\n",
            "targets[[646 1319 779 46 20 50 76 501 0 12828 689 20 148 8 16 2 145 1737 6 6]]\n",
            "targets[[17 5 29 3 0 53 117 1312 98 187 7 45 2 49 735 349 15 2 49 2188]]\n",
            "targets[[289 996 4 66 773 769 25 2743 11962 34 1527 2 4321 237 1 47522 17240 34 5 397]]\n",
            "targets[[5 2 1563 120 3 478 2124 338 98 38 2113 1 9 121 47 20 118 227 1606 0]]\n",
            "targets[[1869 5 2 5597 3084 259 4 956 78 863 8 0 227 3 1809 35729 2 7389 19 36]]\n",
            "targets[[6 6 68 32 259 4 586 57 1 19 6 6 39 784 4 28 108 52 3478 199]]\n",
            "targets[[964 27 1760 48 7358 15 10 19 23 64 5 29 3 0 1536 3468 825 8269 3 258]]\n",
            "targets[[6827 10 17 15 48 17874 264 2213 5 4 28 12495 16 107 186 73 0 64 640 8]]\n",
            "targets[[215 10 397 17 4120 1 9 552 395 7 9 1830 144 0 442 17 15 2 1778 47]]\n",
            "targets[[4652 2220 167 318 10 14 30 0 829 9 353 3 10 300 7 13 497 9 1591 7]]\n",
            "targets[[7 288 21 16 0 189 11 0 893 1 619 789 67 4626 4288 1 194 25059 10229 32]]\n",
            "targets[[884 2 363 3 798 22 4176 5710 469 23 53 155 9 27 92 35 778 4 8946 22]]\n",
            "targets[[2038 751 3073 14 3558 36268 44017 36 26 3284 18257 0 32051 3 4049 6402 601 8088 14 2865]]\n",
            "targets[[72 17257 10 122 9 207 42 136 9 13 244 3 671 107 2 222 3 2 340 3]]\n",
            "targets[[9 68 20 9 59 1812 11822 223 1 138 2568 4 10 337 115 1594 9764 10320 165 118]]\n",
            "targets[[83 366 10 120 33 674 9 420 21 76 30 0 95 144 7 9 1690 7 55 22]]\n",
            "targets[[5 0 117 1206 5834 260 1470 9 139 123 110 14 525 14 9 215 7 9 418 44]]\n",
            "targets[[42 215 10 22 3685 8 0 178 3896 10 19 5475 20 1 2437 20 349 0 655 5]]\n",
            "targets[[852 0 9765 25 428 4 10884 0 708 84 32 535 8 2201 4 10884 105 1476 11764 120]]\n",
            "targets[[13 29 3 0 88 11126 3773 1 684 6418 3 0 104 9 27 123 110 0 5096 3]]\n",
            "targets[[195 4 66 10 42 10 227 2069 31 0 2961 3306 19 1322 31 12 22 4166 10 17]]\n",
            "targets[[0 84 2128 2683 3 0 6335 3184 29993 227 311 31 35890 1351 6 6 5518 5309 20336 1]]\n",
            "targets[[7033 5 29 3 146 2534 120 1445 8233 1412 11 20 211 596 174 147 1 175 427 187]]\n",
            "targets[[64 13 0 109 3 10 19 1962 15 0 4680 8 61 0 105 12711 25 482 4 6018]]\n",
            "targets[[2 168 31 0 5417 3 780 37223 22 10 2147 2 371 1923 1 4692 2123 34 45 1651]]\n",
            "targets[[215 10 19 227 311 31 0 49380 8 1351 650 7 1982 21 77 642 16 3008 154 1123]]\n",
            "targets[[1347 3 13254 23333 1109 1566 5382 4956 23333 7865 26725 14 54 3658 36 3345 4 8802 8 1647]]\n",
            "targets[[44 3 17322 57550 59915 60098 63701 68125 5 2 88 1348 19 44 3 2412 7 1109 2 1566]]\n",
            "targets[[255 65 106 10 1896 46 7 159 21 2924 115 423 621 187 2467 36 2 1356 220 3]]\n",
            "targets[[232 987 11 99 884 48 407 5237 43 584 34869 12 1356 339 9 13 53 3693 8 189]]\n",
            "targets[[0 17 5 1034 184 882 832 827 15 2 53 583 1588 1770 757 10 17 1527 3904 1558]]\n",
            "targets[[2 2378 460 276 9 203 136 11 10 17 5 2 901 2459 11 3776 2 3630 1152 3]]\n",
            "targets[[11687 863 1485 3248 1515 5 2660 4 76 5584 8 0 1274 979 19 7158 134 96 127 9233]]\n",
            "targets[[8 10607 15 91 17089 5784 239 6513 412 204 376 15416 22 2 202 3 1089 3534 1618 1]]\n",
            "targets[[864 3 4 28 594 8 0 1054 443 6 6 39 25 23 108 1054 104 8 0 227]]\n",
            "targets[[1018 5294 31 0 2789 7377 19 1322 1 13 53 1520 9 203 136 9 140 23 31 30]]\n",
            "targets[[3376 5 542 16 107 2 81 181 17 314 751 12388 5 542 16 107 2 81 181 153]]\n",
            "targets[[5 245 4 993 2 17 11 5 37 74 18 133 50 28 53 1121 0 109 392 5]]\n",
            "targets[[442 2850 11106 63 5 2 605 14101 7 5 4558 6513 0 225 5 336 7 5 3945 8]]\n",
            "targets[[29 3 0 88 5716 3440 8 19 472 33 7585 3 91 19273 6497 4 2147 0 361 392]]\n",
            "targets[[693 51 9 1690 55 0 889 11 7 59 28 2 186 74 17 133 9 470 4 66]]\n",
            "targets[[7 12 2 1587 155 17 31 214 4 4248 70 139 30 555 43 18975 12034 12 11317 38847]]\n",
            "targets[[247 1799 22063 7773 725 15 4529 1 3208 811 0 7875 5 2 1348 19 132 7 1449 0]]\n",
            "targets[[105 3778 9493 1711 15 2 936 25 143 4 6411 2714 24895 253 82 1 62 1674 3622 18]]\n",
            "targets[[43 9751 0 803 10 3468 637 5 42 2 742 3 1397 2993 1 27863 111 1105 1862 5]]\n",
            "targets[[307 10 17 15 2 522 227 311 34 5 1082 15 23268 1317 9 230 0 17 118 23268]]\n",
            "targets[[140 213 261 16 2 49 2301 328 1212 487 1 9 27 4 136 9 723 21 110 2]]\n",
            "targets[[50 28 2 261 2844 4 66 0 176 8 2 160 615 49 311 1 49 1985 16 1895]]\n",
            "targets[[50 186 73 2231 2309 36 0 82 4222 798 128 56 365 4 7130 7 30 175 46 39]]\n",
            "targets[[99 884 2 363 3 829 22 6391 0 400 3170 9 42 182 4 731 55 48 10465 14]]\n",
            "targets[[880 10536 5 53 73 2377 8 57 132 7 124 27 2 742 3 81 760 1 1358 0]]\n",
            "targets[[2 360 341 184 10 17 3796 55 357 0 227 315 541 61 19646 392 3 0 11719 4061]]\n",
            "targets[[262 11 16 1051 3359 1 2 115 4574 10 13 8873 4458 12 117 166 1 16 71 67]]\n",
            "targets[[2822 3 7119 5 29 3 0 1536 10103 9678 1 88 3294 1256 3 258 57 37 73 37]]\n",
            "targets[[0 544 10191 1128 2 1605 928 5180 6484 0 13890 23 869 5989 38 2 10531 3 2145 461]]\n",
            "targets[[107 2868 19940 1 1881 48 49 347 3960 36 705 279 1574 14750 10 19 5 2 5339 134]]\n",
            "targets[[10 5 29 4752 55 17 9 481 9 141 27 856 11 15 238 2523 2406 4 584 6853]]\n",
            "targets[[80 23 353 10 46 20 103 43 149 11 17 264 7 59 28 2 453 3 57 33]]\n",
            "targets[[1059 672 149 10 122 1 9 27 4 136 11 7 65 92 71 449 20 27 4 1124]]\n",
            "targets[[19 5 37 37 11233 7 4069 20 8 36 0 84 463 5874 1 94 923 20 164 1]]\n",
            "targets[[0 1450 3 0 234 36 14107 500 1082 7 141 11 12 85 9953 31669 34 1065 0 877]]\n",
            "targets[[23 53 404 11 9 138 4 0 170 17 1593 132 7 12 8 0 2177 18 10 29]]\n",
            "targets[[3 0 829 9 139 353 3 2726 2142 27 77 10759 5073 9 139 110 88 174 422 1]]\n",
            "targets[[19 5 42 2 362 433 452 477 11685 5 42 0 3432 4 76 75 4 66 7 18]]\n",
            "targets[[425 1 545 68 149 0 1591 1972 6 6 99 1889 0 1972 1 149 0 4024 3 440]]\n",
            "targets[[3 0 5910 306 334 72 85 10 5 1034 947 15994 882 14183 1 5476 18 682 7 150]]\n",
            "targets[[2 1083 14099 974 63997 20726 15 35 1524 3 28572 6509 14730 83 2210 1288 440 2411 16 117]]\n",
            "targets[[48 75 25 5303 43 0 608 3 109 190 39 5 2 109 2 849 29 18 416 7]]\n",
            "targets[[17 13 2 297 9730 4 106 9 89 21 121 134 7 5 110 33 48 14 35 1815]]\n",
            "targets[[2297 7 12 542 14 34 10188 3083 8 764 7 12 542 14 0 466 5062 18 445 100]]\n",
            "targets[[12 64 29 151 9 140 164 4 136 43 1161 8 0 2798 14 2 362 17 1 2]]\n",
            "targets[[289 293 11 9 1291 10 17 13 11 2121 7166 5 60 88 3022 847 6303 14 69 9]]\n",
            "targets[[38 10 19 109 0 63 5 65 49 7 274 87 2 403 5 259 26 117 4 3187]]\n",
            "targets[[141 23 1797 62 385 423 4 106 36526 100 52 72 32 141 1797 90 4 106 10852 1033]]\n",
            "targets[[7470 3406 714 970 1042 218 571 8 35 3267 936 6269 109 11 747 51 35 158 425 3]]\n",
            "targets[[87 32 2805 20 205 44 3 127 333 0 17297 1993 817 5 29 3 0 368 74 104]]\n",
            "targets[[140 251 108 3076 68 1066 235 10 18 32 65 1525 21 27 2597 6 6 0 116 288]]\n",
            "targets[[1294 3727 0 244 3 1048 1088 11 5 3678 8 443 257 36 0 3239 39 13 0 249]]\n",
            "targets[[213 196 11 3 30 0 959 2183 992 1 0 2140 559 0 3938 16 107 29 3 0]]\n",
            "targets[[140 23 627 29 4 18342 2 19 9 350 4 66 0 49 753 1 23 1127 22 0]]\n",
            "targets[[0 114 3 71 9 50 21 387 47 75 66 8 10 19 9 215 7 31 0 6181]]\n",
            "targets[[194 49 2069 5 43 2 1665 748 3201 15511 34 45 8745 30 6826 67033 38810 15 2 4277]]\n",
            "targets[[4048 8 60 660 5 0 872 153 123 24 784 56 9482 1509 200 748 399 41 1476 2885]]\n",
            "targets[[20 148 2 340 3 19 1471 1 103 32 89 21 93 2632 38 32 329 4 128 5]]\n",
            "targets[[109 2389 101 1 56 1731 1053 0 64 293 7 218 2 275 8 60 298 5 85 9]]\n",
            "targets[[416 631 8271 2702 15 1007 36 1721 75 4 6467 75 27962 1934 302 265 22 2 29151 1934]]\n",
            "targets[[20 723 21 110 4914 12979 36 0 246 122 1702 328 4309 94 20 25 973 44 4914 5]]\n",
            "targets[[9 1591 7981 9 13 856 7 4 28 53 1000 9 722 104 11 27 65 6206 826 1]]\n",
            "targets[[13430 13859 0 11664 5 2 26774 3 1356 540 1101 4 10 39632 166 0 3486 1 29 3]]\n",
            "targets[[84 969 228 3 23590 67 60 4044 23099 22 0 2727 20921 4 487 187 4 106 137 332]]\n",
            "targets[[2725 4054 13 24178 33 0 116 1506 790 18272 4 1652 26 953 3221 3 0 116 3373 3]]\n",
            "targets[[4595 4945 29 601 21024 4945 29 18 947 17909 17314 23 4 89 0 2432 24372 10402 9 419]]\n",
            "targets[[418 4 0 5722 128 8 16320 9 6417 16 850 1 15 355 873 9 241 569 21 27]]\n",
            "targets[[1018 10 539 354 31 2507 2786 227 1606 1 94 16722 7 31 2253 7 64 195 126 0]]\n",
            "targets[[5 60 2919 908 29463 354 11 9 139 110 1 37 229 0 1536 29 8 10 29 908]]\n",
            "targets[[5 29 3 60 519 2197 2529 98 58 152 7 12 37 615 1 10237 7 188 1632 4]]\n",
            "targets[[3362 8514 1333 436 15 48 155 305 290 9 603 38 7 51 32 278 2 1026 4460 8]]\n",
            "targets[[556 55 80 23 353 10 738 46 20 148 16476 4 66 10 17 6 6 160 4 2304]]\n",
            "targets[[215 10 15 48 355 31 0 69693 19 1322 8 4031 3752 1 70 30 467 7 10 5]]\n",
            "targets[[203 987 60 84 1461 13 7 59 28 42 16 362 9 13 3381 770 42 87 73 3]]\n",
            "targets[[336 460 1223 0 203 630 17 9 27 123 307 7 13 37 3470 1157 11525 1 37 838]]\n",
            "targets[[411 3 0 11469 12 5308 45 30 0 756 11 25 1687 8 643 4 93 35 1097 3585]]\n",
            "targets[[17 1015 22 108 2056 0 109 5 684 21274 0 1419 709 21 3699 0 450 5 12780 161]]\n",
            "targets[[286 1067 128 11 85 10 13 645 8 1728 14512 7 801 11 7 141 28 74 11 5]]\n",
            "targets[[17 1252 5165 959 802 275 3 0 176 12 872 2914 2585 4 0 260 32 2207 775 0]]\n",
            "targets[[242 157 29 34 6654 10 397 369 51 9 13 2 493 9 79 67 0 177 4661 9]]\n",
            "targets[[42 37 7 22 277 147 6 6 35 591 225 267 4 453 22 6690 361 676 61 25]]\n",
            "targets[[215 0 176 3 10235 31 0 6181 2004 19 1322 1 1865 509 7 128 70 27 2 2471]]\n",
            "targets[[2546 5 379 18 5333 13 2 7435 5079 5190 243 34 67 40 568 516 16 5936 281 4]]\n",
            "targets[[136 9 97 329 4 103 7 13 5311 18 23 1557 38 314 2520 12 287 11 28 127]]\n",
            "targets[[20 38 32867 20 27 56 321 47 20 148 973 46 20 723 21 110 10 19 239 10]]\n",
            "targets[[993 10 163 44 3 163 134 6 6 7 1564 2627 78 137 9 1184 387 0 11238 7754]]\n",
            "targets[[17 7256 2 2833 434 3 2 522 3 75 12 451 2481 33 536 9 50 21 136 11]]\n",
            "targets[[20 65 365 4 121 43 10 17 269 99 0 653 130 111 2 216 724 78 2 1993]]\n",
            "targets[[5 42 0 244 3 63 2 234 38 71 59 38 4 28 482 4 380 56 589 178]]\n",
            "targets[[107 2 880 340 3 11540 22917 9 13 8 56 7597 4 66 10 17 18 470 4 66]]\n",
            "targets[[26346 5 35 2801 243 1393 1382 1 53 23168 464 107 37 19988 14 4 3785 22 16108 54]]\n",
            "targets[[139 404 24314 61 266 59 9 248 1569 1826 41 2206 9 67 874 1826 59 28 0 29]]\n",
            "targets[[13525 788 38 2 834 8 1647 3 2 109 1255 20382 12 35 1171 2786 125 34 12 9662]]\n",
            "targets[[1522 3 17 2626 107 10435 2072 296 3 12398 5 23 208 803 8 189 7 12 52 297]]\n",
            "targets[[17 426 45 0 756 0 109 5 1562 1 807 5 1349 0 5538 5 2167 15 2 171]]\n",
            "targets[[139 110 0 84 3 0 5226 98 1 533 9 67 115 247 149 7 39 25 108 836]]\n",
            "targets[[89 21 1111 703 239 51 9 254 545 8 14256 16 29 311 15 161 4 80 9 1712]]\n",
            "targets[[152 0 19 50 113 65 351 0 3647 3 91 197 10926 490 0 9810 4407 0 176 7935]]\n",
            "targets[[215 10 19 31 0 160 728 1322 227 4031 1 13 1520 33 0 3424 3 0 1405 15]]\n",
            "targets[[215 0 206 22 246 154 602 51 9 13 2 527 0 17 67 4 28 1977 185 16]]\n",
            "targets[[424 10 17 9 13 42 20820 144 60 4278 51 9 215 2743 29112 9 693 40 36 0]]\n",
            "targets[[30 98 1 9 140 2 19 6620 46 11 12 273 238 4 20 10 5 0 250 17]]\n",
            "targets[[10 5 2 49 17 0 116 288 21 49 31 30 18 46 20 168 31 48 375 8]]\n",
            "targets[[215 10 17 14 172 3 2 202 3 104 2003 15 0 231 56 7 288 21 14227 33]]\n",
            "targets[[9 353 0 82 798 159 21 103 7 2902 100 49 18 874 4 1972 7 566 376 23]]\n",
            "targets[[3 30 287 71 42 136 11 99 816 10 19 9 618 196 43 503 60 197 877 85]]\n",
            "targets[[402 318 10 17 8 5582 51 246 11935 8 3345 13 13133 0 466 422 3 91 158 377]]\n",
            "targets[[5 2 497 497 778 18 805 7 5 79 180 413 39 25 105 2672 3 832 827 49]]\n",
            "targets[[38 108 82 75 215 0 3566 339 3 10 9 254 7 437 607 5118 0 9148 607 798]]\n",
            "targets[[5 2 3721 1340 19 11 162 20 230 14 152 20 27 1066 35 2269 15 1348 1093 2218]]\n",
            "targets[[859 6850 1 1719 1288 242 239 4 387 134 91 23 38 0 156 8 0 17 118 100]]\n",
            "targets[[232 586 60 938 5313 16 39620 5515 18 128 5 60 10145 15 2198 3471 6 6 0 653]]\n",
            "targets[[37 2 171 3 798 9 139 353 22 10 19 27 446 7 323 5 10 2 1924 3]]\n",
            "targets[[17 1020 223 163 308 463 399 16 0 234 9 140 767 9 140 4883 9 103 186 234]]\n",
            "targets[[5 2 186 1194 2386 12 34 226 7 29 11 406 55 0 6247 43 223 29739 3 0]]\n",
            "targets[[43 735 3113 2861 2367 193 252 33 1549 56937 46266 29 2 5890 1 29 8 1061 499 120]]\n",
            "targets[[12 2 27504 8 14539 6 6 60732 6 6 7 801 179 1100 66 15 127 531 25 15002]]\n",
            "targets[[19 2270 2544 22 2 10445 584 2005 14 2 4079 6454 1927 1 0 75 34 27 4 278]]\n",
            "targets[[5 60 1504 519 17 1306 13375 1 5234 29332 198 1492 347 0 716 13 1094 734 1 1010]]\n",
            "targets[[18149 5 23 2 737 24867 19 8 0 266 3 1425 2834 4747 511 18 29 151 5 16]]\n",
            "targets[[9453 13 840 29 3 0 88 323 1396 4 1656 0 17 260 1287 7735 204 27 67 0]]\n",
            "targets[[467 10 17 7 12 208 2 813 83 1190 12 117 1166 3772 13 53 49 97 46 20]]\n",
            "targets[[27 4 987 9 13 2674 240 33 3098 4676 3471 485 3 0 3303 9 242 23 627 2]]\n",
            "targets[[2272 20 402 51 20 300 10 6 6 350 4 169 0 2606 3 219 6561 1 359 7]]\n",
            "targets[[11 10 17 45 2 171 3 480 707 2346 9 103 7 141 48 52 1095 72 7 45]]\n",
            "targets[[5 5183 87 4648 10730 50 50444 10 32774 155 17 685 5725 1 6480 1681 304 120 1329 433]]\n",
            "targets[[17 13 23 47 9 856 9 856 52 40274 1 6972 52 116 8 643 4 383 71 899]]\n",
            "targets[[19 3032 4 10205 10994 477 3528 12934 2393 7187 1 1493 2477 704 2 115 116 13199 4 63]]\n",
            "targets[[834 3 35 2145 276 619 6559 8 0 687 2603 484 13 1403 18 161 332 8 10 19]]\n",
            "targets[[2 670 74 10 45 30 0 756 3 2 934 226 471 17 5935 839 1379 101 2799 655]]\n",
            "targets[[436 1 556 3 567 63 1159 850 75 3 1361 8 1689 2973 299 160 5094 499 120 565]]\n",
            "targets[[19 45 221 56 3720 7 5 0 3468 2906 17109 13733 3 35 15488 6997 44 29 57 272]]\n",
            "targets[[221 280 38 4908 2860 852 886 0 12742 3 0 2799 1890 24 252 16 2 794 3 8969]]\n",
            "targets[[17 5 29 3 0 117 18642 3 2 1312 3137 11 9 27 123 110 1 239 88 75]]\n",
            "targets[[215 10 17 1059 85 2 425 802 7 15 86 36 4569 99 969 228 9 300 4 86]]\n",
            "targets[[16 2 19 11 188 4 28 259 4 2402 392 14 2 184 39 13 2 5077 608 3]]\n",
            "targets[[333 11 10 428 5417 3 1694 2836 1837 4249 3175 5 1085 1088 2 1369 1647 3 26 12545]]\n",
            "targets[[9 140 532 3 3566 1 908 1441 16262 87 32 59 112 10 17 416 7 12 65 65]]\n",
            "targets[[17 5 157 1387 12799 3491 3 1188 1547 0 1235 5 52 13524 72 0 653 3 8042 18]]\n",
            "targets[[13 97 12546 4 811 462 135 245 4 66 6 6 67 49 63 344 97 74 7 195]]\n",
            "targets[[5 29 3 0 88 4025 74 98 9 27 123 67 0 9563 4 66 6 6 9 307]]\n",
            "targets[[548 16 81 347 22 6996 32 27 802 178 157 1594 8 0 824 3 663 2106 2322 54]]\n",
            "targets[[23610 10 940 20 25 12033 4 0 1315 2982 44 8 258 13519 2571 127 12266 203 28 127]]\n",
            "targets[[64 67911 199 3156 1 10 432 3 4525 2903 25 0 2494 0 1360 1617 2282 6 6 469]]\n",
            "targets[[32625 5 2 480 279 543 1 153 18 272 2 19445 5716 4 191 35 321 1095 16 2]]\n",
            "targets[[4 837 134 2 522 3 75 59 19330 4 2249 10 9 42 307 7 22 957 3136 667]]\n",
            "targets[[735 128 5 134 10 2271 385 201 45 77 3481 33 88 1502 1 45 1201 4 169 0]]\n",
            "targets[[2909 538 162 2 33000 778 4 4576 120 40 9552 15616 186 243 3335 15 10 30546 28791 2546]]\n",
            "targets[[1 2217 1214 363 8 791 10 13 0 4214 3462 1901 529 71 18 9 418 1404 1 307]]\n",
            "targets[[4267 6 6 9 89 21 121 46 1259 0 2279 1554 1765 55 4 3075 4712 18 7 12]]\n",
            "targets[[22 0 17 12 153 520 66244 12 298 43 0 145 114 697 3113 0 176 12 84 1218]]\n",
            "targets[[9 42 470 4 136 11 9 467 0 17 0 271 15 0 12611 626 13 42 81 9]]\n",
            "targets[[449 44 1326 375 1 239 23 2 201 9 603 424 0 9434 3408 3 0 11145 28031 0]]\n",
            "targets[[13 29 3 0 250 1 8714 98 9 27 123 307 1 335 10346 100 530 3 271 13]]\n",
            "targets[[3434 8005 2481 0 2294 11 13 40 812 31 0 129 3 0 84 17 147 54 12 5214]]\n",
            "targets[[5348 5 1887 14 35 6280 183 243 2 28367 5900 4 26858 3090 34 5 8591 33 2 817]]\n",
            "targets[[11 5 155 208 107 3484 16673 45 2 1228 7833 43 283 276 36 7263 4 11984 6931 18]]\n",
            "targets[[1264 3529 1075 730 756 4 13399 12 94 1424 8 0 1718 1521 1464 468 7079 23759 1 982]]\n",
            "targets[[17 5 565 1 774 0 189 11 20 121 87 7 623 162 7 58 447 7 188 38]]\n",
            "targets[[17 5 23 16 0 849 3 333 0 109 5 1293 9 402 884 829 11 329 683 38]]\n",
            "targets[[10028 5353 13 2 19 3176 2117 92 427 718 0 10280 3 0 2401 5802 917 2089 207 2100]]\n",
            "targets[[243 28665 2 396 4 10 176 1 13 624 32 193 68 624 85 2 396 67 2 3196]]\n",
            "targets[[3794 1 185 205 10741 1470 4 0 368 423 12 755 23 64 1449 0 1438 3 91 18]]\n",
            "targets[[143 8 5962 9 215 10 19 31 0 443 16 0 84 57 7 13 35 1136 564 8]]\n",
            "targets[[8689 1 2314 3567 9125 99 1363 17941 1 402 0 311 4 314 8 10 81 1611 19 61]]\n",
            "targets[[0 17 67 42 77 43 2 125 1 2 243 256 35 1620 99 62 5452 84 67 35]]\n",
            "targets[[1654 8126 4303 175 15 10 0 65169 3 30 5539 231 104 10 6116 4404 4789 5 2 972]]\n",
            "targets[[65 470 4 38 10 19 9 371 118 0 177 465 322 264 0 7010 3 7241 141 27]]\n",
            "targets[[140 641 16793 233 9 140 8 0 19 14 0 2976 1837 15 0 16710 1248 18 58 3315]]\n",
            "targets[[17 5 23 427 22 0 3587 7 335 866 3679 44 3 0 17 32 80 23 122 0]]\n",
            "targets[[17 5 822 9 89 21 103 255 546 1669 96 27 92 142 1204 44 3 2 330 652]]\n",
            "targets[[41 334 283 2611 8 0 3887 4009 50 28 10617 4 0 4340 8 1600 0 1241 290 25]]\n",
            "targets[[203 27 77 137 8 0 1026 31 0 1139 111 10 29 13 92 87 332 4 1283 29]]\n",
            "targets[[12 53 871 4 21929 2977 22 35 19323 3410 208 2257 62 3370 577 38083 118 2 539 301]]\n",
            "targets[[47 9 215 8 16616 7 732 11 3006 384 5056 3166 13 478 180 6032 8 0 407 1820]]\n",
            "targets[[3 0 88 374 104 9 27 123 110 9 793 4 169 35 1401 16 0 153 3 0]]\n",
            "targets[[5 2 49 680 15 48 53 1618 135 7 6152 440 212 101 61 9 254 186 841 601]]\n",
            "targets[[857 92 8 2 897 940 5 437 297 479 127 1245 120 9 65 424 714 15121 1 191]]\n",
            "targets[[27 126 19253 5797 33 235 7 14 2 6 6 1138 782 422 3 0 3270 4521 97 73]]\n",
            "targets[[2594 471 869 8 0 4782 314 202 3 2651 1802 92 8 0 969 12 47 695 10 29]]\n",
            "targets[[5226 559 2 115 57 4 76 78 1127 18 282 7 118 39 68 173 274 11 5305 7]]\n",
            "targets[[80 23 76 7 134 25 37 108 75 10643 4 651 10 19 0 250 19 123 46 7]]\n",
            "targets[[19 67 2 363 179 164 16 7 7 5 576 11 48 53 1031 75 67 2 495 8]]\n",
            "targets[[74 19 15 714 7296 1 8563 1873 1156 62 1196 5 43 684 3330 10 5 428 4 28]]\n",
            "targets[[942 11 2 171 3 75 165 509 1363 739 11 91 153 13313 13415 5 2 1031 1 245]]\n",
            "targets[[2483 637 19 2775 302 2 115 158 125 944 16 878 0 125 5 3228 1938 32 854 1158]]\n",
            "targets[[6621 588 317 44 3 163 46 20 182 2 4214 3 47 13 356 15 108 98 8 0]]\n",
            "targets[[624 223 9995 2215 174 1235 3 0 206 208 2679 238 160 41 155 0 109 5 634 0]]\n",
            "targets[[27 4 136 9 475 467 0 17 7 67 7 12 155 375 48 6193 510 42 30 187]]\n",
            "targets[[45730 56 3176 41 2303 3 176 11546 204 710 28 0 117 8373 17 123 60 481 5 11]]\n",
            "targets[[5 2 3630 17 9 203 136 469 9 64 195 4 106 7 22 2 385 336 246 18]]\n",
            "targets[[2 130 11 50 64 28 2208 14 2 432 3 17 235 0 501 930 1 665 3 2]]\n",
            "targets[[13 283 10 210 21 7 67 1069 1560 1 156 34 1189 21 1660 4 8390 0 1425 7]]\n",
            "targets[[5 55 15 10828 27238 10 122 7 13 0 1931 9 424 283 43 7 46 255 5128 46]]\n",
            "targets[[29 1573 3147 31 10 4222 798 878 344 1 2448 184 1116 443 9134 1240 121 47 530 3]]\n",
            "targets[[2 222 3 2 832 827 340 9 13 65 261 931 4 318 10 17 87 671 13 9]]\n",
            "targets[[19 1020 2 163 16 91 539 1110 3 0 176 14 2448 8 0 333 3 2 5152 132]]\n",
            "targets[[27 213 467 0 757 1 412 717 4 10 19 0 19 392 5 64 815 31 117 0]]\n",
            "targets[[9 242 715 0 19 459 44 3 163 42 85 3 0 224 1 48 47 1562 30191 655]]\n",
            "targets[[106 10 19 36 366 4 1454 208 10580 78 2244 31 48 220 3776 221 35 486 3 2219]]\n",
            "targets[[3 0 108 2183 36 0 483 51 5569 3982 13 0 351 2386 5510 1084 314 152 7229 4292]]\n",
            "targets[[1974 680 43 2 10611 243 34 45478 30 146 54 1480 1285 8 643 4 8181 40 2039 2619]]\n",
            "targets[[75 118 23 864 47 32 68 585 33 0 1893 1 0 1253 2649 0 394 697 22 5746]]\n",
            "targets[[67 353 0 298 282 167 51 7 13 84 645 9 67 79 353 3168 3347 61 9 509]]\n",
            "targets[[348 348 6 6 533 9 138 78 2 19 23 1716 4 28 39 41 15 1517 1689 24549]]\n",
            "targets[[2911 144 0 905 9 195 37 1018 55 8 377 1 60 4966 11 9 159 21 942 11]]\n",
            "targets[[14 275 1890 8 5516 111 9 1291 0 277 275 7220 5 35 25225 184 19 38 4585 3079]]\n",
            "targets[[3493 16 52 16 52 638 8 142 2 19 0 156 581 38 32 148 1424 36 116 713]]\n",
            "targets[[1046 15 0 388 34 136 11 30 1828 1066 141 28 92 1367 11837 9 1991 16 2 277]]\n",
            "targets[[12 56 589 32 1296 0 1621 8 0 412 3 10 662 4 19837 1 19837 223 7 45]]\n",
            "targets[[2 340 3 98 38 1021 5238 111 12 26632 3880 9 215 10 85 7 13 1067 17262 8]]\n",
            "targets[[140 1298 4 66 142 35 1094 4042 1 239 6461 729 202 1056 128 8 2930 0 102 3]]\n",
            "targets[[5656 3325 1807 261 38 24 12 42 4959 43 105 2497 200 38946 4534 313 31 0 10675 3792]]\n",
            "targets[[2 1568 3 275 547 0 311 6353 1455 14 29 3 0 117 184 22576 123 763 0 84]]\n",
            "targets[[7065 838 838 686 2709 6 6 1 2877 97 338 31 91 88 8405 1 5079 6 6 0]]\n",
            "targets[[17 5 10759 4179 8 0 1204 10252 2154 1518 1 520 3406 1635 36821 1635 36821 8 0 18034]]\n",
            "targets[[5 241 0 11187 19 9 27 123 110 7 5 0 63 3 35 2089 1 275 3 26]]\n",
            "targets[[20 148 12750 8684 1973 94 10 378 5 53 617 0 3374 3 0 378 5 0 798 92]]\n",
            "targets[[656 9 67 60 2255 281 143 36 10 432 3 1223 37 9 96 18483 7 4 0 346]]\n",
            "targets[[4 22 0 474 10 725 43 9051 22 4758 560 724 354 3 0 309 368 8 1315 3]]\n",
            "targets[[17 45 81 399 8 62 881 154 4662 113 581 16914 14859 15062 13 2 53 1119 1452 25371]]\n",
            "targets[[722 4 500 38 35 158 403 18 1957 9 723 21 110 97 108 98 11 9 38 11]]\n",
            "targets[[44 155 192 1 9 13 31 0 2186 0 17 1197 18 7 927 17476 36 39 9 382]]\n",
            "targets[[25220 5 2 2319 422 15 2 173 4765 0 84 151 43 0 422 5 11 7 302 265]]\n",
            "targets[[3003 54067 8497 13854 5 35 1974 985 243 15 2 183 518 11 515 8 35 5936 1077 16491]]\n",
            "targets[[31565 12 4131 19 9939 3 2 1773 747 15 2 9753 1 68973 563 119 16672 178 3 2]]\n",
            "targets[[267 4 2218 5 35 2483 19 3 5240 112 7 5 226 8 2 6806 1021 717 3 246]]\n",
            "targets[[10 19 2 997 5 7 2 201 1477 7 210 21 2 613 680 39 5 56 6010 11]]\n",
            "targets[[12 84 987 11 10 17 5 23 48 862 436 41 1044 1585 7 204 27 2 49 754]]\n",
            "targets[[17 13 379 9 27 4 1046 15 0 403 34 300 88 3 131 829 68 408 33 75]]\n",
            "targets[[207 27 110 10 19 2905 3 0 829 9253 45 513 48 3 0 88 2824 909 1 117]]\n",
            "targets[[3541 5 4067 480 14 0 455 8 0 36573 3 0 2795 20 241 402 26 955 116 8]]\n",
            "targets[[5467 19 45 2 1116 1057 1 29 3 146 670 3 1637 926 20 42 67 4 66 272]]\n",
            "targets[[42 1125 228 78 10 19 9 1739 4 663 8434 13264 12 881 52 20139 104 11 581 31]]\n",
            "targets[[633 120 16 0 2647 10045 19 1322 9 67 1422 3 10 17 478 36 283 9 353 1]]\n",
            "targets[[3 0 52 1010 959 729 98 5 401 1228 328 10 2103 2 231 1724 2 4718 4 409]]\n",
            "targets[[27 77 53 173 104 9 27 23 77 482 4 865 144 9 92 7 144 900 1794 708]]\n",
            "targets[[12 2828 5 270 8 8488 499 14 1976 51494 7149 18161 2608 39 99 40 812 30655 1439 1976]]\n",
            "targets[[4654 5 127 737 74 538 927 1056 184 832 827 994 17 7 45 2 647 5158 109 15]]\n",
            "targets[[29 7831 0 112 547 3 30 214 5386 0 10159 1935 33 872 31102 5205 269 4 333 0]]\n",
            "targets[[9754 8293 5429 1707 22795 12 4 981 8 6682 22478 4 345 14878 36 2922 13622 4 90 30]]\n",
            "targets[[5 2 115 1594 16 146 1716 2 222 3 8220 707 469 7 389 8 2 794 51 1756]]\n",
            "targets[[42 1779 149 10 17 38 317 228 602 9 13 2613 33 87 73 3 2 81 184 17]]\n",
            "targets[[18142 17 9 139 110 30 291 370 3 155 2757 11741 1 35968 3 0 10974 564 504 347]]\n",
            "targets[[2968 3752 1236 6 6 1321 9 13 1072 9 581 8 60 115 889 4 169 2 17 4]]\n",
            "targets[[3205 150 21 409 55 4 48 3 0 82 16931 6924 184 104 8 1315 3 24306 41 18]]\n",
            "targets[[21 76 71 356 10 17 67 0 1004 18 94 400 71 1295 8 0 632 88 3 0]]\n",
            "targets[[13 241 0 250 17 123 618 9 96 165 80 126 545 7 288 21 58 270 55 2797]]\n",
            "targets[[50 64 103 3 29 151 52 5183 72 235 2 17 36 2 74 225 1 11 5 16]]\n",
            "targets[[27 165 42 1059 110 35 422 3 19529 595 67319 23 3 60 197 32857 352 9 42 27]]\n",
            "targets[[115 1594 204 28 0 117 1397 44 3 7291 8 154 39 25 56 2420 1 56 9621 4]]\n",
            "targets[[0 1561 16 10 159 21 3019 71 8 0 4085 2 115 234 34 50 93 40 9800 835]]\n",
            "targets[[39 13 2 548 24 59 27 92 251 10 17 2464 8 0 3565 68 7 13 37543 55]]\n",
            "targets[[140 42 164 4 76 10 44 3 0 95 167 9 1223 9 424 0 578 1 0 330]]\n",
            "targets[[20 182 2113 41 238 38 0 200 1139 184 2138 11 70 76 861 22 178 131 483 89]]\n",
            "targets[[5 29 3 146 98 11 9 139 110 37 108 214 11 9 50 3116 88 3 7 48]]\n",
            "targets[[164 4 136 7 1 9 140 56 263 2421 755 1410 9475 1563 120 6 6 0 366 5]]\n",
            "targets[[10 3692 2856 33 1580 1501 4 378 680 1141 2095 23866 1917 4440 5 4686 4 2771 2393 1484]]\n",
            "targets[[9 66 108 4222 798 22 87 81 10 122 5 7 371 5 2 2866 28 355 92 8]]\n",
            "targets[[9 402 7 69 0 63949 67 326 55 36 0 25278 4 0 21625 8 2 173 354 154]]\n",
            "targets[[470 6928 4 76 26 42 25170 1 24 159 21 9 121 18 9 182 4 66 0 6789]]\n",
            "targets[[2 425 529 71 2 15526 270 3 1750 504 4930 184 98 9 13 8736 2 115 15921 18]]\n",
            "targets[[5 1033 814 6 6 2 2 348 630 471 17 3729 3729 20 148 330 10350 14 540 6]]\n",
            "targets[[43 2 363 3 3268 885 2367 1 62 40937 34 10884 35 158 6367 44 8 0 632 3]]\n",
            "targets[[844 154 0 101 0 1120 0 1555 7088 32 25 133 155 0 1043 2541 60913 4412 1442 188]]\n",
            "targets[[84 555 43 10 17 36 60 701 34 300 32 68 770 33 87 9050 0 19 13 9]]\n",
            "targets[[67 1900 110 10 22 378 14 0 1969 113 623 1 1059 307 7 22 378 14 2991 12]]\n",
            "targets[[83 818 10 17 85 7 5 513 33 2675 9569 313 32 83 512 137 14 49 14 1969]]\n",
            "targets[[22849 10161 673 5 654 78 2 49 261 18 1262 1099 19 73 38 26 2977 10161 166 13]]\n",
            "targets[[23 73 5 973 31 30 0 17 45 81 156 3842 81 30 187 771 7 5 201 41]]\n",
            "targets[[0 3092 3 1275 331 0 328 22 51295 895 0 895 15 56 390 147 269 0 2444 63]]\n",
            "targets[[109 47 109 5276 7 99 91 2683 227 311 60 355 1 9 874 11 39 13 56 109]]\n",
            "targets[[17 13 647 9 307 7 132 35893 2 5605 3 13220 7 13 65 948 4572 186 251 20]]\n",
            "targets[[467 10 17 7 13 221 0 170 14 0 84 3071 33 0 1993 64 296 3 42 808]]\n",
            "targets[[2868 955 680 43 2 125 11 99 35 1631 2012 1718 3 0 227 105 154 24 3050 4]]\n",
            "targets[[12 2 81 19 1090 7 1505 21 195 97 73 536 14 82 160 2183 80 1 7 704]]\n",
            "targets[[13 770 4 353 48 3 131 34210 829 0 4803 13 60 519 917 8 19 472 1 10]]\n",
            "targets[[401 0 250 19 9 139 123 110 56 1148 1712 3 10 660 236 3824 11 10 412 141]]\n",
            "targets[[987 7 9 424 0 275 588 3 243 3163 1 3166 3892 747 26 637 3799 22 0 13711]]\n",
            "targets[[5 208 813 29 3 0 250 104 9 139 123 110 6 6 0 109 5 37 370 3]]\n",
            "targets[[27 29 864 47 606 118 2758 26350 80 4 0 75 11 92 10 19 828 7 13 7]]\n",
            "targets[[1354 1 3397 2830 304 35 18363 985 363 34 4116 64 4 1757 32 68 9236 985 1907 32]]\n",
            "targets[[13 1027 37 73 36 10 17 0 4024 22 246 68 322 1 5783 5712 5 35 81 1619]]\n",
            "targets[[290 68 81 18 0 63 13 0 170 158 528 11 959 1505 21 226 167 0 653 1584]]\n",
            "targets[[2222 56 517 87 245 9 2637 9 232 113 169 2 126 17 339 3 9444 46 20 112]]\n",
            "targets[[559 71 2 639 3 154 4 66 7 213 693 0 224 18 113 559 0 57 4 106]]\n",
            "targets[[25 3484 4163 4209 622 611 5 427 22 5981 1230 236 2 23084 22 0 849 1 2 6612]]\n",
            "targets[[60 660 10 5 0 250 1224 17 123 92 0 3507 2288 10 1223 15 161 18 194 5629]]\n",
            "targets[[42 27 4 278 60 105 6942 8 10 122 5 208 2 813 60 519 1 9 1818 722]]\n",
            "targets[[273 0 2255 3708 464 0 2620 18 9561 19082 31 753 49 809 2058 3 284 4312 3471 1]]\n",
            "targets[[50 21 395 10 19 14 2 1309 17 1925 7487 12 2540 10717 2619 3 114 1400 22 2]]\n",
            "targets[[13 1819 192 4 5652 0 5722 3 10 19 9 418 4 0 2683 15 56 1422 1 13]]\n",
            "targets[[1739 149 2 12164 3 10 246 17 22 2 2841 2879 532 7 13 42 157 1000 3880 1521]]\n",
            "targets[[509 0 84 2311 12 940 229 52 72 9 118 0 19 51 9 215 7 31 2 325]]\n",
            "targets[[2196 2723 4 71 503 10 4222 940 0 2401 1806 279 543 153 1 21084 4921 1873 780 7184]]\n",
            "targets[[17 1015 16 440 996 84 3 30 46 286 1198 3 48759 15045 445 0 1682 14 2 19]]\n",
            "targets[[242 2 669 340 3 2 772 8046 14 69 14 972 1864 105 3 60 519 98 3 30]]\n",
            "targets[[0 1218 1554 3 34674 144 61 108 2 12688 319 16 0 13940 1455 2 4739 1128 6830 44541]]\n",
            "targets[[22 715 2 122 2 308 163 274 20 25 715 35 554 4883 738 287 12 993 274 22]]\n",
            "targets[[2508 365 23 3019 26 7167 1017 22 0 9484 1387 477 5 23 8 1062 3 107 20683 8]]\n",
            "targets[[42 1779 149 8380 8380 223 292 9 67 110 8380 51 7 1900 389 44 1 159 21 402]]\n",
            "targets[[203 136 11 10 23 2 348 19 31 30 264 9 254 0 2247 115 35196 2 222 4681]]\n",
            "targets[[64 151 20 27 4 121 43 10 19 5 11 7 45 0 1271 7161 633 265 8 14096]]\n",
            "targets[[103 11 11 5000 12 3 10 19 12 1080 1020 2 171 52 12410 72 32 241 123 2034]]\n",
            "targets[[215 0 84 303 377 725 42 99 7 389 44 2206 6302 829 1 9 196 7 236 28]]\n",
            "targets[[4214 1039 2 7236 2039 9720 5 11474 51 0 1061 2592 24 5 22 5 13180 22 0 488]]\n",
            "targets[[5 56 813 8409 33865 5 2 186 243 9 141 136 234 85 54 12 428 4 28 2]]\n",
            "targets[[0 19 218 2 317 58 152 7 12 19453 72 4760 85 143 8 31673 30 0 104 68]]\n",
            "targets[[13 261 144 0 17 15491 8 60 1581 22 13917 1 110 2 17 11 67 23 77 6364]]\n",
            "targets[[19 45 48 631 155 1 1261 2329 375 5201 12179 406 2 81 237 15 26 1728 1246 56]]\n",
            "targets[[5 29 3 146 98 11 494 65 245 4 28 2534 1 120 0 1590 18 3966 0 220]]\n",
            "targets[[112 391 2552 1 9 196 10 17 13 81 85 7 3913 2 171 3 2552 8 7 10]]\n",
            "targets[[13 2 497 1446 15 1377 394 116 444 1 877 7 12 37 74 29 50 21 345 532]]\n",
            "targets[[2 1446 1101 15 4391 227 41 0 1799 1 1348 234 3293 10 5 2 10457 4 0 2996]]\n",
            "targets[[8772 9378 5 29 3 146 104 11 20 50 1999 66 391 22 0 26180 1234 31 187 223]]\n",
            "targets[[10 17 67 37 73 1004 1 9 133 395 7 14 0 809 3796 1 29607 1 1956 25]]\n",
            "targets[[5 379 1043 1 595 379 0 1509 5 1157 272 70 139 30 77 3063 14 3 544 15]]\n",
            "targets[[887 118 7 175 9 467 629 582 111 25 11506 92 33 0 3882 37 73 1 56 640]]\n",
            "targets[[162 29 589 87 10 122 5 133 22 0 922 39 12 77 29 363 11 45 2464 292]]\n",
            "targets[[3 60 894 2753 3 30 57 276 8874 1688 4 28 29 3 0 88 607 1 413 104]]\n",
            "targets[[19 5 29 3 0 173 104 4 7293 71 7 16198 392 4 28 2 423 12 17 18]]\n",
            "targets[[192 30 0 897 798 1529 2208 0 457 1 319 0 1362 119 9 230 2 7801 4 11809]]\n",
            "targets[[39 25 447 98 44 39 88 3 90 92 16 247 22 2 6348 3456 341 41 14 2]]\n",
            "targets[[19 13 16990 14 29 3 0 692 11 3922 2317 448 24 529 2 49 237 8 1 11]]\n",
            "targets[[139 555 3 691 30803 8 7114 6545 4010 5 5285 3789 8 7114 1202 4 136 0 23360 2159]]\n",
            "targets[[9 569 21 58 1392 715 10 2 738 18 256 77 4023 119 0 1350 33 30 146 13536]]\n",
            "targets[[17 5 2 102 2018 1 0 24230 199 0 4375 3 6864 2037 31 372 2446 4 2207 31]]\n",
            "targets[[84 215 10 17 22 544 311 729 8 0 776 3 5582 22 35 1633 1234 61 67 2]]\n",
            "targets[[9 27 56 321 47 3714 5389 13 532 51 24 874 4 93 10 980 379 17 147 9]]\n",
            "targets[[972 3 2 19 16218 468 761 45 15583 421 29 3 60 1628 104 3 30 57 1276 141]]\n",
            "targets[[307 1750 1108 7511 459 44 3 163 10181 2685 6173 1383 725 36 2 102 954 9431 8 60]]\n",
            "targets[[5 2 297 1001 12 17 143 94 32 92 272 1297 214 52 98 72 3058 1 11 162]]\n",
            "targets[[29 3 0 1104 13 39 31 227 311 12 998 44 2683 37 9 195 2 598 4 36640]]\n",
            "targets[[6065 8 38502 35 276 2431 10808 668 1360 24 1825 8 0 176 299 1331 34 27 23 2076]]\n",
            "targets[[335 10966 33 1502 1 17342 439 123 233 91 768 9 592 4 103 11 10 5 241 17342]]\n",
            "targets[[13 2938 4 35 49008 1771 122 446 3528 1 2197 29 3 62 2209 28879 395 11 75 138]]\n",
            "targets[[19 5 273 318 327 16 91 9419 40917 8 0 84 315 35 541 624 3388 6697 101 25]]\n",
            "targets[[12 504 47 98 75 83 93 131 483 51 9 555 10 13 92 8 5284 9 13 31]]\n",
            "targets[[112 131 21446 941 98 20 420 21 93 2 17 38 10 490 1 7 5 945 8 1356]]\n",
            "targets[[64 293 4 106 10 5 0 176 12 84 3147 3 780 1654 6111 251 0 17180 38 1592]]\n",
            "targets[[42 1779 149 10 19 15 1533 264 7 45 48 1407 135 18 1201 4 2086 0 492 934]]\n",
            "targets[[143 51 9055 92 26 84 1222 9 13 924 628 149 1838 1217 14104 240 9 64 470 4]]\n",
            "targets[[121 342 12 1314 3 158 1578 112 547 1880 1127 361 166 17466 4303 69 0 3092 5 1181]]\n",
            "targets[[42 360 341 104 18 30 104 10 5 2 145 7788 46 20 89 21 112 1556 20 241]]\n",
            "targets[[48 1022 1404 6 6 1791 5 2 613 878 1 100 570 31 804 7 8 2 2013 615]]\n",
            "targets[[312 1 9 672 4 106 10 17 15 6315 7 581 2296 1 1338 7 672 44 69 18]]\n",
            "targets[[5 22448 261 16 112 1 741 4 198 7 25 98 52 4 20 72 707 208 1496 5631]]\n",
            "targets[[2 39462 1 684 1588 9 196 9 65 13 164 4 28 2308 1646 60 2219 18 47 2]]\n",
            "targets[[1395 1102 3 0 3602 1418 956 78 35 2509 4538 4 27 2 33563 2504 787 62 197 7811]]\n",
            "targets[[498 425 3 1867 1180 10 17 4 71 1 264 7 559 440 483 4 169 7 9 429]]\n",
            "targets[[1404 6 6 320 656 5 29 3 146 98 43 160 728 8 0 1289 12 51 0 484]]\n",
            "targets[[17 13 37 74 11 7 52 11810 2 53 1467 246 202 72 2 17 39 13 56 181]]\n",
            "targets[[884 0 829 7 886 576 11 295 45323 10 166 87 1262 348 431 87 43 0 49 6475]]\n",
            "targets[[128 70 66 0 82 129 3 0 1598 51 7 269 4 98 15 41 208 3149 881 3896]]\n",
            "targets[[38586 1 1209 11594 1825 51 193 68 9865 8 3345 294 0 8821 32 1016 105 3 0 1536]]\n",
            "targets[[17 13 33 229 0 250 17 11 9 27 123 110 8 60 442 114 9 140 23 58]]\n",
            "targets[[196 11 0 217 369 1078 7 13 2 409 2859 13 53 69 3501 0 116 13 81 1]]\n",
            "targets[[338 1091 11 7 5 57 16 2 160 734 201 61 3908 0 11983 878 3 0 1604 920]]\n",
            "targets[[589 1183 0 125 31 0 2251 3 0 19 5 2002 36 0 12278 3 26 301 24 45]]\n",
            "targets[[181 19 31 485 0 63 3 883 11554 5 42 2 9409 42 200 192 4 1391 0 6070]]\n",
            "targets[[10 5 35 2483 346 378 91 35 3104 3680 19 64 16 29 17656 97 1456 15 3104 1033]]\n",
            "targets[[185 45 329 40 894 564 3 1902 55 15 105 9319 887 29 3 916 54 4471 14 2]]\n",
            "targets[[8 333 11 60 798 25 213 613 2579 2579 2579 2579 2579 2579 2579 2579 2579 2579 10 13]]\n",
            "targets[[12 23 73 4 28 300 43 303 377 10211 2 1278 2007 17 36 0 129 3 0 2769]]\n",
            "targets[[65 856 4 38 10 19 9 112 2 171 3 1871 443 9 27 2 145 1880 1537 16]]\n",
            "targets[[643 4 758 2948 287 71 14087 2 363 3 753 9 242 23 2 773 3307 9 242 23]]\n",
            "targets[[106 23 251 87 255 96 27 2 498 2806 8515 22 142 2 901 637 10 13 2 53]]\n",
            "targets[[4882 5 1186 128 1 0 13604 3 145 1 2434 820 515 69 966 2100 7461 14 213 7256]]\n",
            "targets[[7272 45 194 1390 2 5420 16 1268 22196 14 7 8456 2 266 3 10568 251 1443 49 10561]]\n",
            "targets[[504 19 4763 58 4 2 19 8150 1 26 41 6055 3167 104 10011 5 2 297 13845 10]]\n",
            "targets[[6022 311 3 0 200 3155 51 26134 7980 7 294 0 407 588 2 173 154 602 6 6]]\n",
            "targets[[2 1263 2242 8 6634 108 8544 10067 4307 1 2079 5302 50 23 169 0 95 44 58 15]]\n",
            "targets[[10247 0 2380 1443 3 14624 1175 7 141 27 672 14 2 673 14 2 17 9 215 7]]\n",
            "targets[[3069 47 5 39 332 4 136 43 26 1187 98 24 12 23 42 18318 26 237 8 24]]\n",
            "targets[[287 71 138 136 10 85 9 112 472 1 9 121 11 17 5 88 617 432 8 258]]\n",
            "targets[[9 307 10 17 9 1712 545 46 4403 5458 96 106 7 1 449 44 1326 294 0 217]]\n",
            "targets[[15 88 1061 98 0 919 5 1529 2 2181 16 951 0 63 1061 2560 21 38 11 664]]\n",
            "targets[[17 499 44 15 5331 56856 1287 5466 34 5 44829 2 522 3 75 78 13591 4902 145 3792]]\n",
            "targets[[13 2 65 647 1 1498 17 9 230 186 74 674 10 85 9 242 2 340 3 13391]]\n",
            "targets[[16 47 551 4 26 17 8 1315 3 10309 1 4807 964 14728 1 48080 398 225 16590 1193]]\n",
            "targets[[45 4 28 0 447 970 17 9 139 123 110 7 280 1 968 38 286 763 7 15]]\n",
            "targets[[65 424 10 17 10 5 23 2 471 17 264 0 412 5 248 5166 9 38 0 206]]\n",
            "targets[[869 15 2 754 16 30 146 34 387 11 281 204 810 30 179 8 0 176 5422 252]]\n",
            "targets[[0 14252 2 49 19 56 5 7 0 250 19 123 92 56 9 84 215 0 17 31]]\n",
            "targets[[3 2 316 2798 5 2 4083 2967 19 9 13 1014 221 8639 36 366 4 1454 46 20]]\n",
            "targets[[195 0 3432 55 5 23 47 9 59 58 651 2 17 14 7 5 65 42 17760 16]]\n",
            "targets[[242 23 14 2669 22 10 17 14 88 15009 800 14 2 351 183 534 11 624 4231 4]]\n",
            "targets[[37 9 288 21 1181 8 0 3740 18 60 324 426 13 6 6 24 1180 10 17 4]]\n",
            "targets[[9 13 2313 31 84 4 10524 35 1264 867 2275 17 64 4 28 2371 33 2 19015 4857]]\n",
            "targets[[5428 5 81 8 10 680 9 627 5328 106 6972 3 631 98 18 9 65 367 10 29]]\n",
            "targets[[823 58 33 14276 1645 10 735 2 984 3 0 19860 45 35 9053 109 61 5 23 23848]]\n",
            "targets[[5 35 2801 19 11 3142 20 1384 7 188 4 28 4911 1894 4575 31 440 753 1 94]]\n",
            "targets[[317 5 241 0 9710 202 11 75 27 219 555 3 7 45 634 0 170 9468 14 0]]\n",
            "targets[[418 78 10 15 60 1943 55 33 1706 228 78 0 17 9 420 21 27 77 52 287]]\n",
            "targets[[17 5 901 22 108 2056 0 102 954 0 109 0 116 0 305 290 0 1425 0 224]]\n",
            "targets[[33064 1 37818 10 5 0 117 17 3 0 227 2040 92 33 88 4692 1692 3 0 227]]\n",
            "targets[[17456 12 501 166 8 0 17 1794 29 50 65 168 931 4 66 26 2554 19 14 153]]\n",
            "targets[[246 122 13 1281 29 3 0 733 250 274 123 92 51 9 215 10 12762 3 10 2041]]\n",
            "targets[[160 7271 5 2 669 1446 0 158 29 5140 5 2 972 8 2 1898 4 10 32 1339]]\n",
            "targets[[71 10 13 2 7603 2342 3 619 2114 9 121 88 6 6 331 83 136 47 12 356]]\n",
            "targets[[7622 5 0 116 303 220 8 10 7227 14779 8 1401 16 2 19 46 11 150 21 2179]]\n",
            "targets[[64 5 10 35 379 17 7 3522 22 60 1371 163 3 30 57 9 67 53 360 1422]]\n",
            "targets[[0 1792 3 318 2 4804 3 10 15 0 153 1 2 1252 31 0 32906 3 30 1265]]\n",
            "targets[[5 2 737 8849 673 369 8 11 105 75 34 27 22096 48 441 3 1641 1997 4 76]]\n",
            "targets[[307 0 1659 1 2021 52 72 2 173 4032 199 317 29129 1 328 140 207 8671 12 102]]\n",
            "targets[[1404 1239 661 2815 6 6 618 5 39 100 1048 1088 19 3 0 227 3008 154 185 4]]\n",
            "targets[[12 401 137 2 115 13790 43 7 18 9 140 23 251 47 0 716 13 379 37 272]]\n",
            "targets[[8 2170 39363 4845 3184 35997 5 2 1182 2643 5925 12096 3 713 21527 15 855 3166 1 536]]\n",
            "targets[[17 5 23 16 0 7372 41 849 3 485 7 420 21 1134 46 7 13 164 4 28]]\n",
            "targets[[512 52 36 370 2032 29 3 0 126 1501 4 378 5404 0 4426 168 38 32 27 2]]\n",
            "targets[[72 1001 154 99 91 768 0 84 1470 3 0 400 176 1386 14 29 3 0 88 6984]]\n",
            "targets[[45 35 1055 2871 14 70 66 2 12783 26407 2983 107 1671 14 2 160 314 16 7059 3935]]\n",
            "targets[[140 2 340 3 246 98 8 746 1 10 13 29 3 0 49 692 0 177 347 473]]\n",
            "targets[[236 27 77 2 49 17 46 7 67 4228 137 52 212 248 72 42 0 2353 3 2]]\n",
            "targets[[2 26403 1 2 340 3 0 4677 16 108 154 9 13 53 899 8 318 10 61 9]]\n",
            "targets[[13069 21 16447 5 2 11511 1356 3165 4 0 484 3 615 1 0 484 3 112 2 19]]\n",
            "targets[[9 140 4883 4 15495 1670 547 1 30 18 9 196 10 13 1875 226 6 6 9 65]]\n",
            "targets[[1785 5 607 18 58 26 1619 638 288 21 192 4 4557 10 2248 910 0 1755 201 5]]\n",
            "targets[[5 142 2 1587 49 17 6 6 7 12 10 1836 17819 1472 628 610 155 374 1 1555]]\n",
            "targets[[8738 15943 78 0 209 282 6959 33 11383 14 1832 34 14 2 396 215 26 324 326 33]]\n",
            "targets[[5 24264 29 3 60 2753 123 87 255 96 136 0 101 68 839 1379 5 686 71 0]]\n",
            "targets[[422 5 53 212 1 7 5 366 3 2 160 917 10 5 0 457 3 0 8683 10090]]\n",
            "targets[[6193 19 0 648 955 116 33 284 15625 34 2108 119 1059 2 125 34 13 213 37 15974]]\n",
            "targets[[2 935 10 5 0 84 57 70 27 110 15515 43376 949 1 1501 2 17 11 2103 0]]\n",
            "targets[[122 13 437 394 16 29 714 210 21 155 1 26 362 25 15360 115 12626 24 79 4474]]\n",
            "targets[[3 0 117 1855 12 22 0 1294 264 871 4 387 9 772 97 73 343 1 1436 28366]]\n",
            "targets[[443 8479 3550 223 7 5 1954 11 947 6431 12 563 13 165 2405 33 2 844 291 158]]\n",
            "targets[[112 10 477 3 19 85 7 274 108 13400 3 114 294 0 57 8 61 7 5 2501]]\n",
            "targets[[354 3291 3 1697 11773 1980 8 965 3 2 270 2665 4 168 38 2 11022 346 3 2]]\n",
            "targets[[2343 203 1017 0 6568 16 88 1133 379 153 8 19 472 15 2 3456 3 6649 1206 4454]]\n",
            "targets[[5 2 485 5566 17 11 11072 0 7532 11 3171 342 473 0 154 2829 12 4 930 191]]\n",
            "targets[[16274 16274 832 827 1234 3466 175 15 157 1470 11 1762 0 200 29 23 1558 15 7162 7923]]\n",
            "targets[[9 140 23 251 47 14358 2 1250 9 50 380 20 11 462 3153 14358 2 65 74 832]]\n",
            "targets[[1193 2 846 328 3075 11 9 67 1147 1 2 1702 11710 160 4 106 10 29 9 89]]\n",
            "targets[[5 142 2 7571 2162 30 26 8404 1 6150 1883 78 2 305 115 972 38 10 29 385]]\n",
            "targets[[53761 33 84 57 153 34599 29585 5 0 88 2119 1 348 17 9 27 123 110 0 17]]\n",
            "targets[[483 8 1547 4302 13 1056 408 513 1977 6594 2663 33 2106 34 79 11834 40 145 701 4]]\n",
            "targets[[5 322 502 3 19 1471 221 283 20 207 182 8 10 477 205 36 0 653 326 10]]\n",
            "targets[[196 10 13 2 1349 201 0 743 5 69 408 1 11943 2152 22 0 260 7 45 1010]]\n",
            "targets[[2 153 3 4802 12 564 96 123 512 178 4 182 4 1143 57 15 41 4 456 43]]\n",
            "targets[[1036 14032 4719 8 1380 1332 1 35 1036 5520 99 107 4590 8 35 1259 33 0 1100 12]]\n",
            "targets[[512 88 3 131 2498 2048 1630 1685 104 4 28 2702 15 181 18 88 806 352 2 115]]\n",
            "targets[[853 29 3 0 3773 1 4210 104 3 0 1187 1816 3 1633 17 235 4602 921 138 4]]\n",
            "targets[[10 22 246 227 311 3074 36 0 84 2010 397 1347 78 4982 34815 451 0 102 3 2]]\n",
            "targets[[39 5 29 151 4 395 43 10 19 5 11 7 5 1680 0 834 426 4069 0 310]]\n",
            "targets[[140 23 2 340 3 1140 98 11 300 0 6137 339 9 215 13 523 0 4174 68 31]]\n",
            "targets[[5 35 591 19 18 1449 100 145 1132 352 2211 41 8 1315 3 63 951 6 6 0]]\n",
            "targets[[81 1 1555 153 916 3677 2207 11969 282 14665 2 17 5 1793 46 64 16 0 1301 7]]\n",
            "targets[[13313 13415 118 23 1501 10 19 24 118 2249 7 1 24 1065 0 877 1 917 3 1341]]\n",
            "targets[[242 43 1289 3 0 95 144 10 17 1 9 67 4 535 9 420 21 138 100 1037]]\n",
            "targets[[8 4728 154 3 19 164 9 27 429 2290 0 4161 11 8923 30 82 8290 98 9 27]]\n",
            "targets[[84 172 63 5 43 2 1773 9926 2549 34 218 34420 261 31 42 43 238 24 6981 22]]\n",
            "targets[[3 30 9 242 2 6293 16 1170 4286 316 1 460 10 1394 124 23 4171 7 5 30]]\n",
            "targets[[9484 5 14137 0 657 25 838 1 0 156 14104 144 62 558 15 56 266 3 2718 41]]\n",
            "targets[[261 115 47559 11 12729 23241 1 14123 506 37 229 16 0 184 756 10 17 45 30 0]]\n",
            "targets[[5 29 3 60 519 1871 104 123 38 3207 7 302 265 8 2 4271 863 61 280 38]]\n",
            "targets[[48 293 8 0 544 1289 12 1 407 1001 12 0 711 6428 25204 1554 8 160 728 785]]\n",
            "targets[[215 10 51 9 13 43 463 1 9 13 2441 11 15696 13 145 7 288 21 27452 9]]\n",
            "targets[[0 19 1059 33358 60 112 16 5144 7137 12 224 9 7042 10 277 22 5238 1 196 7]]\n",
            "targets[[89 21 121 87 75 15 56 266 3 1204 50 350 1 949 829 3 2 201 122 255]]\n",
            "targets[[9 42 215 10 22 21 2165 14 29 3 0 631 98 32 122 187 2453 13 10 1281]]\n",
            "targets[[524 364 1191 5 4362 33 5152 38 32 141 3 92 7 1281 246 3106 41 1236 16 2467]]\n",
            "targets[[0 21166 5 2 647 2908 8 0 55228 477 3045 510 4921 64420 1347 1 472 14 70 811]]\n",
            "targets[[572 3 2154 16876 5 7375 5229 14 29 3 0 117 766 2977 3 30 57 91 2583 21361]]\n",
            "targets[[17 59 28 2 4161 13563 252 455 59 191 2 636 3 315 0 177 1 2 679 10648]]\n",
            "targets[[0 461 5 8411 33 2 1218 1 3844 5 319 2308 26 3313 221 1407 68 32 119 341]]\n",
            "targets[[59 38 4 191 10 1421 4 136 11 10 19 5 1297 23 23 106 7 925 20 114]]\n",
            "targets[[501 330 1156 2041 3069 8 0 289 209 13 2 679 471 599 315 501 330 223 5 42]]\n",
            "targets[[9243 236 27 77 29 3 0 117 23581 3 26 57 18 2 1128 309 24 150 21 749]]\n",
            "targets[[5 2 65 69 226 17 11 7280 3621 1894 2 65 1350 3 127 2073 271 29 293 134]]\n",
            "targets[[3133 15 0 798 11 0 17 13 1876 0 1205 802 44 8 0 17 25 42 14 2026]]\n",
            "targets[[84 2374 11 10 5 2 911 17 5 11 7 13 326 22 378 23 19 0 63 5]]\n",
            "targets[[89 21 512 73 44 3 360 341 184 1412 37 9 13 3381 770 33 48 3 0 756]]\n",
            "targets[[17 5 53 1338 8 189 221 2193 37 9 59 395 7 4 255 8 0 1301 4 4783]]\n",
            "targets[[19 420 21 663 16 71 14 9 112 1255 1166 12 21048 155 407 104 1 4141 19 1471]]\n",
            "targets[[164 4 453 2 171 3 57 22 10 29 783 240 39 5 23 29 49 151 9 50]]\n",
            "targets[[358 11 0 84 23334 13 56 4167 3329 2115 7 288 21 58 35 10959 8 392 60 1422]]\n",
            "targets[[50 3764 56 1862 3 655 41 468 13058 18 9 121 8451 1 9 112 40 75 8 7013]]\n",
            "targets[[5 29 3 0 117 3563 9 139 110 233 42667 796 1783 458 10113 0 803 43 10 2372]]\n",
            "targets[[571 15 10 11592 201 680 188 4 28 2600 506 4623 7 12 2 5730 8029 43 6981 8545]]\n",
            "targets[[9 371 509 0 84 17 10 29 4250 9 382 65 4250 0 64 3536 102 5 0 216]]\n",
            "targets[[1 1644 5 29 3 146 272 297 272 23 547 752 713 8001 28145 780 38112 635 349 0]]\n",
            "targets[[11 12 606 47 562 51 20 148 107 3539 1 198 11454 829 4 8343 1001 12 184 98]]\n",
            "targets[[39 5 2 338 2707 13961 22 0 8958 7 5 6167 39 5 35 4538 1563 120 478 21852]]\n",
            "targets[[5 605 1 1504 1243 2 480 502 3 47 2 74 17 5 38 10 50 21 28 2488]]\n",
            "targets[[17 5 2 605 821 2506 262 9 9673 22 4090 55 8 0 18766 419 11 7 59 76]]\n",
            "targets[[42 1779 149 0 27475 184 2 173 228 602 7 12 0 325 57 9 139 110 7 8]]\n",
            "targets[[17228 1065 35 322 298 45186 6 6 286 874 4 93 2 246 2299 202 44 3 7 6]]\n",
            "targets[[14 5417 6454 944 5 241 14 1848 14 0 2926 3 12763 8 32 1103 15 62 8392 22]]\n",
            "targets[[9365 21650 451 8 1844 15 26 183 518 5809 4213 4464 2 1187 10130 3 2873 1816 761 5]]\n",
            "targets[[9 242 2 340 3 0 6845 6565 1209 5040 83 20495 511 98 18 0 13294 13 379 6]]\n",
            "targets[[4774 5 35 5279 814 1448 4 3649 2 1061 111 6439 25 4969 1636 150 21 500 97 10774]]\n",
            "targets[[1591 10 19 8 277 824 208 1237 238 31 30 43 7 172 3 2 3850 8502 3 149]]\n",
            "targets[[176 299 105 338 195 2 171 3 19361 44 3 6581 285 8 10 411 29 33 43784 61]]\n",
            "targets[[1195 2170 5 2 397 3393 92 8 4234 1156 1255 1166 4110 13067 1 1287 55352 8 368 1650]]\n",
            "targets[[10 5 52 38 7 0 84 17 67 48 20390 405 1 48 6921 116 18 7 188 38]]\n",
            "targets[[215 10 22 21 2165 1 13 5070 33 7 9 140 23 2 340 3 2752 4360 85 9]]\n",
            "targets[[9 215 10 16 0 84 57 9 13 52 3 2 527 72 147 2 115 527 1 9]]\n",
            "targets[[128 12 47 9 103 43 685 8653 9 581 31 0 21310 889 16 0 1912 1972 1 9]]\n",
            "targets[[17 210 21 73 3 238 7 12 23 65 1228 882 5018 882 49 31 30 890 10677 1042]]\n",
            "targets[[723 21 353 0 82 4222 798 18 2549 118 0 2690 16 10 19 853 1505 21 110 7]]\n",
            "targets[[2 4052 339 3 29 3 146 527 274 142 14 611 5879 1 20 27 10 19 36 4234]]\n",
            "targets[[38 2007 443 9 38 0 911 536 1 343 0 360 492 3126 1 56 341 444 11 269]]\n",
            "targets[[1186 35 591 544 47493 257 556 36 4895 270 127 1943 360 1 127 15338 1325 303 1 20]]\n",
            "targets[[118 9 1392 4 58 106 0 19 548 515 8 1263 741 80 23 106 10 17 925 0]]\n",
            "targets[[46549 5068 4549 45 42 77 645 22 1 3 268 9 67 4 488 185 4 0 1045 1]]\n",
            "targets[[121 11 29 216 34 207 80 238 4 76 20 3683 2315 127 328 14044 20 36 127 355]]\n",
            "targets[[509 10 17 1 99 149 7 7 92 71 589 42 87 108 22591 1897 12 2001 8 0]]\n",
            "targets[[482 4 66 0 52816 7862 294 10 794 5 65 397 426 39 25 647 1365 1 375 1]]\n",
            "targets[[83 9 123 854 0 14610 2311 22 28443 92 71 103 10 2412 13 157 4167 3329 597 1797]]\n",
            "targets[[12433 5 2 688 777 832 827 680 1156 1209 1484 1 1832 183 1209 285 2 21521 36 157]]\n",
            "targets[[678 2361 311 2069 311 2069 2015 2841 311 7918 2015 6 6 5262 15842 2041 3069 5 4686 4]]\n",
            "targets[[517 47 255 702 20 39 5 2 2710 189 4 0 670 6746 8 19 7276 142 14 47]]\n",
            "targets[[304 499 120 212 18 7 267 185 2000 688 0 64 49 279 5 18422 3673 1 24 45]]\n",
            "targets[[8 0 1955 3 0 2654 12 15306 5447 0 8138 13258 3 0 57 2250 7425 992 15 0]]\n",
            "targets[[235 10 17 56 109 344 1730 286 1453 8 112 381 985 1 256 2 941 568 24155 1]]\n",
            "targets[[735 1048 797 5354 1197 6165 342 10747 446 6165 9801 85 7 12 142 2 28772 369 1 85]]\n",
            "targets[[2 670 3 7654 14 35 276 9 242 23 1082 15 3818 5192 9 121 11 24 12 2]]\n",
            "targets[[1447 3334 0 1873 22 10 0 1561 124 23 80 0 17 1443 1 51 10 3257 7 13]]\n",
            "targets[[103 0 64 166 3 1917 691 11 9 165 509 13 0 3902 650 691 10624 30 0 990]]\n",
            "targets[[21 16 536 6 6 9 195 10028 1408 2 363 3 154 602 16 2 681 1686 9 159]]\n",
            "targets[[17 399 3434 4072 3 2133 0 5394 2024 10 17 43 29 125 12 3166 302 265 31 2]]\n",
            "targets[[5 0 872 17 1255 1166 123 92 1 5 29 3 0 117 1256 3 0 2040 39 25]]\n",
            "targets[[13 23 0 250 17 9 139 123 110 18 11 12 43 14 73 14 50 28 300 43]]\n",
            "targets[[402 10 17 64 85 60 812 1 9 68 0 206 18164 1300 362 60 920 812 1 9]]\n",
            "targets[[12 104 1643 208 485 41 1299 253 5 35 36835 4 0 64 19 24 123 92 10 422]]\n",
            "targets[[366 3 241 0 872 181 4469 4971 1217 45 4 993 552 2 17 11 5 181 2702 7541]]\n",
            "targets[[49 8148 427 22 2 354 63 33 20634 15617 5 244 3 98 11 27 108 756 1 1450]]\n",
            "targets[[20890 2419 5 2 4974 184 19 9 65 470 4 38 7 3 268 7 12 184 1 107]]\n",
            "targets[[140 29 3 0 1229 17 12 1352 1 9 139 106 174 975 98 9 96 169 44 1]]\n",
            "targets[[159 21 121 47 9 13 381 545 78 51 9 278 10 17 8 60 277 1837 36 0]]\n",
            "targets[[17 11 1070 4 28 229 6718 72 91 1155 25 2104 3 3611 0 17 1290 1 505 144]]\n",
            "targets[[30 3 0 536 22 246 1 8 0 711 1397 7 5 2278 4 27 2 122 11 45]]\n",
            "targets[[7529 13 0 293 9 307 10 17 15 60 312 1 105 3255 2220 163 1 1800 23 64]]\n",
            "targets[[215 735 331 22 60 3626 8 3790 132 9 13 240 22 3099 51 9 389 143 346 9]]\n",
            "targets[[311 9 1779 148 149 1303 6802 5980 0 3401 2299 202 3364 36 4213 14379 12 4062 868 673]]\n",
            "targets[[3137 5839 14403 499 261 78 40 582 12 320 54 747 4 1725 137 52 2881 72 1242 2817]]\n",
            "targets[[5 29 3 146 104 0 699 13346 9623 7533 91 281 22 0 289 430 5 2 7965 225]]\n",
            "targets[[12 1116 368 1013 36 160 728 5 270 8 2 30184 4818 160 728 484 45 77 6117 78]]\n",
            "targets[[17 65 3381 770 71 9 856 11 91 3884 1731 806 59 28 0 769 1785 14 13 0]]\n",
            "targets[[5 29 3 0 250 98 3 30 57 7 5 7774 72 149 1126 2176 22 127 821 161]]\n",
            "targets[[10 19 218 2 171 3 659 1 5 1267 2 368 8 0 1174 19 477 133 9 118]]\n",
            "targets[[9 65 509 10 17 1 91 754 61 5 43 3786 4 409 114 4 0 13716 53 4324]]\n",
            "targets[[7000 45 745 3 74 98 445 26 5928 10 5 29 3 26 250 1216 1319 9 112 7100]]\n",
            "targets[[17 13 2 1495 168 31 34392 1087 1 863 11 173 2145 1389 25 1824 60 197 105 423]]\n",
            "targets[[5 2 351 720 1226 16 71 7 12 23 37 73 0 27465 1087 7 4582 7 12 43]]\n",
            "targets[[75 38 545 34 103 1976 1306 4048 5 29 3 0 88 1094 19 1396 8 0 176 27]]\n",
            "targets[[196 7 13 2 81 17 9 424 0 19885 172 0 17 7 12 526 5 155 9 139]]\n",
            "targets[[318 0 5764 984 9 196 7 13 0 1536 95 4 66 14699 786 29475 381 40 4552 16]]\n",
            "targets[[12 3987 5 37 1009 0 11019 25 4318 1 0 17 5 155 9 103 0 84 223 25]]\n",
            "targets[[169 1813 20421 738 53 1848 4029 0 17 190 9 67 0 1421 4 818 0 277 36 2707]]\n",
            "targets[[1036 10090 3333 3055 63 11 96 28 408 8 29 12 1615 1 241 13 0 15301 3 0]]\n",
            "targets[[5 53 1338 1979 436 39 5 56 537 1 600 8 7 37 7 5 23 16 975 340]]\n",
            "targets[[1059 215 10 17 8 2 5392 4235 31 2 1045 1 886 2313 51 9 353 0 143 1029]]\n",
            "targets[[3426 629 5289 1 2917 1609 27 23 740 14 73 57 14 4134 279 4910 8 10 29 7]]\n",
            "targets[[17 2701 491 4 28 2 1116 487 7 494 4 28 4763 647 1 953 7 210 21 7]]\n",
            "targets[[719 6 6 60 84 3 25834 1 2 81 564 0 1889 135 25 81 0 9784 537 130]]\n",
            "targets[[412 3 10 19 799 278 71 120 149 7 23 107 2 20448 2214 340 0 2710 750 3]]\n",
            "targets[[214 2 115 565 18 35 721 823 246 436 15 3767 1 807 10 1979 5766 5 43 2]]\n",
            "targets[[5 2 126 72 648 14830 13231 19 85 0 109 5 263 37 108 3 26 9815 104 168]]\n",
            "targets[[254 7 52 2033 72 155 9 13 261 16 52 450 72 3876 7 12 7 505 44 4]]\n",
            "targets[[159 21 1284 10 31 0 443 307 7 22 277 227 311 1 9 196 7 13 539 618]]\n",
            "targets[[2330 20 2121 7166 1 2383 32111 44377 8 4285 87 108 762 32 59 28 1723 4 950 8]]\n",
            "targets[[10 17 5 23 4558 1848 18 7 5 81 707 88 6512 1314 257 0 309 7873 25 565]]\n",
            "targets[[363 3 483 99 503 43 87 1243 38 1192 12007 1 10 6653 708 4108 281 132 36751 7378]]\n",
            "targets[[20 148 654 120 33 0 45858 1 7550 22 142 274 14 4511 41 200 582 18 0 321]]\n",
            "targets[[17 866 2812 1355 8 60 1637 1 1299 38 161 332 9 139 123 110 10 5 0 63]]\n",
            "targets[[2847 14809 5632 5 2 1116 1179 19 1156 601 2005 8 26 64 19 1222 1681 2332 3 1934]]\n",
            "targets[[7022 5078 9808 67 35 321 4 93 354 104 24 446 90 199 1582 1 1138 228 4 28]]\n",
            "targets[[371 89 21 93 2632 38 10 1557 52 12 0 2336 3922 2317 285 0 209 24 1066 26]]\n",
            "targets[[2419 5 2 4271 832 827 202 270 8 1170 5186 8802 15494 22 2095 3231 10460 2 12900 5701]]\n",
            "targets[[5 2 53 212 1 953 122 51 9 84 1739 149 7 9 467 7 1 793 4 106]]\n",
            "targets[[3230 15294 26 209 14 1541 1012 34 10 57 5 22 0 411 3 2 7272 15966 8916 34]]\n",
            "targets[[37 51 9 5786 9 529 7 2 360 580 18 11 13 1090 2150 3 2463 474 45 53]]\n",
            "targets[[11628 5 35 721 823 279 34 5 92 4 168 38 2 314 33 0 1679 116 3 2460]]\n",
            "targets[[74 104 138 10 29 12 186 744 6 6 9857 3361 23 194 602 645 2 397 5487 277]]\n",
            "targets[[12 60 15052 9 242 2406 4 286 571 8 0 19 37 9 140 23 335 16403 256 300]]\n",
            "targets[[24010 9906 14742 14 1221 2477 5 2 178 2491 3785 814 24 2525 14 2 324 833 4 183]]\n",
            "targets[[5 29 3 0 98 11 270 0 1194 16 98 490 10 17 13 33 229 338 31 7]]\n",
            "targets[[2298 91 197 4749 775 0 872 3 90 13 1654 4359 8 26 10314 14 0 5358 14351 2]]\n",
            "targets[[3945 2939 3 0 17 59 28 137 38 10 2 522 3 53 498 355 26701 14 3 632]]\n",
            "targets[[10 17 67 77 126 1742 1 67 52 1413 1 317 1906 101 9 59 27 424 7 2]]\n",
            "targets[[152 39 12 2 11812 3 119 12867 104 4 2231 36 10 18133 5 404 748 14 0 117]]\n",
            "targets[[13 2 1446 4 66 10 277 99 37 108 154 16 71 0 289 430 12 0 4280 225]]\n",
            "targets[[1022 6 6 10 5 427 22 2 297 63 5 7 46 11 12 0 411 94 134 124]]\n",
            "targets[[103 663 3567 13 2 81 534 18 51 9 168 31 0 339 3 7650 7808 11 691 14961]]\n",
            "targets[[287 71 136 11 9 159 21 38 0 189 11 0 847 386 0 412 11 5 37 759]]\n",
            "targets[[364 57 20 25 31 2 978 1 286 1698 0 82 249 9 555 0 2725 2089 12 83]]\n",
            "targets[[9 288 21 8 0 632 3 2 21916 1 67 161 332 4 80 5678 4537 0 227 223]]\n",
            "targets[[5 2 17 61 1070 2 8894 3 6534 472 270 8 0 2291 484 3 66563 9 874 4]]\n",
            "targets[[107 97 3927 10 45 4 28 29 3 0 250 98 9 27 123 110 8 60 442 114]]\n",
            "targets[[19 5 1367 36 577 7486 1 15884 22 0 167 338 39 13 7183 790 19692 264 11 5]]\n",
            "targets[[360 341 3529 36 4189 1692 601 12830 316 1 460 926 5926 23339 14 2 10326 3284 5517 1837]]\n",
            "targets[[569 21 198 10 17 2 678 7 12 23 1316 9 307 7 64 85 9 140 2 27447]]\n",
            "targets[[1245 15560 499 15 0 4757 3830 5133 3730 1813 8653 1833 26 1819 3399 8072 7805 1270 4 0]]\n",
            "targets[[371 2777 1348 1 39878 5 10 11492 158 1479 9 42901 8 318 158 2661 7 5 34851 2777]]\n",
            "targets[[2685 5080 45 42 400 26 3022 312 3 1582 154 26 435 584 284 22571 213 2382 4 26]]\n",
            "targets[[13372 8776 1224 609 61 1688 11 0 69 188 30 13704 55 45 2 522 3 183 1532 107]]\n",
            "targets[[84 215 10 17 154 602 1 27 3768 4 667 7 440 214 2 291 51 9 27 35]]\n",
            "targets[[5 1535 2129 38 7 5 327 81 1 953 564 43 235 3 1210 2748 1 87 316 75]]\n",
            "targets[[419 10 5 0 129 3 30 0 2113 1563 6096 37 73 3474 1 161 4 122 16 7]]\n",
            "targets[[17 45 77 92 33 29 3 0 88 1854 42905 8 2930 23942 1490 34617 9 13 2245 16]]\n",
            "targets[[4084 8500 45 912 14386 8 0 766 477 1 3364 73 735 1088 53 173 3 26 104 25]]\n",
            "targets[[2 17 446 48503 36 3270 791 87 96 20 138 356 42 1402 8 48 119 0 351 2035]]\n",
            "targets[[11967 3 4522 12 1175 26 84 3915 19 5 2 8553 2434 168 78 0 1578 451 3 6015]]\n",
            "targets[[3 0 81 4644 3 114 3375 36 2956 5 134 337 524 37 404 25 52 899 8 0]]\n",
            "targets[[25 1878 104 9257 4 7366 18 373 311 5 180 7704 775 90 8 10 19 70 25 1671]]\n",
            "targets[[1250 3703 6 6 31 84 6237 10 19 5 42 157 832 827 487 15 2 1562 109 1]]\n",
            "targets[[242 2 3575 291 158 234 1 9 18746 10 19 6 6 0 19 747 15 0 289 102]]\n",
            "targets[[5 2 371 81 19 46 20 76 2 598 28 251 4 66 7 7 12 2 637 393]]\n",
            "targets[[5 2 738 3 0 309 646 768 33 959 1881 9542 35044 1882 1769 1 1038 6 6 9]]\n",
            "targets[[0 88 3074 1 1093 3 6570 814 98 5 6725 7929 12 111 0 16862 623 36 2 65]]\n",
            "targets[[6 9 424 0 17 53 73 397 524 323 667 3 6304 4553 2 53 212 109 1 0]]\n",
            "targets[[1400 39 16 2 132 10 17 5 2 53 1848 1110 3 0 737 8184 416 9 121 7]]\n",
            "targets[[5698 2 508 1988 18 26 582 13 23 37 1819 51 24 429 269 187 24 635 44 24]]\n",
            "targets[[12596 13 2 69 408 63 264 9 448 11 0 17 118 0 271 56 1443 6 6 0]]\n",
            "targets[[35 22922 3 2 8196 3356 833 327 278 4184 5 2 1144 1969 6117 78 2 403 12 13184]]\n",
            "targets[[84 9 67 0 2277 2 171 3 75 319 15 99 318 10 11 676 3 1721 75 32505]]\n",
            "targets[[17 13 37 379 7 162 71 656 9 67 77 3085 2053 1 4700 14 2 493 9 307]]\n",
            "targets[[105 907 93 2 877 3 2 184 339 3 5633 31 14284 12 20 121 137 5 164 4]]\n",
            "targets[[3312 2979 36 2 1892 1511 808 29 3 26 34857 1 94 2 3284 2038 99 24 162 26]]\n",
            "targets[[5 35 322 19 43 2 2432 752 713 231 8 5781 1844 763 22 1599 8 23547 7 399]]\n",
            "targets[[116 374 135 1 29422 1890 11 5571 55 10 1969 0 217 1080 3 0 1473 5 2 997]]\n",
            "targets[[17 13 839 408 839 896 1 53 736 7 13 53 360 341 1 9 50 387 134 7]]\n",
            "targets[[9 84 307 10 17 9 448 38 7 5 42 29 3 146 98 11 9 59 198 2]]\n",
            "targets[[0 1473 513 33 5869 49610 5 2 19 11 204 27 67 1004 18 1015 3324 4 2744 0]]\n",
            "targets[[117 5453 123 92 1228 1 1258 15 101 11 409 1 8016 42 48 3 0 88 2952 101]]\n",
            "targets[[27 2 305 390 10 477 9 651 131 164 4 574 8 2 31701 41 42 574 31701 104]]\n",
            "targets[[17 5 74 1397 1 9 140 65 770 31 0 616 3 200 390 638 34 59 123 1046]]\n",
            "targets[[397 177 3 955 156 391 2 397 177 3 3449 101 4348 9701 745 3 915 81 410 46]]\n",
            "targets[[210 21 2 17 7 12 2363 7 1075 1242 5125 15 0 4547 3 0 2742 11423 14 2]]\n",
            "targets[[31139 2474 3 10 17 5 792 629 6327 12 237 8 479 4890 2863 1 1990 1990 1578 124]]\n",
            "targets[[23337 288 21 42 2 737 3578 7 45 2 765 616 3 3206 8 0 472 3 342 22]]\n",
            "targets[[6 9 242 24246 4 353 37 108 1153 798 43 10 17 11 5 58693 736 1 218 6140]]\n",
            "targets[[10255 285 29 3 26 88 913 101 26 112 16 19 1 5687 285 1764 4 0 2118 0]]\n",
            "targets[[5 2 171 11 9 112 43 284 6644 1 2 171 11 9 89 21 38 73 43 86]]\n",
            "targets[[13 6726 51 9 215 10 8 2177 815 47 9 402 5 0 10664 6387 5564 31 11 57]]\n",
            "targets[[115 1598 3543 9 103 60 16314 45 5829 60 48 220 3 9947 11 0 299 1714 96 23]]\n",
            "targets[[1259 22 20161 92 33 75 34 89 21 950 4 387 2906 4834 41 2402 32000 1216 6 6]]\n",
            "targets[[42 307 18335 12 5521 3 31465 12 460 3520 1 9 27 4 987 47 2 1144 1737 7]]\n",
            "targets[[13 23 0 117 17 18 7 118 23 27 0 488 3 0 4546 1080 8 0 716 41]]\n",
            "targets[[303 499 38 100 82 249 31 53732 6104 303 377 111 115 49534 3137 18327 8624 14220 45 9310]]\n",
            "targets[[140 2 12858 11760 6003 340 1 83 213 198 2 106 4 238 24 12 8 36 1935 4]]\n",
            "targets[[96 27 77 142 2 49 17 499 3 15 10573 4103 3169 55 4572 532 594 70 25 164]]\n",
            "targets[[9 307 10 17 9 1739 4 230 53 4462 14 2 493 1902 55 8 2 3870 1581 9]]\n",
            "targets[[146 34 25 97 183 4 121 10 41 16 146 34 27 1507 0 959 1077 418 221 185]]\n",
            "targets[[184 547 427 22 1102 3 2 32529 12468 1116 11 981 346 18 1168 8 48 95 8 0]]\n",
            "targets[[38920 3700 1781 2 231 125 34 1106 0 1241 2469 31 2 679 27056 2039 635 313 256 4]]\n",
            "targets[[87 50 255 23 112 601 2226 24 67 52 260 1272 72 42 43 255 34 45 123 1601]]\n",
            "targets[[0 457 3 10 19 29 3 0 11868 550 11 24 13 585 11 24 45 105 3466 433]]\n",
            "targets[[17 13 645 8 4704 1156 31947 37151 14 5133 15887 17765 14 6578 1 792 28963 14 24757 8]]\n",
            "targets[[203 5751 167 20 353 10 11 9 242 371 2 794 2397 3310 1 10 57 794 5 29]]\n",
            "targets[[112 6179 8093 1 103 30 3 40 98 25 81 7078 6 6 8 4926 5 29 3 40]]\n",
            "targets[[12071 1 9626 158 62549 3003 23767 4083 252 4 0 10713 12378 33 7828 1942 2012 193 40 568]]\n",
            "targets[[651 10 2 201 18 51 9 42 307 7 9 1514 6 6 64 282 9 481 0 430]]\n",
            "targets[[242 2 143 1734 17 1 246 340 9 467 0 122 160 1 158 1 9 467 30 0]]\n",
            "targets[[289 102 204 28 2 222 348 18 39 25 48 1349 347 33 3269 5342 1 9 58 38]]\n",
            "targets[[145 6664 931 11 1183 2610 92 8 260 201 0 151 11 278 86 1404 3 26 7583 13]]\n",
            "targets[[734 436 513 33 3886 3230 43 0 1729 620 61 3124 199 2 22721 4837 4708 21564 1 2]]\n",
            "targets[[6308 5 2 115 396 34 5 1788 3 283 24 150 21 38 2813 26 6148 41 6744 22]]\n",
            "targets[[19 15 2 10285 341 1 2 173 177 1102 5686 4232 60 6228 16 539 9066 19 235 264]]\n",
            "targets[[19 288 21 539 348 31 375 5314 2459 18 133 273 4 106 7 134 174 362 8 10095]]\n",
            "targets[[27 77 2 340 3 83 1190 16 154 1 9 27 4 136 10 204 28 26 117 19]]\n",
            "targets[[64 10 68 14 49 14 0 158 4365 4364 246 202 18 7 12 23 37 1962 7 3265]]\n",
            "targets[[889 1025 599 25937 25937 14306 11147 269 15 157 201 61 5 2 938 2279 6 6 7 12]]\n",
            "targets[[139 110 10 275 214 253 57 9 27 509 7 58 52 8 60 660 7 5 371 0]]\n",
            "targets[[215 10 17 0 116 13 49 0 109 348 1 111 13 0 807 680 41 184 8 10]]\n",
            "targets[[67 142 303 1943 16 10 19 85 9 467 0 206 37 73 7 188 11 959 190 5]]\n",
            "targets[[149 0 217 202 9 203 136 10 13 2 938 1446 1 0 2017 3187 43 87 179 25]]\n",
            "targets[[30 0 9244 98 10 13 0 64 29 11 1788 0 2903 44 3 71 256 84 2290 7]]\n",
            "targets[[42 1059 4989 10 17 4305 75 1 51 1779 9 13 42 14 1458 14 31 0 457 6519]]\n",
            "targets[[17 5 374 8 2 74 95 7 12 36 0 170 153 284 9695 11 529 178 0 260]]\n",
            "targets[[17 22 708 9 89 21 58 121 111 4 875 18 9 419 9 50 586 157 403 36]]\n",
            "targets[[173 2196 602 0 1054 34050 53228 6364 10 17 14 0 246 1613 3 0 291 767 18 9]]\n",
            "targets[[28 1146 10 19 5 634 2 53 336 1563 120 3 1410 9475 6 6 1 5 56 111]]\n",
            "targets[[9863 45 92 2 590 44 3 2355 0 1052 1055 677 216 84 22 0 2956 122 1 94]]\n",
            "targets[[480 177 1654 6426 11239 19261 13 1024 8 10 6801 570 39 68 327 97 108 4787 1463 4]]\n",
            "targets[[461 5 29 3 0 117 181 98 9 27 123 110 221 126 72 2187 106 7 4104 2080]]\n",
            "targets[[866 37 108 1148 6935 13 0 620 199 790 7936 12 102 1 0 3056 3066 396 428 4]]\n",
            "targets[[3413 136 5484 6911 12 17376 5 33 229 0 117 184 458 4 27 123 77 92 9 139]]\n",
            "targets[[5 29 3 60 30 57 9034 7 12 55 39 15 20382 1 8010 1 1441 6 6 0]]\n",
            "targets[[5 14 0 1029 3 0 378 550 2 734 201 2 247 17 11 264 7 5 23 164]]\n",
            "targets[[22785 2773 2356 5 60 1038 1659 29 3 0 15518 299 98 123 2 1000 158 19 43 5938]]\n",
            "targets[[15 21484 748 2022 9 139 110 10 1593 147 1 133 50 21 136 9 207 395 7 546]]\n",
            "targets[[996 4 61 9 242 23 16860 1 61 204 28 56 52 72 1051 598 0 6434 3 36248]]\n",
            "targets[[4 898 14 69 14 4 174 82 4183 11 1765 2 738 10 151 150 21 27 2 153]]\n",
            "targets[[2153 7194 202 113 180 67 0 713 11 601 1420 118 11168 5 133 164 583 15 108 156]]\n",
            "targets[[13 300 721 10 5 634 13613 22 5049 36 0 53 457 29 50 380 11 10 19 5]]\n",
            "targets[[5 29 3 0 117 3 0 202 9122 55 39 15 4761 452 317 5787 41 39013 227 1013]]\n",
            "targets[[89 21 121 134 10 4183 213 982 4 1170 829 33 75 34 121 23 47 32 25 664]]\n",
            "targets[[12433 2 4866 1166 369 5 5363 5229 14 29 3 0 117 832 827 274 3 0 4754 41]]\n",
            "targets[[811 55 4 0 206 1116 368 7 12 1181 5 2215 2 984 3 0 84 19 18 15]]\n",
            "targets[[60 1627 17 1767 6 6 9 27 77 1712 4 940 22 0 552 119 1281 201 5930 3044]]\n",
            "targets[[1305 1609 195 26 227 1 590 172 14 7238 23782 8 7808 24 67 29 3553 2606 4 338]]\n",
            "targets[[84 215 10 51 7 8921 52 72 720 154 602 9 215 7 175 490 1 7 133 67]]\n",
            "targets[[0 64 49 1397 43 8571 0 3458 5 11 0 3458 2387 1 7950 530 1595 1583 35 212]]\n",
            "targets[[12 419 10 5 0 466 1969 10 5 0 8998 3 2 49 151 781 74 815 39 5]]\n",
            "targets[[4252 2 63 3 1639 12 6411 52712 11 505 78 2 145 4647 879 13 3319 42 1059 22]]\n",
            "targets[[36 0 8354 1 30 144 0 328 499 22 1312 3518 14 2460 1083 3607 34821 1219 40 568]]\n",
            "targets[[723 21 1825 2 725 11 9 420 21 169 137 4 38 43 7 37 264 0 63 5]]\n",
            "targets[[3035 45 186 73 3606 4415 120 0 5257 16 0 1416 3 2872 12170 473 0 178 39 25]]\n",
            "targets[[87 6129 6350 210 21 1824 3 0 19 888 31 0 17 270 9 232 1283 7 12 23]]\n",
            "targets[[3476 13 35 1094 1606 2707 11 13 2240 822 18 79 7295 196 2901 8 91 4585 3079 5179]]\n",
            "targets[[203 136 11 9 242 770 9 27 147 16 0 227 105 1816 41 215 110 30 3 0]]\n",
            "targets[[1633 19 13 29 3 0 117 104 31 0 2810 7102 19 1322 11 9 27 123 110 39]]\n",
            "targets[[0 82 317 454 34 118 23 38 0 17 9 118 108 83 93 0 1414 1 512 2]]\n",
            "targets[[33 859 12454 601 1286 2811 0 63 408 33 947 48117 971 55 23 64 53 212 101 18]]\n",
            "targets[[709 21 97 108 1224 98 9 367 3107 2 2894 199 97 3453 1 97 4429 55 8 127]]\n",
            "targets[[19 45 0 1004 4 28 14 81 14 0 82 105 7 45 186 49 101 2 186 1680]]\n",
            "targets[[693 161 43 10 19 51 9 307 7 22 6113 1234 0 82 249 37 9 13 482 4]]\n",
            "targets[[68 48 49 375 8 251 18 0 173 49 692 96 23 93 55 16 30 0 74 8]]\n",
            "targets[[33 48 3 0 798 8 898 9 13 1027 35 181 17 376 2 909 29 41 2 374]]\n",
            "targets[[112 4511 91 38 2 184 17 64 56 29 1439 17485 213 11 864 34 12 364 9 80]]\n",
            "targets[[17 141 28 329 14 2 11967 4 1893 1500 14 4 134 20 141 23 359 0 16934 2202]]\n",
            "targets[[13 64 2 527 51 10 17 389 44 1 7 92 2 145 1461 22 71 9 478 196]]\n",
            "targets[[146 34 723 21 353 0 298 61 5 60 411 14 69 20 83 169 2 53 1009 1]]\n",
            "targets[[13 261 931 4 10 1165 1 13 2227 671 6 6 1 9 242 53 710 5393 31 4578]]\n",
            "targets[[215 10 22 3685 143 8 4704 14 303 377 38331 29 311 132 303 22 5049 7 4655 258]]\n",
            "targets[[29 581 38 7 13 763 294 0 1582 12 205 185 4 0 1940 32965 55 1126 22 48]]\n",
            "targets[[250 151 43 4697 5 23 11 7 12 896 186 74 41 11 0 109 5 2215 684 3330]]\n",
            "targets[[210 21 165 2417 41 4597 37 9 420 21 198 7 2 666 314 8 189 0 19 5]]\n",
            "targets[[39 25 1022 30366 1211 766 2351 436 427 22 2 673 33 7987 3810 4390 1813 51111 34 79]]\n",
            "targets[[3 0 1187 2183 38 15645 41 0 3202 30 2176 55 366 4 886 612 547 43 1689 2087]]\n",
            "targets[[1291 10 458 16 24371 15285 16 163 6540 41 37 1 9 13 1027 2 337 10012 208 97]]\n",
            "targets[[0 194 472 3 2724 104 50725 1488 2 385 936 3 1036 4168 1 702 0 63 3 2]]\n",
            "targets[[212 101 1 523 116 18 0 1889 868 199 1042 10125 1 0 2329 5 1986 658 1 1346]]\n",
            "targets[[6 6 10 5 239 157 2193 348 17 11 494 4 76 33 22 1880 1960 7419 1 431]]\n",
            "targets[[19 270 8 3345 8 8493 499 41151 15 2 563 119 3 0 563 3 0 484 2937 11]]\n",
            "targets[[856 37 73 52 36 6657 20620 1 10125 6674 10 17 13 401 2 58205 0 109 13 1567]]\n",
            "targets[[140 3072 0 907 27 113 353 2 298 3 100 244 73 334 2 5834 673 1 426 23]]\n",
            "targets[[5 2 583 17 36 2 1308 1 1638 1998 132 0 63 5 595 7 5 1051 1 5075]]\n",
            "targets[[9 215 0 277 1980 8 0 1045 9 152 429 2 17 43 9183 15 1 7 83 28]]\n",
            "targets[[738 1430 1260 1022 6 6 402 9105 3 0 330 2 155 975 201 15 449 44 1326 375]]\n",
            "targets[[13 3618 44 8 2 147 5489 1170 36 157 898 4222 11 255 34 236 66 0 25148 1135]]\n",
            "targets[[177 10 17 84 120 5505 194 188 38 2 337 192 1627 18 2 1092 5517 8379 24 12]]\n",
            "targets[[65 470 4 38 10 869 107 2 340 3 0 477 1 2 340 3 6454 944 1304 944]]\n",
            "targets[[1216 103 11 30 104 27 48 3720 2 363 3 594 135 48 744 181 56 14376 201 41]]\n",
            "targets[[50 9769 10 1356 564 15 29 670 1533 174 782 3 10 17 83 93 20 230 38 20]]\n",
            "targets[[22908 71 4 993 2 17 15 2 171 3 60 519 156 1908 1 3722 9 772 1654 3977]]\n",
            "targets[[7 22 11316 1047 44264 11316 5 35 12030 19 36 2213 12 480 153 2106 18147 2 63 427]]\n",
            "targets[[65 50 136 9 448 0 17 8 91 205 3370 111 0 333 1409 36 8622 625 2410 78]]\n",
            "targets[[2 462 1 12850 311 8 5735 2 901 12328 3153 6687 0 611 410 1 0 8375 24324 0]]\n",
            "targets[[84 215 10 19 42 99 9 319 0 3302 8 8632 143 94 7 465 38 35 212 19]]\n",
            "targets[[38 33016 5051 601 1420 279 2154 1518 465 4 106 44 16 2 160 209 2006 4 26 594]]\n",
            "targets[[3417 8 0 328 5 2 53 368 1084 33 761 1625 2814 4 62 3092 18 15 657 3]]\n",
            "targets[[2 1349 115 19 10 5 92 8 5290 22 47 13 3551 2 53 360 341 10 105 32005]]\n",
            "targets[[20 387 5270 6503 10 17 386 21 65 382 73 4 20 35 570 13 92 4 39176 2]]\n",
            "targets[[897 3615 538 912 22 0 17 7 12 2 997 87 74 7 5 1 56 29 59 738]]\n",
            "targets[[509 10 19 69 7958 1 186 953 951 3 2 49 196 2901 63 6 6 70 793 4]]\n",
            "targets[[0 47911 65441 906 4 0 116 11 162 8389 9 140 37 1679 9 96 28 2 18077 71]]\n",
            "targets[[374 17 39 96 28 317 263 98 36 10 63 74 225 74 12826 74 1684 74 135 134]]\n",
            "targets[[13 42 157 2952 19 3 0 4202 1322 18 995 416 33 4027 4458 61 9 67 110 48]]\n",
            "targets[[37 9 103 91 49 247 6 6 22 0 4711 616 6 6 9 10149 0 168 8 48]]\n",
            "targets[[2114 1 0 15194 79 542 14 14786 5 29 3 146 2319 2574 7 5 2 53 49 19]]\n",
            "targets[[159 21 138 78 10 17 15 303 1422 1 32 68 186 73 1825 99 107 65 4021 15]]\n",
            "targets[[9 242 37 899 8 1993 1890 9 65 10149 10 17 10 17 5 273 2 66 46 20]]\n",
            "targets[[17 96 64 573 2 19 11779 0 361 274 0 220 3 667 3 0 455 102 9346 10]]\n",
            "targets[[254 10 19 0 84 57 51 9 13 2650 16 48 515 8 1868 2896 26775 30594 67 7370]]\n",
            "targets[[17 67 35 322 63 344 0 156 68 81 1 0 1068 3 3287 14493 14 7507 13 1175]]\n",
            "targets[[9 84 555 43 10 17 9 196 11 0 109 2902 2013 2 299 15 2930 96 28 186]]\n",
            "targets[[17 5 23 14 49 14 30 103 0 156 25 1 0 63 5 53 705 38 9 1158]]\n",
            "targets[[47 0 412 12769 9 382 20 50 21 65 512 238 765 15 2 412 38 11 51 20]]\n",
            "targets[[2669 5613 5 438 2 18150 122 15 2 4039 49 834 18 7 1015 13635 8 503 85 3]]\n",
            "targets[[64 151 613 43 10 17 5 0 450 69 273 0 2255 1686 9 232 2330 20 106 7]]\n",
            "targets[[6313 529 10 17 35 823 1991 3 1108 223 47 5 7 2 997 10 17 141 4205 4]]\n",
            "targets[[898 109 2690 31791 162 7 500 38 7 5 6741 2005 12 17 51 30077 22388 5 0 1380]]\n",
            "targets[[5 2 53 49 92 16 246 19 7 4582 1062 8 11306 7685 2654 12 1 0 441 3]]\n",
            "targets[[10618 3662 888 218 5599 22 2 6585 1294 1 32 203 169 2 95 4 5056 120 175 132]]\n",
            "targets[[17 165 45 2 977 49 63 18 218 13428 185 8 440 1300 1265 7 12 221 14 46]]\n",
            "targets[[17 5 1056 99 0 13949 25373 202 91 23 135 36 0 202 91 2 217 160 1435 17]]\n",
            "targets[[1216 350 4 758 0 681 160 5198 31 0 711 11032 1045 85 39 12 37 108 74 184]]\n",
            "targets[[4184 180 2 631 487 9 13 84 3800 4 10 115 184 43 1125 154 602 33 60 1560]]\n",
            "targets[[5 0 244 3 17 20 2577 20 278 8 127 7619 7 5 48 948 74 1563 120 339]]\n",
            "targets[[9 140 23 2 48757 10 1 2382 25 105 3 0 52 1480 7676 104 9 139 110 1059]]\n",
            "targets[[3 131 507 798 25 42 630 23 1343 4 106 15 127 2824 82 9 13 18165 4 60]]\n",
            "targets[[23 42 853 29 3 0 250 7 5 0 250 19 3 30 57 2 145 4161 0 153]]\n",
            "targets[[5 2 1571 1 2950 13300 436 39 5 0 919 1 0 57 16191 22 0 2395 4259 3]]\n",
            "targets[[5 42 43 0 250 1141 202 11 45 77 3319 22 2304 246 9 89 21 121 134 0]]\n",
            "targets[[65 448 1541 227 311 37 9 15621 10 19 349 15 0 22177 1 7036 1028 533 20 42]]\n",
            "targets[[17 5 23 6158 464 0 6349 827 369 1 91 3968 4 4895 2605 2 462 9036 16 1532]]\n",
            "targets[[307 1750 3144 3752 459 44 3 163 10181 577 4224 1009 18 25346 2503 36 0 7440 3379 3]]\n",
            "targets[[13 42 2 394 17 56 29 141 453 62 57 138 66 137 332 10 17 5 208 2]]\n",
            "targets[[10 19 31 0 2004 184 832 827 1322 8 42244 6593 227 311 10 5 0 84 19 11]]\n",
            "targets[[2506 1652 87 394 10 17 5 242 9 0 64 29 128 34 635 0 95 91 1264 39182]]\n",
            "targets[[84 6237 2 1490 772 59 950 4 28 0 250 17 8 472 376 10 5 297 9 382]]\n",
            "targets[[19 210 21 164 4 636 127 114 7 12 247 1 1244 8 2 8975 1986 13 131 454]]\n",
            "targets[[65 5702 10 17 16 108 996 84 0 290 25 497 1 1407 0 116 5 497 584 1882]]\n",
            "targets[[289 940 22 10 17 5 87 28984 13 482 4 76 3146 156 4 166 22 10 17 1186]]\n",
            "targets[[7537 73 3 23057 2569 12 160 19 0 887 4990 5 1050 15 20963 2642 7607 405 1 2801]]\n",
            "targets[[987 11 0 2105 3 10 19 13 3273 18 9 13 133 2445 7 45 2 397 266 3]]\n",
            "targets[[10 17 16 145 11 12 30 9 96 103 0 84 57 9 215 10 19 0 63 1109]]\n",
            "targets[[3386 5 35 322 637 11 12 251 4 597 9069 439 38 545 14 69 14 6825 439 1]]\n",
            "targets[[139 110 2 363 3 9004 427 98 1 2950 30 3 90 68 186 49 9 1124 51 2]]\n",
            "targets[[0 88 3496 43 276 19 8 0 5622 160 728 19 1322 5 9785 8 1806 0 1553 194]]\n",
            "targets[[413 17 4401 10220 15869 14 2 4602 216 748 8408 36 2561 1047 34 11252 218 19289 4 2491]]\n",
            "targets[[19 274 0 6095 3 5843 1 0 6351 1 10734 3 0 342 34 67 4 4216 131 1120]]\n",
            "targets[[3293 210 21 1427 4 28 859 819 42 2 247 19 0 109 13 1424 23 0 1467 4591]]\n",
            "targets[[43811 4478 0 2128 443 8 2213 36 4286 2514 213 583 31 0 889 1025 1 627 951 909]]\n",
            "targets[[27 35 379 3625 1 10453 8604 3 4981 1 9 182 4 66 7 8 30 91 5487 3296]]\n",
            "targets[[149 10 17 43 2 249 8 0 114 3 2 3043 9 420 21 387 0 303 678 7]]\n",
            "targets[[9 67 0 1792 3 2683 10 19 16 35 6341 19 3089 70 25 8 0 3 3657 104]]\n",
            "targets[[13 2 245 17 4 106 1 9 59 23 395 7 4 255 11 9 121 9 140 30]]\n",
            "targets[[604 262 11 255 96 27 12589 281 4 66 10 17 0 5836 116 36 295 575 24374 11627]]\n",
            "targets[[12 66 128 25 0 3353 3 0 1245 1649 1125 7303 676 3 2 2614 1 2 328 1125]]\n",
            "targets[[5 29 1 29 293 624 4 66 10 774 10180 184 487 1364 11559 91 53 13903 4 71]]\n",
            "targets[[23 335 379 10 19 9912 152 1633 964 32719 0 1139 1577 1 87 7 51528 4096 39 5]]\n",
            "targets[[545 230 10 19 5 2 1247 2808 23 64 5 7 0 457 3 4287 4467 12 590 18]]\n",
            "targets[[1302 4 999 60 8486 134 134 9 307 10 442 19 22 3685 9 371 103 9 96 139]]\n",
            "targets[[59 376 198 1108 41 700 4 10 2363 19 85 7 274 51 1 87 2 2363 19 476]]\n",
            "targets[[17 43 0 88 11184 329 668 3298 670 8 0 646 1081 11 5 52 899 8 6993 205]]\n",
            "targets[[17 5 65 305 7 12 2 53 323 17 61 499 15 275 14998 13063 26 582 29625 1]]\n",
            "targets[[9 1281 10 2 700 44 3 2 163 9 64 529 7 2 700 85 9 723 21 110]]\n",
            "targets[[74 7 12 38 20 141 10015 0 2725 2 4341 24865 8 42329 61 56 619 123 188 4]]\n",
            "targets[[2 2458 6625 10 530 3 6625 45 195 4 9713 0 320 23005 3 625 729 597 68464 191]]\n",
            "targets[[145 368 720 44 3 720 174 279 5 414 0 877 5 2 2404 9548 3 2565 135 135]]\n",
            "targets[[0 19 9360 5 3770 427 22 0 5995 3 2401 178 5643 9360 7017 55711 57758 0 15974 1880]]\n",
            "targets[[42 182 4 712 60 105 6942 273 1 3213 71 46 9 242 5210 137 11 45 478 77]]\n",
            "targets[[9 89 21 382 43 0 17 9 382 43 47 551 22 796 1783 13108 9 159 21 27]]\n",
            "targets[[2924 1022 6 6 9 136 11 18 255 11064 192 4 28 884 10 50 241 833 44 174]]\n",
            "targets[[1291 10 17 227 2740 31 60 711 17 6353 7 13 810 223 76 223 850 1 9 932]]\n",
            "targets[[12861 285 23792 2 183 640 234 11 724 10521 8 112 15 0 160 3144 291 158 3512 2351]]\n",
            "targets[[10 17 13 2 1446 16 10 846 647 340 194 22 35231 1 23 3136 0 206 143 63]]\n",
            "targets[[67 4 3385 0 981 5677 3 0 2727 1113 51 9 2439 4 860 11 780 1275 32002 289]]\n",
            "targets[[5 35 2428 18 24 5 1824 43 7 1 1398 8 8094 26 114 5 475 348 1 24]]\n",
            "targets[[5 60 519 17 123 6 6 131 25 0 3353 16 71 6 6 36 10835 12 1215 468]]\n",
            "targets[[567 1138 9 133 402 0 3446 918 10 2888 368 67 22 71 14 2 527 1902 55 8]]\n",
            "targets[[5 0 244 3 158 3041 707 11 0 2626 329 4 14234 44 174 1307 1549 584 2005 285]]\n",
            "targets[[9 215 0 889 9 196 9 13 8 16 2 53 200 181 960 17 17859 13 9 8]]\n",
            "targets[[312 550 31 219 282 2 1307 11 9 1690 0 250 614 19 16 178 4 106 8 10]]\n",
            "targets[[117 172 3 0 17 13 11 9 1591 7 1027 2 4161 18 0 3297 13 17985 1 60]]\n",
            "targets[[149 10 17 9 67 48 613 5242 43 7 23 64 5 10 2 5218 436 1 14 20]]\n",
            "targets[[675 12 211 688 1 5369 8 10 3945 7511 201 11 1015 4 1634 238 498 4 2457 41]]\n",
            "targets[[47 2 19 10 552 3934 688 17 3776 2522 4712 0 52 20 278 8 0 52 20 76]]\n",
            "targets[[59 103 75 59 76 1555 22 87 374 10 4463 3968 458 122 5 15 7 12 3732 2833]]\n",
            "targets[[9 113 196 2 17 1886 4 28 8416 2 308 18 10 29 5 1203 0 250 17 9]]\n",
            "targets[[959 874 4 498 959 3500 3435 3471 13 8 91 32506 10 3683 55 0 369 888 4 278]]\n",
            "targets[[27 77 149 483 3 258 451 16 1783 154 1 242 133 2 669 340 9 27 254 39]]\n",
            "targets[[8676 7606 11530 3161 3176 17341 269 4 474 4 169 44 43 501 1 40112 15 2 1540 522]]\n",
            "targets[[203 136 9 13 770 15 0 492 3 0 17 7 13 229 126 72 9 856 2595 1]]\n",
            "targets[[121 9 242 23 0 310 16 10 910 18 58 60 14494 13 1072 33 7 0 63 302]]\n",
            "targets[[72 327 0 4284 3 417 1325 3744 1781 5278 12 5996 0 125 1 26 989 3978 274 87]]\n",
            "targets[[12 17237 5 11381 33 108 1502 14 29 3 0 2075 2601 3 907 3 619 12105 54 13]]\n",
            "targets[[125 1 26 312 25 1018 259 4 1013 0 16929 1253 11 2109 0 665 2348 62 766 256]]\n",
            "targets[[112 10 17 7 5 35 322 527 17 1 9 419 11 295 83 31 219 106 7 9]]\n",
            "targets[[50 20 371 122 28642 9 103 9 27 371 110 2 1178 8 181 15 44226 2 19 11]]\n",
            "targets[[47 46 48 136 10 13 379 0 726 177 445 663 5 165 53 49 193 0 703 1]]\n",
            "targets[[9 288 21 15 2 742 3 82 355 31 0 797 9 59 27 2518 44 99 0 84]]\n",
            "targets[[12 47 9 50 136 10 17 5 37 74 113 445 100 2216 66 10 17 9 350 4]]\n",
            "targets[[3897 12 320 22 0 11856 5 2 1875 2967 2565 436 270 5976 2 2307 22287 4889 22 0]]\n",
            "targets[[582 761 6 6 1235 9384 308 6626 308 6 6 500 2756 13423 3462 6 6 1057 35 422]]\n",
            "targets[[139 42 4989 0 6137 339 3 2 19 11 9 402 15 73 4731 36 1700 1 7 12]]\n",
            "targets[[37 108 82 964 34 17151 8 0 3392 8286 5421 284 3467 11314 5241 511 8182 4942 12 1187]]\n",
            "targets[[84 1461 61 5 164 4 28 1016 8 779 2602 5 11 134 5 10 19 748 29905 1167]]\n",
            "targets[[1022 6 6 10 17 0 18807 5 65 212 30 9 6961 693 43 7 13 11 7 59]]\n",
            "targets[[360 341 5037 404 2996 18 437 607 17 5 606 47 2 171 3 200 341 104 663 2]]\n",
            "targets[[139 1632 48 798 33 82 898 6313 11 27 5702 10 17 9 89 21 182 4 2376 0]]\n",
            "targets[[3522 14 29 3 0 173 3563 349 15 33190 1773 111 26 2420 1 1054 3283 25 88 1501]]\n",
            "targets[[19 5 8 0 56193 7937 530 6 6 32 68 193 2062 18 32 25 1297 126 72 10]]\n",
            "targets[[89 21 387 0 1359 3 10 19 7 45 56 109 61 5 23 2802 2 74 151 157]]\n",
            "targets[[21 76 71 356 9 140 2 669 340 3 108 3 2042 12 98 538 26 544 1289 12]]\n",
            "targets[[45 4 993 1295 775 0 2645 250 303 369 1053 98 3 30 57 0 109 1 63 344]]\n",
            "targets[[227 311 44921 60 738 3 1675 3 299 64 307 7 0 311 167 1 23 65 381 1763]]\n",
            "targets[[509 21600 983 53 73 10 5 241 0 117 201 9 27 8 60 17 1568 0 101 25]]\n",
            "targets[[834 16 10 17 5 595 1 37 5 0 225 35 3745 4873 218 26 1566 435 4 1150]]\n",
            "targets[[2 7439 12241 9 13 261 931 4 318 10 17 257 14 7 67 13924 8 7 6 6]]\n",
            "targets[[157 2521 1792 10 5 1 2 371 1136 29 3463 1456 5 23 47 20 207 512 36 4895]]\n",
            "targets[[17 5 2193 74 29 26945 0 7725 25 259 4 93 2 2571 43 1995 296 32 14360 62]]\n",
            "targets[[200 1022 37 353 15 1598 456 41 15 1598 12622 11 9 2020 20 223 588 3 127 114]]\n",
            "targets[[17 67 37 108 689 9 89 21 121 111 4 366 0 109 4493 2625 22 8697 404 5752]]\n",
            "targets[[1838 96 23 27 77 52 5646 41 11949 31757 3272 46 2290 144 0 531 3 735 1048 1864]]\n",
            "targets[[1923 432 3 637 715 2 4225 2926 3 2 640 1772 7468 719 392 16 1037 2058 830 44]]\n",
            "targets[[7 12 35 212 834 18 0 153 3966 88 3 0 5137 7 1564 8122 64 2 3274 3]]\n",
            "targets[[17 13 42 1043 74 42 43 174 814 17 675 5 930 1 22284 16 74 216 218 240]]\n",
            "targets[[4140 4 2666 6756 439 78 0 797 33 575 519 156 36 11 19 8 2 299 63 15]]\n",
            "targets[[4 875 0 305 290 141 28 748 305 16384 51 0 153 15745 181 9 481 24 79 11402]]\n",
            "targets[[37 108 683 1652 10 19 18 64 29 83 2731 7 55 6 6 609 6 6 84 120]]\n",
            "targets[[9 65 424 887 33247 97 9 13 261 931 4 157 1592 2966 408 1086 99 318 11 19]]\n",
            "targets[[529 10 17 2 796 85 14 73 14 9 118 367 7 39 68 2 173 179 11 159]]\n",
            "targets[[371 196 7 13 92 8 0 4803 6 6 0 74 116 0 18025 471 1846 2027 0 5909]]\n",
            "targets[[13 53 1683 33 0 894 547 8 0 19 0 17 67 807 1487 224 1 436 61 9]]\n",
            "targets[[12 23 73 9 50 136 11 1505 21 478 77 300 8 0 897 16200 829 3 11160 5239]]\n",
            "targets[[1029 581 53 337 1815 11 13 7 9 140 767 18 9 2305 149 10 19 99 43 969]]\n",
            "targets[[5 2 81 502 3 19 1471 14 174 130 45 48 441 3 2828 6248 22 0 1590 0]]\n",
            "targets[[36 227 328 22 0 319 577 2 13176 92 10 1224 17 15 2 225 36 0 314 3]]\n",
            "targets[[39 8 2659 484 51 0 17 13 763 8 0 1606 3 5332 70 1102 3 0 3385 31]]\n",
            "targets[[1059 0 53 2139 27167 1 418 120 78 474 4 169 48 1409 4 359 90 22 9 1291]]\n",
            "targets[[327 379 7 1688 60 3055 43 314 611 10 5 428 4 28 81 246 85 0 216 34]]\n",
            "targets[[7030 1 966 4422 25 7167 8 10 245 168 78 0 462 489 3 34978 5906 7030 14 0]]\n",
            "targets[[60 7906 9 409 8 10163 1 51 36364 1287 5476 389 4 47676 54 418 205 144 60 3420]]\n",
            "targets[[65 5 57 4 704 10 4 2 498 10 5 270 8 0 4754 7 1739 8 5332 37]]\n",
            "targets[[2 360 341 17 9 481 20 50 136 11 7 56 50 21 58 136 238 49 43 10]]\n",
            "targets[[9 1591 262 9 13 1027 48 911 1212 19 9 13 3381 770 4 169 2 49 63 523]]\n",
            "targets[[17 971 55 440 617 1205 43 7967 863 124 10 17 93 97 73 359 3 536 51 7]]\n",
            "targets[[3 178 31 219 9377 105 3427 0 145 176 111 70 25 31 0 6658 3 2216 1 0]]\n",
            "targets[[80 112 360 341 98 18 10 29 5 42 379 1 23 8 0 49 379 266 11 5]]\n",
            "targets[[139 424 10 122 16 2 132 6 6 1364 2 1043 374 115 396 1 7672 2 2877 234]]\n",
            "targets[[490 7 12 12814 11 255 11677 185 4 2 4467 17 83 27 2564 5708 718 7 1978 14454]]\n",
            "targets[[64 0 117 5564 19 18 29 3 60 15137 104 3 30 57 6 6 51 9 84 307]]\n",
            "targets[[12 15598 31 0 49475 2903 3846 1 21323 1 27 4959 30 32 50 1858 62 21252 25 7305]]\n",
            "targets[[21 262 131 156 5322 22 16 10 216 1635 35 922 1028 370 2349 5981 1199 2 21251 9]]\n",
            "targets[[12 7607 2198 2818 5 14 49 14 9 856 7 4 28 11 5 1348 1 11592 1094 3186]]\n",
            "targets[[2 34 2164 55 149 1174 104 36 0 200 1820 2566 638 13 0 12644 19 16 11 2040]]\n",
            "targets[[15 0 158 1655 15 0 160 6 6 9 38 10 17 85 3 91 1247 393 730 4]]\n",
            "targets[[148 93 3 16550 60733 2 53 348 17 1 53 736 1100 30 27 110 7 167 4891 0]]\n",
            "targets[[5 2 13581 115 1594 3 2 19 20 103 20 27 7 2700 44 33 0 84 315 541]]\n",
            "targets[[2733 45 4 28 2 9038 279 24 252 2 183 125 985 4 2 4058 8 32844 35 1754]]\n",
            "targets[[113 949 43 98 18 10 5 0 29 17 11 45 371 92 71 230 1213 9 1095 7]]\n",
            "targets[[45 2 81 412 18 0 17 210 21 273 0 19 91 92 15 0 109 5 379 1]]\n",
            "targets[[307 0 17 0 19871 8 54960 111 172 3 0 19 13 92 9 371 509 0 442 17]]\n",
            "targets[[3 0 52 2246 869 30 62127 1839 17383 45 0 11231 3 108 11489 92 294 0 10855 3]]\n",
            "targets[[5 38 2 9478 1989 1556 18 447 142 336 116 18 58 447 5 0 109 701 1410 62]]\n",
            "targets[[7403 12 17 1971 1 227 9 419 7403 12 116 5 165 480 4 28 1146 37 47 162]]\n",
            "targets[[5 23 606 35 1592 1939 17 152 51 9 195 7 36 7051 26 390 13 15223 22 7]]\n",
            "targets[[13 29 3 43 5384 75 11 13 1819 192 4 66 35 407 5862 3 10 19 6 6]]\n",
            "targets[[42 215 10 19 8 2647 2314 60 425 693 286 34 912 22 7 37 9 196 9 207]]\n",
            "targets[[499 33 6263 178 0 507 11 5 4 5227 2 8535 303 2284 1542 1293 13651 22 35 958]]\n",
            "targets[[49 10 17 5 23 594 31 30 9 1184 529 10 2 459 678 9 13 532 272 223]]\n",
            "targets[[17 1386 29 3 3985 12 117 347 4 1309 843 7157 1927 24 5 29 3 105 179 11]]\n",
            "targets[[17 13478 0 170 291 14 1640 12 23718 1 193 5193 1256 27 2 171 8 1105 193 104]]\n",
            "targets[[7 288 21 38 0 298 18 33 23 256 353 0 298 9 288 21 11298 33 47 4]]\n",
            "targets[[4854 3 30 5 87 10 1086 123 3814 0 1774 1 4715 4 76 120 0 1526 22 0]]\n",
            "targets[[27 110 105 3 0 275 762 1 9 27 4 380 20 11 10 5453 45 71 149 174]]\n",
            "targets[[6239 11 9 242 113 878 4 2 19 14 74 14 10 29 7 67 2 115 1004 18]]\n",
            "targets[[29 95 3 532 43 10 19 61 5 35 9106 3 2 304 0 84 486 203 129 31]]\n",
            "targets[[307 10 17 65 544 227 311 1 627 46 7 12 544 94 9 140 186 10650 3 98]]\n",
            "targets[[19 19985 22 174 485 3456 5877 9 467 253 26185 8 0 17 16 256 142 485 39 68]]\n",
            "targets[[5 29 3 146 98 11 20 27 4 865 1 103 43 16 5083 2537 51 9 2564 672]]\n",
            "targets[[19 5 2762 58 33 0 4480 1645 3 1528 33644 33075 1 5376 25 105 15 53 263 4499]]\n",
            "targets[[467 24270 37 9 13 2313 4 169 44 36111 13 107 3319 22 2 711 27901 1554 9 207]]\n",
            "targets[[454 103 11 9360 5 23 49 85 3 0 181 172 3 7 13 23 49 192 69 46]]\n",
            "targets[[470 4 350 10 19 85 3 3134 6163 1 28163 18 1587 34 8649 9723 24 96 28 49]]\n",
            "targets[[11651 5 110 8 26 648 393 4286 12 2181 15 626 112 573 1 648 224 14 15 88]]\n",
            "targets[[2 184 832 827 10 19 5 2 26038 2102 7 12 239 157 1036 1563 120 1016 8 0]]\n",
            "targets[[3 60 1628 104 84 215 7 51 9 13 43 163 61 241 702 20 2 171 43 0]]\n",
            "targets[[83 169 7 727 4 6530 10 360 341 56 390 778 254 64 22 0 8360 3 2 173]]\n",
            "targets[[1407 19 9 409 8 1351 1 0 109 5 37 1938 9371 7 12 630 56 29 96 28]]\n",
            "targets[[5 2 220 111 29 1129 179 11 29 50 21 106 85 91 37 6714 155 29 83 706]]\n",
            "targets[[64 151 11 2574 71 52 72 0 639 3 75 34 424 10 17 5 11 7 13 513]]\n",
            "targets[[16134 12 582 25704 1 26 312 865 31 2 2472 8 62 3148 6820 62 493 34 4272 199]]\n",
            "targets[[67 113 196 0 1194 3 24867 104 59 123 20033 4 142 35 2875 0 19 45 2 1847]]\n",
            "targets[[37 9 13 11677 185 16 223 588 3 247 1847 9 112 2 49 4317 487 18 9 67]]\n",
            "targets[[1591 10 17 227 311 1027 2 737 2484 2230 19 9 13 628 4 169 7 13 73 52]]\n",
            "targets[[2440 14 628 10283 971 915 282 175 4 0 590 3 1640 2440 10 17 5 29 3 0]]\n",
            "targets[[1830 185 4 10 19 23 1237 238 686 47 0 1561 2501 1 9 67 64 2 4016 1718]]\n",
            "targets[[9 140 23 164 4 3640 0 17 16 146 3 20 34 723 21 110 7 18 11507 67]]\n",
            "targets[[19 5 73 52 72 157 5138 26127 18 0 5138 135 25 81 7 12 2 2018 3 355]]\n",
            "targets[[24616 5 2 1349 3254 22 2361 311 409 18 40 209 8 10 17 150 21 198 40 238]]\n",
            "targets[[1018 10 22 484 246 227 311 27591 13411 5622 51 9167 144 0 4278 1 58 152 9 67]]\n",
            "targets[[12 327 29 3 0 250 98 9 27 123 110 6 6 7 5 245 4 262 75 278]]\n",
            "targets[[116 9114 1 208 2 666 16684 3 1629 41 11210 18 52 497 72 0 116 5 0 500]]\n",
            "targets[[1407 246 1659 926 0 3 0 1149 36 0 8647 705 2462 41 7 13 428 4 566 15]]\n",
            "targets[[2 1250 6 6 2937 192 7 5 23 404 11 1306 313 1411 55 35 1222 8 0 2919]]\n",
            "targets[[17 45 48 1131 2346 11 93 7 749 44 229 36 0 10195 3 1001 12 184 98 46]]\n",
            "targets[[232 198 90 220 16 49 305 290 1 337 369 1220 9 232 58 1537 90 2 220 85]]\n",
            "targets[[89 21 121 771 4 395 10 17 4 0 439 3 18777 41 23 134 18777 85 20 50]]\n",
            "targets[[27 4 402 11 0 1138 12 68 2254 2 4270 18342 51 7 389 4 98 338 13 8]]\n",
            "targets[[3 0 2303 15 24 125 1 54 8465 5 29 3 60 519 423 12 98 51 9 13]]\n",
            "targets[[5 0 4508 4 2412 2 1047 691 20 121 47 127 373 329 4 11484 292 36 9245 22857]]\n",
            "targets[[572 45 77 642 22 88 23593 20468 22 26134 233 9 329 4 106 7 132 1938 36 377]]\n",
            "targets[[959 176 1 5165 959 1313 27 2391 2 1165 446 0 2301 2747 16 154 9 27 77 4]]\n",
            "targets[[10 5 2 7665 22 0 7976 16350 63 270 8 1844 7 58 1905 15 2 326 3 2]]\n",
            "targets[[13 770 51 9 4885 0 904 3 10 5453 4 66 11 7 67 23 77 427 22 2]]\n",
            "targets[[121 9 27 239 4 66 2 4495 6184 47 32 25 18708 150 21 6184 7 3044 150 21]]\n",
            "targets[[105 92 16 246 98 11 1201 4 6948 2 246 202 143 8 5051 1459 764 429 92 26]]\n",
            "targets[[13 33 0 412 3 0 17 1 9 242 1298 11 32 4652 8801 740 0 129 4 2633]]\n",
            "targets[[1591 10 17 85 7 465 37 630 1 9 196 7 59 28 607 9 13 1027 137 38]]\n",
            "targets[[2 13731 340 9 395 10 19 14 2814 4 0 1973 1 69 896 14 35 1783 291 158]]\n",
            "targets[[987 4 256 77 2 340 3 0 206 858 369 9 113 215 0 17 339 357 53 4733]]\n",
            "targets[[29 3773 20253 130 99 157 9 13 180 5164 11 7 59 30 211 292 8 0 129 61]]\n",
            "targets[[1351 0 901 1665 1588 1925 7440 1091 4 10256 0 3590 808 30 0 3105 6119 8 2 1332]]\n",
            "targets[[467 10 322 17 7101 7500 252 0 172 22734 1 15 49 485 54 285 2 243 34 5]]\n",
            "targets[[12 0 297 63 3 3723 601 7909 5 2 4067 336 5487 984 3 62 10395 5001 8003 611]]\n",
            "targets[[13 2917 1609 12 17643 4504 16 2257 0 7737 629 6060 28755 1078 0 3262 11 0 412 102]]\n",
            "targets[[183 125 45 598 4 28195 24438 741 51 6987 2419 4384 2 1856 2070 6 6 0 209 3]]\n",
            "targets[[285 0 4741 3636 1659 42 143 36 1199 47891 185 8 0 3101 299 22 560 24 2029 26]]\n",
            "targets[[2273 47398 124 8 2 115 52 72 29 541 47 82 52 3204 1 6275 104 1981 4 80]]\n",
            "targets[[16 15895 5 60 519 17 3 30 57 37 100 160 1086 36 1543 2508 45 53 200 3108]]\n",
            "targets[[467 10 19 9 196 7 59 28 727 4 106 1 727 4 843 9 2191 44 99 149]]\n",
            "targets[[4 783 4344 294 0 434 737 18 24 12 226 73 126 8 0 501 6 6 67 4]]\n",
            "targets[[1690 55 10 17 16 463 2280 31 2 11032 298 1045 1640 2440 5 2 1149 279 1 9]]\n",
            "targets[[548 47 35 3096 17 980 681 15 1163 305 290 0 1474 5 252 33 29 216 8 838]]\n",
            "targets[[1591 10 17 0 82 249 1 203 136 9 27 23 110 2 447 17 8 180 48 57]]\n",
            "targets[[4062 5 4204 379 14 2 184 19 18 5 2800 35 413 434 1160 4 35 221 1766 5855]]\n",
            "targets[[2 360 341 1086 0 19 13 2 1002 0 63 5 212 1 0 156 68 1119 4914 12979]]\n",
            "targets[[118 255 332 165 367 0 1192 461 6311 31 219 54 288 21 348 1 54 159 21 11382]]\n",
            "targets[[17 13 379 0 797 13 330 15 2972 1090 295 13 2984 4 28 8 39 149 142 1223]]\n",
            "targets[[0 29 291 299 5 221 31 35 129 2 8619 9522 3 489 1108 45 77 8227 33 20238]]\n",
            "targets[[5 0 244 3 17 11 1762 0 247 44 3 164 4 0 443 134 865 144 10 244]]\n",
            "targets[[156 4205 8 2 471 17 6 6 23 29 3 90 5149 721 10 10609 20 221 230 74]]\n",
            "targets[[19 5 2 2271 201 715 7163 18575 0 598 4 80 47 54 124 117 54 45 2 13877]]\n",
            "targets[[3 10 104 1550 45 77 400 233 9 2290 7 14 2 163 12286 158 493 1160 4 0]]\n",
            "targets[[341 637 7 12 30 43 1592 1939 1807 1 26 972 1302 796 36 3270 791 7 3448 3908]]\n",
            "targets[[470 4 106 10 17 233 9 215 0 48661 477 680 735 832 827 1 2 523 463 694]]\n",
            "targets[[12 2 4145 1563 120 3 338 1116 599 487 2113 1156 2588 3635 1 11341 3579 64 128 20]]\n",
            "targets[[307 10 17 154 602 1028 4 33 60 1171 939 1 9 50 380 20 10 10 17 2144]]\n",
            "targets[[2574 56 2381 1684 56 1293 112 22093 10 17 5 1051 1 595 707 815 7 12 5166 1]]\n",
            "targets[[113 196 9 207 230 37 6464 3 57 6 6 9 1667 66 65 74 98 85 56 517]]\n",
            "targets[[467 10 17 7 67 0 205 3 3475 1 1278 4875 8 7 0 217 6222 5890 151 13]]\n",
            "targets[[113 7063 78 22845 10110 357 2 173 762 167 0 905 308 1994 9 13 5900 4 7 205]]\n",
            "targets[[287 12 384 7 264 10 19 5 53 22674 3869 1 0 270 1672 5 2 1737 16 0]]\n",
            "targets[[10 13 38 381 2 1040 49504 6881 8 127 384 119 1 119 175 58 51 20 196 11]]\n",
            "targets[[9 1281 10 17 2 223 16 804 2 605 608 3 778 8 259 4 1006 2 492 184]]\n",
            "targets[[280 38 0 17 159 21 1090 73 281 18 7 118 1090 0 153 2 171 3 532 4]]\n",
            "targets[[2182 3 884 0 15378 1 816 10 19 45 1403 60 312 1 9 4 160 2056 1059 9]]\n",
            "targets[[17 5 686 74 9 196 7 96 28 2 523 192 201 15 48 885 18277 4924 6 6]]\n",
            "targets[[50 2 19 11 1430 37 73 1751 1 4921 28 37 1587 348 11 5 0 864 9 1712]]\n",
            "targets[[5 2 17 20 59 112 46 20 112 0 3476 17 12 1080 69 0 1080 1386 170 18]]\n",
            "targets[[13 371 2 81 17 9 467 1681 3244 1 0 442 2836 739 3654 19362 5 79 2 53]]\n",
            "targets[[117 3093 298 43 10776 3301 8 4880 5 15004 33 91 23049 99 24658 2353 11 0 63 45]]\n",
            "targets[[117 151 43 2 577 2146 104 25 0 756 3 55683 0 11309 13 0 8998 3 2 81]]\n",
            "targets[[5 1247 4 66 2 1707 17 92 37 10430 1 2240 2488 9 1046 11 48 305 290 68]]\n",
            "targets[[25 64 2 173 274 11 9 437 722 29 5 333 3 21801 10 122 5 157 6 6]]\n",
            "targets[[0 217 10 13 2 186 49 186 247 17 7 401 92 71 449 44 1326 2 742 3]]\n",
            "targets[[994 11113 5 0 21951 3 994 27282 23 64 124 7 191 265 8 2 176 70 50 262]]\n",
            "targets[[59 4997 136 11 805 9 402 318 10 17 8 60 407 1700 9 420 21 353 0 2283]]\n",
            "targets[[5 29 3 0 88 5530 1 2193 348 17 9 27 123 307 287 71 1283 0 63 5]]\n",
            "targets[[286 67 4 706 3 2 115 2834 8 0 1916 7 13 2891 4 592 46 828 4593 92]]\n",
            "targets[[53 155 2561 974 1274 19 4129 33 0 8487 3 34381 12 20319 12893 4119 8 0 3821 1]]\n",
            "targets[[307 10 17 51 9 13 2 527 844 154 602 9 42 1591 7 0 82 311 16 60]]\n",
            "targets[[7725 67 4 28 445 0 2452 3 16778 11 25 23 1818 930 8 0 652 376 137 36]]\n",
            "targets[[651 10 0 250 17 3 0 291 41 0 250 17 123 642 8 2177 5 2011 51174 31]]\n",
            "targets[[4716 1897 3 10266 45 195 4 28 29 3 0 88 206 1 4179 3 30 0 104 2042]]\n",
            "targets[[0 7072 3 1173 3556 19 1447 45 371 599 847 1371 14720 41763 1655 45 16 0 501 154]]\n",
            "targets[[286 14 18820 14 153 32140 35004 96 191 1966 0 38 3 584 3936 1 1206 15060 1 12607]]\n",
            "targets[[2 21743 160 12464 9 236 28 52 2662 72 88 8 149 484 2379 18 9 27 4 136]]\n",
            "targets[[96 27 77 2 49 19 7 67 30 0 4679 18 5 1089 2371 33 105 3167 214 8176]]\n",
            "targets[[74 74 767 4 255 34 196 10 13 2 49 17 1019 841 1 1101 4 0 247 688]]\n",
            "targets[[103 11 11828 22905 152 54 204 350 245 5 23 53 49 31 30 9 481 7 13 85]]\n",
            "targets[[1073 32861 3229 3 2 1040 3235 8 1511 15 30 91 9989 1 17411 5 0 265 111 114]]\n",
            "targets[[45 4 28 29 3 0 250 104 9 27 123 110 208 2 813 0 64 151 212 8]]\n",
            "targets[[60 1948 3297 4137 30392 12 2977 25 0 88 353 1 0 5971 2977 80 122 48 2350 1]]\n",
            "targets[[5 60 519 30 57 17 7 329 4 28 60 2069 311 17 15 2 7336 1 4517 3]]\n",
            "targets[[0 2547 1 4373 83 169 10 19 1348 146 34 121 238 43 0 3246 83 66 7 16]]\n",
            "targets[[289 7585 3 10 17 5 0 655 1 0 41418 1301 7 2298 0 109 22 0 82 495]]\n",
            "targets[[12 213 244 3 10410 4 103 3 82 104 11 845 15 112 1 1328 1 0 2381 4333]]\n",
            "targets[[17 5 2 4823 14 229 14 1987 138 9 196 4230 887 2634 13 74 8 2 95 97]]\n",
            "targets[[255 23 1082 15 970 12 20323 12 298 10 19 141 28 212 7 5 3078 69 896 1]]\n",
            "targets[[1197 10 17 1240 99 3450 12 312 10 17 5 2 984 3 11 29 1 9 467 4376]]\n",
            "targets[[348 1 1383 246 19 297 99 796 1783 7 5 245 4 106 2 1521 17 1365 8 160]]\n",
            "targets[[70 30 196 11 0 869 67 400 91 1359 8 258 687 249 1 567 3685 389 15 2]]\n",
            "targets[[1689 2550 8329 755 15 2314 3567 14 0 4757 1403 33 10280 3 22420 4 1150 44 40 43354]]\n",
            "targets[[1121 2739 4696 1084 1129 0 981 3 0 133 12444 7936 0 10388 1 26 3552 2008 796 0]]\n",
            "targets[[5 634 2 201 4468 33 0 4475 1966 3 0 66118 2194 32402 1 6656 25888 39 12 48]]\n",
            "targets[[38 2 49 1341 19 14 73 46 23 52 37 72 0 364 403 37 837 87 9 448]]\n",
            "targets[[42846 2970 1654 2 1253 1376 5 6869 33 2 1627 425 1376 1209 25765 284 4967 34 3000 26]]\n",
            "targets[[14969 16 2 989 13 0 117 17 8 0 2621 1257 98 9 103 11 10 29 426 50]]\n",
            "targets[[67 77 7405 4 66 10 17 16 48 57 2969 7 13 1312 249 1 20 2330 9 13]]\n",
            "targets[[481 10 5 2 49 17 4 106 8 0 443 152 64 46 20 27 286 4 690 4]]\n",
            "targets[[5 1310 715 37 303 2921 4 10 211 22 0 17 5 437 348 9 140 23 2 3757]]\n",
            "targets[[12 384 7 46183 5 74 2 7167 1521 447 2 605 6650 3 0 847 15 1817 239 10687]]\n",
            "targets[[122 12 1616 739 188 4 27 35 769 16 0 303 377 564 1 62 1834 8521 0 919]]\n",
            "targets[[242 2 340 3 1166 3464 18 10 17 1762 10 17 5 2 984 3 2 2498 2048 17]]\n",
            "targets[[0 1080 514 4646 3 184 67 137 164 16 7 200 57 184 964 11 25 147 319 1193]]\n",
            "targets[[225 16 4127 326 223 2133 0 1746 141 27 77 1865 6795 119 1 119 15 2 480 6659]]\n",
            "targets[[19 2191 31 219 35 541 1123 72 7 141 27 1 3913 97 108 330 129 7544 11 141]]\n",
            "targets[[232 987 9 112 0 168 3 32293 42283 18 9 722 26 2183 211 22 32 25 30 0]]\n",
            "targets[[12 23 520 4880 6 6 103 3 30 0 2952 20715 1761 622 590 615 45 77 41121 16]]\n",
            "targets[[1855 122 13 413 1 247 16 0 88 172 11 785 71 149 1 58 381 0 442 202]]\n",
            "targets[[19 926 105 53 583 789 1 32 68 23 3031 4 27 11308 8 30 179 58 343 14]]\n",
            "targets[[1140 11388 972 5 371 539 4 71 7 12409 283 11 443 5 1003 4 28 7 12 1144]]\n",
            "targets[[17 5 180 327 29 3 0 117 9 27 123 4420 0 1308 697 1011 8 10 19 25]]\n",
            "targets[[73 4 136 43 10 19 134 80 32 93 131 1 16 916 737 184 19 15 2 684]]\n",
            "targets[[84 215 10 17 51 9 13 43 2373 41 2784 43 3008 154 602 22 2015 729 2950 9]]\n",
            "targets[[334 9 38 7 6 6 84 120 131 701 159 21 486 38 701 32 122 56 145 4385]]\n",
            "targets[[300 49 18 10 122 5 504 6 6 99 149 0 84 422 88 75 83 25901 7 14]]\n",
            "targets[[215 10 22 246 0 82 311 9 693 7 288 21 164 4 28 35 859 1316 17 18]]\n",
            "targets[[4638 5 7390 29 3 0 88 9038 1 4763 964 1104 8 472 24 13 666 8858 1777 16]]\n",
            "targets[[29 45 4 198 0 153 1095 16 87 16138 24 13 16138 59 28 0 205 2609 23 64]]\n",
            "targets[[28 10 19 45 48 1513 18 132 149 7 9 288 21 97 6729 33 11 128 70 27]]\n",
            "targets[[738 204 2924 48 1022 6 6 42 51 20 196 32 159 21 93 90 37 554 74 1557]]\n",
            "targets[[65 509 10 17 88 338 961 98 25 53 839 226 327 85 32 1667 177 255 15 0]]\n",
            "targets[[24623 2 2054 847 548 32 793 4 535 86 32 793 4 14053 86 0 793 4 15222 26]]\n",
            "targets[[13 37 379 11 23 58 761 21789 4869 41 1431 96 93 10 1678 6 6 47 68 32]]\n",
            "targets[[3066 5 2 81 19 46 20 25 4700 1 2053 10 5 88 20784 0 88 3056 19 123]]\n",
            "targets[[106 10 17 1 589 134 0 1787 2462 13 4953 55 37 73 33 7 8 354 0 19]]\n",
            "targets[[63 5 953 192 4 7716 235 2 17 190 10 17 1683 95 97 565 4 1017 2 507]]\n",
            "targets[[65 5 35 322 19 29 3 60 9034 55 39 15 4144 1331 1 282 718 2 57 8]]\n",
            "targets[[7 1147 0 947 200 57 9 139 213 448 11 4071 274 3 10 9274 9 772 158 969]]\n",
            "targets[[0 57 3 10 1641 7 13 2004 16228 11 4793 67 2 320 656 164 78 11157 15 35]]\n",
            "targets[[3055 3 2766 5 35 1887 102 2018 3 35 1743 5095 11001 4 956 850 3 3203 1 7244]]\n",
            "targets[[7 288 21 37 73 2 184 17 14 7 13 2 497 17 6 6 9 512 11 10]]\n",
            "targets[[17 10066 2281 2589 150 21 306 4 28 2 583 220 8 0 235 3 10 19 115 10750]]\n",
            "targets[[10 17 702 178 0 88 4867 151 11 50 592 4 20 8 2 1503 15 127 355 0]]\n",
            "targets[[42 307 10 17 1 7 13 1149 9 196 7 13 53 825 257 87 0 101 68 1011]]\n",
            "targets[[637 5 31 91 117 51 7 5 327 804 0 47262 12568 1 2094 10168 39 5 56 9185]]\n",
            "targets[[9 76 14631 17996 36 7051 9 404 1451 8 48 374 98 533 85 9 230 38 149 2]]\n",
            "targets[[5 29 3 0 117 184 1412 100 29 8 62 205 333 96 4216 91 2323 72 360 341]]\n",
            "targets[[87 155 1063 3489 12 978 18457 13 1 11 0 102 3 12496 13 81 8 7 20 59]]\n",
            "targets[[67 353 0 298 275 214 51 7 84 389 44 37 9 13 2313 51 9 195 6681 4]]\n",
            "targets[[307 10 19 8 1913 522 111 60 873 20192 1913 1741 1 26 312 119 7 94 48 1174]]\n",
            "targets[[1319 6953 4202 529 1922 4529 1 3732 3208 157 61173 725 99 351 2798 46 11 13 614 264]]\n",
            "targets[[50 9 136 43 10 17 11 1505 21 478 77 300 37 87 7604 48 935 1589 46 20]]\n",
            "targets[[19 13 180 2 2319 842 9 59 395 7 4 174 29 14 7 426 5 49 443 2]]\n",
            "targets[[7 12 42 85 9 27 35 1614 1096 3 18371 1 3242 528 18 10 29 195 445 60]]\n",
            "targets[[17 5 554 2139 1 1020 31 219 2 463 463 163 2041 1469 1 3247 3861 4943 25 0]]\n",
            "targets[[722 146 17 829 11 65 2831 7 1182 22 0 17 8 864 18 99 42 3138 0 227]]\n",
            "targets[[418 4 66 10 19 4120 1 264 9 159 21 27 303 1943 16 10 19 9 13 133]]\n",
            "targets[[93 2 19 27820 0 13590 1 0 145 314 1515 2622 59 6420 58 2 81 19 2775 468]]\n",
            "targets[[13 53 671 31 58185 9 215 10 17 233 9 13 1520 33 0 1144 290 8 9 419]]\n",
            "targets[[17 5 413 192 696 4 35 322 237 33 4451 5960 1 0 189 11 10696 33478 5 1311]]\n",
            "targets[[325 315 3 2041 5443 12 4516 7891 22 3028 8450 2107 15 26 227 4753 4 21042 2855 4]]\n",
            "targets[[307 1108 3106 7511 223 44 3 163 10181 5312 66694 948 3973 17 43 2 234 15 17766 34]]\n",
            "targets[[958 5 2 832 827 1234 17 7 12 53 155 85 7 45 2 1000 63 74 116 74]]\n",
            "targets[[470 4 66 10 17 123 233 7 13 84 6364 22 246 9 418 4 24879 474 4 66]]\n",
            "targets[[9 42 254 10 458 248 74 1 9 140 64 11681 10 85 9 13 770 23 4 169]]\n",
            "targets[[2701 182 4 198 10 17 2 163 9 65 80 48 98 257 184 98 25 37 341 11]]\n",
            "targets[[74 98 138 10 5 186 74 61 5 186 49 46 20 148 2 74 17 4500 38 9]]\n",
            "targets[[67 2 81 321 287 12 27 8042 18006 80 40 197 1236 1281 339 3 9670 20461 5134 105]]\n",
            "targets[[606 14 60 2690 550 10 5 2 53 69 92 677 44 11492 17 43 2 10954 12907 19]]\n",
            "targets[[275 3 0 289 1761 0 893 1038 455 2312 23629 0 12055 216 12375 1 0 1192 962 1188]]\n",
            "targets[[418 4 303 377 15 1592 10908 9 912 31 0 170 746 26796 4119 14 1592 9 693 30]]\n",
            "targets[[71 943 18 9 254 299 3 0 3486 4 28 2 2604 16057 132 0 109 1159 2 943]]\n",
            "targets[[25 4 945 0 19298 6 6 10 17 5 2 4430 3 105 4682 208 381 348 0 153]]\n",
            "targets[[466 2908 8 714 2990 12 314 1515 98 5 404 5229 14 0 4463 3 0 171 190 10]]\n",
            "targets[[10 13 645 16 378 0 170 291 7 13 645 8 2177 2 7065 360 317 3423 6589 8]]\n",
            "targets[[204 41 204 23 28 1267 212 11 0 64 293 9 65 4885 44 10 17 8 0 84]]\n",
            "targets[[19864 4029 35 119 5419 941 107 3716 33 2 12863 5226 416 11 65 5 0 109 9 207]]\n",
            "targets[[70 27 211 143 4 111 70 672 14 3636 3317 302 55 0 9107 3 0 81 10629 1630]]\n",
            "targets[[9 429 195 187 4 149 1073 4 30279 22 17986 0 82 311 1 9 89 21 387 134]]\n",
            "targets[[2907 12 1628 757 174 666 4101 1689 2829 13 1262 452 1 41 14250 1 526 4351 133 31]]\n",
            "targets[[2393 1 200 284 13 23 427 22 6471 1 8803 18 22 0 297 63 3 0 2111 3]]\n",
            "targets[[9624 5 2 196 2901 17 141 1711 138 22 0 191 41 4188 62 3974 9 103 11 557]]\n",
            "targets[[1591 10 17 227 311 15 355 1 31 84 70 68 261 16 2 65 74 17 15 315]]\n",
            "targets[[89 21 93 90 38 10 1557 46 23 286 141 8 2030 15 157 19 9 2963 11 88]]\n",
            "targets[[5 2 9739 19 6 6 0 992 8 855 4893 199 331 1 342 5 642 17444 33 2]]\n",
            "targets[[10 738 1430 2 1250 6 6 1357 221 12326 74 857 9 300 221 10 5 161 52 72]]\n",
            "targets[[76 9366 22 0 143 3 0 415 15 2 23007 3282 6 6 223 2252 60 3049 349 0]]\n",
            "targets[[213 3454 51 286 2466 2 880 13121 17 5 0 250 123 18 9 242 2161 5741 4 93]]\n",
            "targets[[8 3752 9 215 297 761 23846 12 6441 4 1547 13069 21 16447 51 9 215 7 9 467]]\n",
            "targets[[139 110 30 668 3 0 98 8 10 202 253 29 16063 1037 1 1037 36 0 1177 10]]\n",
            "targets[[5 2 65 594 17 9 509 7 4623 1 106 7 174 57 7 5 22 246 6 6]]\n",
            "targets[[1680 834 3 495 1435 994 211 4 114 8 2 493 12 5180 1496 190 9 837 0 823]]\n",
            "targets[[307 10 17 33 598 76 2229 33 0 1561 22 246 9 38 51 9 1757 98 38 10]]\n",
            "targets[[9 136 308 163 9 65 382 379 8 2 9299 18 744 441 3 95 6 6 10 17]]\n",
            "targets[[5 0 18142 115 17 0 405 5 2 115 911 18 20 27 4 387 7 13 92 8]]\n",
            "targets[[112 131 115 29 4857 3609 11 3857 2746 8 31 0 129 3 62 6261 11909 98 14 5173]]\n",
            "targets[[8 4704 51 15159 389 44 961 98 68 53 1076 99 0 1002 3 2654 12 2605 38 2361]]\n",
            "targets[[2021 10 17 13 381 12077 69 167 7 599 0 2177 1 9 97 159 21 27 303 1943]]\n",
            "targets[[993 7 2 163 33 87 7 4080 71 51 9 84 215 7 22 729 154 602 241 13856]]\n",
            "targets[[27 77 2782 43 0 13031 16 668 154 147 1 9 140 23 674 9 121 73 52 72]]\n",
            "targets[[223 483 602 235 2 738 16 0 10091 17 9 1715 9 27 23 278 2 738 185 16]]\n",
            "targets[[5 29 3 0 250 104 9 139 123 110 464 0 343 1 1007 0 109 5 630 0]]\n",
            "targets[[3 0 578 4349 5 2 155 2686 3 0 5140 19 1 0 3752 984 3 2804 3 0]]\n",
            "targets[[89 21 103 9 96 27 509 7 52 152 765 179 68 1211 9 140 23 164 4 136]]\n",
            "targets[[2188 11 48 19 1155 603 146 1403 33 338 365 4 121 42 393 124 23 2132 9 481]]\n",
            "targets[[5 2 28208 168 31 1697 12 114 143 51 24 133 2 7699 844 137 0 145 346 3286]]\n",
            "targets[[89 21 121 272 0 372 3 0 75 8289 22 10 17 68 261 16 35 1984 1465 1724]]\n",
            "targets[[7 204 23 28 295 12 4165 3 3853 1 7 426 45 7 12 1513 18 16 71 31]]\n",
            "targets[[223 13 2 977 49 17 15 2 583 177 18 7 42 159 21 80 7 16 71 9]]\n",
            "targets[[254 10 277 31 200 745 16 223 15 934 48843 1254 3 1681 4554 1 520 5960 538 36]]\n",
            "targets[[19 5 2 4823 9 89 21 58 387 134 32 874 4 2609 10 2 975 17 0 179]]\n",
            "targets[[118 23 512 2 171 36 10 17 99 0 394 114 5 2 4726 7 505 44 11 10]]\n",
            "targets[[120 9 182 4 136 11 10 19 5 1316 3 52 72 0 668 399 9 1281 7 9]]\n",
            "targets[[293 10 1140 19 5 133 2290 490 1 509 5 327 85 0 153 3 10 19 13 3937]]\n",
            "targets[[1982 21 110 10 19 8 241 4728 154 37 51 9 1059 2021 11 7 13 164 4 28]]\n",
            "targets[[9 42 300 9 140 1213 3 2955 2630 19 18 7552 861 71 4 8699 60 683 9 112]]\n",
            "targets[[13 2 49 17 36 47 9 215 58 46 48 3 0 436 13 911 0 807 13 49]]\n",
            "targets[[2 1092 13044 2 216 5 516 33 1803 15 2 30104 26 939 6066 38025 9362 2029 86 1]]\n",
            "targets[[45 7 11 5906 7030 13 437 10570 11 54 159 21 1288 0 859 16 4337 9786 2829 13]]\n",
            "targets[[174 49 63 28 4299 15 1296 2281 2598 224 650 146 34 50 21 211 55 15 62 197]]\n",
            "targets[[89 21 3133 11 10 17 45 81 1513 9 382 0 743 96 28 52 6919 0 826 96]]\n",
            "targets[[48 1022 10 17 5 911 1820 184 8 30 91 8391 0 109 302 95 97 194 4 76]]\n",
            "targets[[111 80 9 58 875 1530 988 0 1153 84 6 6 1570 944 124 93 16 2 4039 49]]\n",
            "targets[[215 10 29 143 8 0 407 1118 12 9 4452 402 532 7 288 21 53 49 18 233]]\n",
            "targets[[4 0 889 1 14 35 1193 548 8516 137 948 378 10 806 5 15450 292 36 819 11427]]\n",
            "targets[[17 13 374 0 109 13 7717 1 0 225 13 5066 1 4999 39 5 137 618 356 15]]\n",
            "targets[[7 45 42 77 10470 1 34669 33 3284 3 13147 31 6304 4553 1 2698 368 98 349 15]]\n",
            "targets[[36 0 599 5927 1 4962 892 2884 0 201 3882 270 44 22 2116 47130 4962 285 908 34]]\n",
            "targets[[499 8 26557 2201 8 61 2 125 22695 26 312 1 40 1352 4 320 1 0 6598 1791]]\n",
            "targets[[849 792 2790 34 79 513 35 3778 9731 3083 183 1278 14996 13147 186 18 23 1031 6894 5973]]\n",
            "targets[[21 512 4 66 2 171 3 2552 128 1090 39 210 21 91 2 436 45 283 9988 303]]\n",
            "targets[[2139 19 5 404 1232 1097 8 15123 2 841 876 3 0 2333 1572 1795 2608 8 2 385]]\n",
            "targets[[215 10 31 111 7 13 391 14 0 653 311 17 256 23 555 238 43 7 167 9]]\n",
            "targets[[7 5 30 43 343 2042 1333 12 283 20 213 470 4 121 43 343 18 68 1660 4]]\n",
            "targets[[120 9 140 35 276 9 723 21 110 100 798 22 898 43 10 202 239 36 2 1100]]\n",
            "targets[[1054 2693 2 988 156 4829 5389 4206 1697 745 3 28270 4059 5120 16317 9995 15 2881 5726 1195]]\n",
            "targets[[573 13 2567 14 9 13 9167 144 1 215 0 390 25067 60 390 5 45269 37 9 196]]\n",
            "targets[[600 8 10 19 13 49 1544 43 30 0 49 9 50 136 43 10 19 9 66 388]]\n",
            "targets[[418 78 0 443 15 53 360 1422 53 360 9 140 627 53 26320 15 104 1 242 23]]\n",
            "targets[[379 17 13 65 1343 4 106 2 385 522 36 2 7340 1218 11207 514 4 11951 2 1760]]\n",
            "targets[[5 2 414 502 3 2 202 11 194 40070 91 32700 9 467 19321 1 0 1245 1 307]]\n",
            "targets[[577 11301 5 39 100 279 52 2139 72 10 216 9 382 24 12 81 8 186 73 283]]\n",
            "targets[[183 9742 1112 36 1844 4 160 728 4 166 16 0 1076 3550 5971 12 8 2 419 4]]\n",
            "targets[[5 0 244 3 17 20 232 38 1 20 232 27 4 66 175 37 1228 37 2715 413]]\n",
            "targets[[411 3 98 11 68 4240 33 2 171 3 6313 7 236 166 18 4 198 463 694 16]]\n",
            "targets[[289 293 4 66 10 19 5 3834 966 34 5 8 351 824 14 0 27832 4753 3439 24]]\n",
            "targets[[7024 2928 65 491 4 93 2 13737 37 24 218 2 13725 1300 92 16 26 1444 324 12]]\n",
            "targets[[318 1 2206 48 3 64442 1145 8046 3613 4 81 237 33 986 125 7449 3939 4176 1145 23]]\n",
            "targets[[19 912 16 71 8 275 263 741 84 0 116 13 583 15 745 3 314 492 325 0]]\n",
            "targets[[1291 2 270 3 459 5655 16 163 3708 31 60 711 43649 61 3913 10 17 1 275 82]]\n",
            "targets[[13 7107 4 353 0 1153 829 3 10 397 1470 3 1303 6802 9 1046 13171 15 30 0]]\n",
            "targets[[50 21 262 48 5910 25 21119 4462 43 10 17 6 6 7 4250 6 6 51 2959 2289]]\n",
            "targets[[17 5 2 453 3 19 1903 80 20 262 11 0 5257 3 2 1302 3 2 1230 1693]]\n",
            "targets[[215 10 19 22 246 440 214 14 2 396 8 0 407 41 1752 3239 31 11 567 7]]\n",
            "targets[[1 19201 14612 25 2 3866 260 363 61 5 1843 36 62 84 135 62 4445 347 25 4468]]\n",
            "targets[[13 0 325 19 9 139 110 8 0 84 29 32934 8837 21632 46499 16879 118 35 5398 301]]\n",
            "targets[[215 10 19 440 214 14 2 527 1 65 509 7 318 7 14 2 1800 291 158 7]]\n",
            "targets[[9372 0 412 102 3 284 1781 12 0 12792 1584 71 3 0 3485 125 36 5211 12 1047]]\n",
            "targets[[0 53 84 19 11 1788 71 4 320 9 551 1284 7 51 60 920 582 1236 9 1490]]\n",
            "targets[[110 0 885 12950 14882 8 0 186 49 356 479 9 874 4 1226 10 29 55 296 3]]\n",
            "targets[[12 37 115 128 3 0 822 2194 6336 298 11 47 5 128 162 56 266 48 3 0]]\n",
            "targets[[112 2651 1 9 112 1911 5482 99 318 2 1191 8 0 1814 175 9 2207 23312 14 4]]\n",
            "targets[[3 0 227 81 3661 3 0 3037 9 13 700 154 158 0 84 57 9 215 10 17]]\n",
            "targets[[15 2 1228 225 2955 444 1 84 993 347 33 1840 3346 1 1975 10411 14580 5520 14 52]]\n",
            "targets[[29 41 105 615 18 1010 1633 1256 25 645 294 0 291 16862 3 160 728 5 29 3]]\n",
            "targets[[17 45 53 49 116 33 2215 30 0 177 2 3074 63 15 2 3135 271 81 224 1]]\n",
            "targets[[2893 682 118 23 182 4 28 8 10 19 1 28 861 4 304 2 172 2116 41 24]]\n",
            "targets[[939 3496 71 78 318 10 17 85 54 1285 1312 98 9 89 21 1216 333 90 352 37]]\n",
            "targets[[1022 4267 6 6 49 17 53 49 17 1 9 140 770 4 136 11 545 85 9 140]]\n",
            "targets[[1787 399 14 3558 11790 48 244 3 2 19945 34 6833 16 2 305 458 61 2103 107 6969]]\n",
            "targets[[194 227 9 1339 4 76 60 933 22 2236 12 19372 0 368 832 827 2017 1568 317 3451]]\n",
            "targets[[76 15680 30 0 57 33 231 1 355 16 60 1695 119 98 1 32 68 23 671 51]]\n",
            "targets[[10 13 2 1133 2598 304 94 389 0 1470 445 0 444 3 6109 3892 2042 1333 67 64]]\n",
            "targets[[830 5 710 29 3 0 250 104 3 0 8147 0 109 5 335 1099 91 8037 3 69207]]\n",
            "targets[[140 251 11 294 26 590 8 26 309 154 8499 7804 13 2760 0 598 4 3075 391 324]]\n",
            "targets[[215 10 17 51 9 13 1800 1 9 65 424 5792 23810 34 309 2663 8 263 12841 14]]\n",
            "targets[[19 13 585 152 2 202 3 2081 14 585 33 2 330 243 3235 22 2 19346 31 0]]\n",
            "targets[[816 10 17 9 207 27 4 136 11 7 13 241 0 250 2101 3 60 1187 501 4]]\n",
            "targets[[254 0 29 1 64 940 43 10 17 1085 40190 1 3582 97 2669 37 9 27 874 4]]\n",
            "targets[[436 180 16945 18 69 226 1699 33 2 49 1032 3840 1794 31 272 40 117 237 31 98]]\n",
            "targets[[5 428 4 28 155 205 6542 11 8 333 111 25 0 657 111 25 0 20708 10 122]]\n",
            "targets[[1329 896 1 1056 19 43 342 12 66718 294 0 27564 2332 20024 2 81 472 2188 4 30]]\n",
            "targets[[17 13 194 1 348 1608 11 7 13 6369 16 7989 264 32 2446 4 38 13345 220 5]]\n",
            "targets[[84 315 541 3 10 19 288 21 74 31 30 9 196 7 13 157 630 898 678 469]]\n",
            "targets[[2 57 1899 17 211 22 20 68 913 8 22498 685 3294 165 2210 11 5 23 0 411]]\n",
            "targets[[50 21 10 530 3 16302 413 735 28 763 8 0 160 1128 7 923 0 507 532 1]]\n",
            "targets[[103 11 0 940 3 5 229 97 119 909 16 10 2463 115 222 3 19 10 5 23]]\n",
            "targets[[4 0 277 8175 12 4214 35 14831 2431 13368 2 109 433 0 6131 4390 0 207 2 5]]\n",
            "targets[[1591 10 19 85 7 67 2034 81 829 33 7646 11050 1 37 22 463 1 1108 531 3]]\n",
            "targets[[5 29 3 60 30 57 1628 246 202 9 13 1819 192 4 366 149 7 14 0 202]]\n",
            "targets[[3 12738 153 11131 30170 12 811 55 4 26 184 14913 16 37586 817 328 5 2 247 1165]]\n",
            "targets[[307 10 17 16 0 84 57 227 311 1 13 335 2674 240 9 353 1295 11 7 389]]\n",
            "targets[[2 453 3 19 6 6 4242 1 161 206 180 404 294 0 19 9 196 9 13 149]]\n",
            "targets[[6614 13 2 669 270 143 16 15515 1 7 188 11 24 1505 21 211 44 3 11 1521]]\n",
            "targets[[89 21 121 134 18 99 30 0 3474 22 28443 9 196 10 13 2 160 17 30 0]]\n",
            "targets[[569 21 136 10 5 0 250 17 123 18 9 59 136 7 1762 186 74 597 89 21]]\n",
            "targets[[203 27 110 10 2 2497 214 119 0 154 9 13 43 3575 51 9 84 215 7 8]]\n",
            "targets[[19 5 8 56 95 707 18 52 3 2 168 862 78 0 6142 3 0 9678 489 3]]\n",
            "targets[[215 19969 446 624 8 646 31 0 2634 22606 2004 19 1322 7 12 213 49 4 28 482]]\n",
            "targets[[169 10 19 1099 200 845 39 13 35 17091 620 10 757 50 1019 2474 2 17 1 584]]\n",
            "targets[[103 0 430 5 97 108 75 25 4376 10 17 15 82 98 1 4043 4 942 1544 91]]\n",
            "targets[[834 204 306 2423 18 233 1932 12 102 150 21 191 7 618 7 1612 4680 0 310 78]]\n",
            "targets[[211 22 34 0 574 96 169 10 17 3 30 0 2411 7 165 195 1338 2 991 3127]]\n",
            "targets[[2 385 3071 2 9322 194 4859 2127 34 4420 26 1462 381 19679 393 1107 3819 1 516 14]]\n",
            "targets[[17 11 5 371 2 32049 22 2558 9 215 7 22 0 364 249 9 215 22 246 9]]\n",
            "targets[[307 10 1 13 1375 16 31 219 2 173 49 135 3 450 18 13 1079 671 32 118]]\n",
            "targets[[63 344 13 248 212 18 0 101 68 248 1060 1 31 214 97 1598 8 62 2185 1964]]\n",
            "targets[[384 7 1475 87 2285 206 50 20 28 115 2971 11 409 55 8 0 8980 11 211 185]]\n",
            "targets[[1203 89 21 66 87 37 108 75 196 10 5 2 2611 423 12 122 60 518 3160 4]]\n",
            "targets[[425 3 1867 195 71 10 115 2412 16 1312 85 24 698 9 367 149 74 98 627 9]]\n",
            "targets[[215 10 17 132 8 1092 8 6405 9 1514 357 9 4105 9 13 8 1533 9 4817 22]]\n",
            "targets[[1887 0 17 361 37 407 8 0 1128 203 27 2700 44 48 3 91 1004 53 407 22]]\n",
            "targets[[13 6813 48 158 1912 6474 9 27 1 389 596 0 246 122 284 9708 0 9345 2 1312]]\n",
            "targets[[3 0 7856 510 43 6813 35 540 328 530 17 5 6879 8 0 477 12 390 7 12]]\n",
            "targets[[587 3 0 2457 3149 41 842 3 36 10898 2057 2804 32 141 28 3031 4 359 0 170]]\n",
            "targets[[215 30 317 206 3531 98 1 9 103 32 25 607 147 9 874 4 818 0 178 984]]\n",
            "targets[[3 0 82 829 5372 128 27 1101 10 17 40628 15 38773 12 2 3298 4 275 4309 1]]\n",
            "targets[[3 0 250 98 123 92 23 64 8 0 6511 477 61 1745 35 504 7047 3 1356 10609]]\n",
            "targets[[2 390 38 5837 814 47 25 20 65 1027 10 17 5 2 414 502 3 2 6161 1185]]\n",
            "targets[[3325 14 7997 0 16564 5 2 1714 6683 14 35 16564 3485 2954 59972 24 9927 33 2705 9558]]\n",
            "targets[[50 9 136 43 0 84 19 123 6 6 20 50 21 993 10 85 7 12 23 428]]\n",
            "targets[[307 0 84 422 22 22 4537 227 311 1 9 27 4 136 11 9 13 23 1520 31]]\n",
            "targets[[59217 12 10319 5755 316 2069 2567 60 1422 36 56 2897 1027 7 4 28 2 523 436 3129]]\n",
            "targets[[25 48 1731 2346 61 3441 10 17 36 107 14 379 14 2198 5515 0 21875 4980 10790 717]]\n",
            "targets[[45 77 154 233 9 27 110 10 19 18 13 1986 273 0 57 9 480 5186 104 212]]\n",
            "targets[[106 1083 19180 12 237 3252 40 652 1081 40 480 652 4199 40 1340 18 10215 1097 3686 10]]\n",
            "targets[[19 8 0 2783 4336 717 5 2 81 1444 55 36 0 227 19 4336 2979 47 2 821]]\n",
            "targets[[8520 236 53 69 28 29 3 0 1164 7894 8 338 490 54 1398 54 4470 54 4721 54]]\n",
            "targets[[399 44 3 163 6 6 286 650 467 0 2145 1406 15 5209 2893 1 7045 5547 1 874]]\n",
            "targets[[11660 537 299 5 270 8 687 249 764 111 1092 1967 83 2 1273 44574 12784 8536 6020 1134]]\n",
            "targets[[1084 13 647 18 0 63 165 67 2 115 52 1132 1 1487 4 7 72 82 1084 98]]\n",
            "targets[[98 50 28 247 10 29 5 394 0 116 5 2762 546 16 4956 5869 14588 1 0 225]]\n",
            "targets[[5 165 2 19 11 52 41 334 5 677 4 378 41 246 17 530 18 8 2 647]]\n",
            "targets[[65 1022 8 60 660 18 9 470 4 1029 545 2112 14 0 3766 1252 2659 3538 491 0]]\n",
            "targets[[11687 5 0 227 3 0 81 14516 199 153 8434 13264 1 534 11089 3317 32 83 23 166]]\n",
            "targets[[13 53 671 33 10 19 16 2 173 996 16 0 84 315 541 7 12 165 186 523]]\n",
            "targets[[4530 2175 12 117 19 1 2950 192 7 12 23 58 2 5075 201 7 12 165 35 181]]\n",
            "targets[[50 147 712 10 3851 151 4 60 250 163 98 7 5 43 14 18150 1 1938 4409 14]]\n",
            "targets[[13 3991 1128 1670 12 84 570 4 93 2 17 18812 0 8221 1776 36 10 3117 7 5]]\n",
            "targets[[12 201 104 38 5113 582 9321 35815 43030 25 394 18 10 19 5 58 447 2 984 3]]\n",
            "targets[[115 36 7 1 20 232 28 597 15 47 20 76 9 13 4624 176 5 2 927 1056]]\n",
            "targets[[9440 31371 1649 36 0 27376 26982 1113 5 37908 3104 7756 5394 11 25 148 32227 4838 6 6]]\n",
            "targets[[6621 588 317 44 3 163 46 20 182 2 4214 3 47 13 356 15 108 98 8 0]]\n",
            "targets[[2040 45 2 393 0 3780 12 99 0 299 67 2 53 3934 393 10 17 45 983 3]]\n",
            "targets[[20 25 8 365 3 2 675 5024 2451 38669 144 2 994 1844 94 10 5 0 19 16]]\n",
            "targets[[899 8 816 2 225 7415 41 2 3927 743 889 1403 33 0 354 12 18509 3930 29106 8205]]\n",
            "targets[[6 6 10 3786 487 702 0 8890 755 3 9788 2 10804 5668 6062 34 12 258 289 102]]\n",
            "targets[[17 339 3 1725 635 5853 2355 2 1008 15584 11 45 77 358 2 572 411 8 61 40]]\n",
            "targets[[122 5 37 49 7 45 283 1 7 5 6737 607 7 45 1278 4875 38 450 1 38]]\n",
            "targets[[159 21 121 180 47 4 512 36 10 19 9 159 21 512 615 1 10237 18 10 17]]\n",
            "targets[[112 10 17 815 37 272 7 280 38 42 2 681 1071 1436 487 18 39 12 37 73]]\n",
            "targets[[89 21 66 87 6428 4384 13543 969 1476 2 291 10 216 12 657 25 37 348 1 6628]]\n",
            "targets[[5 2 10522 18 552 413 19 11 9 242 678 1945 72 7 1020 16 2 3508 293 7]]\n",
            "targets[[1567 109 5 16836 33 336 116 1 447 1249 1883 0 1360 3463 8 2 6585 1074 20516 1199]]\n",
            "targets[[255 5 1545 134 56 29 162 98 38 32 329 4 15 2390 102 1 2 595 757 3]]\n",
            "targets[[73 14 9 112 8319 13005 10 13 2 394 17 0 109 13 244 3 2 42656 1563 120]]\n",
            "targets[[14362 436 1583 2 397 63 3 0 205 4 1991 2461 407 227 1128 18 2549 6369 0 11700]]\n",
            "targets[[9 76 78 10 19 9 207 42 38 4 940 22 0 227 173 228 51 115 7794 3906]]\n",
            "targets[[10 2179 55 3 184 104 1138 12 1049 299 5395 7611 917 764 1 303 377 104 1640 7094]]\n",
            "targets[[307 1286 12630 227 311 1 9 27 4 136 205 36 0 457 2 1778 113 319 60 384]]\n",
            "targets[[0 457 3 0 17 8 160 728 302 97 194 0 17 5 2 203 66 16 75 34]]\n",
            "targets[[19 5 23 379 7 12 548 87 379 295 50 66 147 11 0 7440 3379 50 21 486]]\n",
            "targets[[4332 68 23 64 2 522 11 5189 0 4836 1447 1 3 268 0 176 3 707 32 896]]\n",
            "targets[[661 2 173 2212 588 1812 10 609 1 66 0 5632 206 10 5 157 502 3 2 17]]\n",
            "targets[[5 2 1387 2174 17 18 2 3902 471 17 5730 120 819 36 142 889 1025 1784 14 4971]]\n",
            "targets[[207 73 248 28 28180 33 2 3167 10609 26027 80 146 12197 10174 132 55 4 60 3307 8]]\n",
            "targets[[149 10 17 41 828 1100 651 7 60 56 308 1036 17 13 8 2948 199 131 173 2519]]\n",
            "targets[[4573 25 20646 187 0 3651 3 0 18521 2818 14 7 3906 91 795 16894 543 153 4944 43689]]\n",
            "targets[[20 25 2 706 245 2920 2495 16056 340 38 545 10 5 35 1504 203 27 16 0 7579]]\n",
            "targets[[0 653 904 9 67 48 419 7 581 37 74 11 9 196 7 236 28 155 437 0]]\n",
            "targets[[13 12244 14 2 662 4 1988 8039 61 13 2 53 49 19 8 0 360 341 2621 9]]\n",
            "targets[[3230 399 14 4200 3844 2 557 1768 34 12827 2 1479 461 34 7599 5737 34 24 23205 190]]\n",
            "targets[[1473 203 139 77 1702 4 957 0 8054 51 24 3348 0 455 209 8 10 618 2957 807]]\n",
            "targets[[17 672 71 22 2 1722 2599 1992 7 5 2 63 370 3 1290 1 505 2 17 3]]\n",
            "targets[[13 579 143 0 84 375 3 0 17 9 80 23 1046 15 10 530 3 231 11410 190]]\n",
            "targets[[3 99 1156 8 0 552 413 5858 3025 459 1 0 7615 13273 5401 203 706 3636 3317 45]]\n",
            "targets[[17 2391 2 177 3 853 0 250 156 1 1396 123 4 1656 0 200 260 6 6 99]]\n",
            "targets[[220 5 2 1244 2807 33 0 19 12 129 9 13 1073 16 258 5275 2643 963 2349 549]]\n",
            "targets[[7958 934 408 4993 15 5629 1 1060 405 23 2 666 130 3198 0 156 1735 15 2 2193]]\n",
            "targets[[20 139 123 3580 134 32 89 21 93 1436 15 2 109 106 989 2852 22 0 29 495]]\n",
            "targets[[67 4 28 0 117 3 100 8373 17 645 8 646 1323 229 58 46 20 723 21 77]]\n",
            "targets[[5 161 447 72 2 17 1310 8 7 698 83 2819 56 29 1398 56 29 4721 238 523]]\n",
            "targets[[5 37 17154 4 66 29 81 432 3 540 9835 78 157 208 16889 41 16596 9 67 56]]\n",
            "targets[[1889 149 10 22 201 1380 1 5200 431 2 19 43 48 454 11413 8 0 12054 9 232]]\n",
            "targets[[629 6327 5 2 1737 4 106 8 558 111 0 410 24 2400 25 49 1 1494 2 598]]\n",
            "targets[[425 585 71 3 284 29601 227 1606 99 70 195 78 2 2390 43 1206 19602 9 118 23]]\n",
            "targets[[632 2076 568 1840 3346 724 16 2 323 183 243 4459 3412 26 312 4287 9901 499 40 197]]\n",
            "targets[[17 581 38 2 1251 144 16 10096 2018 88 1336 9 113 195 73 571 15 0 3123 365]]\n",
            "targets[[152 10 59 28 35 815 17 233 9 38 1229 1 184 98 8 746 18 9 118 23]]\n",
            "targets[[5 2 186 943 201 7468 8 700 4077 30 13036 22 263 1429 3 343 7 12 2 335]]\n",
            "targets[[20 27 2 49 266 3 450 3112 450 23 4127 1335 41 3393 20 83 367 10 17 43]]\n",
            "targets[[114 1 214 3 1956 926 42 11 0 249 4 249 114 3 35 1974 2645 291 158 160]]\n",
            "targets[[196 11 10942 13 29 3 0 1536 1 88 69 408 98 4 1309 3834 6359 118 35 4854]]\n",
            "targets[[203 5751 9 89 21 38 2116 98 492 5 0 289 1708 566 9 203 2744 39 5 75]]\n",
            "targets[[17 288 21 30 11 81 0 298 5 126 18 0 17 288 21 30 11 74 352 7]]\n",
            "targets[[627 38 201 98 9 65 367 90 18 9 89 21 65 76 0 220 3 7793 9 382]]\n",
            "targets[[108 75 9 2164 55 1729 12911 38017 10 17 45 37 108 4474 1374 40 5417 7 4582 114]]\n",
            "targets[[29 141 66 0 17 1 353 0 298 167 884 60 798 9 1291 0 298 8 1943 7]]\n",
            "targets[[13 1375 10 17 4 28 126 72 5401 203 706 1 9 13 23 671 9 371 262 10]]\n",
            "targets[[3 0 108 98 11 2768 5047 16 901 405 38 184 98 11 359 600 4 39495 807 131]]\n",
            "targets[[9 59 139 358 10 2 315 220 46 9 207 77 482 29 5 107 3616 10 162 284]]\n",
            "targets[[17 5 2 145 1594 0 5294 3 0 0 109 5 4827 8 0 84 317 228 0 101]]\n",
            "targets[[460 1026 8337 1238 165 7 12 2 9033 185 41302 978 4581 1427 1956 12 1272 5 552 1725]]\n",
            "targets[[17 45 2 171 3 756 4 7 1 7 2937 912 16 71 9 80 23 103 7 13]]\n",
            "targets[[402 318 10 17 51 9 13 43 459 154 158 1 287 71 380 20 11 7 13 81]]\n",
            "targets[[5 2 641 212 680 15 48 49 179 18 97 108 497 2768 11 335 7993 100 3359 36]]\n",
            "targets[[75 34 3159 10 17 27 56 266 3 47 162 2 17 155 4953 13 840 155 73 52]]\n",
            "targets[[42 307 10 480 432 3 707 1 9 203 136 11 7 12 29 3 0 117 104 11]]\n",
            "targets[[5 35 504 122 0 64 3159 9 96 27 433 7 5 11 20 27 4 28 65 4631]]\n",
            "targets[[236 500 2 115 2669 7 426 288 21 0 250 17 9 27 123 110 18 7 12 185]]\n",
            "targets[[66368 702 2 1052 30020 339 3 0 297 63 3 29 243 12 3699 1735 14 2 1610 3]]\n",
            "targets[[175 0 170 1082 63 43 2 125 543 128 34 2132 26 1299 4 0 1727 8 643 4]]\n",
            "targets[[215 10 17 51 9 13 2 527 64 105 98 27 1254 1 135 11 83 783 15 71]]\n",
            "targets[[50 21 136 11 45346 5 0 250 19 8 0 2988 477 85 460 2988 1406 302 0 3938]]\n",
            "targets[[1693 1154 38 10357 1832 3269 12150 2194 185 1 2465 3977 1482 120 0 84 81 1218 3562 154]]\n",
            "targets[[50 21 262 255 196 39 13 238 206 41 212 43 10 17 9 140 2 340 3 1048]]\n",
            "targets[[42 121 11 51 2 428 637 747 15 0 940 2703 5 0 10499 3 0 1727 11 7]]\n",
            "targets[[242 2 53 200 340 3 0 1755 15663 3254 790 7557 174 57 9 66 29 3 26 409]]\n",
            "targets[[5 0 117 17 123 7 926 48 3 0 117 156 123 7 45 0 117 17 5017 8]]\n",
            "targets[[379 280 38 0 153 177 26 7678 14657 1 2 2839 535 5111 8 0 455 558 4423 8]]\n",
            "targets[[1594 16 600 1767 5 554 2139 7 12 1051 2807 1 247 2262 58605 3 537 4887 1 316]]\n",
            "targets[[103 11 58 46 9 13 23 2 669 340 3 193 986 331 8 10 19 9 59 27]]\n",
            "targets[[5 2 19 1003 64 16 0 2177 1 141 28 11298 4 13892 4 4248 6 6 9 42]]\n",
            "targets[[7 12 426 23 208 3720 478 543 153 5598 14955 5 10718 15 1623 1356 290 8 951 26]]\n",
            "targets[[3 0 88 5784 104 123 15 322 655 7287 55 33 11196 22218 1 1492 3116 80 20 262]]\n",
            "targets[[14750 5 2 29 8 2 1476 705 1175 24 267 36 34913 4 2922 4 49720 4 2556 4]]\n",
            "targets[[159 21 103 73 3 10 51 9 84 215 7 1 89 21 103 73 3 7 147 7]]\n",
            "targets[[4 366 591 89 21 1823 10 19 4 521 1418 16 2 366 630 46 7 13 58 2]]\n",
            "targets[[17 1762 9 402 149 7 51 9 13 43 1750 154 158 1 9 10119 38 7 94 9]]\n",
            "targets[[236 2924 2 1250 37 5139 6 6 46 7 67 77 5384 1696 3167 41 105 1476 75 124]]\n",
            "targets[[42 307 10911 3170 1 96 23 28 52 671 9 242 2 340 3 577 2146 24 1 8182]]\n",
            "targets[[1147 10 17 51 7 1601 1 9 215 7 42 4733 85 9 353 48 53 6877 829 22]]\n",
            "targets[[103 1306 790 45 669 1004 18 10 13 0 356 2181 8 61 4 570 4 956 44 14]]\n",
            "targets[[956 55 5 23 155 7 12 77 8681 14 2 201 18 7 426 210 21 0 1766 7521]]\n",
            "targets[[191 49 261 1 69 177 18 1262 2212 6 6 9 723 21 353 0 298 239 1 10]]\n",
            "targets[[5000 3 885 676 802 10 19 11 494 4 28 155 9 856 2 2646 19 9 1024 459]]\n",
            "targets[[1046 15 88 3 0 82 454 2 453 3 47772 1 4588 57 6 6 799 56 997 5]]\n",
            "targets[[522 3 355 25 44 11413 29 311 51 32 1134 4 350 44 35 1904 1 2925 48 4643]]\n",
            "targets[[3184 17494 786 1047 25311 67 48 2169 3554 142 14 710 1410 2 3859 31 40 544 844 12]]\n",
            "targets[[5 2 186 336 19 35 9774 5141 16 336 1595 56 283 8 303 2238 773 41 316 460]]\n",
            "targets[[123 81 4341 826 18 743 1 0 63 5 379 4558 39 25 37 108 3554 7 236 14]]\n",
            "targets[[139 213 77 2 669 340 3 2317 12 98 51 24 13 78 0 209 24 13 14 49]]\n",
            "targets[[1591 10 17 8 0 378 1045 16 60 1408 291 158 518 7 2882 0 959 5334 1 67]]\n",
            "targets[[35 554 74 29 31 11 87 194 118 10 1218 3640 227 2779 762 41 137 9 50 66]]\n",
            "targets[[2887 5346 9676 31122 11 650 8549 8 2177 1 2588 0 23185 1 62663 3 9040 35 56761 46]]\n",
            "targets[[2789 343 201 451 55 4 91 6380 7745 1 21208 3751 55 4 2 2013 1 8212 1345 39]]\n",
            "targets[[12 241 56 220 8 259 4 1652 21100 1278 9197 1028 25783 17 4 255 34 1505 21 478]]\n",
            "targets[[4001 262 10 9 13 2873 51 9 215 37 8399 70 9610 3008 154 309 9 7 1 2077]]\n",
            "targets[[9 4001 28 194 18 9 3413 136 10 9 307 10 17 85 3 0 82 15540 9 772]]\n",
            "targets[[10 17 5792 12404 6395 26 384 514 108 12778 469 286 79 12572 30 0 915 1295 56 29]]\n",
            "targets[[422 5 60 1628 85 7 117 4622 0 1004 0 122 67 4 1494 6 6 9 402 149]]\n",
            "targets[[5138 144 0 898 9 5708 718 0 1942 16 0 963 3 0 2303 9 1982 21 110 7]]\n",
            "targets[[113 27 195 134 10 122 13 37 1076 9 1203 113 693 9 121 11 60 812 5 2]]\n",
            "targets[[9 84 215 0 17 9 420 21 165 8022 46 7 5 35 181 17 41 2 17 8828]]\n",
            "targets[[13 53 2313 4 66 11 32 67 92 2 17 44 3 60 519 298 123 9 159 21]]\n",
            "targets[[5 2 186 49 19 9 196 7 12 126 72 47 75 2228 10 17 4 28 9 121]]\n",
            "targets[[162 0 19 1678 5 91 12602 2686 43935 33 2457 0 19 5 2088 2 17397 3 105 10067]]\n",
            "targets[[13 14454 144 60 22 4537 1 254 10 19 532 591 10 204 28 2 523 360 341 184]]\n",
            "targets[[9 138 22 9 27 4 987 4 107 2 669 10885 13516 340 8 189 1544 47 3814 71]]\n",
            "targets[[215 10 17 22 2 2766 4 5009 1 9 654 7 120 39 13 161 332 4 80 18]]\n",
            "targets[[89 21 121 47 4 136 43 10 19 9 418 78 7 15 1719 1422 976 36 9770 12413]]\n",
            "targets[[11 880 291 550 52 72 20 50 103 3 1 0 291 5 241 0 64 293 11 9]]\n",
            "targets[[3752 7552 5 977 160 8 0 2304 539 19 3 2 1758 297 63 46 20 121 1047 36]]\n",
            "targets[[2332 9120 6832 1306 14 275 887 34 723 21 3053 16 154 22 2 1218 8 2292 33 4200]]\n",
            "targets[[5267 41 5912 60 312 1 9 215 10 17 8 1547 7 13 446 1547 11716 31 0 57]]\n",
            "targets[[10 22 277 8 206 1081 15 646 17053 352 0 29582 13 53 336 41 0 851 743 150]]\n",
            "targets[[4 2261 48 881 11566 6 6 308 2083 2909 5 23 35 859 2343 11 13 26 812 11]]\n",
            "targets[[196 10 2333 1224 288 21 97 74 39 68 2 173 1097 1747 1 58 2 173 2565 375]]\n",
            "targets[[17 1193 36 107 335 2227 92 3779 100 145 109 29 782 39 428 4 28 235 2 378]]\n",
            "targets[[886 2 1116 17 8 1485 1092 1500 152 9 307 7 357 7 5 35875 8 2304 6 6]]\n",
            "targets[[10744 906 5 337 18 282 75 366 664 0 19 267 78 2 37322 0 109 188 14 152]]\n",
            "targets[[12114 4 5750 3 0 8372 4280 347 1 2 533 526 5043 225 30 8 2 65 594 328]]\n",
            "targets[[2 222 5311 22 0 3127 3 4315 14 0 1919 1656 3 4415 10 5 133 2 1492 19]]\n",
            "targets[[195 10 277 69 119 223 154 602 1 64 874 4 106 7 4120 9 89 21 121 134]]\n",
            "targets[[5 497 58 16 2 423 12 17 0 848 5 73 97 13758 16 2 63 10 462 1]]\n",
            "targets[[139 147 307 30 668 4459 3412 5691 513 33 40 568 284 30 25 180 394 3 268 18]]\n",
            "targets[[96 28 126 72 3138 157 223 588 8 0 1077 3 105 3 246 12 872 1419 5971 8149]]\n",
            "targets[[14406 12 9345 68 2 519 3 1867 233 1700 10 19 162 71 230 38 2 527 175 815]]\n",
            "targets[[139 213 254 7 3259 51 368 2183 304 836 760 4 835 0 181 349 1 22350 24070 12]]\n",
            "targets[[82 311 2 425 2305 33 15 2 1005 3 0 10899 9 67 113 555 3 7 167 1]]\n",
            "targets[[17 5 428 4 28 43 668 1230 331 259 4 169 114 8 2 640 8091 44 33 2]]\n",
            "targets[[17 5 822 0 63 0 760 0 116 91 137 113 110 167 1 65 69 1011 9 89]]\n",
            "targets[[215 10 23 97 194 602 1 9 203 136 10 17 5 394 9 106 2124 98 16 247]]\n",
            "targets[[122 5 53 1383 1 431 37 736 438 7 45 2 49 834 9 382 34 150 21 112]]\n",
            "targets[[8 0 885 1 8782 4261 2494 10121 20556 61039 4947 8307 1612 2 10503 30037 3450 15459 3649 0]]\n",
            "targets[[5764 12 8448 19475 14699 786 29475 13 3589 33 0 1351 64403 557 548 8516 90 16 2853 4]]\n",
            "targets[[21 1392 149 0 17 0 1561 5 0 117 172 0 372 5 42 5173 978 1 1503 135]]\n",
            "targets[[544 4031 5267 922 2213 2766 50053 61 67 48 39377 5779 22 1904 3650 36 18873 4 1547 13]]\n",
            "targets[[1471 5179 570 15 2 4995 1 16323 109 11 188 677 44 3 2 1305 4519 673 469 0]]\n",
            "targets[[4035 5 2 1031 216 18 10 2181 5 35 4601 0 1536 510 25 10944 4134 18 32 25]]\n",
            "targets[[7 65 614 16 2 17 4 28 10 74 9 64 307 10 85 60 425 3224 4 818]]\n",
            "targets[[5 3731 1 10406 528 92 8 2 3092 2737 3 0 117 1049 299 1177 1 2605 22 2623]]\n",
            "targets[[11 12 134 5177 49238 98 25 37 617 4 30 3 178 4702 51 32 25 37 69 226]]\n",
            "targets[[467 10 17 7 13 29 3 0 154 117 32325 9 402 149 7 22 17596 41 48 548]]\n",
            "targets[[821 5 0 82 1141 1471 19 33 4522 349 15 303 1 360 8 10 19 2 9193 7632]]\n",
            "targets[[470 4 1937 137 36 0 246 1059 37 9 1983 35 221 1507 1912 1972 44 3 0 14320]]\n",
            "targets[[1059 215 10 19 16 0 84 57 233 318 7 108 154 602 8 1600 4 91 107 413]]\n",
            "targets[[241 210 21 1270 11 9 27 195 4 66 0 2105 3 30 0 212 829 22 0 6957]]\n",
            "targets[[9 67 84 555 3 10337 3505 94 195 2 3503 3 0 177 9 3580 134 9 67 113]]\n",
            "targets[[88 1623 1356 1737 9 551 22 10 19 8 0 632 9 13 37 3943 33 7 9 25114]]\n",
            "targets[[13 29 3 272 1408 75 34 139 123 110 10 151 9 1830 144 7 649 44 3 1158]]\n",
            "targets[[13 29 3 0 250 98 9 27 123 110 34330 465 4 27 37 73 1062 6272 26 1233]]\n",
            "targets[[5582 5 43 2 471 17 3409 243 34 267 78 1061 42 4 169 44 34 39856 40 115]]\n",
            "targets[[5466 213 45 0 170 209 8 174 17 61 5 17225 1 2 4637 69 128 5 0 117]]\n",
            "targets[[64 151 1308 43 10 19 5 11 39 13 282 2 125 748 21241 11 67 108 4309 1]]\n",
            "targets[[12815 1 7956 28158 62 339 3 10501 12 0 13285 8 5912 7 13 2 1348 46 25989 92]]\n",
            "targets[[17 5 52 17509 72 123 787 2 2565 261 279 38 3985 4 304 8 10 432 3 2684]]\n",
            "targets[[0 440 829 11399 9 11452 56 632 1526 1996 352 1653 10 19 41 467 7 12994 35988 336]]\n",
            "targets[[702 2 755 3 5638 8945 12 34 44308 78 0 9296 2494 111 137 1036 5 7643 2770 33]]\n",
            "targets[[19 141 27 77 52 212 15 0 1004 3 142 2 177 0 225 494 4 28 617 840]]\n",
            "targets[[17 10 1000 141 113 66 0 615 3 249 0 116 5 838 0 536 5 42 30 119]]\n",
            "targets[[17 5 305 23 42 16 91 492 18 16 47 7 5 23 7 5 23 1050 15 844]]\n",
            "targets[[1832 8163 87 118 35 279 3 26 5526 1797 313 4 76 2377 8 10 910 60 548 10]]\n",
            "targets[[42 307 10 19 16 0 84 57 8 108 154 1160 3857 1 7 12 133 53 155 7]]\n",
            "targets[[80 9 366 15 10 29 39 5 56 813 11 10 5 29 3 0 250 1358 3 1223]]\n",
            "targets[[113 12882 4 11642 71 87 20 50 191 35 322 279 1 278 86 4 453 8 2 19]]\n",
            "targets[[9 207 380 20 137 46 9 207 470 20 4 121 20 194 14723 435 3 2 0 31623]]\n",
            "targets[[82 18236 34 27 4240 22 10 17 12 1246 4 13734 1238 46794 9 103 11 10 901 19]]\n",
            "targets[[107 2 669 340 3 2959 13745 12 84 200 17 0 26395 9 13 53 3943 8 318 26]]\n",
            "targets[[3539 2181 16 7190 13498 8227 31 0 316 2511 1268 3 0 3392 210 21 1990 49 464 2]]\n",
            "targets[[987 11 8396 5 8 0 876 3 30 3 4200 2055 12 104 1 26 393 83 241 113]]\n",
            "targets[[5 35 437 497 17 152 133 126 72 193 56299 1 22 2413 1526 117 359 3 520 3406]]\n",
            "targets[[5 0 117 1640 2440 17 9 27 123 110 6 6 9 242 56 1123 2 2166 37 9]]\n",
            "targets[[5 43 2 522 3 2872 5068 2803 8 6153 34 211 596 48 24193 11078 132 7734 2 160]]\n",
            "targets[[698 1859 5 2 3333 3055 680 43 2 16210 5805 12087 18812 0 1770 22092 3 25897 294 4065]]\n",
            "targets[[1062 15 10 19 5 39 25 31 219 275 49 104 2603 4 76 44 1 587 3 90]]\n",
            "targets[[9 365 4 93 2 22543 84 10 17 5 42 1043 1244 14 229 14 9 50 380 0]]\n",
            "targets[[88 19450 71 128 5 0 263 4607 75 27 9 327 50 21 262 7 51 75 2470 10]]\n",
            "targets[[42 1779 0 298 10656 265 227 311 1 13 2313 4 76 0 17 22 23540 4 66 87]]\n",
            "targets[[27 195 4 4003 2 17 11 695 1 94 8923 91 197 6979 25932 218 205 55 8 127]]\n",
            "targets[[54 77 358 2 325 598 8 338 3444 2811 236 23 27 77 37 927 8590 78 2389 471]]\n",
            "targets[[0 4878 5 2 263 176 1 0 231 1735 4 16479 0 344 199 17077 4510 1 62 1943]]\n",
            "targets[[1348 5035 15349 7120 285 157 11064 6211 243 2853 4 1309 175 1 152 48 779 204 136 54]]\n",
            "targets[[42 80 23 66 49 104 38 10 107 6364 1557 10 17 475 12448 60 1422 9 467 283]]\n",
            "targets[[5 2 53 69 92 299 17 152 9 139 195 4 987 11 10 5 2 477 11 627]]\n",
            "targets[[39 2 666 1153 4 10 19 1502 34 693 161 3 378 1409 96 1537 0 13045 3554 92]]\n",
            "targets[[236 27 67 0 227 449 235 0 88 281 8 4818 18 14 49 14 7 218 35216 44]]\n",
            "targets[[109 3 0 17 5 2 49 29 18 186 737 3 2 471 530 680 17 46 20 89]]\n",
            "targets[[45 4 28 29 3 0 250 98 123 92 9 89 21 456 46 7 13 92 16 362]]\n",
            "targets[[11687 702 0 63 3 2 183 640 396 34 302 2 301 14 2 5291 4 2 2499 1368]]\n",
            "targets[[32273 45465 5 2 19 43 2 28428 231 259 4 169 62 95 8 0 3524 863 15 11]]\n",
            "targets[[720 291 158 424 7 16 71 7 13 245 4 76 144 7 1543 2495 252 7 95 119]]\n",
            "targets[[2 340 3 9004 9 196 7 13 35 212 1080 4 3743 48 3 0 2942 36 0 63]]\n",
            "targets[[17 13 29 3 3500 12 1070 31 235 2 184 17 792 1710 393 18 296 654 44 2]]\n",
            "targets[[3 30 9 1865 509 10 17 253 57 9 139 307 7 45 802 1695 4 60 531 9]]\n",
            "targets[[0 28237 11 1198 38 2 125 5 143 147 107 2072 33 3795 10656 4855 6442 2 183 243]]\n",
            "targets[[17 92 71 864 60 197 7041 3 2219 6 6 29 50 64 6239 11 0 1675 83 1624]]\n",
            "targets[[37 286 559 0 1122 21578 3 0 3202 18956 2977 1 329 90 14 35 1401 16 10 2715]]\n",
            "targets[[0 697 8 23009 1795 1662 4 346 1058 346 8365 15 0 323 2460 107 29 3 26 160]]\n",
            "targets[[5 29 3 463 2610 11 25 22 0 84 277 3 2610 12 25939 1256 8 746 1101 4]]\n",
            "targets[[27539 3 409 2114 2103 105 5358 22093 61 1546 29 125 31 2 1105 21951 15 105 331 1]]\n",
            "targets[[5 710 29 3 0 250 463 98 9 139 123 110 7 12 23 631 41 100 3 0]]\n",
            "targets[[298 33 28644 1190 5 126 7 12 627 37 14 7 45 0 791 4 2203 0 101 270]]\n",
            "targets[[42 195 226 149 15421 22 8844 16 0 2919 57 233 9 84 215 7 143 8 7013 3]]\n",
            "targets[[17 67 48 49473 18 7 12 35 158 63 11 327 96 113 592 3302 47491 96 113 956]]\n",
            "targets[[25 2 19314 83 89 21 20 121 47 11 5 10 17 5 186 73 30 11 20 722]]\n",
            "targets[[50 9 136 43 2528 2962 223 69 9 50 136 8 30 3974 9 83 64 106 10 19]]\n",
            "targets[[47 50 9 136 6 6 0 2832 3 10 2515 10483 0 2123 1360 0 36408 32 384 1]]\n",
            "targets[[471 98 36 18284 7 12 42 247 4 66 0 15551 1650 15089 1 1220 3 863 12 501]]\n",
            "targets[[0 1194 29 8348 530 181 104 111 116 1 2169 25 4885 31 0 1191 10 17 5 31]]\n",
            "targets[[103 9 204 28 356 128 11 10 13 2 6077 16 0 99 462 184 3089 9 140 2]]\n",
            "targets[[2 1352 3 0 2434 8 540 1 19 9 13 4021 4 1757 10 19 22 13406 7 5]]\n",
            "targets[[382 1374 0 189 11 7 569 21 28 2 354 7607 5317 412 6 6 2997 1989 1556 10505]]\n",
            "targets[[2 216 8808 2 378 361 1 162 2 637 43 87 24 218 2 1309 15 2588 3635 8]]\n",
            "targets[[0 653 717 4 0 129 904 6528 45 2 765 1438 4 7 376 7 13 0 946 393]]\n",
            "targets[[9 196 39 207 28 48 450 4 91 3057 9 481 9 195 47 9 856 23 73 52]]\n",
            "targets[[1508 1 0 20290 5 427 22 947 15994 12 673 3 0 170 390 0 63 5 2 22371]]\n",
            "targets[[634 5 2 1224 17 317 4037 138 4 4010 1473 4 5978 1279 13220 1 1282 44 3 268]]\n",
            "targets[[28597 37662 5 35 25911 4 3328 1 0 1071 75 7 5 258 472 1 3032 4 258 1087]]\n",
            "targets[[22 3 0 84 2922 98 556 44 3 338 11 274 87 0 299 16520 146 12149 12 41]]\n",
            "targets[[1420 8 0 5583 69 11 12 0 95 7 280 5293 5204 5 99 30 117 542 14 1420]]\n",
            "targets[[65 379 18 29 83 213 589 47 3716 0 4623 1031 4751 1286 1710 1 5012 6499 4 93]]\n",
            "targets[[470 4 2826 0 246 149 7 13 1789 9 1653 7 113 106 10 17 0 3653 25 612]]\n",
            "targets[[17 32756 199 3895 5998 436 1 4242 868 6 6 0 5998 436 172 13 1390 292 33 0]]\n",
            "targets[[15 0 883 5 186 73 1507 147 18 2325 2 1260 3153 3 1893 573 143 8 8575 51]]\n",
            "targets[[8920 5 13971 2 112 63 199 105 10708 101 15 62 197 18745 0 109 5 1680 192 4]]\n",
            "targets[[22 378 1 23 53 69 2483 116 118 23 359 14570 53 69 153 45 56 266 3 1821]]\n",
            "targets[[5 23 2 49 17 20 113 169 44 47 606 520 9547 124 41 134 24 5 932 4]]\n",
            "targets[[84 816 9 152 10 13 0 4463 3 153 3073 9743 104 190 38 30 3 26 515 7]]\n",
            "targets[[365 4 138 78 2 65 194 2939 3 47 9 722 43 10 17 42 353 30 3 0]]\n",
            "targets[[2 374 684 155 201 0 3379 25 74 8 62 101 1 0 657 25 374 1 4784 51]]\n",
            "targets[[232 241 113 169 10 29 31 127 711 378 1045 41 58 2 679 29 18 46 67798 8]]\n",
            "targets[[9643 1562 17 43 2 742 3 454 1 2 4994 8 0 2494 11075 33 1370 17288 34 1259]]\n",
            "targets[[17 13 397 2 19 1016 33 0 4646 39 12 10 4062 527 8 377 1 24 267 943]]\n",
            "targets[[5 2 605 7130 3 0 84 19 9 509 0 84 19 18 0 325 29 13 1986 610]]\n",
            "targets[[147 20 141 478 121 43 10 19 0 3231 5896 1931 11 186 73 418 677 4 378 1728]]\n",
            "targets[[10194 0 440 45055 9 27 1367 4 71 31 60 1025 1 389 55 15 31 219 1582 20080]]\n",
            "targets[[0 104 9 139 1339 4 76 2 168 31 2573 7576 12412 45 92 31 219 275 11 25]]\n",
            "targets[[13 2917 6385 12 84 1156 209 8 2 19 1 54 429 1197 0 176 47 2 81 638]]\n",
            "targets[[5022 92 0 368 18013 20108 8 5962 1156 24902 64125 29799 24297 6705 1 6962 66641 1101 4 11]]\n",
            "targets[[5428 285 0 323 18 3240 312 3 2 2641 23085 54 12 2002 36 39912 1 4542 345 36]]\n",
            "targets[[19 188 38 2 11349 31 84 6237 18 39 25 48 19556 1340 1619 375 464 0 7615 3]]\n",
            "targets[[5 2 65 155 19 33 284 3233 1535 941 18573 16576 1 7 12 26 21083 19 6675 2698]]\n",
            "targets[[737 360 341 680 184 17 15 2 177 11 150 21 704 73 2344 4 35 2448 507 18]]\n",
            "targets[[2765 3 391 688 1 1691 15 189 10 5 2 1329 896 1 1338 19 0 5656 3325 102]]\n",
            "targets[[3173 653 717 8 10543 0 324 34 5 2 31977 3 35 10205 0 711 38479 0 25048 30]]\n",
            "targets[[84 3 30 88 3 10 17 1762 18 43 1125 228 3 7 5 0 1536 151 9 139]]\n",
            "targets[[278 39 12 161 4 28 5850 36 149 31414 7 12 23 155 7 12 23 841 16 2]]\n",
            "targets[[11226 5 2 1819 125 26 98 25 238 18 206 8 1080 0 88 913 743 5 1216 8109]]\n",
            "targets[[307 0 277 1237 64 4452 11 39 25 29745 2649 10 19 18 159 21 121 100 3 0]]\n",
            "targets[[963 6826 5267 5 2 822 1633 2484 2230 19 33 0 2401 20121 66 8939 1 5 376 29]]\n",
            "targets[[22 2 297 63 10 202 5 2 1594 719 91 244 0 3952 11 476 1406 33 4913 0]]\n",
            "targets[[35 158 462 328 17 22 0 28200 489 7 12 2 735 7 45 668 1497 705 756 2]]\n",
            "targets[[10 19 5 64 334 72 5617 228 8 1576 0 2037 875 4 2510 55 248 927 10 1745]]\n",
            "targets[[215 10 19 143 8 2514 15282 51 7 13 84 645 1 424 7 2 171 94 147 27]]\n",
            "targets[[112 149 497 98 8 746 36 34367 4 9602 4 2864 98 9 221 213 1535 36 2244 6]]\n",
            "targets[[402 1727 821 391 22 13100 221 844 154 602 1 60 920 812 1 40 355 149 7 1]]\n",
            "targets[[3 471 1 970 17 1252 2154 4638 12 872 1116 1935 13 0 9559 2181 1900 18477 16 681]]\n",
            "targets[[5 0 872 734 201 3 30 57 376 7 58 672 0 442 477 6 6 9 196 0]]\n",
            "targets[[2 19 4500 16 0 250 1521 19 3 30 57 1 20 236 76 2759 38 0 10531 8476]]\n",
            "targets[[1520 71 88 43 10 19 13 87 20 213 121 47 2126 5 553 10 5 3875 85 3]]\n",
            "targets[[670 348 6 6 0 183 9003 280 49 18 54 12 2862 220 16 11 207 0 17 5]]\n",
            "targets[[70 27 0 1638 755 3 0 14088 28040 10 1324 13 852 2481 33 2 1100 12 922 3087]]\n",
            "targets[[966 32647 7349 28243 36 19254 584 7302 4 489 15 947 1840 4172 12672 51 1840 4542 35 9178]]\n",
            "targets[[601 14905 439 30 119 0 176 107 2 669 340 3 601 545 9 509 10 17 7914 39]]\n",
            "targets[[50 9 136 6 6 499 120 480 1 8875 0 648 63 2 2845 63 16068 549 195 48]]\n",
            "targets[[418 4 2 2683 3 10 17 1 132 7 67 2 363 375 11 92 71 449 7 67]]\n",
            "targets[[38 2 1670 5 2 1772 2957 19 11 2800 45 91 5003 69 896 649 1 1329 763 0]]\n",
            "targets[[402 2656 276 2864 223 317 22 0 170 277 1 9 555 74 829 43 317 37 9 581]]\n",
            "targets[[10679 4162 3 10777 449 44 1326 201 9117 15 1338 2910 375 162 10 19 305 1 3294 8072]]\n",
            "targets[[461 1635 2 3006 460 2316 1 316 27300 5 808 0 355 3 338 1252 6862 16316 2110 50976]]\n",
            "targets[[2175 213 9927 71 24 13 371 29 3 0 88 607 7401 260 8652 3 407 443 1 0]]\n",
            "targets[[9 65 424 11 17 7 13 53 53 49 9 242 2 81 340 3 734 1256 1 9]]\n",
            "targets[[243 34 3901 4111 2913 18115 1 40 435 1885 17552 27 1683 78 2 385 474 1 203 845]]\n",
            "targets[[98 20 42 121 20 148 164 4 112 36 0 84 173 1603 10 5 29 3 146 98]]\n",
            "targets[[13 95 247 29 3 60 519 2521 7785 30 0 156 25 8 351 824 128 1 9 467]]\n",
            "targets[[1457 8349 67 161 4 80 15 503 10 662 18 58 46 24 67 9 813 46 24 59]]\n",
            "targets[[3905 5 142 2 1175 69 31 219 14 35 534 9 121 54 12 77 92 247 3 16]]\n",
            "targets[[17 67 48 49 375 1 2 81 366 9 67 1507 11 4929 5262 513 7 1 51 7]]\n",
            "targets[[467 0 321 3 10 19 36 0 561 9 84 215 2 1561 16 7 11103 45 213 77]]\n",
            "targets[[3412 236 27 67 2 590 67 54 23 287 40 544 568 284 191 119 14 40 153 7]]\n",
            "targets[[11 52 734 1256 68 14 11347 2097 14 10 29 9 113 196 238 14 4740 14 0 595]]\n",
            "targets[[84 215 10 17 51 7 1900 389 44 9 13 43 796 14458 158 1 254 10 17 193]]\n",
            "targets[[1059 215 21288 31 0 13104 19 1322 7 12 2 1311 191 22 0 17615 11 61930 3642 0]]\n",
            "targets[[13 2 49 122 321 1 53 155 18 9 159 21 230 11 807 553 9 13 1375 4]]\n",
            "targets[[10569 1128 1308 3344 25 273 2 168 16 0 10874 695 1 1337 338 2626 236 1624 890 62]]\n",
            "targets[[13 497 3076 3 75 0 708 1905 55 10 17 2939 13 37 5147 1 11405 9 856 2]]\n",
            "targets[[168 31 2 17208 8 6221 1128 7945 5340 0 547 3 1408 3600 3 101 33 1023 637 2775]]\n",
            "targets[[2150 17 427 22 2 49246 13919 1795 354 63 2 2717 494 4 8901 0 176 144 2 49]]\n",
            "targets[[27 781 33 233 89 2332 329 26 1630 1685 11372 4 191 185 2 2217 34 13 17979 4]]\n",
            "targets[[389 596 8 26 114 0 284 6644 63 22 246 2 173 3520 602 132 23 180 29426 0]]\n",
            "targets[[452 702 3 2 6546 1116 622 1102 50 2713 10695 1 39269 144 0 1959 3262 3 537 5036]]\n",
            "targets[[195 10 2628 36 378 1647 3 5756 23 65 1237 16 251 47 9 13 8 16 9 13]]\n",
            "targets[[47 50 9 136 43 10 972 9 27 113 110 2 19 167 11 51 9 84 307 7]]\n",
            "targets[[874 4 818 0 17 427 22 0 189 11 898 12 2921 16 0 17 13 700 308 44]]\n",
            "targets[[27 30 77 2224 3459 134 89 21 32 984 0 1224 104 11 68 64 591 296 3 12037]]\n",
            "targets[[19 13 533 49 18 229 97 404 179 195 658 1 7 886 245 4 191 0 17 618]]\n",
            "targets[[1568 5 815 18 7 3966 108 3286 36 193 13841 9 103 46 4896 278 44 872 1784 3286]]\n",
            "targets[[22 2 966 19930 63 10 17 45 0 462 6755 18 825 168 3 26 166 0 540 444]]\n",
            "targets[[470 4 854 43 0 1095 1447 2 53 617 1447 11 406 178 0 1246 4 810 5791 1]]\n",
            "targets[[65 509 10 17 7 559 2 186 462 63 11 3 2590 12 12235 1 4429 7 8 2]]\n",
            "targets[[2838 5 29 3 146 274 11 42 162 20 449 2905 3 47 20 103 5 155 9 1317]]\n",
            "targets[[27 23 110 192 3 284 3467 12 104 4 2797 14130 26 652 3 166 18 427 718 47]]\n",
            "targets[[14590 5 35 554 1492 1826 4 5415 51 54 12 1635 42 2 1778 251 18 39 12 64]]\n",
            "targets[[3007 124 4054 284 4806 13068 1425 0 362 25 1009 192 4 93 29 32528 1 1464 5348 3007]]\n",
            "targets[[12 12 117 19 123 437 333 3684 180 1211 152 18 11 12 47 1112 178 24 45 2715]]\n",
            "targets[[751 9 121 70 30 467 20 22 346 5154 15 1956 1333 18 618 80 20 23 27 238]]\n",
            "targets[[3905 5 213 35 504 534 18 39 5 56 1132 4 40 102 882 4 255 332 12 54]]\n",
            "targets[[5 401 29 3 0 872 959 98 123 92 7 12 2 145 22237 4 255 7 232 93]]\n",
            "targets[[9 13 149 10 19 9 1715 87 4118 7958 10 19 13 4 5106 0 3197 8 57 11]]\n",
            "targets[[480 19 1601 1059 14 172 3 2 18224 19 1322 31 0 2099 6353 3 540 8 2559 207]]\n",
            "targets[[51 0 1953 1222 3 1306 2691 261 58 52 33836 72 24 118 8 5356 5515 5 0 303]]\n",
            "targets[[10 17 5 2 145 34359 14 286 34 5 8 35 17091 1328 9 13 2229 4 66 87]]\n",
            "targets[[1 2286 0 2825 45 56 297 1754 3 417 929 18 296 5923 292 675 12 8 2 4100]]\n",
            "targets[[15 1882 22720 1 584 12079 685 6229 13 35 6849 3086 967 0 53 84 2380 422 3 3086]]\n",
            "targets[[2 4520 18203 3086 3480 4 246 8 5353 1 30 463 762 36 11 291 25 53 4280 7]]\n",
            "targets[[3 0 250 46 23 0 250 30 187 17 9 27 123 110 74 290 497 116 1346 405]]\n",
            "targets[[437 1653 10 17 9 118 38 0 4869 223 8 2 647 441 3 95 0 84 13 49]]\n",
            "targets[[2 81 9324 3 7469 6098 9 67 4 429 106 10 53 53 774 434 7 5 663 6098]]\n",
            "targets[[413 15 35 851 63 344 11 92 266 1 58 2 842 628 271 467 0 405 97 761]]\n",
            "targets[[49 5521 3 0 2590 9247 2180 43 1641 5631 2420 4507 1 1515 0 19 499 8 900 3]]\n",
            "targets[[1059 215 10 17 16 0 84 57 9 13 2873 51 7 13 645 9 13 1027 7 4]]\n",
            "targets[[13 241 29 3 0 250 98 9 139 123 110 9 538 288 21 1027 10 2099 6811 19]]\n",
            "targets[[418 4 66 10 17 1027 2 337 10477 57 8 0 797 15 60 1137 812 296 9 67]]\n",
            "targets[[215 10 19 22 246 143 8 0 407 1001 12 0 994 43 0 1700 3 8257 1588 2055]]\n",
            "targets[[19843 33258 5 35 276 578 8 8451 1 752 14 2 2697 3586 54 3901 40 301 1198 30]]\n",
            "targets[[9 13 3144 60 303 377 3763 7594 7594 22436 61 5 56 81 842 233 7 5 414 303]]\n",
            "targets[[46 9 470 4 136 137 337 43 10 19 9 481 0 1361 1 492 3 0 277 2628]]\n",
            "targets[[67 856 10 662 4 28 8 344 15 0 84 207 207 17 15 5231 4 0 746 230]]\n",
            "targets[[2790 2130 2652 47 70 27 194 2439 7920 5057 13 38 7 5 2 144 2790 12 237 70]]\n",
            "targets[[0 372 3 178 34 112 2 49 3225 1 937 63 11 5 2 5107 4 76 20 2532]]\n",
            "targets[[10 17 16 47 7 5 23 2 984 18 2 335 263 1538 4 0 170 1080 7 12]]\n",
            "targets[[89 21 121 134 18 7 188 38 0 1155 3 0 19 67 2 317 1307 16472 4 76]]\n",
            "targets[[2 4034 340 3 11631 10764 9 139 110 48 2124 2605 10 2 984 3 2 869 8 2]]\n",
            "targets[[0 1289 12 2997 6040 1878 354 1400 1387 3722 8015 55 4 479 1657 1 29111 44406 174 111]]\n",
            "targets[[113 1981 4 28 2613 1 7445 33 0 452 11 45 77 35372 8 0 472 3 0 176]]\n",
            "targets[[9 141 136 0 84 944 18587 19 9 50 93 7 144 208 107 1072 4 1695 9 195]]\n",
            "targets[[3466 175 6 6 520 27088 499 35 1452 15729 2 7560 34 2979 17398 1 94 695 43 1731]]\n",
            "targets[[356 18 0 109 5 81 58 46 0 1308 1973 25 356 0 17 5 180 49 0 17]]\n",
            "targets[[17 23 64 6000 0 450 3 2 125 34 5 3228 2377 8 0 8978 12 1 2 687]]\n",
            "targets[[5 29 3 146 37 446 368 98 9 42 89 21 76 91 904 25 8582 1 153 17193]]\n",
            "targets[[9 196 0 1934 13 74 15 0 1539 11 10 17 45 29 3 0 872 156 3 258]]\n",
            "targets[[526 2362 338 432 3 609 5 1184 273 318 46 20 148 2 1909 3851 338 1116 36470 20]]\n",
            "targets[[14 0 19 4 366 0 1998 2930 202 16 0 3790 6181 19 1322 0 733 4568 5235 1878]]\n",
            "targets[[17 329 4 2357 71 4623 51 9 13 1137 7 13 0 84 631 17 9 215 14 2]]\n",
            "targets[[5 0 250 19 9 27 123 110 233 0 2986 1868 1086 683 4 1652 60 1440 16 10]]\n",
            "targets[[3285 8 2 1702 570 4 383 55 15 0 780 4172 8357 24160 917 3 5037 646 2540 1436]]\n",
            "targets[[418 4 2 57478 3 10 8 407 3340 1 7 13 3978 6275 33 29 3 0 2391 5938]]\n",
            "targets[[149 316 9 4769 9 68 2053 1 4700 37 11 9 59 113 27 67 4 4216 10 17]]\n",
            "targets[[1830 144 221 29 422 3 10 202 1 42 420 21 191 1557 7 448 14 152 9 207]]\n",
            "targets[[40135 8 160 5094 0 2395 2106 16435 2917 1609 5 35 15990 1 3063 183 243 36 0 863]]\n",
            "targets[[140 2 340 3 193 156 5920 257 14340 1 51 9 84 1757 10 17 1 106 0 1561]]\n",
            "targets[[120 9 113 191 0 57 4 165 949 2 738 3 100 3 0 98 9 27 110 18]]\n",
            "targets[[8920 8 60 660 5 2 81 11209 7669 17 29 3 0 872 179 43 10 17 8 60]]\n",
            "targets[[693 10 19 13 428 4 28 37 74 7 13 155 37 9 418 78 7 15 11 6443]]\n",
            "targets[[10327 1179 17 15 48 705 2060 2340 33 0 322 284 10534 264 24 5 65 4968 55 26]]\n",
            "targets[[12 84 12879 78 0 176 3 317 9620 5 1136 34477 12 972 13 293 192 4 810 2]]\n",
            "targets[[1696 1696 185 0 10996 6 6 7 12 35 181 17 11 12 23 1094 2 1952 11 12]]\n",
            "targets[[215 10 14 2 385 493 1 58 31 142 2 183 567 10 17 22095 60 1299 1 9]]\n",
            "targets[[2 670 394 0 851 63 14100 5 2 641 7171 3885 755 11 45 2 53 13494 786 15372]]\n",
            "targets[[17 31 2 621 57 3 16217 228 13 43 22784 228 97 194 0 716 8 392 13 49]]\n",
            "targets[[74 1711 259 4 4615 30 452 8 7967 863 15 2 842 1703 8 2 3313 10 17 113]]\n",
            "targets[[19 13 35 2449 4 0 1648 3 0 779 6 6 0 109 5 11 10 557 2524 45]]\n",
            "targets[[21 262 11 32 25 235 2 160 19 339 10 5 0 22360 786 1047 22360 1 255 34]]\n",
            "targets[[215 10 17 31 0 3148 1074 19 1322 8 30004 1332 160 5213 9 230 37 1819 4 27]]\n",
            "targets[[5 23 127 823 959 528 7 12 53 53 247 58 16 1532 34 627 3454 31 0 10632]]\n",
            "targets[[5 2278 4 66 2 17 43 985 114 11 702 7 38 7 5 10 17 165 45 2]]\n",
            "targets[[3400 3189 2770 2 63 43 2 4256 590 1 2 112 63 11 2182 92 0 3400 3189 142]]\n",
            "targets[[16643 5 934 896 15 5646 743 1 497 22169 4 0 705 46 20 424 0 705 89 21]]\n",
            "targets[[17 5 37 348 1 1876 9 382 42 168 31 0 1126 0 1126 45160 11 20 195 4]]\n",
            "targets[[1656 5 2 230 49 17 15 7 12 485 8 0 205 265 1656 5 1059 8878 1 2352]]\n",
            "targets[[9 856 2 171 36 10 17 7 2902 38 29 3 146 3787 184 98 15 2 461 936]]\n",
            "targets[[13 29 3 0 117 2716 2139 2183 3 0 4128 46 9 96 169 7 22 1972 277 1295]]\n",
            "targets[[19 45 77 12131 16 37 108 154 37 4 429 27 7 22 277 5 81 7 5 35]]\n",
            "targets[[5 0 19 11 92 2365 2226 2 314 1 349 15 115 7226 1 8578 15 780 13376 23]]\n",
            "targets[[18705 51479 1655 5 10514 446 2 17 7 12 2756 5 427 22 2 637 393 1 53 934]]\n",
            "targets[[0 183 234 31 0 2251 3 0 63 5 21743 4 2 1871 1313 3815 31 0 5416 3]]\n",
            "targets[[99 149 7 9 42 27 4 121 34 0 574 25 131 336 336 13631 4055 11 25 715]]\n",
            "targets[[3 30 287 71 136 11 9 242 42 457 4 76 60 1071 184 443 4223 37 9 140]]\n",
            "targets[[10 19 3257 9 13 2 3144 291 158 340 3 4121 3892 9 196 40 2769 1 0 19]]\n",
            "targets[[19 5 2 397 17 427 22 0 114 3 2 125 446 3541 7721 8 3631 2930 9 254]]\n",
            "targets[[159 21 211 78 10 17 15 303 1422 9 693 7 13 2088 2 2686 3 0 2988 477]]\n",
            "targets[[108 1517 798 53 1608 50 21 76 501 0 22931 12 1 18151 3 0 158 483 13 447]]\n",
            "targets[[3380 928 16 35 4544 303 377 1 9 1491 2757 4966 37 11 0 1500 50 854 43 0]]\n",
            "targets[[17 5 446 84 6608 22 9154 8 646 0 216 167 71 446 7 2240 1492 24 203 27]]\n",
            "targets[[547 30 2014 1 10502 5220 8 773 6348 7883 223 1363 3602 2 394 6742 1050 15 3477 762]]\n",
            "targets[[425 1180 10 17 4 71 9 13 7840 31 84 9 140 2 1485 1 9 723 21 65]]\n",
            "targets[[5 0 88 1157 680 123 0 109 267 29 95 94 1320 12867 7292 7 10535 143 2497 4333]]\n",
            "targets[[3 0 250 244 74 116 33 2215 0 217 177 552 736 992 3 0 455 534 5 11407]]\n",
            "targets[[1 0 2140 5 371 0 117 1264 17 3 30 57 3896 9 307 175 99 459 41 463]]\n",
            "targets[[59 93 52 266 4 667 10 63 14 2 246 2299 202 0 95 7 13 1900 1056 72]]\n",
            "targets[[277 5 8 471 1846 14662 18 1449 100 1132 133 280 158 270 8 0 15267 0 961 1178]]\n",
            "targets[[17 695 91 63 8 105 8871 11101 29 43 2511 114 1 640 578 1 157 43 183 1]]\n",
            "targets[[7 1189 21 16 0 6135 63 5697 55 282 22 3857 1 33 598 381 4 1972 7 9]]\n",
            "targets[[17 43 47 31 0 57 13 1267 29 3 0 88 2799 1497 123 85 3 0 2216 13]]\n",
            "targets[[5 23 0 88 1094 41 1887 3 12 104 0 1069 5 2 222 565 1 0 109 10951]]\n",
            "targets[[67 113 555 3 10 19 2723 4 318 7 9 3580 46 7 13 35 1633 19 1 9]]\n",
            "targets[[2100 1100 207 5 2 222 52 1945 341 72 127 1959 1001 12 184 487 18 23 2802 73]]\n",
            "targets[[2 17 43 2016 1389 33 2016 1389 815 37 48 3 90 25 2369 37 376 70 141 712]]\n",
            "targets[[215 10 17 31 0 443 194 602 8 189 7 13 37 194 602 11 0 289 806 133]]\n",
            "targets[[125 218 2 1245 7318 8 2 508 1988 1 14 2 914 24 5 25266 2 3260 406 86]]\n",
            "targets[[509 10 17 14 2 527 51 7 389 44 1 4 10 249 133 80 2 595 63 1159]]\n",
            "targets[[27 2260 55 15 4536 5021 30 60 114 60 1231 2164 55 15 4536 5021 70 27 42 307]]\n",
            "targets[[5 2 19141 458 15 1582 245 2056 9 252 7 16 223 154 429 14804 7 20 366 120]]\n",
            "targets[[1571 680 163 8600 3340 2089 36 2214 1523 6 6 42 1090 6 6 1156 1832 3269 6719 11803]]\n",
            "targets[[2307 1106 144 7 5 427 22 0 297 63 3 105 1921 5406 887 3818 1 780 2946 2964]]\n",
            "targets[[329 4 28 35 6345 507 357 9 1317 1066 194 1049 588 3001 1738 2 346 16 0 460]]\n",
            "targets[[88 497 8894 3 2 81 202 7 141 23 27 77 748 7923 7271 85 7 12 64 0]]\n",
            "targets[[4885 10 44 14 35 13095 51 14454 144 0 17 1045 1 420 21 27 77 100 52 3381]]\n",
            "targets[[683 50 1652 0 1533 9 418 144 149 64 172 3 10 19 9 112 2041 18 10 65]]\n",
            "targets[[5 0 17 11 23127 0 207 207 1096 3 0 1820 1 58 490 0 1096 107 11 75]]\n",
            "targets[[5 2 849 662 7 1449 0 573 1 615 1135 3 0 2125 125 446 1744 8 799 174]]\n",
            "targets[[2847 14809 5 35 3278 19 1 46 39 25 100 439 3 727 5381 44 39 34 27 23]]\n",
            "targets[[0 3631 39 68 180 2 173 548 379 3661 11 25 5530 245 4 2791 490 11 12 85]]\n",
            "targets[[4134 369 5 2 9997 185 339 3 0 17699 5011 2 63 3 2 1626 9354 4 48 7]]\n",
            "targets[[2643 18 69 10419 10 407 691 14961 19 59 27 178 262 11 30 11 5 932 4 704]]\n",
            "targets[[60 60 60 10 422 5 504 9 402 7 107 49 18 1587 6 6 32 4023 0 9466]]\n",
            "targets[[60 1675 9 50 21 262 0 678 1577 128 64 267 14 360 14 308 314 9 13 1375]]\n",
            "targets[[772 471 12 5 0 212 412 3 2 19 61 42 150 21 306 4 121 47 310 7]]\n",
            "targets[[9680 285 2 814 381 78 26 354 57 42 167 8402 1237 47 70 80 43 557 98 70]]\n",
            "targets[[165 67 56 2962 3 318 10 17 51 9 207 84 555 43 7 239 157 20 195 2754]]\n",
            "targets[[0 1341 8 10457 5 2 1896 0 116 5 394 0 876 5 684 3330 1 0 101 25]]\n",
            "targets[[17 45 4 28 0 250 17 9 27 123 110 8 60 114 10 17 5 0 5244 3]]\n",
            "targets[[25 375 8 10 953 1084 3 1051 992 18 438 7 12 23 53 49 1728 848 14 69]]\n",
            "targets[[2 57 111 848 801 1759 7 12 81 4 66 2 556 143 4 4606 15 417 101 6]]\n",
            "targets[[9 215 16087 3899 22 0 1029 3 10 277 9 196 16 251 7 59 28 212 1 247]]\n",
            "targets[[19 11 150 21 453 2 561 114 5 354 1 245 8 10 19 93 29 1414 1 20]]\n",
            "targets[[159 21 58 693 10 17 4354 357 3584 99 318 4147 12089 9 13 8280 187 22 0 12089]]\n",
            "targets[[0 88 5018 1 3428 3 30 1266 104 24045 124 23 776 78 100 3 0 7516 11184 3457]]\n",
            "targets[[2257 26 5860 9956 4 2 11126 15264 2 4477 1368 4291 55 8 0 24927 1586 3498 15 2]]\n",
            "targets[[25292 13 0 153 3 1394 1840 2264 0 2397 5352 20073 37741 4045 0 580 1840 23153 5322 0]]\n",
            "targets[[653 463 228 529 71 419 94 9382 2148 24 64 67 29 49 321 16 0 372 3 0]]\n",
            "targets[[7299 972 10 13450 78 0 176 3 0 1611 1 0 2333 1 7 124 53 69 7 150]]\n",
            "targets[[3677 28 2 637 9 215 7 61 5 4624 8 2563 1 9 27 4 136 11 7 13]]\n",
            "targets[[63 1425 101 1 116 258 217 231 307 7 575 60 463 12286 158 6727 7 65 3257 60]]\n",
            "targets[[151 9 121 43 10 19 5 11 9158 1526 153 6578 17350 203 27 67 2 81 57 235]]\n",
            "targets[[1357 2 277 15 11631 10764 1 1287 10827 16 64 19045 2 2173 9 196 1 9 13 205]]\n",
            "targets[[5 2 948 17 43 35 10998 6343 0 1087 3 0 2291 3030 54 302 2 65 1163 261]]\n",
            "targets[[65 89 21 38 4 136 74 179 43 88 98 9 106 56 517 87 74 32 25 9]]\n",
            "targets[[13 381 1467 15 10 17 8 0 457 465 838 17655 1 229 4632 16 0 88 172 58]]\n",
            "targets[[45 2 186 49 834 18 431 60 548 124 0 2368 2209 10363 9 89 21 38 4 359]]\n",
            "targets[[5 2 81 17 88 3 178 27 110 7697 1332 111 0 4265 3055 5 16058 33 951 43]]\n",
            "targets[[17 288 21 42 74 7 13 394 99 9 307 7 9 165 448 0 365 4 191 2]]\n",
            "targets[[74 9 232 13433 36 715 7 2 29 85 9 1385 0 1035 203 27 226 47 32 96]]\n",
            "targets[[5 81 1160 4 1241 2965 1 9482 10 17 1601 22 246 42 38 174 6944 98 19178 104]]\n",
            "targets[[9 555 43 18637 1 215 2993 36 7 1 0 829 68 649 1153 9 65 470 4 66]]\n",
            "targets[[139 195 4 987 9 288 21 251 46 9 13 164 4 38 10 19 85 32 67 239]]\n",
            "targets[[5 2 49 202 15 583 753 1 849 753 6 6 2312 1 7355 560 0 10752 1 31653]]\n",
            "targets[[215 10 432 3 12 227 10665 1 9 27 113 654 0 729 120 8 142 5313 1756 24104]]\n",
            "targets[[13 0 88 394 17 9 27 123 110 0 2690 3 7 150 21 65 93 266 1 7]]\n",
            "targets[[5 2 19 61 141 28 110 33 1859 899 8 16520 33 41 2002 36 35 1879 7345 7]]\n",
            "targets[[17 288 21 53 49 7 971 161 160 4 897 1370 461 1474 104 0 109 5 161 81]]\n",
            "targets[[63 5 2 1492 202 3 270 1358 16 2197 2529 4 122 26 953 1966 1 10249 48 3]]\n",
            "targets[[5 29 3 0 400 18 254 104 642 22 3857 22 459 459 18056 650 10 1 105 82]]\n",
            "targets[[850 2879 2 173 3708 4 138 66 2 17 48 49 355 33 60 489 1 9 92 0]]\n",
            "targets[[83 93 10 1369 6 6 10 5 2 523 17 5 7 335 7361 56 83 20 367 7]]\n",
            "targets[[1538 88 98 15 2 34118 769 85 88 3 90 29617 56 196 4096 41 2615 1089 10 17]]\n",
            "targets[[17 45 0 117 15756 3 100 17 9 139 123 110 7 12 2 595 1110 3 223 454]]\n",
            "targets[[0 1272 3 2273 6227 12736 34 5 31 26 24325 117 50 21 586 10 16532 115 201 36]]\n",
            "targets[[204 28 2669 4 136 11 520 16301 5 29 3 0 88 4204 74 964 752 490 18 26]]\n",
            "targets[[2 2319 842 2 959 13142 1501 4 378 662 11 12 165 49 0 3571 691 308 308 223]]\n",
            "targets[[20 182 127 104 4 27 2189 101 20 241 1525 21 138 740 10 29 10 5 2 53]]\n",
            "targets[[255 121 47 244 3 12279 284 21 5963 9 280 38 2 1752 4 544 1289 12 1781 10]]\n",
            "targets[[215 0 17 31 0 19 1322 7 5 2 394 17 9 242 58 770 7 13 6369 16]]\n",
            "targets[[140 2779 37 20 241 59 103 9 27 113 555 3 714 2966 41 2685 5080 41 255 38]]\n",
            "targets[[121 20 148 23 65 792 3625 89 21 20 10 5 64 2 989 51 20 3504 55 20]]\n",
            "targets[[2 2018 3 0 17 3615 20 236 28 5741 4 103 10 5 157 1099 734 17 43 105]]\n",
            "targets[[3084 3 12183 5 1186 8 0 2974 3 0 452 7911 18465 8092 16976 24 1684 15 1786 1]]\n",
            "targets[[5 2 940 248 72 2 738 0 2939 22 10 412 5 5147 9 772 8927 8453 51 2]]\n",
            "targets[[9 970 2008 65 1455 16 37 980 2124 9 516 545 39 13 437 56 116 4 1111 3]]\n",
            "targets[[3008 228 78 0 19 9 196 10 13 29 3 0 4463 3086 12 123 85 7 67 0]]\n",
            "targets[[4258 16 2 2038 10998 169 44 32 148 22 0 10601 296 51 0 6182 36 2 8354 18714]]\n",
            "targets[[2340 2 1424 168 31 13380 443 22 1047 59953 786 1047 2236 18 7 5 22 10 972 11]]\n",
            "targets[[9072 158 1475 2053 792 45833 245 752 21606 3519 10830 1 26 11724 312 3175 13840 8384 543 966]]\n",
            "targets[[50 21 262 11 0 16867 19 12203 1411 281 78 1223 38 10 31 0 5699 3 613 19]]\n",
            "targets[[227 154 694 104 4 706 16 10 5 0 63 3 522 3 75 34 27 4369 99 863]]\n",
            "targets[[18 7 12 23 6 6 10 5 0 250 19 123 92 9 1690 7 55 29 249 1]]\n",
            "targets[[3033 846 751 31322 1 846 2959 1813 49564 21442 11 39 25 29 1476 493 5737 8 0 176]]\n",
            "targets[[0 84 6720 13 2 368 2 248 49 2294 17 11 9 987 672 1366 18 5850 6851 349]]\n",
            "targets[[2 366 9 80 23 395 149 10 17 8386 0 17 1109 0 900 16 0 2192 2864 3958]]\n",
            "targets[[24616 1 2743 32340 25 775 0 2646 342 4 27 77 22 2361 311 409 7 12 2335 11]]\n",
            "targets[[17 13 142 2 4564 7 45 11 230 49 239 475 8 127 384 2067 11 4069 71 4]]\n",
            "targets[[1551 1353 644 5 245 4 1652 4 0 823 507 7 1584 71 3 2 6257 6629 19 15]]\n",
            "targets[[5 29 3 0 250 98 123 9 50 21 1283 682 87 74 10 17 5 9 121 9]]\n",
            "targets[[5 213 337 51 2 17 45 2 220 9 3432 4 2831 127 2798 29 18 51 7 150]]\n",
            "targets[[17 7 923 20 8 769 2925 1 12447 4 91 878 9 80 23 121 87 1848 7 5]]\n",
            "targets[[12 2 155 151 43 149 1140 98 8 0 6221 1128 58 1140 98 11 27 77 69 6137]]\n",
            "targets[[20 182 4 262 11 20 25 2 1674 824 3 1874 106 10 19 1 94 380 295 20]]\n",
            "targets[[5 35 158 3041 1875 247 423 12 17 15 1477 0 88 2488 12137 1868 123 995 108 687]]\n",
            "targets[[63 3 275 524 34 138 78 0 18971 3 12341 1 129 55 6969 33 2 4450 8 0]]\n",
            "targets[[80 20 366 87 43 0 9425 754 10 19 5 4968 44 4 423 34 12 2256 2161 27]]\n",
            "targets[[17400 1273 50178 3340 408 1 513 33 18008 66840 13 642 31 0 4641 303 724 19 1322 14]]\n",
            "targets[[5 29 155 19 0 1196 5 42 37 81 3080 4498 1 9796 59703 68 1003 4 28 292]]\n",
            "targets[[0 64 122 9 367 149 22 10190 3520 1 29 3 60 1628 436 766 274 3 30 57]]\n",
            "targets[[1224 10907 362 31 2 69 31 2 8985 1244 16581 90 8 0 7016 741 1671 8 0 2069]]\n",
            "targets[[17 118 304 38 2 989 41 272 58 38 35 9102 7 13 4100 7 13 634 2 742]]\n",
            "targets[[216 520 22204 252 33 0 15614 3926 520 60772 218 35 20259 1904 14 2 3196 16 26 10191]]\n",
            "targets[[1714 5 10159 3187 3 0 19508 4828 11 3733 1088 45 67 22 443 0 412 3 0 17]]\n",
            "targets[[555 37 73 43 10 17 87 7 13 2 81 1224 1 29 3 146 407 1001 12 98]]\n",
            "targets[[5548 868 5 65 35 46179 984 3 19950 24175 12 1471 673 9 985 2 330 125 56 517]]\n",
            "targets[[45 1983 258 2987 175 75 7 280 38 0 129 3 15963 29023 42 288 21 0 41897 24]]\n",
            "targets[[7 12 297 10 17 13 379 1 46 9 96 76 60 281 143 9 59 7 13 0]]\n",
            "targets[[1438 3 6725 7929 12 12342 13233 19 1471 5 11 7 45 4933 2962 16054 0 6755 3370 3]]\n",
            "targets[[422 5 426 263 72 30 0 82 64482 152 48 3 0 1362 25 133 39 0 5810 5]]\n",
            "targets[[25 765 98 20 42 27 4 106 46 64 16 62 2519 624 15 142 2 412 20 6187]]\n",
            "targets[[19 1745 29 3 0 30 57 81 1363 24008 3736 199 1832 3269 12 7054 5469 1 2 831]]\n",
            "targets[[25 37 108 2423 179 43 10 17 11 9 50 21 853 390 18 2 173 6 6 2893]]\n",
            "targets[[136 15 81 14191 11 10 13 0 872 725 1613 3 60 2732 239 39 306 4 28 56]]\n",
            "targets[[4003 0 116 1883 3 2588 3635 1 3231 6020 18 9 13 671 33 0 2572 63 61 9]]\n",
            "targets[[2 81 17 9 65 509 149 1209 304 26 209 14 2041 3158 9 467 0 919 111 38]]\n",
            "targets[[53733 12 7723 3103 1244 5 2 938 2102 22 174 614 616 10 19 13 4182 8 2838 14]]\n",
            "targets[[1652 10 17 14 2 316 201 43 2 749 55 705 259 4 93 7 14 2 705 42]]\n",
            "targets[[64 151 8 10 17 11 5 0 219 222 413 5 0 527 36664 24911 34 923 951 26]]\n",
            "targets[[255 380 71 111 9 236 169 0 3782 1787 201 122 4234 8 352 1912 41 277 4 4192]]\n",
            "targets[[1078 0 6633 11 7235 4 235 10 17 29 3 371 81 443 1935 142 14 0 63 0]]\n",
            "targets[[15 2 412 38 10349 3044 8 2 200 13892 797 47 236 20 512 4 66 508 4486 107]]\n",
            "targets[[12 2 247 181 122 241 59 27 421 2 1484 199 9437 1621 5013 1 15140 29 3 0]]\n",
            "targets[[19 5 0 84 500 434 763 1085 22 1599 15 49 109 1 81 181 33 0 2098 11]]\n",
            "targets[[80 23 121 134 9 27 23 5372 2 940 22 10 19 167 147 566 126 544 72 113]]\n",
            "targets[[76 10 44 3 0 95 9 1291 10 17 85 0 534 22 0 1029 21667 30305 13 53]]\n",
            "targets[[4 136 43 9338 75 1374 7 4250 69 88 3 0 3566 888 12 368 410 27 478 77]]\n",
            "targets[[1080 3 10 17 5 539 1622 353 17 12 109 2690 6 6 10 19 45 56 628 129]]\n",
            "targets[[176 5 2 1485 1633 19 15 35 3332 1080 11 159 21 180 93 7 31 30 7 1905]]\n",
            "targets[[48 1517 798 10 19 45 10771 8 0 898 4791 7 12 133 273 2 168 14 10 5]]\n",
            "targets[[3 146 104 11 12 273 318 46 16 56 82 293 72 7 12 13249 6 6 7 12]]\n",
            "targets[[10 17 13 1427 4 93 71 230 767 16 0 4087 10421 14649 10 640 69 7 118 23]]\n",
            "targets[[1347 3 13254 23333 13 2 19 11 9 307 440 214 51 9 13 2 493 9 509 7]]\n",
            "targets[[13005 210 21 0 289 102 3 10 17 24 12 1184 8 7 88 3 0 260 57 5]]\n",
            "targets[[3988 15283 926 1039 6092 14 3008 137 1047 23512 3891 590 1 82 114 2612 3885 188 1876 147]]\n",
            "targets[[19 5 23 2 74 17 18 16 48 293 22 128 91 107 2776 9 307 10 14 2]]\n",
            "targets[[215 0 768 3 0 105 117 1987 3 30 57 4600 223 5665 249 1 944 2750 12 7948]]\n",
            "targets[[737 50670 2136 201 436 2712 230 49 19082 18 10 57 36 0 627 52 6280 27697 605 15]]\n",
            "targets[[10131 8475 443 153 8 5284 67 0 266 31 0 57 51 10 8290 19 13 84 1 113]]\n",
            "targets[[314 13835 699 1806 1038 369 280 81 47 20 50 66 3 7 9 27 275 2415 105 1912]]\n",
            "targets[[284 1802 12 52 836 17 2412 0 29116 10 19 5 37 74 11 7 5 745 3 247]]\n",
            "targets[[13 11527 15335 12 117 237 7 9927 71 11 54 58 8255 15 104 38 0 234 364 1191]]\n",
            "targets[[27 424 174 29 3 284 15363 12 98 11 9 139 110 1 0 963 3 17258 18421 5]]\n",
            "targets[[5 3 268 2 81 705 202 18 10 422 274 52 72 100 82 87 7 50 3087 2]]\n",
            "targets[[18 9 27 4 28 9582 22 10 17 9 13 748 99 0 455 102 60 373 13 2]]\n",
            "targets[[738 1430 109 1022 6 6 0 84 1924 11 0 975 7883 13 164 4 2819 7 12 2]]\n",
            "targets[[10 487 45 2 171 433 7 74 116 74 225 74 946 360 53 360 341 1 52 2684]]\n",
            "targets[[196 10 17 13 497 0 116 1 946 13 137 11 2 668 291 158 96 80 9 118]]\n",
            "targets[[12 0 244 3 112 63 11 9 80 367 149 1 649 7 12 16 105 996 29 7]]\n",
            "targets[[165 149 0 17 14 9 949 10 9 448 5330 4 1226 55 60 16038 1 13751 60 4706]]\n",
            "targets[[1062 9 27 149 10 17 490 5 111 118 0 227 3008 1408 154 138 9 13 22 60]]\n",
            "targets[[1690 10 55 10 2269 16 56 82 293 72 0 177 431 251 147 1 94 9 80 367]]\n",
            "targets[[0 129 3 4415 22 708 0 3279 1738 2 526 6549 2872 484 16 2 173 75 4 10986]]\n",
            "targets[[347 33 7094 8916 7068 10392 1 14522 284 1829 5 2 3061 8 61 0 101 66 0 803]]\n",
            "targets[[1430 108 108 1022 23 11 7 2339 233 283 5 37 14464 576 6 6 431 60 548 111]]\n",
            "targets[[13 208 5446 2577 1 15 862 6392 11 227 311 9 3338 29 3 0 338 720 4 0]]\n",
            "targets[[20 68 4 1661 427 22 0 17 624 0 11958 11 529 0 858 725 2 6185 344 2]]\n",
            "targets[[31 0 5416 3 764 12 2623 1521 5395 10864 5 29 3 146 1195 8193 29 433 0 108]]\n",
            "targets[[2 173 3 3054 12 30 399 10 552 1097 4150 3 699 184 3046 187 2 328 1 0]]\n",
            "targets[[80 1035 38 24466 16203 122 3030 14 49 75 1 6153 75 14 74 75 13 2 200 864]]\n",
            "targets[[5332 51 13828 389 44 0 2664 13 42 381 120 0 1526 47 32 2228 8 10 17 188]]\n",
            "targets[[16716 70 27 745 1 745 5548 1319 75 8 474 1 32 27 77 128 16 2 53 194]]\n",
            "targets[[59 551 51 2 4012 814 515 15 2 8486 22 16911 204 28 2 171 3 247 10 17]]\n",
            "targets[[5 29 4 106 2 173 214 0 322 503 274 32 67 4 27 1400 10 63 41 121]]\n",
            "targets[[17 2107 15 57 1899 22 2 1040 2341 1 38 88 832 827 104 7 5 727 4 1226]]\n",
            "targets[[41179 1047 19555 41 0 27388 789 0 961 14 9 262 5 7 12 1105 646 412 5 270]]\n",
            "targets[[112 1048 1088 1 83 106 221 238 8 0 477 264 37 229 27 19197 318 7273 708 9]]\n",
            "targets[[20 67 4998 1862 43 286 1 11 286 118 23 121 11 20 693 87 59 20 359 11]]\n",
            "targets[[10 84 8019 5 1250 850 6 6 4133 2614 5 43 0 2089 2447 7939 252 33 4213 9203]]\n",
            "targets[[42 1018 10 8915 2784 782 201 868 36 7773 645 4 276 2177 8 6203 22 3857 14 172]]\n",
            "targets[[0 1915 266 10 5 1728 848 0 3274 3 8613 42 668 25 5151 5347 15 2162 0 63]]\n",
            "targets[[19 5 43 2 243 34 400 40 568 1 435 8 2 2150 1259 40 114 267 78 2]]\n",
            "targets[[685 0 8124 5 29 3 146 104 11 42 2560 21 2009 28 295 12 4165 3 3853 7]]\n",
            "targets[[2 17 76 447 123 9 1291 10 17 23 1375 4 169 81 946 41 116 42 29069 1]]\n",
            "targets[[32604 12 445 0 170 2032 788 38 2 2914 755 85 7 20511 625 8 2200 3 3259 436]]\n",
            "targets[[50 28 7870 55 8 668 354 683 81 19 1896 271 6 6 1250 1250 1250 1250 353 36]]\n",
            "targets[[9 555 3464 92 10 17 9 13 53 2313 85 29 151 11 9 121 9641 83 28 35]]\n",
            "targets[[2139 201 972 8204 3641 8312 1 1799 29 3 0 872 276 1256 2 297 166 3 1560 540]]\n",
            "targets[[160 984 5 401 29 3 60 519 8286 5421 104 8 154 4342 18594 204 4934 399 14 0]]\n",
            "targets[[291 3 768 0 2004 177 1 369 30 5716 71 51 9 1830 4 106 0 311 3 0]]\n",
            "targets[[215 10 17 8 1054 1418 1 9 196 7 13 65 413 251 7 288 21 0 5416 3]]\n",
            "targets[[17 16616 5 273 2 168 8 60 4684 660 9 353 0 829 1 9 13 770 31 0]]\n",
            "targets[[13 356 43 10 19 51 7 13 645 8 4234 532 7 13 42 2 838 16804 3 714]]\n",
            "targets[[2506 402 0 390 3 0 289 279 284 601 566 24 5 0 29 15 0 354 1736 5738]]\n",
            "targets[[60 4335 702 3 2 647 41445 61 3368 199 2 1043 7513 37817 619 1025 3483 15204 1 40]]\n",
            "targets[[50 21 136 238 74 43 0 19 7 45 37 108 49 75 11 68 3130 8 235 0]]\n",
            "targets[[1274 11232 78 2 57 1170 2922 51 0 3843 8728 19396 8293 12 4131 3473 1 2 8728 3]]\n",
            "targets[[128 7 5 53 1336 0 250 17 9 27 123 110 9 67 353 43 10 19 194 602]]\n",
            "targets[[19 5 5970 11188 247 137 0 1187 7175 16949 19 3779 9 50 21 870 4 76 0 277]]\n",
            "targets[[12 2 145 903 9 723 21 110 2 666 4804 41 2 23811 16 10 17 828 152 0]]\n",
            "targets[[112 0 4646 3 184 202 1 0 1421 7 2298 16 5208 115 98 16 70 34 112 184]]\n",
            "targets[[289 430 15 10 19 5 0 1032 14 13214 9502 12 1049 568 3922 2317 13 177 24 5]]\n",
            "targets[[887 1 9 467 10 17 0 84 57 70 215 7 31 0 1150 8 797 8 194 958]]\n",
            "targets[[70 478 27 2 2690 3 0 122 9 1385 7 5 2 49 151 11 70 25 2782 43]]\n",
            "targets[[329 4 38 1464 1469 14 57 45 781 22 9 139 211 4 942 11 376 9 89 21]]\n",
            "targets[[140 2 669 1303 6238 340 1 1374 107 2 806 1576 19 2 297 340 491 4 66 14]]\n",
            "targets[[481 9 83 28 0 64 29 4 278 51398 22 10 3022 166 61 1859 22 0 2147 11769]]\n",
            "targets[[4 10 122 544 262 7 13 0 4367 1 466 422 51 84 307 7 1 13 2674 240]]\n",
            "targets[[0 457 1012 24021 252 2 102 446 115 582 94 29 249 115 582 2164 55 21758 78 1457]]\n",
            "targets[[1046 15 0 897 1996 11 26329 29529 772 5 0 19559 1 88 1211 432 3 8473 92 33]]\n",
            "targets[[149 10 122 9 59 23 395 255 4 1066 281 4 106 10 22 0 200 260 9 551]]\n",
            "targets[[1725 39 25 440 2027 3 10 18355 398 0 7356 0 1005 9 215 2890 2625 22 908 12]]\n",
            "targets[[379 159 21 227 73 501 220 29 1033 208 6 6 9654 736 208 8123 394 686 2709 6]]\n",
            "targets[[7 12 0 929 3 0 104 24 31632 8 100 411 761 4347 5 8 2215 174 130 8]]\n",
            "targets[[91 4785 42 87 74 2 1162 16 18524 2000 13 2154 16440 2442 26595 13 43 14 6338 14]]\n",
            "targets[[63 499 120 31 0 900 3 14 2 1054 4091 21581 699 410 1 4545 0 23526 4 1844]]\n",
            "targets[[1099 17 15 161 18 2262 536 0 64 247 9 67 13 391 1537 0 1599 14 73 3]]\n",
            "targets[[67 353 64 74 829 43 10 17 18 9 874 4 350 4 169 7 566 51 9 118]]\n",
            "targets[[17705 5 65 0 6728 3 0 3423 705 205 147 5 54 65 273 30 0 3474 416 1]]\n",
            "targets[[9427 499 44 22 2 2630 2059 1179 111 2 557 7105 2181 45 8192 0 733 8702 50 21]]\n",
            "targets[[0 2829 12 2838 159 21 138 16 817 98 38 764 118 10 29 36 6094 5 29 3]]\n",
            "targets[[42 1779 148 149 0 442 202 22 277 2 173 483 602 1 7 529 71 2 3953 1461]]\n",
            "targets[[569 21 1818 949 2 940 22 344 18 10 5 0 250 17 9 139 123 110 23 64]]\n",
            "targets[[47 5 1640 36433 117 166 4 1309 0 4853 6191 2102 628 10283 203 2680 0 1694 41402 2697]]\n",
            "targets[[5 33 229 0 872 842 8 1054 15224 19 369 513 33 0 9587 468 2057 27727 34 627]]\n",
            "targets[[5 23 6531 3134 12 117 19 18 7 12 426 23 0 250 352 61 150 21 136 73]]\n",
            "targets[[17 236 27 77 641 523 46 7 1982 21 77 16 0 394 1468 1595 1 500 4836 315]]\n",
            "targets[[65 66 10 17 2 81 1312 17 23 58 498 774 2014 1 335 1796 8 1629 1 485]]\n",
            "targets[[22 584 8041 836 673 9 9063 5 0 2017 1989 1556 3484 2528 5190 1 10 836 646 5453]]\n",
            "targets[[12 88 504 43 10 19 5 87 710 20 843 20 25 149 2 17 1 23 42 105]]\n",
            "targets[[147 22 2783 277 370 246 2299 202 0 543 1548 20804 215 10 9741 556 58 24 13 2984]]\n",
            "targets[[103 9 139 110 30 3 0 20099 98 147 1 1216 32 148 30 53 336 546 16 0]]\n",
            "targets[[24 494 4 2259 514 0 15150 1173 970 153 1236 1286 8653 50 21 5288 26 393 8 0]]\n",
            "targets[[947 13 554 1211 2033 1 462 7 13 79 34338 155 87 9 467 7 174 102 13 53]]\n",
            "targets[[27 300 9 89 21 87 108 214 11 46 0 17 68 606 38 0 458 70 59 66]]\n",
            "targets[[63 3 3523 5 29 11 45 5070 71 16 108 154 37 10 13 2 203 66 16 71]]\n",
            "targets[[1950 10 581 38 2 81 1080 823 216 22 0 17406 5445 55 2456 25289 5136 21057 34 5]]\n",
            "targets[[12 23 2 74 1080 7 96 27 77 186 49 18 839 9095 839 3501 839 896 0 455]]\n",
            "targets[[10 17 1 20 232 66 134 7 159 21 138 21869 7 42 50 21 1017 7 12 197]]\n",
            "targets[[149 10 19 9 13 319 15 2 105 53 21476 43 10 19 134 118 32 93 10827 12]]\n",
            "targets[[42 319 2 2683 3 3692 935 31 0 160 21430 19 41201 10 5 29 3 0 88 4640]]\n",
            "targets[[318 2072 22 2 1666 2766 4 764 317 154 602 9 371 2439 9 67 110 0 250 19]]\n",
            "targets[[3055 7 12 2 81 321 16 2 316 201 2 377 527 1861 2 3209 132 26 701 25]]\n",
            "targets[[52 901 2 2968 476 0 52 7 20538 91 8 2536 699 531 0 872 7847 3 0 10191]]\n",
            "targets[[480 177 1654 6426 11239 19261 13 1024 8 10 6801 570 39 68 327 97 108 4787 1463 4]]\n",
            "targets[[20 307 10 17 20 121 134 9 300 2426 2426 2426 44652 174 57 32 300 2426 2426 2426]]\n",
            "targets[[1708 3 4116 1 87 7 7240 423 5 64 9776 3829 15 8 10 13518 63 3 2 628]]\n",
            "targets[[140 23 1824 3 16451 29828 14 2 705 298 41 5 7 2063 673 9 165 89 21 121]]\n",
            "targets[[139 555 43 87 379 9699 4758 12 1204 5 10 19 710 1 927 9625 11 6 6 10]]\n",
            "targets[[1022 16 146 34 64018 456 6 6 69 9 307 7 0 217 151 1 9 159 21 38]]\n",
            "targets[[348 1 736 99 64 720 228 78 0 19 9 96 7201 60 114 22 47 59 592 31]]\n",
            "targets[[307 0 17 1 9 13 65 671 0 17 2544 22 275 263 3600 3 75 1 380 62]]\n",
            "targets[[3609 46 10 5 0 170 153 34682 34 92 104 38 20030 45623 6 6 2 675 207 757]]\n",
            "targets[[1010 19 13 1900 2 928 19 1 132 9 2265 11 206 19 13 186 74 7 13 92]]\n",
            "targets[[737 25288 19 18 94 175 23 737 25288 4721 4470 1 304 29 3 0 986 558 10 5]]\n",
            "targets[[183 243 34 3514 2 2985 76 120 2 2592 8 0 10072 2468 525 635 44 54 12 107]]\n",
            "targets[[140 23 251 47 5 447 2 74 19 38 0 2789 910 20 1 71 1 295 70 121]]\n",
            "targets[[45 213 77 29 3 60 1628 98 1 83 213 28 119 0 227 173 154 9 27 421]]\n",
            "targets[[20 123 1251 15847 38 82 75 2959 3269 550 4 2 1258 34 12 22 30 29787 261 16]]\n",
            "targets[[3 440 3661 43 9051 22 560 7 5 0 648 7108 974 234 7357 8224 23194 44 3042 244]]\n",
            "targets[[13 3326 44 3 60 1551 16 10 19 1 9375 23763 185 4 0 711 443 111 9 1499]]\n",
            "targets[[115 542 189 43 71 5 11 9 140 2 200 340 3 10237 734 1256 134 569 21 20]]\n",
            "targets[[12148 4846 10568 251 3682 22 0 4079 766 231 11 5990 86 14 2 599 125 8 0 32172]]\n",
            "targets[[65 18 2 7788 2888 487 16 127 17369 978 143 6244 9 1982 21 58 23909 7 14 2]]\n",
            "targets[[1167 157 1224 19 15 2 461 808 75 7 12 81 11 0 17 4514 187 649 2 759]]\n",
            "targets[[49 834 5 1024 15 74 743 1679 101 1 2 549 11 50 21 1150 2 508 7 12]]\n",
            "targets[[604 262 30 3 0 74 829 11 10 17 5 381 7 5 682 0 117 662 8 0]]\n",
            "targets[[17 11 65 96 27 77 2 171 126 23 30 11 74 18 229 36 49 48 3 0]]\n",
            "targets[[17 5 17445 8 2556 37 7 5 1154 4 3171 7 36 2556 8 6533 718 7 8 60]]\n",
            "targets[[10 5 2 17 11 9 59 10935 14 9 400 105 588 3 60 114 16 10 7 13]]\n",
            "targets[[13 0 250 17 9 27 123 110 8 0 17 797 9 13 164 4 2 171 3 98]]\n",
            "targets[[7 13 42 0 797 41 272 0 14392 403 159 21 121 47 24 13 398 18 8 5617]]\n",
            "targets[[16 808 0 2818 15 10 2412 284 3467 1 2858 790 3808 10 17 1762 22 37 108 2056]]\n",
            "targets[[37 73 247 241 2 222 73 16 1117 276 362 1 65 7 12 2 3436 4 651 10]]\n",
            "targets[[5 2 394 19 8 189 7 12 29 3 0 250 104 9 139 110 1059 1 10 5]]\n",
            "targets[[242 3999 149 10 17 22 3857 9 27 213 467 0 2883 1354 3397 2830 339 446 60 519]]\n",
            "targets[[17 5 394 14148 95 5247 5 2 81 19 7 210 21 18 91 29 3 0 126 766]]\n",
            "targets[[10 22 12016 1 13 1072 44 3 60 4301 36 0 84 163 228 9 1385 3905 1 5554]]\n",
            "targets[[10 19 285 22 729 20 236 182 4 586 43 1118 228 3 127 57 1 636 0 1234]]\n",
            "targets[[36487 113 65 92 7 686 0 4543 3522 3 1630 2722 654 156 2323 72 89 0 2507 2332]]\n",
            "targets[[23306 363 6894 4713 1911 138 4 2 962 601 3753 4 350 4 15546 7 515 18 4713 1366]]\n",
            "targets[[5 2 248 774 17 43 2 1602 11 2298 2 45779 2416 1 218 2227 11162 51 24 1075]]\n",
            "targets[[17 5 539 8 174 95 7 2479 22 0 10380 3 1729 1489 8 2 3442 95 18 113]]\n",
            "targets[[17 5 56 813 92 257 16 5217 1090 7 5 1587 658 1 4515 1 250 3 30 7]]\n",
            "targets[[8 91 5909 2852 4 169 0 1504 1371 3 0 5366 45 426 19431 392 15 10 371 2033]]\n",
            "targets[[26919 10983 52 393 1 1656 42 777 36 1980 4 1353 22 0 1814 72 20 50 169 8]]\n",
            "targets[[5 2 65 155 19 257 0 325 795 1 2919 57 20 106 7 7 12 2 186 354]]\n",
            "targets[[27 467 10 19 233 9 13 2 115 527 9 59 8485 636 238 43 0 63 1255 3208]]\n",
            "targets[[17 5 2 2240 323 29 4 106 1037 52 7 12 2 81 17 4 106 16 91 101]]\n",
            "targets[[23 512 238 2167 51 20 818 10 17 2 461 499 808 1566 524 1 921 61 83 852]]\n",
            "targets[[25790 3563 11 1127 2 2364 385 522 3 1512 3104 205 3098 1 4495 3600 38 10 8 0]]\n",
            "targets[[286 34 267 44 3 26 95 4 66 347 3 0 125 34 389 4 2218 29 3 0]]\n",
            "targets[[7 5 10 19 9 837 11 46 840 39 5 2 1517 13836 5666 4055 25 3169 4 2]]\n",
            "targets[[139 110 2281 1 10632 98 167 18 9 627 27 56 430 6595 90 10 64 1018 60 769]]\n",
            "targets[[163 3758 275 277 270 1670 869 1935 42 4356 22 29781 3106 5622 60 84 1226 4 106 13]]\n",
            "targets[[3039 25 213 212 51 417 547 25 571 1 10 5 2 417 63 23 137 4 80 15]]\n",
            "targets[[13 1072 187 37893 37 9 307 10 17 1 9 96 23 535 1014 283 13 37 630 0]]\n",
            "targets[[65 467 7 264 132 884 0 829 7 13 180 1211 4 71 18 14 35 1855 540 340]]\n",
            "targets[[3717 41 328 3 320 14 7 5 542 128 5 29 3 0 88 1854 184 104 9 139]]\n",
            "targets[[12 1 98 25 16 707 3839 9 262 8 11 266 10 436 5 2 351 720 806 0]]\n",
            "targets[[543 947 26856 14 5182 1333 7383 494 4 8901 158 23400 1 366 2 160 114 16 313 14]]\n",
            "targets[[81 63 427 22 2 297 63 43 2 183 316 125 1 30 0 5410 349 0 1179 107]]\n",
            "targets[[60 65607 64911 69 7 426 124 99 10 15358 2241 3 2 19 87 22 708 9 1339 4]]\n",
            "targets[[17 499 44 15 48 28516 3354 61 302 799 733 228 7 406 0 1122 2690 3 47 5]]\n",
            "targets[[458 45 0 11892 2823 3 107 0 84 458 11 9 27 2305 391 205 8 0 632 3]]\n",
            "targets[[213 448 11 2 49 19 141 27 2 109 10 880 19 13 973 29 1 9 230 11]]\n",
            "targets[[45 77 300 43 14905 13640 107 3691 8 10 19 18 9 89 21 1046 0 4050 11 2]]\n",
            "targets[[9 1239 545 2 4419 1012 4458 340 9 242 164 4 350 4 278 10 14 1764 14 614]]\n",
            "targets[[84 215 10 17 51 9 13 43 700 1 9 65 180 509 7 87 356 13 9 99]]\n",
            "targets[[9 949 10 738 8 5622 70 25 23341 8 2 984 1087 17 2626 306 2780 4 2667 14]]\n",
            "targets[[470 4 38 0 3349 2504 3 0 2195 18 7 6745 1898 4 2 229 1674 19 1 1015]]\n",
            "targets[[140 767 4 136 11 10 19 3353 0 430 15 259 4 21488 297 547 22 0 260 6]]\n",
            "targets[[2 903 4 66 105 822 2722 17025 33 62 857 4 897 11794 62 5 17969 39 5 2]]\n",
            "targets[[80 23 121 46 10 98 689 25 52 0 2043 3 444 41 225 14 20 83 66 8]]\n",
            "targets[[1591 10 17 22 277 208 1237 47 4 512 1 14 9 242 43 4 2018 19 235 8]]\n",
            "targets[[0 289 234 102 5 727 22 0 531 0 17 190 210 21 9 27 56 321 87 10]]\n",
            "targets[[210 21 29 3 146 829 43 336 305 290 41 2157 41 107 1876 1205 11 64 0 55459]]\n",
            "targets[[6953 17161 118 8 235 10 19 490 59 113 28 3224 175 235 2 1485 63 15 36042 1761]]\n",
            "targets[[1518 1 1209 22185 182 4 76 985 18 9205 1221 1469 491 4 278 90 4548 48 10528 4]]\n",
            "targets[[2 8580 31 2 52438 2 125 5 1827 190 464 10 9270 8 2 644 370 3 75 7]]\n",
            "targets[[122 5 1149 1 9 139 110 7 43 1108 214 6 6 2370 7 204 28 1796 8 5108]]\n",
            "targets[[570 1 49 990 3300 3 0 3209 417 3402 3001 253 82 44 18 2 336 914 0 153]]\n",
            "targets[[88 338 98 11 203 28 35694 78 9307 201 436 868 10 17 10040 4 28 30 3 131]]\n",
            "targets[[6813 10 19 9 50 64 138 33 60 2430 14 2 2740 3958 398 60 1122 2763 8 7013]]\n",
            "targets[[5 29 3 0 250 98 123 92 4 27 0 4085 598 3 256 2 49 17 20 27]]\n",
            "targets[[9 13 1137 9 65 509 149 74 729 70 139 30 77 2521 3 7 31 48 57 41]]\n",
            "targets[[3939 3428 157 81 209 14 991 3254 4176 1145 622 798 213 23669 0 7310 1145 371 16420 0]]\n",
            "targets[[4058 3 2896 5359 204 23 28 2 81 19 18 7092 2 9440 3 1562 2026 5198 7 12]]\n",
            "targets[[834 3 0 17 13 815 1 9 118 367 688 10993 4 66 87 32 912 0 5834 6555]]\n",
            "targets[[523 116 337 655 63 288 21 9095 69 101 6258 1 319 15 115 4 56 1798 41 12361]]\n",
            "targets[[45 4 28 29 3 0 117 1855 104 44 39 2247 11965 5 8 60 660 42 14 49]]\n",
            "targets[[19 7333 295 143 4 7371 844 7473 111 70 465 4 28 172 3 0 81 20302 9 3677]]\n",
            "targets[[125 1 26 312 76 8 2 497 508 1631 51 0 312 5 319 8 2 12560 46700 1074]]\n",
            "targets[[3851 6005 4 30129 10 5 0 53 84 17 123 4 28 642 22 735 1048 797 5354 396]]\n",
            "targets[[119 0 6434 3 0 798 128 9 27 4 589 46 9 58 307 0 170 19 49 1675]]\n",
            "targets[[3581 4 61892 127 940 11 10 13 29 3 1669 12 8106 5 1958 3 0 947 7 13]]\n",
            "targets[[3233 974 2399 1 0 25 2167 10 13 3233 84 145 1139 19 341 1 7 65 559 178]]\n",
            "targets[[50 7437 255 0 4381 344 4254 18 7 150 21 306 4 6500 4 3859 9262 14 32 383]]\n",
            "targets[[165 195 60 435 2 737 2873 291 158 4 211 119 1 66 47 9 13 149 1 1014]]\n",
            "targets[[5 2 1099 2859 3 2 2227 610 63 11 1886 126 0 1032 13 336 116 1407 257 19405]]\n",
            "targets[[9 139 110 10 19 43 844 214 1 9 103 9 204 106 7 31 219 844 52 134]]\n",
            "targets[[42 215 10 31 0 19 1322 8 7281 1 9 27 4 136 9 13 671 0 109 67]]\n",
            "targets[[9 987 9 4105 294 10 17 7 13 37 980 1383 11 9 420 21 345 545 18 1535]]\n",
            "targets[[1347 3 3883 10 19 1109 0 451 3 29 231 578 8 2 7722 958 474 8 699 6541]]\n",
            "targets[[10 1003 4 28 155 18 56 12637 7 12 23 58 65 155 8 11 475 23 1003 4]]\n",
            "targets[[242 371 671 9 215 0 177 1 9 13 65 1027 137 44 3 10 17 9 350 4]]\n",
            "targets[[7958 475 263 36 0 298 33 1956 22452 34 1065 0 206 0 10260 24992 7 124 27 0]]\n",
            "targets[[1190 12 325 806 5 165 53 730 4 26 84 193 25 270 119 29 249 1 806 0]]\n",
            "targets[[30 3 20 597 4487 0 574 120 3073 10201 287 12 198 20 969 1696 4 93 2 17]]\n",
            "targets[[13 0 1269 3 10 19 9 1478 7 13 4 93 2 3274 3 156 1 62 1104 1]]\n",
            "targets[[474 3 30343 29780 5 2 948 18 397 265 0 101 59 28 42 356 1 97 1211 18]]\n",
            "targets[[17 5 677 6798 1753 4924 4924 15 1753 1761 460 1711 381 39776 33 316 4924 34 1664 1753]]\n",
            "targets[[17 13 379 264 9 27 110 48 447 98 167 0 26910 5 0 88 612 102 58 152]]\n",
            "targets[[911 1501 4 378 471 17 264 0 116 13 186 49 39 68 2 171 3 84 993 156]]\n",
            "targets[[215 10 17 15 60 425 1 70 25586 535 1014 9 382 39 13 161 631 43 10 17]]\n",
            "targets[[8500 67 513 43 1138 98 233 7909 533 24 12 53 49 18 51 24 12 74 24 12]]\n",
            "targets[[624 223 400 8 160 728 4 71 5 35 322 1312 487 8 60 660 0 7516 11 1457]]\n",
            "targets[[17 5 186 49 315 2 291 602 9 1291 7 22 277 18 84 9 196 11 7 13]]\n",
            "targets[[6650 3 691 2048 45 195 4 28 29 3 0 1536 98 11 9 139 123 110 42 85]]\n",
            "targets[[5 2 19 11 13 194 15474 58 8 3758 1 7933 0 310 3 0 617 2188 11 460]]\n",
            "targets[[3324 4856 2138 556 36 640 12 351 17 369 328 5 2 842 2 9465 6471 1 8803 0]]\n",
            "targets[[215 35 5044 2683 3 10 17 1 7 401 210 21 14 49 14 0 84 29 15 0]]\n",
            "targets[[42 215 10 17 227 311 1 107 286 34 67 53 360 1422 4 875 15 13 133 671]]\n",
            "targets[[786 4246 1 1364 53664 314 8 8096 10 9 467 10 19 2 171 584 786 4246 1 1364]]\n",
            "targets[[89 12 653 344 550 283 43 10 17 7 302 265 22 0 958 3 15149 0 958 3]]\n",
            "targets[[2779 93 56 2768 43 7 5 2 81 112 878 15 2 390 14 7 45 195 47 50]]\n",
            "targets[[103 10 5 0 117 3 0 668 685 1975 104 99 318 731 1 930 2331 7 5 731]]\n",
            "targets[[13 2 65 155 201 0 95 114 5 8 2 737 7722 40578 5 1011 924 1 0 263]]\n",
            "targets[[0 84 422 111 8 2 11932 876 70 66 2 2467 234 15 35 3843 2316 22 40 415]]\n",
            "targets[[232 987 7 9 140 2 2521 340 3 0 246 122 5201 5 2 1413 102 1 0 17]]\n",
            "targets[[17 141 113 27 77 92 30 3 0 1800 7440 57457 104 4205 4 0 5537 17 2808 30]]\n",
            "targets[[42 236 103 20 27 110 0 250 19 123 9602 0 933 3 1995 1302 796 824 3270 791]]\n",
            "targets[[1471 60 1628 477 6725 7929 12 811 55 4 2393 5 2 19 1471 270 8 2 15224 160]]\n",
            "targets[[80 20 454 121 0 2908 626 349 15 0 904 9 65 169 0 760 53 49 1 59]]\n",
            "targets[[722 7 51 30 9 50 103 3 132 149 100 17 5 51 83 7 129 9 96 28]]\n",
            "targets[[5 2 145 4161 9 50 103 3 161 4 395 10 19 0 19 4826 5 36 2 335]]\n",
            "targets[[183 831 12 390 5 6471 46772 54 12 1604 5 650 578 2 186 523 114 18 30 3]]\n",
            "targets[[12 28 1146 3677 70 1697 600 56 52 371 2052 43 0 2851 72 88 1475 456 43 23496]]\n",
            "targets[[0 5699 3 4963 2 222 675 7 288 21 22 2174 15 0 117 3 0 477 142 14]]\n",
            "targets[[980 2694 15503 4 3756 74 116 3946 826 1 4597 946 10 19 3032 8 17 1000 12 1896]]\n",
            "targets[[584 3998 1 5133 498 252 62 558 15 142 7337 9 327 4105 5133 498 12 209 14 3175]]\n",
            "targets[[173 75 22 10 1942 27 1101 3179 4 2 441 3 7299 3037 339 3 0 5633 1418 18]]\n",
            "targets[[1032 41 25543 1032 74 116 1 1308 7877 416 37 446 472 1506 36 0 1100 12 7 124]]\n",
            "targets[[10 738 1430 1022 6 6 60 564 15 1871 104 45 1216 23 77 53 49 47 562 5]]\n",
            "targets[[921 25 8 1547 14 2 19707 8913 2 6445 2865 1 2 8000 5738 0 1676 5 8 49]]\n",
            "targets[[206 738 13 382 1167 10 122 5 374 0 3066 1759 80 528 51 0 5264 210 21 261]]\n",
            "targets[[509 10 17 180 2 171 520 1654 14 2041 2005 5 437 539 1 2881 1 0 117 1235]]\n",
            "targets[[280 38 7 13 92 33 19 377 36514 46 11 19 377 13 8 10243 27560 33800 5 0]]\n",
            "targets[[20 89 21 27 238 4 80 1 20 65 112 4 66 74 98 208 2 773 344 69]]\n",
            "targets[[5 2 53 53 407 2739 4696 1084 14 2 914 0 102 5 133 8 2 4685 794 24]]\n",
            "targets[[12 610 51 20 50 66 47 2 17 13 2853 4 80 1 7 5 180 576 11 7]]\n",
            "targets[[3 30 9 112 303 377 1092 919 5539 231 1 556 3 567 436 464 256 0 756 8]]\n",
            "targets[[67 213 244 3 8590 10 17 14 19340 1866 12 36448 18 318 7 490 8 0 6221 1128]]\n",
            "targets[[205 15 0 795 19756 12 4054 3 16458 16480 292 48 2423 11125 109 44 3 2 173 1187]]\n",
            "targets[[5 606 0 293 134 108 75 2207 4349 85 374 1104 957 62 281 4 93 379 104 38]]\n",
            "targets[[215 10 17 51 9 13 8 0 1249 143 8 0 3392 349 15 572 22 0 13695 2617]]\n",
            "Traceback (most recent call last):\n",
            "  File \"generate_samples.py\", line 301, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 126, in run\n",
            "    _sys.exit(main(argv))\n",
            "  File \"generate_samples.py\", line 297, in main\n",
            "    generate_samples(hparams, data_set, id_to_word, log_dir, output_file)\n",
            "  File \"generate_samples.py\", line 253, in generate_samples\n",
            "    generate_logs(sess, model, output_file, id_to_word, eval_feed)\n",
            "  File \"generate_samples.py\", line 148, in generate_logs\n",
            "    [model.present, model.inputs, model.fake_sequence], feed_dict=feed)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 905, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1137, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1355, in _do_run\n",
            "    options, run_metadata)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1361, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1340, in _run_fn\n",
            "    target_list, status, run_metadata)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOwDbEL3c3B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9aZeEuOc3kK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huMuu2c6c4OQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHl8sFSttCHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRPevP8JsZ3J",
        "colab_type": "text"
      },
      "source": [
        "## Save and Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiPsRppGw1CK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FB7DYX0w17O",
        "colab_type": "code",
        "outputId": "7f24f459-61d6-4e1e-a74c-9d9e241829db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# #copy checkpoints to drive\n",
        "%cd /content\n",
        "%cp -av maskgan /content/gdrive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "'maskgan' -> '/content/gdrive/My Drive/maskgan'\n",
            "'maskgan/checkpoint_convert.py' -> '/content/gdrive/My Drive/maskgan/checkpoint_convert.py'\n",
            "'maskgan/sample_shuffler.py' -> '/content/gdrive/My Drive/maskgan/sample_shuffler.py'\n",
            "'maskgan/pretrain_mask_gan.py' -> '/content/gdrive/My Drive/maskgan/pretrain_mask_gan.py'\n",
            "'maskgan/README.md' -> '/content/gdrive/My Drive/maskgan/README.md'\n",
            "'maskgan/dataset' -> '/content/gdrive/My Drive/maskgan/dataset'\n",
            "'maskgan/dataset/iccv' -> '/content/gdrive/My Drive/maskgan/dataset/iccv'\n",
            "'maskgan/dataset/iccv/ptb.valid.txt' -> '/content/gdrive/My Drive/maskgan/dataset/iccv/ptb.valid.txt'\n",
            "'maskgan/dataset/iccv/ptb.train.txt' -> '/content/gdrive/My Drive/maskgan/dataset/iccv/ptb.train.txt'\n",
            "'maskgan/dataset/iccv/ptb.test.txt' -> '/content/gdrive/My Drive/maskgan/dataset/iccv/ptb.test.txt'\n",
            "'maskgan/dataset/iccv2017' -> '/content/gdrive/My Drive/maskgan/dataset/iccv2017'\n",
            "'maskgan/dataset/iccv2017/ptb.train.txt' -> '/content/gdrive/My Drive/maskgan/dataset/iccv2017/ptb.train.txt'\n",
            "'maskgan/dataset/iccv2017/ptb.valid.txt' -> '/content/gdrive/My Drive/maskgan/dataset/iccv2017/ptb.valid.txt'\n",
            "'maskgan/dataset/iccv2017/ptb.test.txt' -> '/content/gdrive/My Drive/maskgan/dataset/iccv2017/ptb.test.txt'\n",
            "'maskgan/.ipynb_checkpoints' -> '/content/gdrive/My Drive/maskgan/.ipynb_checkpoints'\n",
            "'maskgan/pretrain_mask_gan.pyc' -> '/content/gdrive/My Drive/maskgan/pretrain_mask_gan.pyc'\n",
            "'maskgan/data' -> '/content/gdrive/My Drive/maskgan/data'\n",
            "'maskgan/data/imdb_loader.py' -> '/content/gdrive/My Drive/maskgan/data/imdb_loader.py'\n",
            "'maskgan/data/ptb_loader.py' -> '/content/gdrive/My Drive/maskgan/data/ptb_loader.py'\n",
            "'maskgan/data/__init__.py' -> '/content/gdrive/My Drive/maskgan/data/__init__.py'\n",
            "'maskgan/data/__init__.pyc' -> '/content/gdrive/My Drive/maskgan/data/__init__.pyc'\n",
            "'maskgan/data/ptb_loader.pyc' -> '/content/gdrive/My Drive/maskgan/data/ptb_loader.pyc'\n",
            "'maskgan/data/imdb_loader.pyc' -> '/content/gdrive/My Drive/maskgan/data/imdb_loader.pyc'\n",
            "'maskgan/nas_utils' -> '/content/gdrive/My Drive/maskgan/nas_utils'\n",
            "'maskgan/nas_utils/configs.py' -> '/content/gdrive/My Drive/maskgan/nas_utils/configs.py'\n",
            "'maskgan/nas_utils/variational_dropout.py' -> '/content/gdrive/My Drive/maskgan/nas_utils/variational_dropout.py'\n",
            "'maskgan/nas_utils/__init__.py' -> '/content/gdrive/My Drive/maskgan/nas_utils/__init__.py'\n",
            "'maskgan/nas_utils/custom_cell.py' -> '/content/gdrive/My Drive/maskgan/nas_utils/custom_cell.py'\n",
            "'maskgan/nas_utils/custom_cell.pyc' -> '/content/gdrive/My Drive/maskgan/nas_utils/custom_cell.pyc'\n",
            "'maskgan/nas_utils/variational_dropout.pyc' -> '/content/gdrive/My Drive/maskgan/nas_utils/variational_dropout.pyc'\n",
            "'maskgan/nas_utils/configs.pyc' -> '/content/gdrive/My Drive/maskgan/nas_utils/configs.pyc'\n",
            "'maskgan/nas_utils/__init__.pyc' -> '/content/gdrive/My Drive/maskgan/nas_utils/__init__.pyc'\n",
            "'maskgan/models' -> '/content/gdrive/My Drive/maskgan/models'\n",
            "'maskgan/models/cnn.py' -> '/content/gdrive/My Drive/maskgan/models/cnn.py'\n",
            "'maskgan/models/attention_utils.py' -> '/content/gdrive/My Drive/maskgan/models/attention_utils.py'\n",
            "'maskgan/models/rollout.py' -> '/content/gdrive/My Drive/maskgan/models/rollout.py'\n",
            "'maskgan/models/bidirectional_zaremba.py' -> '/content/gdrive/My Drive/maskgan/models/bidirectional_zaremba.py'\n",
            "'maskgan/models/rnn_nas.py' -> '/content/gdrive/My Drive/maskgan/models/rnn_nas.py'\n",
            "'maskgan/models/seq2seq_vd.py' -> '/content/gdrive/My Drive/maskgan/models/seq2seq_vd.py'\n",
            "'maskgan/models/feedforward.py' -> '/content/gdrive/My Drive/maskgan/models/feedforward.py'\n",
            "'maskgan/models/critic_vd.py' -> '/content/gdrive/My Drive/maskgan/models/critic_vd.py'\n",
            "'maskgan/models/__init__.py' -> '/content/gdrive/My Drive/maskgan/models/__init__.py'\n",
            "'maskgan/models/bidirectional.py' -> '/content/gdrive/My Drive/maskgan/models/bidirectional.py'\n",
            "'maskgan/models/seq2seq_zaremba.py' -> '/content/gdrive/My Drive/maskgan/models/seq2seq_zaremba.py'\n",
            "'maskgan/models/seq2seq.py' -> '/content/gdrive/My Drive/maskgan/models/seq2seq.py'\n",
            "'maskgan/models/rnn_vd.py' -> '/content/gdrive/My Drive/maskgan/models/rnn_vd.py'\n",
            "'maskgan/models/bidirectional_vd.py' -> '/content/gdrive/My Drive/maskgan/models/bidirectional_vd.py'\n",
            "'maskgan/models/seq2seq_nas.py' -> '/content/gdrive/My Drive/maskgan/models/seq2seq_nas.py'\n",
            "'maskgan/models/rnn.py' -> '/content/gdrive/My Drive/maskgan/models/rnn.py'\n",
            "'maskgan/models/rnn_zaremba.py' -> '/content/gdrive/My Drive/maskgan/models/rnn_zaremba.py'\n",
            "'maskgan/models/evaluation_utils.py' -> '/content/gdrive/My Drive/maskgan/models/evaluation_utils.py'\n",
            "'maskgan/models/bidirectional.pyc' -> '/content/gdrive/My Drive/maskgan/models/bidirectional.pyc'\n",
            "'maskgan/models/evaluation_utils.pyc' -> '/content/gdrive/My Drive/maskgan/models/evaluation_utils.pyc'\n",
            "'maskgan/models/__init__.pyc' -> '/content/gdrive/My Drive/maskgan/models/__init__.pyc'\n",
            "'maskgan/models/rnn_zaremba.pyc' -> '/content/gdrive/My Drive/maskgan/models/rnn_zaremba.pyc'\n",
            "'maskgan/models/bidirectional_vd.pyc' -> '/content/gdrive/My Drive/maskgan/models/bidirectional_vd.pyc'\n",
            "'maskgan/models/rnn.pyc' -> '/content/gdrive/My Drive/maskgan/models/rnn.pyc'\n",
            "'maskgan/models/bidirectional_zaremba.pyc' -> '/content/gdrive/My Drive/maskgan/models/bidirectional_zaremba.pyc'\n",
            "'maskgan/models/seq2seq_vd.pyc' -> '/content/gdrive/My Drive/maskgan/models/seq2seq_vd.pyc'\n",
            "'maskgan/models/attention_utils.pyc' -> '/content/gdrive/My Drive/maskgan/models/attention_utils.pyc'\n",
            "'maskgan/models/cnn.pyc' -> '/content/gdrive/My Drive/maskgan/models/cnn.pyc'\n",
            "'maskgan/models/seq2seq.pyc' -> '/content/gdrive/My Drive/maskgan/models/seq2seq.pyc'\n",
            "'maskgan/models/seq2seq_nas.pyc' -> '/content/gdrive/My Drive/maskgan/models/seq2seq_nas.pyc'\n",
            "'maskgan/models/rnn_nas.pyc' -> '/content/gdrive/My Drive/maskgan/models/rnn_nas.pyc'\n",
            "'maskgan/models/seq2seq_zaremba.pyc' -> '/content/gdrive/My Drive/maskgan/models/seq2seq_zaremba.pyc'\n",
            "'maskgan/models/rollout.pyc' -> '/content/gdrive/My Drive/maskgan/models/rollout.pyc'\n",
            "'maskgan/models/rnn_vd.pyc' -> '/content/gdrive/My Drive/maskgan/models/rnn_vd.pyc'\n",
            "'maskgan/models/critic_vd.pyc' -> '/content/gdrive/My Drive/maskgan/models/critic_vd.pyc'\n",
            "'maskgan/models/feedforward.pyc' -> '/content/gdrive/My Drive/maskgan/models/feedforward.pyc'\n",
            "'maskgan/regularization' -> '/content/gdrive/My Drive/maskgan/regularization'\n",
            "'maskgan/regularization/variational_dropout.py' -> '/content/gdrive/My Drive/maskgan/regularization/variational_dropout.py'\n",
            "'maskgan/regularization/zoneout.py' -> '/content/gdrive/My Drive/maskgan/regularization/zoneout.py'\n",
            "'maskgan/regularization/__init__.py' -> '/content/gdrive/My Drive/maskgan/regularization/__init__.py'\n",
            "'maskgan/regularization/zoneout.pyc' -> '/content/gdrive/My Drive/maskgan/regularization/zoneout.pyc'\n",
            "'maskgan/regularization/__init__.pyc' -> '/content/gdrive/My Drive/maskgan/regularization/__init__.pyc'\n",
            "'maskgan/regularization/variational_dropout.pyc' -> '/content/gdrive/My Drive/maskgan/regularization/variational_dropout.pyc'\n",
            "'maskgan/losses' -> '/content/gdrive/My Drive/maskgan/losses'\n",
            "'maskgan/losses/losses.py' -> '/content/gdrive/My Drive/maskgan/losses/losses.py'\n",
            "'maskgan/losses/__init__.py' -> '/content/gdrive/My Drive/maskgan/losses/__init__.py'\n",
            "'maskgan/losses/losses.pyc' -> '/content/gdrive/My Drive/maskgan/losses/losses.pyc'\n",
            "'maskgan/losses/__init__.pyc' -> '/content/gdrive/My Drive/maskgan/losses/__init__.pyc'\n",
            "'maskgan/train_mask_gan.py' -> '/content/gdrive/My Drive/maskgan/train_mask_gan.py'\n",
            "'maskgan/model_utils' -> '/content/gdrive/My Drive/maskgan/model_utils'\n",
            "'maskgan/model_utils/model_losses.py' -> '/content/gdrive/My Drive/maskgan/model_utils/model_losses.py'\n",
            "'maskgan/model_utils/variable_mapping.py' -> '/content/gdrive/My Drive/maskgan/model_utils/variable_mapping.py'\n",
            "'maskgan/model_utils/model_optimization.py' -> '/content/gdrive/My Drive/maskgan/model_utils/model_optimization.py'\n",
            "'maskgan/model_utils/model_utils.py' -> '/content/gdrive/My Drive/maskgan/model_utils/model_utils.py'\n",
            "'maskgan/model_utils/helper.py' -> '/content/gdrive/My Drive/maskgan/model_utils/helper.py'\n",
            "'maskgan/model_utils/__init__.py' -> '/content/gdrive/My Drive/maskgan/model_utils/__init__.py'\n",
            "'maskgan/model_utils/n_gram.py' -> '/content/gdrive/My Drive/maskgan/model_utils/n_gram.py'\n",
            "'maskgan/model_utils/variable_mapping.pyc' -> '/content/gdrive/My Drive/maskgan/model_utils/variable_mapping.pyc'\n",
            "'maskgan/model_utils/n_gram.pyc' -> '/content/gdrive/My Drive/maskgan/model_utils/n_gram.pyc'\n",
            "'maskgan/model_utils/model_utils.pyc' -> '/content/gdrive/My Drive/maskgan/model_utils/model_utils.pyc'\n",
            "'maskgan/model_utils/helper.pyc' -> '/content/gdrive/My Drive/maskgan/model_utils/helper.pyc'\n",
            "'maskgan/model_utils/__init__.pyc' -> '/content/gdrive/My Drive/maskgan/model_utils/__init__.pyc'\n",
            "'maskgan/model_utils/model_losses.pyc' -> '/content/gdrive/My Drive/maskgan/model_utils/model_losses.pyc'\n",
            "'maskgan/model_utils/model_optimization.pyc' -> '/content/gdrive/My Drive/maskgan/model_utils/model_optimization.pyc'\n",
            "'maskgan/model_utils/model_construction.py' -> '/content/gdrive/My Drive/maskgan/model_utils/model_construction.py'\n",
            "'maskgan/model_utils/model_construction.pyc' -> '/content/gdrive/My Drive/maskgan/model_utils/model_construction.pyc'\n",
            "'maskgan/train_mask_gan.pyc' -> '/content/gdrive/My Drive/maskgan/train_mask_gan.pyc'\n",
            "'maskgan/generate_samples.py' -> '/content/gdrive/My Drive/maskgan/generate_samples.py'\n",
            "'maskgan/maskGAN' -> '/content/gdrive/My Drive/maskgan/maskGAN'\n",
            "'maskgan/maskGAN/.ipynb_checkpoints' -> '/content/gdrive/My Drive/maskgan/maskGAN/.ipynb_checkpoints'\n",
            "'maskgan/maskGAN/train-log.txt' -> '/content/gdrive/My Drive/maskgan/maskGAN/train-log.txt'\n",
            "'maskgan/maskGAN/maskGAN_mle' -> '/content/gdrive/My Drive/maskgan/maskGAN/maskGAN_mle'\n",
            "'maskgan/maskGAN/maskGAN_mle/train-log.txt' -> '/content/gdrive/My Drive/maskgan/maskGAN/maskGAN_mle/train-log.txt'\n",
            "'maskgan/maskGAN/maskGAN_mle/train' -> '/content/gdrive/My Drive/maskgan/maskGAN/maskGAN_mle/train'\n",
            "'maskgan/maskGAN/maskGAN_mle/train/.ipynb_checkpoints' -> '/content/gdrive/My Drive/maskgan/maskGAN/maskGAN_mle/train/.ipynb_checkpoints'\n",
            "'maskgan/maskGAN/maskGAN_mle/train/checkpoint' -> '/content/gdrive/My Drive/maskgan/maskGAN/maskGAN_mle/train/checkpoint'\n",
            "'maskgan/maskGAN/maskGAN_mle/train/model.ckpt-906.index' -> '/content/gdrive/My Drive/maskgan/maskGAN/maskGAN_mle/train/model.ckpt-906.index'\n",
            "'maskgan/maskGAN/maskGAN_mle/train/model.ckpt-906.data-00000-of-00001' -> '/content/gdrive/My Drive/maskgan/maskGAN/maskGAN_mle/train/model.ckpt-906.data-00000-of-00001'\n",
            "'maskgan/maskGAN/maskGAN_mle/train/model.ckpt-906.meta' -> '/content/gdrive/My Drive/maskgan/maskGAN/maskGAN_mle/train/model.ckpt-906.meta'\n",
            "'maskgan/maskGAN/train' -> '/content/gdrive/My Drive/maskgan/maskGAN/train'\n",
            "'maskgan/maskGAN/train/.ipynb_checkpoints' -> '/content/gdrive/My Drive/maskgan/maskGAN/train/.ipynb_checkpoints'\n",
            "'maskgan/maskGAN/train/graph.pbtxt' -> '/content/gdrive/My Drive/maskgan/maskGAN/train/graph.pbtxt'\n",
            "'maskgan/maskGAN/train/model.ckpt-1059.index' -> '/content/gdrive/My Drive/maskgan/maskGAN/train/model.ckpt-1059.index'\n",
            "'maskgan/maskGAN/train/model.ckpt-1059.data-00000-of-00001' -> '/content/gdrive/My Drive/maskgan/maskGAN/train/model.ckpt-1059.data-00000-of-00001'\n",
            "'maskgan/maskGAN/train/checkpoint' -> '/content/gdrive/My Drive/maskgan/maskGAN/train/checkpoint'\n",
            "'maskgan/maskGAN/train/model.ckpt-1059.meta' -> '/content/gdrive/My Drive/maskgan/maskGAN/train/model.ckpt-1059.meta'\n",
            "'maskgan/maskGANj_working.ipynb' -> '/content/gdrive/My Drive/maskgan/maskGANj_working.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fV7rJwxZ0Xa",
        "colab_type": "code",
        "outputId": "6b8d2052-fc97-4b59-b923-1b5f40e55c1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# copy from drive into runtime\n",
        "%cd /content/gdrive/My\\ Drive\n",
        "%cp -r maskgan /content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXXGgoq0aZo8",
        "colab_type": "code",
        "outputId": "a89c677f-572e-46da-9978-e07b0e2b7edb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/maskgan/maskGAN/train\n",
        "from google.colab import files\n",
        "files.download('model.ckpt-1542.data-00000-of-00001') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/maskgan/maskGAN/train\n",
            "----------------------------------------\n",
            "Exception happened during processing of request from ('::ffff:127.0.0.1', 35792, 0, 0)\n",
            "----------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python2.7/SocketServer.py\", line 293, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python2.7/SocketServer.py\", line 321, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python2.7/SocketServer.py\", line 334, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python2.7/SocketServer.py\", line 657, in __init__\n",
            "    self.finish()\n",
            "  File \"/usr/lib/python2.7/SocketServer.py\", line 716, in finish\n",
            "    self.wfile.close()\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 283, in close\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python2.7/socket.py\", line 307, in flush\n",
            "    self._sock.sendall(view[write_offset:write_offset+buffer_size])\n",
            "error: [Errno 32] Broken pipe\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AcystW6oRMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJLAY-ot-rAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcqrMZ7W-uEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dMi-HZO_Leb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}