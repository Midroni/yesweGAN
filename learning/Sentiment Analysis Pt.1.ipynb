{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Sentiment Analysis\n",
    "[Original article here](https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184)\n",
    "[Data from here](https://github.com/aaronkub/machine-learning-examples/blob/master/imdb-sentiment-analysis/movie_data.tar.gz)\n",
    "\n",
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #I like to live dangerously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = []\n",
    "for line in open ('../../../data/movie_data/full_train.txt','r'):\n",
    "    reviews_train.append(line.strip())\n",
    "    \n",
    "reviews_test = []\n",
    "for line in open ('../../../data/movie_data/full_test.txt','r'):\n",
    "    reviews_test.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Preprocess\n",
    "We will now use Regex (REGular EXpression) functions in Python to do our cleaning. Being comfortable with Regex is an absolute must for text mining. \n",
    "\n",
    "The `re.compile()` method is given a regular expression pattern (the crazy sequence of characters) which is used for pattern matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#REPLACE_NO_SPACE pattern matches for the characters within it (mostly punctuation)\n",
    "#and replaces them with no space\n",
    "REPLACE_NO_SPACE = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
    "\n",
    "#REPLACE_WITH_SPACE pattern matches for all the characters within it\n",
    "#and replaces them with a space\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to do some pattern matching of your own and connect what is being placed as an input to `re.compile()` to what is being removed from the strings below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hello to you too!\n"
     ]
    }
   ],
   "source": [
    "print(REPLACE_NO_SPACE.sub(\"\",\"!!?'H()el?l?o!\"))\n",
    "print(REPLACE_WITH_SPACE.sub(\" \",'Hello-to/you<br /><br />too!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_reviews(reviews):\n",
    "    #line.lower() is turning each line in reviews into all lower case\n",
    "    \n",
    "    if isinstance(reviews,str):\n",
    "        reviews = [reviews] #if it's not a list, wrap it in a list so we can use the code below\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\",line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \",line) for line in reviews]\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will preprocess our text such that we have removed the punctuation and unwanted HTML artifacts.\n",
    "\n",
    "Let's see an example of this preprocessing technique at work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph without preprocessing\n",
      "\n",
      "Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n"
     ]
    }
   ],
   "source": [
    "print('Paragraph without preprocessing\\n')\n",
    "print(reviews_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph with preprocessing\n",
      "\n",
      "['bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell highs satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled  at  high a classic line inspector im here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isnt']\n"
     ]
    }
   ],
   "source": [
    "print('Paragraph with preprocessing\\n')\n",
    "print(preprocess_reviews(reviews_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, any 'noisy' text that we would want to remove has been removed. As well, we have also changed it to all lower case and gotten rid of punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess_reviews(reviews_train)\n",
    "test = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "We will now need to convert each review to a numeric representation, which as we know is the process of vectorization.\n",
    "\n",
    "We know that there are other steps we can perform before vectorization (normalization and lemmatization) to make our corpus better, but let's naively move forward and perhaps witness the benefits of these effects later on.\n",
    "\n",
    "Here, we will pass in: \n",
    "```python\n",
    "binary=True\n",
    "```\n",
    "which will return a very large matrix with **one column for each unique word** in the corpus and **one row for each review**. In our case, the corpus contains 50K reviews, and a 1 in row will indicate the presence of that word in that review. This is the process known as **one hot encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(train)\n",
    "X = cv.transform(train)\n",
    "X_test = cv.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classifier\n",
    "\n",
    "Now that our dataset is in a format suitable for modeling we can start building a classifier. We can use **Logistic Regression** as a good baseline model as they are easy to interpret and linear models tend to work well on sparse datasets like this one. As well, they learn very fast which will lend itself well to the large binary matrices we just created.\n",
    "\n",
    "**Note**: the targets/labels will be the same for the train and test sets as both datasets are structured the same. The first 12.5K are positive reviews and the last 12.5K are negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,target,train_size=0.75)\n",
    "#we will include 75% of our data in the train set and 25% in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.87152\n",
      "Accuracy for C=0.05: 0.88384\n",
      "Accuracy for C=0.025: 0.88016\n",
      "Accuracy for C=0.5: 0.87632\n",
      "Accuracy for C=1: 0.8744\n"
     ]
    }
   ],
   "source": [
    "#quick HP sweep\n",
    "for c in [0.01, 0.05, 0.025, 0.5, 1]:\n",
    "    lr = LogisticRegression(C=c) #C is the inverse of regularization strength\n",
    "    lr.fit(X_train,y_train)\n",
    "    \n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That the value of C which gives the highest accuracy is 0.5\n",
    "\n",
    "## Train Final Model\n",
    "We can now train a model with the entire training set and evaluat eon the test set we've reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.88152\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.05)\n",
    "final_model.fit(X, target)\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % accuracy_score(target, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "Above we've chosen to move quickly to the modeling stage for some basic results rather than dive into the nitty gritty of improving our accuracy. Let's do a post-mortem analysis here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we make a dictionary with the key being the word and the corresponding \n",
    "#value being the coefficient for that variable in the linear model\n",
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(cv.get_feature_names(),final_model.coef_[0])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets sort through and look at the 5 most discriminating words for both positive and negative reviews. These would correspond to the largest and smallest coefficients respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 0.9292549121503528)\n",
      "('perfect', 0.7907005783795896)\n",
      "('great', 0.67453235464691)\n",
      "('amazing', 0.6127039931007847)\n",
      "('superb', 0.6019368001642376)\n"
     ]
    }
   ],
   "source": [
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:5]:\n",
    "    print (best_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('worst', -1.3645958972261922)\n",
      "('waste', -1.1664242065789645)\n",
      "('awful', -1.0324189439735652)\n",
      "('poorly', -0.8752018765502437)\n",
      "('boring', -0.8563543421846104)\n"
     ]
    }
   ],
   "source": [
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:5]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's nice to see that the model has achieved a strong grasp of the association of these words to negative and positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
